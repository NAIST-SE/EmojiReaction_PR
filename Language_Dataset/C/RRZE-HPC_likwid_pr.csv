RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,29,2016-02-05T16:27:17Z,2016-02-05T18:57:04Z,2016-02-05T18:57:04Z,MERGED,True,1,1,1,https://github.com/rrzefox,remove erroneous dollar sign,1,[],https://github.com/RRZE-HPC/likwid/pull/29,https://github.com/rrzefox,1,https://github.com/RRZE-HPC/likwid/pull/29,remove erroneous dollar sign,remove erroneous dollar sign,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,40,2016-06-20T08:44:42Z,2016-06-20T08:47:19Z,2016-06-20T08:47:20Z,MERGED,True,1,1,1,https://github.com/rschoene,"Fix for likwid-powermeter, which uses the wrong RAPL domain when requesting energy",2,[],https://github.com/RRZE-HPC/likwid/pull/40,https://github.com/rschoene,1,https://github.com/RRZE-HPC/likwid/pull/40,"Simple fix, just pass the correct domain, not zero.","Simple fix, just pass the correct domain, not zero.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,40,2016-06-20T08:44:42Z,2016-06-20T08:47:19Z,2016-06-20T08:47:20Z,MERGED,True,1,1,1,https://github.com/rschoene,"Fix for likwid-powermeter, which uses the wrong RAPL domain when requesting energy",2,[],https://github.com/RRZE-HPC/likwid/pull/40,https://github.com/TomTheBear,2,https://github.com/RRZE-HPC/likwid/pull/40#issuecomment-227083963,"Simple fix, just pass the correct domain, not zero.",Thanks for the fix. I just read the power related code after your issue and didn't find this one. Thanks.,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,42,2016-06-22T12:07:19Z,2016-07-07T10:57:46Z,2016-07-07T10:57:46Z,MERGED,True,39,41,15,https://github.com/gueraf,API: Declare parameters const where applicable,3,[],https://github.com/RRZE-HPC/likwid/pull/42,https://github.com/gueraf,1,https://github.com/RRZE-HPC/likwid/pull/42,see #41,see #41,True,{'HEART': ['https://github.com/bryonglodencissp']}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,42,2016-06-22T12:07:19Z,2016-07-07T10:57:46Z,2016-07-07T10:57:46Z,MERGED,True,39,41,15,https://github.com/gueraf,API: Declare parameters const where applicable,3,[],https://github.com/RRZE-HPC/likwid/pull/42,https://github.com/TomTheBear,2,https://github.com/RRZE-HPC/likwid/pull/42#issuecomment-229329162,see #41,"Hi,
Thanks for the PR. I only had time for a quick check and I cannot see any problematic changes. Have you checked all the functions or only the obvious ones (properly documented in Doxygen)?
For your todos, the first one is a documentation error, it must be [in,out] and the second is a noop, I have to change these two lines. But I'll wait until we merged this PR.
As soon as I have time, I check your PR in detail and hopefully merge it.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,42,2016-06-22T12:07:19Z,2016-07-07T10:57:46Z,2016-07-07T10:57:46Z,MERGED,True,39,41,15,https://github.com/gueraf,API: Declare parameters const where applicable,3,[],https://github.com/RRZE-HPC/likwid/pull/42,https://github.com/gueraf,3,https://github.com/RRZE-HPC/likwid/pull/42#issuecomment-229334591,see #41,"Hi,
thanks for reviewing the PR.
I only considered the methods declared in the header likwid.h and propagated changes to implementations if necessary; I think that all functions in likwid.h have Doxygen annotations.
If it helps I can go through the implementation of the internal methods in a separate PR and try to change the obvious ones, but I don't think that this adds any real benefit for users of the library.
I will fix the documentation todo tomorrow right now and add the change to this PR. Do you want me to also remove the noop statements or should I leave the todo in place?
Cheers,
Fabian",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,42,2016-06-22T12:07:19Z,2016-07-07T10:57:46Z,2016-07-07T10:57:46Z,MERGED,True,39,41,15,https://github.com/gueraf,API: Declare parameters const where applicable,3,[],https://github.com/RRZE-HPC/likwid/pull/42,https://github.com/TomTheBear,4,https://github.com/RRZE-HPC/likwid/pull/42#issuecomment-229338099,see #41,"Hi,
I'm pretty sure that all function definitions in likwid.h have annotations, I'm not really motivated to document everything, but I forced myself for the likwid.h.
I don't think that we need the const internally. Especially as const function parameters are only used for error checking, no optimizations can be performed by the compiler.
You can remove the noop statements in your PR, that way I don't forget it afterwards. Thanks
Greetings,
Thomas",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,42,2016-06-22T12:07:19Z,2016-07-07T10:57:46Z,2016-07-07T10:57:46Z,MERGED,True,39,41,15,https://github.com/gueraf,API: Declare parameters const where applicable,3,[],https://github.com/RRZE-HPC/likwid/pull/42,https://github.com/gueraf,5,https://github.com/RRZE-HPC/likwid/pull/42#issuecomment-229339358,see #41,Done.,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,42,2016-06-22T12:07:19Z,2016-07-07T10:57:46Z,2016-07-07T10:57:46Z,MERGED,True,39,41,15,https://github.com/gueraf,API: Declare parameters const where applicable,3,[],https://github.com/RRZE-HPC/likwid/pull/42,https://github.com/TomTheBear,6,https://github.com/RRZE-HPC/likwid/pull/42#issuecomment-231046945,see #41,I checked your pull request again and it looks fine. I merge it into the master branch. Thank you.,True,{'THUMBS_UP': ['https://github.com/gueraf']}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,51,2016-08-31T00:55:46Z,2016-08-31T10:20:34Z,2016-08-31T12:03:30Z,MERGED,True,72,96,4,https://github.com/K-Wic,Fixed the incorrectly named events in the PORT_USAGE group on sandy/ivybridge,1,[],https://github.com/RRZE-HPC/likwid/pull/51,https://github.com/K-Wic,1,https://github.com/RRZE-HPC/likwid/pull/51,Change the UOPS_EXECUTED_PORT in the PORT_USAGE group to UOPS_DISPATCHED_PORT for sandybridge and ivybridge. Also limited the number of ports to the available six.,Change the UOPS_EXECUTED_PORT in the PORT_USAGE group to UOPS_DISPATCHED_PORT for sandybridge and ivybridge. Also limited the number of ports to the available six.,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,51,2016-08-31T00:55:46Z,2016-08-31T10:20:34Z,2016-08-31T12:03:30Z,MERGED,True,72,96,4,https://github.com/K-Wic,Fixed the incorrectly named events in the PORT_USAGE group on sandy/ivybridge,1,[],https://github.com/RRZE-HPC/likwid/pull/51,https://github.com/TomTheBear,2,https://github.com/RRZE-HPC/likwid/pull/51#issuecomment-243722110,Change the UOPS_EXECUTED_PORT in the PORT_USAGE group to UOPS_DISPATCHED_PORT for sandybridge and ivybridge. Also limited the number of ports to the available six.,Thanks for the correction.,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,52,2016-08-31T01:19:02Z,2016-08-31T10:52:54Z,2016-08-31T12:15:16Z,CLOSED,False,9,4,2,https://github.com/K-Wic,Turning on the debug build now also disables optimizations for GCC.,1,[],https://github.com/RRZE-HPC/likwid/pull/52,https://github.com/K-Wic,1,https://github.com/RRZE-HPC/likwid/pull/52,"Not using -O0 is a real pita when trying to debug things with gdb.
Unfortunately this step also requires uninlining two functions, which are optimized away in the release build, but cause linker problems when left in.","Not using -O0 is a real pita when trying to debug things with gdb.
Unfortunately this step also requires uninlining two functions, which are optimized away in the release build, but cause linker problems when left in.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,52,2016-08-31T01:19:02Z,2016-08-31T10:52:54Z,2016-08-31T12:15:16Z,CLOSED,False,9,4,2,https://github.com/K-Wic,Turning on the debug build now also disables optimizations for GCC.,1,[],https://github.com/RRZE-HPC/likwid/pull/52,https://github.com/TomTheBear,2,https://github.com/RRZE-HPC/likwid/pull/52#issuecomment-243728583,"Not using -O0 is a real pita when trying to debug things with gdb.
Unfortunately this step also requires uninlining two functions, which are optimized away in the release build, but cause linker problems when left in.","Hi, thanks for the PR. I always debugged with -O2 and it was suitable for my needs. I won't merge your PR because I don't want to have general changes in the compiler-specific files. I added it to config_defines.mk where the -g flag is added to CFLAGS when DEBUG is set to true. The inlines are also removed from the two functions in calculator.c",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,67,2016-11-03T14:17:07Z,2019-11-09T17:31:57Z,2019-11-09T17:31:57Z,CLOSED,False,7073,94,100,https://github.com/TomTheBear,LIKWID support for POWER8 processors.,12,[],https://github.com/RRZE-HPC/likwid/pull/67,https://github.com/TomTheBear,1,https://github.com/RRZE-HPC/likwid/pull/67,This version of LIKWID supports IBM POWER8 processors. Thanks to the IBM Labs @ Boeblingen for their support.,This version of LIKWID supports IBM POWER8 processors. Thanks to the IBM Labs @ Boeblingen for their support.,True,"{'THUMBS_UP': ['https://github.com/psteinb', 'https://github.com/grisuthedragon', 'https://github.com/csbnw', 'https://github.com/kadircs']}"
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,67,2016-11-03T14:17:07Z,2019-11-09T17:31:57Z,2019-11-09T17:31:57Z,CLOSED,False,7073,94,100,https://github.com/TomTheBear,LIKWID support for POWER8 processors.,12,[],https://github.com/RRZE-HPC/likwid/pull/67,https://github.com/TomTheBear,2,https://github.com/RRZE-HPC/likwid/pull/67#issuecomment-479561653,This version of LIKWID supports IBM POWER8 processors. Thanks to the IBM Labs @ Boeblingen for their support.,"This PR is outdated. It uses a native backend to access the performance registers. On the one hand LIKWID can do everything itself with less overhead but on the other hand you have to load a kernel module which enables the user-level access to the registers.
Therefore, I added another PR (#217) which includes POWER8 and POWER9 and uses perf_event as backend. It's not 100% stable but I'm working on it.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,67,2016-11-03T14:17:07Z,2019-11-09T17:31:57Z,2019-11-09T17:31:57Z,CLOSED,False,7073,94,100,https://github.com/TomTheBear,LIKWID support for POWER8 processors.,12,[],https://github.com/RRZE-HPC/likwid/pull/67,https://github.com/TomTheBear,3,https://github.com/RRZE-HPC/likwid/pull/67#issuecomment-552120593,This version of LIKWID supports IBM POWER8 processors. Thanks to the IBM Labs @ Boeblingen for their support.,I close this PR. The support for POWER8 and POWER9 was merged into master from PR  #217 .,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,68,2016-11-11T00:40:19Z,2016-11-11T09:13:25Z,2016-11-11T09:13:25Z,MERGED,True,4,4,4,https://github.com/K-Wic,Fix event options,4,[],https://github.com/RRZE-HPC/likwid/pull/68,https://github.com/K-Wic,1,https://github.com/RRZE-HPC/likwid/pull/68,Fixed several EVENT_OPTIONS that did not match their corresponding events.,Fixed several EVENT_OPTIONS that did not match their corresponding events.,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,68,2016-11-11T00:40:19Z,2016-11-11T09:13:25Z,2016-11-11T09:13:25Z,MERGED,True,4,4,4,https://github.com/K-Wic,Fix event options,4,[],https://github.com/RRZE-HPC/likwid/pull/68,https://github.com/TomTheBear,2,https://github.com/RRZE-HPC/likwid/pull/68#issuecomment-259914344,Fixed several EVENT_OPTIONS that did not match their corresponding events.,Thanks for fixing the groups and event options.,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,72,2016-12-12T11:08:20Z,2016-12-16T11:08:23Z,2016-12-16T11:08:23Z,MERGED,True,47,13,4,https://github.com/davydden,allow external lua,1,[],https://github.com/RRZE-HPC/likwid/pull/72,https://github.com/davydden,1,https://github.com/RRZE-HPC/likwid/pull/72,"WIP, but internal lua seems to build for me on Ubuntu 16.04, so this part should be fine.
p.s. adding support of external libs in makefile-only packages is a grand royal PITA 😄 I have not tested it mostly because lua i have around is a static lib with, presumably, -fPIC flags. So it should be fine to use it in shared libraries, but I seriously don't know what else/how needs to be changed to support this usage case.","WIP, but internal lua seems to build for me on Ubuntu 16.04, so this part should be fine.
p.s. adding support of external libs in makefile-only packages is a grand royal PITA 😄 I have not tested it mostly because lua i have around is a static lib with, presumably, -fPIC flags. So it should be fine to use it in shared libraries, but I seriously don't know what else/how needs to be changed to support this usage case.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,72,2016-12-12T11:08:20Z,2016-12-16T11:08:23Z,2016-12-16T11:08:23Z,MERGED,True,47,13,4,https://github.com/davydden,allow external lua,1,[],https://github.com/RRZE-HPC/likwid/pull/72,https://github.com/davydden,2,https://github.com/RRZE-HPC/likwid/pull/72#issuecomment-266979334,"WIP, but internal lua seems to build for me on Ubuntu 16.04, so this part should be fine.
p.s. adding support of external libs in makefile-only packages is a grand royal PITA 😄 I have not tested it mostly because lua i have around is a static lib with, presumably, -fPIC flags. So it should be fine to use it in shared libraries, but I seriously don't know what else/how needs to be changed to support this usage case.","it's getting somewhere, with
LUA_INCLUDE_DIR = /usr/include/lua5.2/#NO SPACE
LUA_LIB_DIR = /usr/lib/x86_64-linux-gnu/#NO SPACE
LUA_LIB_NAME = lua5.2#NO SPACE

it links as expected against
$ ldd liblikwid.so 
	linux-vdso.so.1 =>  (0x00007ffe6a5f4000)
	libm.so.6 => /lib/x86_64-linux-gnu/libm.so.6 (0x00007f8f37ded000)
	librt.so.1 => /lib/x86_64-linux-gnu/librt.so.1 (0x00007f8f37be5000)
	liblua5.2.so.0 => /usr/lib/x86_64-linux-gnu/liblua5.2.so.0 (0x00007f8f379b2000)
	liblikwid-hwloc.so.4.1 => not found
	libpthread.so.0 => /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007f8f37795000)
	libc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007f8f373cb000)
	/lib64/ld-linux-x86-64.so.2 (0x000056185e42a000)
	libdl.so.2 => /lib/x86_64-linux-gnu/libdl.so.2 (0x00007f8f371c7000)

whereas with internal lua we have:
$ ldd liblikwid.so 
	linux-vdso.so.1 =>  (0x00007ffc9c383000)
	libm.so.6 => /lib/x86_64-linux-gnu/libm.so.6 (0x00007fecb5934000)
	librt.so.1 => /lib/x86_64-linux-gnu/librt.so.1 (0x00007fecb572c000)
	liblikwid-hwloc.so.4.1 => not found
	liblikwid-lua.so.4.1 => not found
	libpthread.so.0 => /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007fecb550e000)
	libc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007fecb5144000)
	/lib64/ld-linux-x86-64.so.2 (0x000056094de3f000)

@TomTheBear there are still some things failing on Travis, I would appreciate if you could have a look and advise on how to fix the remaining issues.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,72,2016-12-12T11:08:20Z,2016-12-16T11:08:23Z,2016-12-16T11:08:23Z,MERGED,True,47,13,4,https://github.com/davydden,allow external lua,1,[],https://github.com/RRZE-HPC/likwid/pull/72,https://github.com/davydden,3,https://github.com/RRZE-HPC/likwid/pull/72#issuecomment-266990354,"WIP, but internal lua seems to build for me on Ubuntu 16.04, so this part should be fine.
p.s. adding support of external libs in makefile-only packages is a grand royal PITA 😄 I have not tested it mostly because lua i have around is a static lib with, presumably, -fPIC flags. So it should be fine to use it in shared libraries, but I seriously don't know what else/how needs to be changed to support this usage case.","@TomTheBear failures are
/home/travis/build.sh: /usr/local/bin/likwid-pin: /usr/local/bin/likwid-lua: bad interpreter: No such file or directory
/home/travis/build.sh: /usr/local/bin/likwid-perfctr: /usr/local/bin/likwid-lua: bad interpreter: No such file or directory
/usr/local/bin/likwid-bench: error while loading shared libraries: liblikwid-lua.so.4.1: cannot open shared object file: No such file or directory

but i don't quite see why this happens...",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,72,2016-12-12T11:08:20Z,2016-12-16T11:08:23Z,2016-12-16T11:08:23Z,MERGED,True,47,13,4,https://github.com/davydden,allow external lua,1,[],https://github.com/RRZE-HPC/likwid/pull/72,https://github.com/TomTheBear,4,https://github.com/RRZE-HPC/likwid/pull/72#issuecomment-267026638,"WIP, but internal lua seems to build for me on Ubuntu 16.04, so this part should be fine.
p.s. adding support of external libs in makefile-only packages is a grand royal PITA 😄 I have not tested it mostly because lua i have around is a static lib with, presumably, -fPIC flags. So it should be fine to use it in shared libraries, but I seriously don't know what else/how needs to be changed to support this usage case.","Hi,
I think there was a failure in your sed commands. I got it running with Lua 5.1. I committed a patch to the master branch, so that the Lua interface is ready to be used with Lua 5.1 to 5.3
My other changes:
$ git diff make/config_defines.mk
diff --git a/make/config_defines.mk b/make/config_defines.mk
index 7a95106..fae3f87 100644
--- a/make/config_defines.mk
+++ b/make/config_defines.mk
@@ -11,13 +11,15 @@ DEFINES   += -DVERSION=$(VERSION)         \
                 -DLIKWIDSOCKETBASE=$(LIKWIDSOCKETBASE) \
                 -D_GNU_SOURCE
 
+CWD := $(PWD)
+CWD ?= .
 DYNAMIC_TARGET_LIB := liblikwid.so
 STATIC_TARGET_LIB := liblikwid.a
 # LUA:
 ifdef LUA_INCLUDE_DIR
 LUA_INTERNAL := false#NO SPACE
 else
-LUA_FOLDER := $(PWD)/ext/lua#NO SPACE
+LUA_FOLDER := ext/lua#NO SPACE
 LUA_INCLUDE_DIR := $(LUA_FOLDER)/includes#NO SPACE
 LUA_LIB_DIR := $(LUA_FOLDER)#NO SPACE
 LUA_LIB_NAME := likwid-lua#NO SPACE
@@ -67,19 +69,11 @@ CFLAGS += $(SHARED_CFLAGS)
 LIBS += -L. -pthread -lm -ldl
 TARGET_LIB := $(DYNAMIC_TARGET_LIB)
 TARGET_HWLOC_LIB=$(HWLOC_FOLDER)/$(SHARED_LIBHWLOC)
-ifeq ($(LUA_INTERNAL),true)
 TARGET_LUA_LIB=$(LUA_LIB_DIR)/$(SHARED_LIBLUA)
 else
-TARGET_LUA_LIB=
-endif
-else
 TARGET_LIB := $(STATIC_TARGET_LIB)
 TARGET_HWLOC_LIB=$(HWLOC_FOLDER)/$(STATIC_LIBHWLOC)
-ifeq ($(LUA_INTERNAL),true)
 TARGET_LUA_LIB=$(LUA_LIB_DIR)/$(STATIC_LIBLUA)
-else
-TARGET_LUA_LIB=
-endif
 endif
 
 ifeq ($(HAS_SCHEDAFFINITY),1)

and
$ git diff Makefile
diff --git a/Makefile b/Makefile
index 5df35db..2002209 100644
--- a/Makefile
+++ b/Makefile
@@ -113,14 +113,14 @@ docs:
 $(L_APPS):  $(addprefix $(SRC_DIR)/applications/,$(addsuffix  .lua,$(L_APPS)))
        @echo ""===>  ADJUSTING  $@""
        @if [ ""$(ACCESSMODE)"" = ""direct"" ]; then sed -i -e s/""access_mode = 1""/""access_mode = 0""/g $(SRC_DIR)/applications/$@.lua;fi
-       @if [ ""$(LUA_INTERNAL)"" = ""false""]; then \
-               @sed -e s/'<INSTALLED_BINPREFIX>'\\/likwid-lua/$(subst /,\\/,$(INSTALLED_BINPREFIX))\\/$(LUA_LIB_NAME)/g; \
-       fi
        @sed -e s/'<INSTALLED_BINPREFIX>'/$(subst /,\\/,$(INSTALLED_BINPREFIX))/g \
                -e s/'<INSTALLED_PREFIX>'/$(subst /,\\/,$(INSTALLED_PREFIX))/g \
                -e s/'<VERSION>'/$(VERSION).$(RELEASE)/g \
                -e s/'<DATE>'/$(DATE)/g \
                $(addprefix $(SRC_DIR)/applications/,$(addsuffix  .lua,$@)) > $@
+       @if [ ""$(LUA_INTERNAL)"" = ""false"" ]; then \
+               sed -i -e s+""$(subst /,\\/,$(INSTALLED_BINPREFIX))/likwid-lua""+""/usr/bin/$(LUA_LIB_NAME)""+ $@; \
+       fi
        @if [ ""$(ACCESSMODE)"" = ""direct"" ]; then sed -i -e s/""access_mode = 0""/""access_mode = 1""/g $(SRC_DIR)/applications/$@.lua;fi
 
 $(L_HELPER):
@@ -327,8 +327,8 @@ install: install_daemon install_freq
        @for APP in $(C_APPS); do \
                install -m 755 $$APP  $(BINPREFIX); \
        done
-       @if [ ""$(LUA_INTERNAL)"" = ""true""]; then \
-               @install -m 755 ext/lua/lua $(BINPREFIX)/$(LUA_LIB_NAME); \
+       @if [ ""$(LUA_INTERNAL)"" = ""true"" ]; then \
+               install -m 755 ext/lua/lua $(BINPREFIX)/$(LUA_LIB_NAME); \
        fi
        @echo ""===> INSTALL helper applications to $(BINPREFIX)""
        @install -m 755 perl/feedGnuplot $(BINPREFIX)
@@ -342,8 +342,8 @@ install: install_daemon install_freq
        @install -m 755 $(TARGET_LIB) $(LIBPREFIX)/$(TARGET_LIB).$(VERSION).$(RELEASE)
        @install -m 755 liblikwidpin.so $(LIBPREFIX)/liblikwidpin.so.$(VERSION).$(RELEASE)
        @install -m 755 $(TARGET_HWLOC_LIB) $(LIBPREFIX)/$(shell basename $(TARGET_HWLOC_LIB)).$(VERSION).$(RELEASE)
-       @if [ ""$(LUA_INTERNAL)"" = ""true""]; then \
-               @install -m 755 $(TARGET_LUA_LIB) $(LIBPREFIX)/$(shell basename $(TARGET_LUA_LIB)).$(VERSION).$(RELEASE); \
+       @if [ ""$(LUA_INTERNAL)"" = ""true"" ]; then \
+               install -m 755 $(TARGET_LUA_LIB) $(LIBPREFIX)/$(shell basename $(TARGET_LUA_LIB)).$(VERSION).$(RELEASE); \
        fi
        @cd $(LIBPREFIX) && ln -fs $(TARGET_LIB).$(VERSION).$(RELEASE) $(TARGET_LIB)
        @cd $(LIBPREFIX) && ln -fs $(TARGET_LIB).$(VERSION).$(RELEASE) $(TARGET_LIB).$(VERSION)
@@ -351,9 +351,9 @@ install: install_daemon install_freq
        @cd $(LIBPREFIX) && ln -fs $(PINLIB).$(VERSION).$(RELEASE) $(PINLIB).$(VERSION)
        @cd $(LIBPREFIX) && ln -fs $(shell basename $(TARGET_HWLOC_LIB)).$(VERSION).$(RELEASE) $(shell basename $(TARGET_HWLOC_LIB))
        @cd $(LIBPREFIX) && ln -fs $(shell basename $(TARGET_HWLOC_LIB)).$(VERSION).$(RELEASE) $(shell basename $(TARGET_HWLOC_LIB)).$(VERSION)
-       @if [ ""$(LUA_INTERNAL)"" = ""true""]; then \
-               @cd $(LIBPREFIX) && ln -fs $(shell basename $(TARGET_LUA_LIB)).$(VERSION).$(RELEASE) $(shell basename $(TARGET_LUA_LIB)); \
-               @cd $(LIBPREFIX) && ln -fs $(shell basename $(TARGET_LUA_LIB)).$(VERSION).$(RELEASE) $(shell basename $(TARGET_LUA_LIB)).$(VERSION); \
+       @if [ ""$(LUA_INTERNAL)"" = ""true"" ]; then \
+               cd $(LIBPREFIX) && ln -fs $(shell basename $(TARGET_LUA_LIB)).$(VERSION).$(RELEASE) $(shell basename $(TARGET_LUA_LIB)); \
+               cd $(LIBPREFIX) && ln -fs $(shell basename $(TARGET_LUA_LIB)).$(VERSION).$(RELEASE) $(shell basename $(TARGET_LUA_LIB)).$(VERSION); \
        fi
        @echo ""===> INSTALL man pages to $(MANPREFIX)/man1""
        @mkdir -p $(MANPREFIX)/man1",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,72,2016-12-12T11:08:20Z,2016-12-16T11:08:23Z,2016-12-16T11:08:23Z,MERGED,True,47,13,4,https://github.com/davydden,allow external lua,1,[],https://github.com/RRZE-HPC/likwid/pull/72,https://github.com/TomTheBear,5,https://github.com/RRZE-HPC/likwid/pull/72#issuecomment-267039703,"WIP, but internal lua seems to build for me on Ubuntu 16.04, so this part should be fine.
p.s. adding support of external libs in makefile-only packages is a grand royal PITA 😄 I have not tested it mostly because lua i have around is a static lib with, presumably, -fPIC flags. So it should be fine to use it in shared libraries, but I seriously don't know what else/how needs to be changed to support this usage case.",Congrats. Keep in mind that the Travis-CI test run uses the default configuration without system Lua. If you want to test it with system Lua you have to adjust .travis.yaml to install Lua and to update config.mk,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,72,2016-12-12T11:08:20Z,2016-12-16T11:08:23Z,2016-12-16T11:08:23Z,MERGED,True,47,13,4,https://github.com/davydden,allow external lua,1,[],https://github.com/RRZE-HPC/likwid/pull/72,https://github.com/davydden,6,https://github.com/RRZE-HPC/likwid/pull/72#issuecomment-267040929,"WIP, but internal lua seems to build for me on Ubuntu 16.04, so this part should be fine.
p.s. adding support of external libs in makefile-only packages is a grand royal PITA 😄 I have not tested it mostly because lua i have around is a static lib with, presumably, -fPIC flags. So it should be fine to use it in shared libraries, but I seriously don't know what else/how needs to be changed to support this usage case.","there are still some issues with system's lua
bash: _install/bin/likwid-pin: /usr/local/bin/likwid-lua: bad interpreter: No such file or directory

Looks like something somewhere is not sed-ed properly.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,72,2016-12-12T11:08:20Z,2016-12-16T11:08:23Z,2016-12-16T11:08:23Z,MERGED,True,47,13,4,https://github.com/davydden,allow external lua,1,[],https://github.com/RRZE-HPC/likwid/pull/72,https://github.com/TomTheBear,7,https://github.com/RRZE-HPC/likwid/pull/72#issuecomment-267045363,"WIP, but internal lua seems to build for me on Ubuntu 16.04, so this part should be fine.
p.s. adding support of external libs in makefile-only packages is a grand royal PITA 😄 I have not tested it mostly because lua i have around is a static lib with, presumably, -fPIC flags. So it should be fine to use it in shared libraries, but I seriously don't know what else/how needs to be changed to support this usage case.",I don't get the error. I tried Lua 5.1 (with commit e13d4c3 from master branch for 5.1 compatibility) and Lua 5.2 and both work fine.,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,72,2016-12-12T11:08:20Z,2016-12-16T11:08:23Z,2016-12-16T11:08:23Z,MERGED,True,47,13,4,https://github.com/davydden,allow external lua,1,[],https://github.com/RRZE-HPC/likwid/pull/72,https://github.com/davydden,8,https://github.com/RRZE-HPC/likwid/pull/72#issuecomment-267049556,"WIP, but internal lua seems to build for me on Ubuntu 16.04, so this part should be fine.
p.s. adding support of external libs in makefile-only packages is a grand royal PITA 😄 I have not tested it mostly because lua i have around is a static lib with, presumably, -fPIC flags. So it should be fine to use it in shared libraries, but I seriously don't know what else/how needs to be changed to support this usage case.","for me the installed scripts like likwid-pin still have
#!/usr/local/bin/likwid-lua

I don't even know where from /usr/local/bin come, as I had
LUA_INCLUDE_DIR = /usr/include/lua5.2#NO SPACE
LUA_LIB_DIR = /usr/lib/x86_64-linux-gnu#NO SPACE
LUA_LIB_NAME = lua5.2#NO SPACE, executable is assumed to have the same name
LUA_BIN = /usr/bin#NO SPACE",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,72,2016-12-12T11:08:20Z,2016-12-16T11:08:23Z,2016-12-16T11:08:23Z,MERGED,True,47,13,4,https://github.com/davydden,allow external lua,1,[],https://github.com/RRZE-HPC/likwid/pull/72,https://github.com/davydden,9,https://github.com/RRZE-HPC/likwid/pull/72#issuecomment-267053944,"WIP, but internal lua seems to build for me on Ubuntu 16.04, so this part should be fine.
p.s. adding support of external libs in makefile-only packages is a grand royal PITA 😄 I have not tested it mostly because lua i have around is a static lib with, presumably, -fPIC flags. So it should be fine to use it in shared libraries, but I seriously don't know what else/how needs to be changed to support this usage case.","looking at $(L_APPS), i never see in the logs @echo ""===>  ADJUSTING  $@"". Is there something more than just
make all
make install

?",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,72,2016-12-12T11:08:20Z,2016-12-16T11:08:23Z,2016-12-16T11:08:23Z,MERGED,True,47,13,4,https://github.com/davydden,allow external lua,1,[],https://github.com/RRZE-HPC/likwid/pull/72,https://github.com/davydden,10,https://github.com/RRZE-HPC/likwid/pull/72#issuecomment-267054345,"WIP, but internal lua seems to build for me on Ubuntu 16.04, so this part should be fine.
p.s. adding support of external libs in makefile-only packages is a grand royal PITA 😄 I have not tested it mostly because lua i have around is a static lib with, presumably, -fPIC flags. So it should be fine to use it in shared libraries, but I seriously don't know what else/how needs to be changed to support this usage case.","Anyway, if you tested it and it works, i must be doing something wrong here. Feel free to merge this PR.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,72,2016-12-12T11:08:20Z,2016-12-16T11:08:23Z,2016-12-16T11:08:23Z,MERGED,True,47,13,4,https://github.com/davydden,allow external lua,1,[],https://github.com/RRZE-HPC/likwid/pull/72,https://github.com/davydden,11,https://github.com/RRZE-HPC/likwid/pull/72#issuecomment-267074266,"WIP, but internal lua seems to build for me on Ubuntu 16.04, so this part should be fine.
p.s. adding support of external libs in makefile-only packages is a grand royal PITA 😄 I have not tested it mostly because lua i have around is a static lib with, presumably, -fPIC flags. So it should be fine to use it in shared libraries, but I seriously don't know what else/how needs to be changed to support this usage case.",@TomTheBear works! That's because i did not clean it and make was not updating likwid-pin and alike.,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,72,2016-12-12T11:08:20Z,2016-12-16T11:08:23Z,2016-12-16T11:08:23Z,MERGED,True,47,13,4,https://github.com/davydden,allow external lua,1,[],https://github.com/RRZE-HPC/likwid/pull/72,https://github.com/davydden,12,https://github.com/RRZE-HPC/likwid/pull/72#issuecomment-267075581,"WIP, but internal lua seems to build for me on Ubuntu 16.04, so this part should be fine.
p.s. adding support of external libs in makefile-only packages is a grand royal PITA 😄 I have not tested it mostly because lua i have around is a static lib with, presumably, -fPIC flags. So it should be fine to use it in shared libraries, but I seriously don't know what else/how needs to be changed to support this usage case.","ldd looks right as well:
$ ldd _install/lib/liblikwid.so
	linux-vdso.so.1 =>  (0x00007ffdd556d000)
	libm.so.6 => /lib/x86_64-linux-gnu/libm.so.6 (0x00007f6e35e57000)
	librt.so.1 => /lib/x86_64-linux-gnu/librt.so.1 (0x00007f6e35c4f000)
	liblua5.2.so.0 => /usr/lib/x86_64-linux-gnu/liblua5.2.so.0 (0x00007f6e35a1c000)
	liblikwid-hwloc.so.4.1 => /home/davydden/libs/likwid/_install/lib/liblikwid-hwloc.so.4.1 (0x00007f6e357eb000)
	libpthread.so.0 => /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007f6e355ce000)
	libc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007f6e35204000)
	/lib64/ld-linux-x86-64.so.2 (0x0000559f580f8000)
	libdl.so.2 => /lib/x86_64-linux-gnu/libdl.so.2 (0x00007f6e35000000)",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,73,2016-12-14T00:43:15Z,2016-12-14T08:27:57Z,2016-12-14T08:27:57Z,MERGED,True,6,6,6,https://github.com/orlovan,Fix for L2 to L3 evict volume metric in all CACHES.txt,1,[],https://github.com/RRZE-HPC/likwid/pull/73,https://github.com/orlovan,1,https://github.com/RRZE-HPC/likwid/pull/73,Fixed a typo.,Fixed a typo.,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,78,2017-02-07T15:33:19Z,2017-02-13T13:52:45Z,2017-02-13T13:52:45Z,MERGED,True,1,0,1,https://github.com/rrzeschorscherl,Toll,1,[],https://github.com/RRZE-HPC/likwid/pull/78,https://github.com/rrzeschorscherl,1,https://github.com/RRZE-HPC/likwid/pull/78,Leerzeile,Leerzeile,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,79,2017-02-09T12:25:49Z,2017-02-14T14:20:51Z,2017-02-14T14:20:51Z,MERGED,True,5,0,1,https://github.com/mgottschlag,Implement Skylake frontend events,1,[],https://github.com/RRZE-HPC/likwid/pull/79,https://github.com/mgottschlag,1,https://github.com/RRZE-HPC/likwid/pull/79,"While the frontend events were defined, the MSR_PEBS_FRONTEND register apparently wasn't configured anywhere.","While the frontend events were defined, the MSR_PEBS_FRONTEND register apparently wasn't configured anywhere.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,79,2017-02-09T12:25:49Z,2017-02-14T14:20:51Z,2017-02-14T14:20:51Z,MERGED,True,5,0,1,https://github.com/mgottschlag,Implement Skylake frontend events,1,[],https://github.com/RRZE-HPC/likwid/pull/79,https://github.com/TomTheBear,2,https://github.com/RRZE-HPC/likwid/pull/79#issuecomment-279397502,"While the frontend events were defined, the MSR_PEBS_FRONTEND register apparently wasn't configured anywhere.","Thanks for the PR but after I rechecked the documentation of the FRONTEND_RETIRED events. It seems that PEBS is required to use these events and that's not possible for LIKWID. PEBS requires to set up some kernel-level buffers which cannot be done by LIKWID as it runs completely in user-space.
My opinion: In order to avoid confusion the FRONTEND_RETIRED events should be deleted from the event lists.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,79,2017-02-09T12:25:49Z,2017-02-14T14:20:51Z,2017-02-14T14:20:51Z,MERGED,True,5,0,1,https://github.com/mgottschlag,Implement Skylake frontend events,1,[],https://github.com/RRZE-HPC/likwid/pull/79,https://github.com/mgottschlag,3,https://github.com/RRZE-HPC/likwid/pull/79#issuecomment-279420708,"While the frontend events were defined, the MSR_PEBS_FRONTEND register apparently wasn't configured anywhere.","In ""Table 19-3. Non-Architectural Performance Events of the Processor Core Supported by Skylake Microarchitecture"", the events are marked ""PS"", but ""PS"" is defined as ""Also supports PEBS."" (where ""also"" implies that they do not require PEBS). While the detailed description is strongly linked to PEBS, that table isn't.
In fact, the events seem to work on real hardware, without any kernel code.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,79,2017-02-09T12:25:49Z,2017-02-14T14:20:51Z,2017-02-14T14:20:51Z,MERGED,True,5,0,1,https://github.com/mgottschlag,Implement Skylake frontend events,1,[],https://github.com/RRZE-HPC/likwid/pull/79,https://github.com/TomTheBear,4,https://github.com/RRZE-HPC/likwid/pull/79#issuecomment-279439824,"While the frontend events were defined, the MSR_PEBS_FRONTEND register apparently wasn't configured anywhere.","OK, I have never tested them. I just checked the event definitions and there are inconsistencies between Intel SDM and the Perfmon online DB. You PR seems fine and I'll merge it soon, thanks for your contribution.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,80,2017-02-14T12:39:02Z,2017-02-14T14:19:50Z,2017-02-14T14:29:37Z,MERGED,True,1,1,1,https://github.com/jeorsch,set correct path to liblikwidpin,1,[],https://github.com/RRZE-HPC/likwid/pull/80,https://github.com/jeorsch,1,https://github.com/RRZE-HPC/likwid/pull/80,For LIBLIKWIDPIN the wrong INSTALLED_PREFIX instead of the correct INSTALLED_LIBPREFIX is used to determine the path to the shared object. Fixed this in config.mk.,For LIBLIKWIDPIN the wrong INSTALLED_PREFIX instead of the correct INSTALLED_LIBPREFIX is used to determine the path to the shared object. Fixed this in config.mk.,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,80,2017-02-14T12:39:02Z,2017-02-14T14:19:50Z,2017-02-14T14:29:37Z,MERGED,True,1,1,1,https://github.com/jeorsch,set correct path to liblikwidpin,1,[],https://github.com/RRZE-HPC/likwid/pull/80,https://github.com/TomTheBear,2,https://github.com/RRZE-HPC/likwid/pull/80#issuecomment-279718988,For LIBLIKWIDPIN the wrong INSTALLED_PREFIX instead of the correct INSTALLED_LIBPREFIX is used to determine the path to the shared object. Fixed this in config.mk.,Thanks for the PR,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,82,2017-02-20T14:18:06Z,2017-02-21T13:26:43Z,2017-02-21T13:26:43Z,MERGED,True,4,4,2,https://github.com/LangdalP,Fixed error in Sandy Bridge L3 miss ratio calculation,2,[],https://github.com/RRZE-HPC/likwid/pull/82,https://github.com/LangdalP,1,https://github.com/RRZE-HPC/likwid/pull/82,"I noticed that on my Sandy Bridge rig, the L3 miss ratio did not range between 0-1, but between 0 and some arbitrarily high number. This was because the division failed because it was wrongly specified.
I do not fully understand the syntax used for the calculations, but I managed to fix it by changing the divisor to PMC1:MATCH0=0x0081:MATCH1=0x1, which matches how it was specified in the EVENTSET section. Before I changed it, the divisor was PMC1:MATCH0=0081:MATCH1=0x1. Notice that MATCH0 is set to 0081 before, and 0x0081 after.
After making this change, the L3 miss ratio is equal to OFFCORE_RESPONSE_0_OPTIONS / OFFCORE_RESPONSE_1_OPTIONS, which seems to range between 0-1 in my experiments.
As mentioned, I do not fully understand the file syntax, so someone should inspect the changes to see that they are correct.
What was done, specifically:
'MATCH0=0081' was changed to 'MATCH0=0x0081' in a few places","I noticed that on my Sandy Bridge rig, the L3 miss ratio did not range between 0-1, but between 0 and some arbitrarily high number. This was because the division failed because it was wrongly specified.
I do not fully understand the syntax used for the calculations, but I managed to fix it by changing the divisor to PMC1:MATCH0=0x0081:MATCH1=0x1, which matches how it was specified in the EVENTSET section. Before I changed it, the divisor was PMC1:MATCH0=0081:MATCH1=0x1. Notice that MATCH0 is set to 0081 before, and 0x0081 after.
After making this change, the L3 miss ratio is equal to OFFCORE_RESPONSE_0_OPTIONS / OFFCORE_RESPONSE_1_OPTIONS, which seems to range between 0-1 in my experiments.
As mentioned, I do not fully understand the file syntax, so someone should inspect the changes to see that they are correct.
What was done, specifically:
'MATCH0=0081' was changed to 'MATCH0=0x0081' in a few places",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,82,2017-02-20T14:18:06Z,2017-02-21T13:26:43Z,2017-02-21T13:26:43Z,MERGED,True,4,4,2,https://github.com/LangdalP,Fixed error in Sandy Bridge L3 miss ratio calculation,2,[],https://github.com/RRZE-HPC/likwid/pull/82,https://github.com/TomTheBear,2,https://github.com/RRZE-HPC/likwid/pull/82#issuecomment-281341367,"I noticed that on my Sandy Bridge rig, the L3 miss ratio did not range between 0-1, but between 0 and some arbitrarily high number. This was because the division failed because it was wrongly specified.
I do not fully understand the syntax used for the calculations, but I managed to fix it by changing the divisor to PMC1:MATCH0=0x0081:MATCH1=0x1, which matches how it was specified in the EVENTSET section. Before I changed it, the divisor was PMC1:MATCH0=0081:MATCH1=0x1. Notice that MATCH0 is set to 0081 before, and 0x0081 after.
After making this change, the L3 miss ratio is equal to OFFCORE_RESPONSE_0_OPTIONS / OFFCORE_RESPONSE_1_OPTIONS, which seems to range between 0-1 in my experiments.
As mentioned, I do not fully understand the file syntax, so someone should inspect the changes to see that they are correct.
What was done, specifically:
'MATCH0=0081' was changed to 'MATCH0=0x0081' in a few places","Thanks for the PR. Your changes affect only the group file for desktop SandyBridges (groups/sandybridge/L3CACHE.txt) but the same error exists in the server SandyBridges files (groups/sandybridgeEP/L3CACHE.txt). Can you change this file, too, so that the PR is complete?",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,82,2017-02-20T14:18:06Z,2017-02-21T13:26:43Z,2017-02-21T13:26:43Z,MERGED,True,4,4,2,https://github.com/LangdalP,Fixed error in Sandy Bridge L3 miss ratio calculation,2,[],https://github.com/RRZE-HPC/likwid/pull/82,https://github.com/LangdalP,3,https://github.com/RRZE-HPC/likwid/pull/82#issuecomment-281343267,"I noticed that on my Sandy Bridge rig, the L3 miss ratio did not range between 0-1, but between 0 and some arbitrarily high number. This was because the division failed because it was wrongly specified.
I do not fully understand the syntax used for the calculations, but I managed to fix it by changing the divisor to PMC1:MATCH0=0x0081:MATCH1=0x1, which matches how it was specified in the EVENTSET section. Before I changed it, the divisor was PMC1:MATCH0=0081:MATCH1=0x1. Notice that MATCH0 is set to 0081 before, and 0x0081 after.
After making this change, the L3 miss ratio is equal to OFFCORE_RESPONSE_0_OPTIONS / OFFCORE_RESPONSE_1_OPTIONS, which seems to range between 0-1 in my experiments.
As mentioned, I do not fully understand the file syntax, so someone should inspect the changes to see that they are correct.
What was done, specifically:
'MATCH0=0081' was changed to 'MATCH0=0x0081' in a few places",No problem. I have now applied the same fixes to that file.,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,89,2017-03-15T01:24:50Z,2017-03-15T11:01:22Z,2017-03-15T11:01:26Z,MERGED,True,2,2,1,https://github.com/aaronknister,Use SLURM_* vars when no MPI_LOCAL* vars,1,[],https://github.com/RRZE-HPC/likwid/pull/89,https://github.com/aaronknister,1,https://github.com/RRZE-HPC/likwid/pull/89,The environment variables MPI_LOCALNRANKS and MPI_LOCALRANKID don't appear to be native to SLURM. So as to not break sites alread using likwid that may have these MPI_LOCAL* vars use the SLURM_* equivalents only if the MPI_LOCAL* vars are unavailable.,The environment variables MPI_LOCALNRANKS and MPI_LOCALRANKID don't appear to be native to SLURM. So as to not break sites alread using likwid that may have these MPI_LOCAL* vars use the SLURM_* equivalents only if the MPI_LOCAL* vars are unavailable.,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,89,2017-03-15T01:24:50Z,2017-03-15T11:01:22Z,2017-03-15T11:01:26Z,MERGED,True,2,2,1,https://github.com/aaronknister,Use SLURM_* vars when no MPI_LOCAL* vars,1,[],https://github.com/RRZE-HPC/likwid/pull/89,https://github.com/TomTheBear,2,https://github.com/RRZE-HPC/likwid/pull/89#issuecomment-286698361,The environment variables MPI_LOCALNRANKS and MPI_LOCALRANKID don't appear to be native to SLURM. So as to not break sites alread using likwid that may have these MPI_LOCAL* vars use the SLURM_* equivalents only if the MPI_LOCAL* vars are unavailable.,"Looks reasonable, can be merged.
Does the SLURM support work for you? I tested it only on one system, so there might be errors on other systems.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,89,2017-03-15T01:24:50Z,2017-03-15T11:01:22Z,2017-03-15T11:01:26Z,MERGED,True,2,2,1,https://github.com/aaronknister,Use SLURM_* vars when no MPI_LOCAL* vars,1,[],https://github.com/RRZE-HPC/likwid/pull/89,https://github.com/aaronknister,3,https://github.com/RRZE-HPC/likwid/pull/89#issuecomment-286709058,The environment variables MPI_LOCALNRANKS and MPI_LOCALRANKID don't appear to be native to SLURM. So as to not break sites alread using likwid that may have these MPI_LOCAL* vars use the SLURM_* equivalents only if the MPI_LOCAL* vars are unavailable.,"Yep, it worked for me with a couple tests I ran. Thanks!",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,89,2017-03-15T01:24:50Z,2017-03-15T11:01:22Z,2017-03-15T11:01:26Z,MERGED,True,2,2,1,https://github.com/aaronknister,Use SLURM_* vars when no MPI_LOCAL* vars,1,[],https://github.com/RRZE-HPC/likwid/pull/89,https://github.com/TomTheBear,4,https://github.com/RRZE-HPC/likwid/pull/89#issuecomment-286709310,The environment variables MPI_LOCALNRANKS and MPI_LOCALRANKID don't appear to be native to SLURM. So as to not break sites alread using likwid that may have these MPI_LOCAL* vars use the SLURM_* equivalents only if the MPI_LOCAL* vars are unavailable.,"OK, thanks for the information.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,95,2017-04-11T13:33:05Z,2017-04-11T13:37:32Z,2017-04-11T13:37:32Z,MERGED,True,2,0,1,https://github.com/mcolmant,Add missing return statements for the perf_event support.,1,[],https://github.com/RRZE-HPC/likwid/pull/95,https://github.com/mcolmant,1,https://github.com/RRZE-HPC/likwid/pull/95,"Some return statements are missing when using the perf_event support.
To be compliant with the other headers, I added the same statements where they were missing.","Some return statements are missing when using the perf_event support.
To be compliant with the other headers, I added the same statements where they were missing.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,95,2017-04-11T13:33:05Z,2017-04-11T13:37:32Z,2017-04-11T13:37:32Z,MERGED,True,2,0,1,https://github.com/mcolmant,Add missing return statements for the perf_event support.,1,[],https://github.com/RRZE-HPC/likwid/pull/95,https://github.com/TomTheBear,2,https://github.com/RRZE-HPC/likwid/pull/95#issuecomment-293265233,"Some return statements are missing when using the perf_event support.
To be compliant with the other headers, I added the same statements where they were missing.",Thanks for trying and refining the perf_event backend.,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,98,2017-04-12T12:29:29Z,2017-04-18T13:38:25Z,2017-04-18T13:38:25Z,MERGED,True,44,1,3,https://github.com/mcolmant,Add the support of the pid and flags parameters (perf_event).,1,[],https://github.com/RRZE-HPC/likwid/pull/98,https://github.com/mcolmant,1,https://github.com/RRZE-HPC/likwid/pull/98,Add the possibility to use the PID and flags parameters for the perf_event_open call when using the perf_event interface (#96).,Add the possibility to use the PID and flags parameters for the perf_event_open call when using the perf_event interface (#96).,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,98,2017-04-12T12:29:29Z,2017-04-18T13:38:25Z,2017-04-18T13:38:25Z,MERGED,True,44,1,3,https://github.com/mcolmant,Add the support of the pid and flags parameters (perf_event).,1,[],https://github.com/RRZE-HPC/likwid/pull/98,https://github.com/mcolmant,2,https://github.com/RRZE-HPC/likwid/pull/98#issuecomment-293866409,Add the possibility to use the PID and flags parameters for the perf_event_open call when using the perf_event interface (#96).,"Oh, thanks, it has been fixed.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,98,2017-04-12T12:29:29Z,2017-04-18T13:38:25Z,2017-04-18T13:38:25Z,MERGED,True,44,1,3,https://github.com/mcolmant,Add the support of the pid and flags parameters (perf_event).,1,[],https://github.com/RRZE-HPC/likwid/pull/98,https://github.com/TomTheBear,3,https://github.com/RRZE-HPC/likwid/pull/98#issuecomment-293877056,Add the possibility to use the PID and flags parameters for the perf_event_open call when using the perf_event interface (#96).,"Looks fine and my first tests don't throw any errors.
What came into my mind: If you want to use the PID feature for the wrapped executable, we have to reconstruct the flow of likwid-perfctr. Currently, the eventset is added to LIKWID and the events are set up before the executable is started and you get the PID. I would require something like, start the executable and pause it directly. Afterwards get the PID, add the eventset with PID option, set up the events, start the counters and unpause the executable.
Or is your use-case always that the executable is already running and you want to monitor it from the outside?",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,98,2017-04-12T12:29:29Z,2017-04-18T13:38:25Z,2017-04-18T13:38:25Z,MERGED,True,44,1,3,https://github.com/mcolmant,Add the support of the pid and flags parameters (perf_event).,1,[],https://github.com/RRZE-HPC/likwid/pull/98,https://github.com/mcolmant,4,https://github.com/RRZE-HPC/likwid/pull/98#issuecomment-294099273,Add the possibility to use the PID and flags parameters for the perf_event_open call when using the perf_event interface (#96).,"For what I want to do right now, I'm monitoring the PID from outside.
But I have already used a similar approach (start, pause, counters, restart) to use the inherit option (child processes).
I think it could be good to add this support also in the wrapped executable, maybe it can be useful for other users.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,98,2017-04-12T12:29:29Z,2017-04-18T13:38:25Z,2017-04-18T13:38:25Z,MERGED,True,44,1,3,https://github.com/mcolmant,Add the support of the pid and flags parameters (perf_event).,1,[],https://github.com/RRZE-HPC/likwid/pull/98,https://github.com/TomTheBear,5,https://github.com/RRZE-HPC/likwid/pull/98#issuecomment-294846825,Add the possibility to use the PID and flags parameters for the perf_event_open call when using the perf_event interface (#96).,"I implemented the start/pause/counters/unpause scheme in likwid-perfctr. Moreover, a command line option ""--execpid"" that adds perf_pid=<PID_of_the_started_application> to the last event in the event string. So, I think this PR can be merged.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,103,2017-05-19T00:53:27Z,2017-05-19T16:42:54Z,2017-05-19T16:42:54Z,MERGED,True,193,17,13,https://github.com/jianbinfang,Armv8,3,[],https://github.com/RRZE-HPC/likwid/pull/103,https://github.com/jianbinfang,1,https://github.com/RRZE-HPC/likwid/pull/103,Here are some armv8 changes. Please check and merge if necessary.,Here are some armv8 changes. Please check and merge if necessary.,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,103,2017-05-19T00:53:27Z,2017-05-19T16:42:54Z,2017-05-19T16:42:54Z,MERGED,True,193,17,13,https://github.com/jianbinfang,Armv8,3,[],https://github.com/RRZE-HPC/likwid/pull/103,https://github.com/TomTheBear,2,https://github.com/RRZE-HPC/likwid/pull/103#issuecomment-302753060,Here are some armv8 changes. Please check and merge if necessary.,Thanks for the PR. Looks fine and I cannot find any errors.,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,104,2017-05-23T12:15:57Z,2017-05-23T12:49:56Z,2017-05-23T12:49:56Z,MERGED,True,2,2,1,https://github.com/kronbichler,Fix category on Broadwell.,1,[],https://github.com/RRZE-HPC/likwid/pull/104,https://github.com/kronbichler,1,https://github.com/RRZE-HPC/likwid/pull/104,Fix typo.,Fix typo.,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,104,2017-05-23T12:15:57Z,2017-05-23T12:49:56Z,2017-05-23T12:49:56Z,MERGED,True,2,2,1,https://github.com/kronbichler,Fix category on Broadwell.,1,[],https://github.com/RRZE-HPC/likwid/pull/104,https://github.com/TomTheBear,2,https://github.com/RRZE-HPC/likwid/pull/104#issuecomment-303387374,Fix typo.,Many thanks.,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,106,2017-06-16T07:33:19Z,2017-06-16T07:59:31Z,2017-06-16T07:59:31Z,MERGED,True,2,2,1,https://github.com/csbnw,Update ENERGY.txt for knl,1,[],https://github.com/RRZE-HPC/likwid/pull/106,https://github.com/csbnw,1,https://github.com/RRZE-HPC/likwid/pull/106,Use PWR3 to compute DRAM energy and power metrics.,Use PWR3 to compute DRAM energy and power metrics.,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,106,2017-06-16T07:33:19Z,2017-06-16T07:59:31Z,2017-06-16T07:59:31Z,MERGED,True,2,2,1,https://github.com/csbnw,Update ENERGY.txt for knl,1,[],https://github.com/RRZE-HPC/likwid/pull/106,https://github.com/TomTheBear,2,https://github.com/RRZE-HPC/likwid/pull/106#issuecomment-308960497,Use PWR3 to compute DRAM energy and power metrics.,Thanks for the fix.,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,121,2017-10-12T11:00:09Z,2017-10-12T11:15:10Z,2017-10-12T11:15:11Z,MERGED,True,2,2,1,https://github.com/lluchs,AMD Zen: Fix valid options masks,1,[],https://github.com/RRZE-HPC/likwid/pull/121,https://github.com/lluchs,1,https://github.com/RRZE-HPC/likwid/pull/121,,,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,122,2017-10-12T14:00:45Z,2017-10-13T08:07:14Z,2017-10-13T08:07:14Z,MERGED,True,2,2,1,https://github.com/lluchs,AMD Zen: Don't invert thread/slice selectors,1,[],https://github.com/RRZE-HPC/likwid/pull/122,https://github.com/lluchs,1,https://github.com/RRZE-HPC/likwid/pull/122,"Is there any reason why these are inverted? If I'm trying to filter events by thread, I usually think of ""I'd like to get events from these threads"", not ""I'd like to not get events from these threads"".","Is there any reason why these are inverted? If I'm trying to filter events by thread, I usually think of ""I'd like to get events from these threads"", not ""I'd like to not get events from these threads"".",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,122,2017-10-12T14:00:45Z,2017-10-13T08:07:14Z,2017-10-13T08:07:14Z,MERGED,True,2,2,1,https://github.com/lluchs,AMD Zen: Don't invert thread/slice selectors,1,[],https://github.com/RRZE-HPC/likwid/pull/122,https://github.com/TomTheBear,2,https://github.com/RRZE-HPC/likwid/pull/122#issuecomment-336381313,"Is there any reason why these are inverted? If I'm trying to filter events by thread, I usually think of ""I'd like to get events from these threads"", not ""I'd like to not get events from these threads"".","I'm not sure why I inverted the mask but I created the Zen support without a system. I just tried it on our Zen machine and you are right, the masks shouldn't be inverted. Thanks for finding and fixing it",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,124,2017-10-30T16:30:21Z,2017-11-02T10:10:51Z,2017-11-02T10:10:51Z,MERGED,True,0,1,1,https://github.com/lunixoid,Fixed double `free`,1,[],https://github.com/RRZE-HPC/likwid/pull/124,https://github.com/lunixoid,1,https://github.com/RRZE-HPC/likwid/pull/124,"I'm a member of the Pinguem.ru competition on finding errors in open source projects. Error, found using PVS-Studio:
likwid/src/calculator.c     771     err     V586 The 'free' function is called twice for deallocation of the same memory space. Inspect the first argument. Check lines: 760, 771.","I'm a member of the Pinguem.ru competition on finding errors in open source projects. Error, found using PVS-Studio:
likwid/src/calculator.c     771     err     V586 The 'free' function is called twice for deallocation of the same memory space. Inspect the first argument. Check lines: 760, 771.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,124,2017-10-30T16:30:21Z,2017-11-02T10:10:51Z,2017-11-02T10:10:51Z,MERGED,True,0,1,1,https://github.com/lunixoid,Fixed double `free`,1,[],https://github.com/RRZE-HPC/likwid/pull/124,https://github.com/TomTheBear,2,https://github.com/RRZE-HPC/likwid/pull/124#issuecomment-341374853,"I'm a member of the Pinguem.ru competition on finding errors in open source projects. Error, found using PVS-Studio:
likwid/src/calculator.c     771     err     V586 The 'free' function is called twice for deallocation of the same memory space. Inspect the first argument. Check lines: 760, 771.",Many thanks for the PR.,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,135,2017-12-15T10:25:28Z,2017-12-18T09:10:41Z,2017-12-18T09:10:41Z,MERGED,True,1,1,1,https://github.com/rschoene,Increased MAX_LENGTH_MSR_DEV_NAME,1,[],https://github.com/RRZE-HPC/likwid/pull/135,https://github.com/rschoene,1,https://github.com/RRZE-HPC/likwid/pull/135,Got an buffer overflow since /dev/cpu/18/msr_safe did not fit within the 20 chars,Got an buffer overflow since /dev/cpu/18/msr_safe did not fit within the 20 chars,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,148,2018-02-09T15:44:51Z,2018-03-22T12:36:45Z,2018-03-22T12:36:45Z,MERGED,True,126,0,8,https://github.com/yogeshVU,added ansible role,2,[],https://github.com/RRZE-HPC/likwid/pull/148,https://github.com/yogeshVU,1,https://github.com/RRZE-HPC/likwid/pull/148,added ansible role which currently dowloads stable release from the ftp server and installs the stable release on the target server.,added ansible role which currently dowloads stable release from the ftp server and installs the stable release on the target server.,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,148,2018-02-09T15:44:51Z,2018-03-22T12:36:45Z,2018-03-22T12:36:45Z,MERGED,True,126,0,8,https://github.com/yogeshVU,added ansible role,2,[],https://github.com/RRZE-HPC/likwid/pull/148,https://github.com/TomTheBear,2,https://github.com/RRZE-HPC/likwid/pull/148#issuecomment-365557397,added ansible role which currently dowloads stable release from the ftp server and installs the stable release on the target server.,"Is it required by ansible to have its folder directly at first level? Because ansible is not the only tool for which people asked to have packaging stuff (spec-File for RPM, Debian rules, ...) and it would be nice to have it grouped together in some subfolder.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,148,2018-02-09T15:44:51Z,2018-03-22T12:36:45Z,2018-03-22T12:36:45Z,MERGED,True,126,0,8,https://github.com/yogeshVU,added ansible role,2,[],https://github.com/RRZE-HPC/likwid/pull/148,https://github.com/yogeshVU,3,https://github.com/RRZE-HPC/likwid/pull/148#issuecomment-365635044,added ansible role which currently dowloads stable release from the ftp server and installs the stable release on the target server.,"@TomTheBear ansible can be used for targeting various distributions(ubuntu/centos..etc). For now I have it tested only on ubuntu.
Directory structure placement does not matter for the ansible. It can also be moved to a totally different repository if required.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,148,2018-02-09T15:44:51Z,2018-03-22T12:36:45Z,2018-03-22T12:36:45Z,MERGED,True,126,0,8,https://github.com/yogeshVU,added ansible role,2,[],https://github.com/RRZE-HPC/likwid/pull/148,https://github.com/TomTheBear,4,https://github.com/RRZE-HPC/likwid/pull/148#issuecomment-365913432,added ansible role which currently dowloads stable release from the ftp server and installs the stable release on the target server.,"Thanks for the clarification. What I had in mind is to put the ansible stuff in a subfolder like 'packaging' or similar, so that we can group all packaging stuff there.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,148,2018-02-09T15:44:51Z,2018-03-22T12:36:45Z,2018-03-22T12:36:45Z,MERGED,True,126,0,8,https://github.com/yogeshVU,added ansible role,2,[],https://github.com/RRZE-HPC/likwid/pull/148,https://github.com/yogeshVU,5,https://github.com/RRZE-HPC/likwid/pull/148#issuecomment-365959300,added ansible role which currently dowloads stable release from the ftp server and installs the stable release on the target server.,That's a good approach.,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,148,2018-02-09T15:44:51Z,2018-03-22T12:36:45Z,2018-03-22T12:36:45Z,MERGED,True,126,0,8,https://github.com/yogeshVU,added ansible role,2,[],https://github.com/RRZE-HPC/likwid/pull/148,https://github.com/yogeshVU,6,https://github.com/RRZE-HPC/likwid/pull/148#issuecomment-369816290,added ansible role which currently dowloads stable release from the ftp server and installs the stable release on the target server.,Any changes required to make this merged?,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,148,2018-02-09T15:44:51Z,2018-03-22T12:36:45Z,2018-03-22T12:36:45Z,MERGED,True,126,0,8,https://github.com/yogeshVU,added ansible role,2,[],https://github.com/RRZE-HPC/likwid/pull/148,https://github.com/TomTheBear,7,https://github.com/RRZE-HPC/likwid/pull/148#issuecomment-369879311,added ansible role which currently dowloads stable release from the ftp server and installs the stable release on the target server.,"I'm currently preparing a new 4.3 release, so only little time to take care of the master branch.
You could move the 'ansible.likwid' folder to a subfolder 'packaging' and rename your folder in 'ansible'. I still havn't had time to look more deeply into ansible but since it builds from source, is it possible to make configuration steps (like changing the access mode or similar)? Commonly, these packages contain information like a description, license, etc. Is this information already included in your commit or should it be added after merging?",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,154,2018-04-29T12:22:50Z,2018-04-30T17:09:08Z,2018-04-30T17:09:13Z,MERGED,True,15,14,13,https://github.com/fendor,Replace perl she-bangline ,3,[],https://github.com/RRZE-HPC/likwid/pull/154,https://github.com/fendor,1,https://github.com/RRZE-HPC/likwid/pull/154,This is a pull request for the issue #153.,This is a pull request for the issue #153.,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,154,2018-04-29T12:22:50Z,2018-04-30T17:09:08Z,2018-04-30T17:09:13Z,MERGED,True,15,14,13,https://github.com/fendor,Replace perl she-bangline ,3,[],https://github.com/RRZE-HPC/likwid/pull/154,https://github.com/fendor,2,https://github.com/RRZE-HPC/likwid/pull/154#issuecomment-385248228,This is a pull request for the issue #153.,The second commit is to add warning flags to the perl files.,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,154,2018-04-29T12:22:50Z,2018-04-30T17:09:08Z,2018-04-30T17:09:13Z,MERGED,True,15,14,13,https://github.com/fendor,Replace perl she-bangline ,3,[],https://github.com/RRZE-HPC/likwid/pull/154,https://github.com/TomTheBear,3,https://github.com/RRZE-HPC/likwid/pull/154#issuecomment-385463946,This is a pull request for the issue #153.,Thank you for the PR. Looks good to me.,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,166,2018-06-20T10:01:59Z,2018-06-20T10:21:05Z,2018-06-20T10:21:05Z,MERGED,True,1,1,1,https://github.com/ohlmann,fix missing uncore measurements with likwid-mpirun,1,[],https://github.com/RRZE-HPC/likwid/pull/166,https://github.com/ohlmann,1,https://github.com/RRZE-HPC/likwid/pull/166,"to check for the first core in a socket, a comparison of the cpu id is
done; unfortunately, the comparison is between a string and integers
converting the cpu id to a number fixes the comparison and the uncore
counters (e.g., memory related counters) are read by the first cores
in each socket","to check for the first core in a socket, a comparison of the cpu id is
done; unfortunately, the comparison is between a string and integers
converting the cpu id to a number fixes the comparison and the uncore
counters (e.g., memory related counters) are read by the first cores
in each socket",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,173,2018-07-19T09:51:29Z,2018-07-20T13:11:11Z,2018-07-20T13:11:11Z,MERGED,True,1,1,1,https://github.com/ohlmann,change PREFIX to INSTALLED_PREFIX for cmake config,1,[],https://github.com/RRZE-HPC/likwid/pull/173,https://github.com/ohlmann,1,https://github.com/RRZE-HPC/likwid/pull/173,"The cmake config file should point to the directories where likwid is
installed, not where it was built.","The cmake config file should point to the directories where likwid is
installed, not where it was built.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,180,2018-08-09T10:11:18Z,2018-08-09T10:46:57Z,2018-08-09T11:48:14Z,MERGED,True,1,1,1,https://github.com/ohlmann,fix likwid-mpirun bug with slurm,1,[],https://github.com/RRZE-HPC/likwid/pull/180,https://github.com/ohlmann,1,https://github.com/RRZE-HPC/likwid/pull/180,"the problem lies in setting SLURM_NODELIST in likwid-mpirun
currently, the hostlist is read from a scontrol command using a lua
pipe with f:read('*a')
this leads to line break at the end of the environment variable
SLURM_NODELIST, causing srun to segfault
this can be fixed by using f:read('*l') because the scontrol output
should always be only one line -> the line break is ignored","the problem lies in setting SLURM_NODELIST in likwid-mpirun
currently, the hostlist is read from a scontrol command using a lua
pipe with f:read('*a')
this leads to line break at the end of the environment variable
SLURM_NODELIST, causing srun to segfault
this can be fixed by using f:read('*l') because the scontrol output
should always be only one line -> the line break is ignored",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,180,2018-08-09T10:11:18Z,2018-08-09T10:46:57Z,2018-08-09T11:48:14Z,MERGED,True,1,1,1,https://github.com/ohlmann,fix likwid-mpirun bug with slurm,1,[],https://github.com/RRZE-HPC/likwid/pull/180,https://github.com/ohlmann,2,https://github.com/RRZE-HPC/likwid/pull/180#issuecomment-411708705,"the problem lies in setting SLURM_NODELIST in likwid-mpirun
currently, the hostlist is read from a scontrol command using a lua
pipe with f:read('*a')
this leads to line break at the end of the environment variable
SLURM_NODELIST, causing srun to segfault
this can be fixed by using f:read('*l') because the scontrol output
should always be only one line -> the line break is ignored","For me, this seems to fix one of the issues reported in https://groups.google.com/forum/#!topic/likwid-users/Qd1vpfhL3qg (srun did not work in the script because of the different environment variables).",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,180,2018-08-09T10:11:18Z,2018-08-09T10:46:57Z,2018-08-09T11:48:14Z,MERGED,True,1,1,1,https://github.com/ohlmann,fix likwid-mpirun bug with slurm,1,[],https://github.com/RRZE-HPC/likwid/pull/180,https://github.com/TomTheBear,3,https://github.com/RRZE-HPC/likwid/pull/180#issuecomment-411711365,"the problem lies in setting SLURM_NODELIST in likwid-mpirun
currently, the hostlist is read from a scontrol command using a lua
pipe with f:read('*a')
this leads to line break at the end of the environment variable
SLURM_NODELIST, causing srun to segfault
this can be fixed by using f:read('*l') because the scontrol output
should always be only one line -> the line break is ignored","Thanks for the PR. Looks reasonable. The only issue I have is

because the scontrol output should always be only one line

Is it and will it be always like this?",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,180,2018-08-09T10:11:18Z,2018-08-09T10:46:57Z,2018-08-09T11:48:14Z,MERGED,True,1,1,1,https://github.com/ohlmann,fix likwid-mpirun bug with slurm,1,[],https://github.com/RRZE-HPC/likwid/pull/180,https://github.com/ohlmann,4,https://github.com/RRZE-HPC/likwid/pull/180#issuecomment-411712519,"the problem lies in setting SLURM_NODELIST in likwid-mpirun
currently, the hostlist is read from a scontrol command using a lua
pipe with f:read('*a')
this leads to line break at the end of the environment variable
SLURM_NODELIST, causing srun to segfault
this can be fixed by using f:read('*l') because the scontrol output
should always be only one line -> the line break is ignored","I think so, because the hostlist expression is always one line (e.g. broadwell[001-009,014],skylake01).",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,180,2018-08-09T10:11:18Z,2018-08-09T10:46:57Z,2018-08-09T11:48:14Z,MERGED,True,1,1,1,https://github.com/ohlmann,fix likwid-mpirun bug with slurm,1,[],https://github.com/RRZE-HPC/likwid/pull/180,https://github.com/TomTheBear,5,https://github.com/RRZE-HPC/likwid/pull/180#issuecomment-411716778,"the problem lies in setting SLURM_NODELIST in likwid-mpirun
currently, the hostlist is read from a scontrol command using a lua
pipe with f:read('*a')
this leads to line break at the end of the environment variable
SLURM_NODELIST, causing srun to segfault
this can be fixed by using f:read('*l') because the scontrol output
should always be only one line -> the line break is ignored","I checked the SLURM documentation and it's not directly mentioned but you can somehow read it out that it always on one line:

If no hostlist expression is supplied, the contents of the SLURM_JOB_NODELIST environment variable is used. For example ""tux[1-3]"" is mapped to ""tux1"",""tux2"" and ""tux3"" (one hostname per line). hostlist takes a list of host names and prints the hostlist expression for them (the inverse of hostnames)

The inverse of ""one hostname per line ""would be ""all hostnames in one line"".",True,{'THUMBS_UP': ['https://github.com/ohlmann']}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,183,2018-09-11T18:40:35Z,2018-09-12T09:08:56Z,2018-09-12T09:08:56Z,MERGED,True,6,7,5,https://github.com/termim,Events syntax,3,[],https://github.com/RRZE-HPC/likwid/pull/183,https://github.com/termim,1,https://github.com/RRZE-HPC/likwid/pull/183,Some typos in events descriptions,Some typos in events descriptions,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,183,2018-09-11T18:40:35Z,2018-09-12T09:08:56Z,2018-09-12T09:08:56Z,MERGED,True,6,7,5,https://github.com/termim,Events syntax,3,[],https://github.com/RRZE-HPC/likwid/pull/183,https://github.com/TomTheBear,2,https://github.com/RRZE-HPC/likwid/pull/183#issuecomment-420571825,Some typos in events descriptions,Thanks for checking and fixing the events.,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,184,2018-09-12T16:17:44Z,2018-09-12T16:42:52Z,2018-09-12T16:42:52Z,MERGED,True,16,18,7,https://github.com/termim,Events syntax,4,[],https://github.com/RRZE-HPC/likwid/pull/184,https://github.com/termim,1,https://github.com/RRZE-HPC/likwid/pull/184,More fixes,More fixes,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,184,2018-09-12T16:17:44Z,2018-09-12T16:42:52Z,2018-09-12T16:42:52Z,MERGED,True,16,18,7,https://github.com/termim,Events syntax,4,[],https://github.com/RRZE-HPC/likwid/pull/184,https://github.com/TomTheBear,2,https://github.com/RRZE-HPC/likwid/pull/184#issuecomment-420716286,More fixes,Thank you again. Nice work and I should be more careful when adding new events,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,188,2018-11-05T13:27:32Z,2018-11-05T13:47:00Z,2018-11-05T14:49:16Z,MERGED,True,2,0,1,None,Update likwid-mpirun.lua,1,[],https://github.com/RRZE-HPC/likwid/pull/188,None,1,https://github.com/RRZE-HPC/likwid/pull/188,Function executeOpenMPI now also initializes bindstr when using Open MPI v3.x.x,Function executeOpenMPI now also initializes bindstr when using Open MPI v3.x.x,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,188,2018-11-05T13:27:32Z,2018-11-05T13:47:00Z,2018-11-05T14:49:16Z,MERGED,True,2,0,1,None,Update likwid-mpirun.lua,1,[],https://github.com/RRZE-HPC/likwid/pull/188,https://github.com/TomTheBear,2,https://github.com/RRZE-HPC/likwid/pull/188#issuecomment-435877867,Function executeOpenMPI now also initializes bindstr when using Open MPI v3.x.x,"Thank for the PR. I didn't even know that OpenMPI reached version 3.x already. I think this PR can be merged.
The travis-ci message is misleading as it fails setting up the base environment. In this case it cannot find a suitable package for gcc.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,188,2018-11-05T13:27:32Z,2018-11-05T13:47:00Z,2018-11-05T14:49:16Z,MERGED,True,2,0,1,None,Update likwid-mpirun.lua,1,[],https://github.com/RRZE-HPC/likwid/pull/188,None,3,https://github.com/RRZE-HPC/likwid/pull/188#issuecomment-435901680,Function executeOpenMPI now also initializes bindstr when using Open MPI v3.x.x,Thank you too for checking the PR this fast!,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,192,2018-11-27T09:42:55Z,2018-11-27T11:06:48Z,2019-08-22T07:11:03Z,MERGED,True,6,6,6,https://github.com/shkodm,Fix typos in Lua files,1,[],https://github.com/RRZE-HPC/likwid/pull/192,https://github.com/shkodm,1,https://github.com/RRZE-HPC/likwid/pull/192,"""Argmument"" -> ""Argument""","""Argmument"" -> ""Argument""",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,192,2018-11-27T09:42:55Z,2018-11-27T11:06:48Z,2019-08-22T07:11:03Z,MERGED,True,6,6,6,https://github.com/shkodm,Fix typos in Lua files,1,[],https://github.com/RRZE-HPC/likwid/pull/192,https://github.com/TomTheBear,2,https://github.com/RRZE-HPC/likwid/pull/192#issuecomment-442019050,"""Argmument"" -> ""Argument""",Thanks for the fixes.,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,194,2018-12-06T15:34:59Z,2018-12-11T15:17:13Z,2018-12-11T15:17:13Z,CLOSED,False,0,7,1,https://github.com/hahnjo,Do not restrict access daemon to single CPU,1,[],https://github.com/RRZE-HPC/likwid/pull/194,https://github.com/hahnjo,1,https://github.com/RRZE-HPC/likwid/pull/194,"I think this comes from a time where likwid would start one daemon
per CPU. Nowadays there is only one daemon (unless you are in a
threaded environment?) and consequently reading hardware registers
becomes really slow if there is a user application also pinned to
that CPU.","I think this comes from a time where likwid would start one daemon
per CPU. Nowadays there is only one daemon (unless you are in a
threaded environment?) and consequently reading hardware registers
becomes really slow if there is a user application also pinned to
that CPU.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,194,2018-12-06T15:34:59Z,2018-12-11T15:17:13Z,2018-12-11T15:17:13Z,CLOSED,False,0,7,1,https://github.com/hahnjo,Do not restrict access daemon to single CPU,1,[],https://github.com/RRZE-HPC/likwid/pull/194,https://github.com/TomTheBear,2,https://github.com/RRZE-HPC/likwid/pull/194#issuecomment-444935590,"I think this comes from a time where likwid would start one daemon
per CPU. Nowadays there is only one daemon (unless you are in a
threaded environment?) and consequently reading hardware registers
becomes really slow if there is a user application also pinned to
that CPU.","In the MarkerAPI case, where multiple threads require to access the hardware registers simultaneously, multiple AccessDaemons are started. I'm not sure how much overhead it creates when a thread running on core X communicates with a daemon on core Y that accesses MSRs at core X. But the idea was to avoid it and keep the daemon on the same core as the requesting thread.
In cases where one thread/process reads all cores, only one daemon is started. In this case it is pinned to the first CPU in the CPUset. This is indeed not required.
During the MarkerAPI initialization phase only one daemon is started and currently pinned to the first CPU in the eventset (the one the master thread runs on). When registering or starting the first region, LIKWID starts the remaining daemons because it detects a multi-threaded environment. The daemon for the master thread would still have the whole CPUset when not pinned in the first place but this could be fixed by changing the CPUset for the master daemon when detecting a multi-threaded environment.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,194,2018-12-06T15:34:59Z,2018-12-11T15:17:13Z,2018-12-11T15:17:13Z,CLOSED,False,0,7,1,https://github.com/hahnjo,Do not restrict access daemon to single CPU,1,[],https://github.com/RRZE-HPC/likwid/pull/194,https://github.com/hahnjo,3,https://github.com/RRZE-HPC/likwid/pull/194#issuecomment-444963426,"I think this comes from a time where likwid would start one daemon
per CPU. Nowadays there is only one daemon (unless you are in a
threaded environment?) and consequently reading hardware registers
becomes really slow if there is a user application also pinned to
that CPU.","If the MarkerAPI is the main use case, would it be an option to disable binding unless started with the MarkerAPI? If not how would you propose to solve the issue? I think this is what's causing wrong number in our monitoring system because likwid can't read the hardware counters fast enough...",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,194,2018-12-06T15:34:59Z,2018-12-11T15:17:13Z,2018-12-11T15:17:13Z,CLOSED,False,0,7,1,https://github.com/hahnjo,Do not restrict access daemon to single CPU,1,[],https://github.com/RRZE-HPC/likwid/pull/194,https://github.com/TomTheBear,4,https://github.com/RRZE-HPC/likwid/pull/194#issuecomment-446238855,"I think this comes from a time where likwid would start one daemon
per CPU. Nowadays there is only one daemon (unless you are in a
threaded environment?) and consequently reading hardware registers
becomes really slow if there is a user application also pinned to
that CPU.","I committed and improved version of your PR. Common runs start daemon without pinning, MarkerAPI/multithreaded pins the daemon as soon as detected
0148749",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,200,2019-02-03T16:56:31Z,2020-01-02T21:37:33Z,2020-01-02T21:37:33Z,CLOSED,False,105,0,1,https://github.com/davydden,python: add terminal output parser of tables,1,[],https://github.com/RRZE-HPC/likwid/pull/200,https://github.com/davydden,1,https://github.com/RRZE-HPC/likwid/pull/200,"fixes #199
@phibel I checked this with likwid-mpirun and MEM_DP group with markers, but I know for sure in it's current form it won't work for likwid-perfct as it has a different output format for regions and groups. Hopefully this script can be improved/bended to cover that case, as well as likwid-powermeter. Feel free to create PRs to this branch.","fixes #199
@phibel I checked this with likwid-mpirun and MEM_DP group with markers, but I know for sure in it's current form it won't work for likwid-perfct as it has a different output format for regions and groups. Hopefully this script can be improved/bended to cover that case, as well as likwid-powermeter. Feel free to create PRs to this branch.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,200,2019-02-03T16:56:31Z,2020-01-02T21:37:33Z,2020-01-02T21:37:33Z,CLOSED,False,105,0,1,https://github.com/davydden,python: add terminal output parser of tables,1,[],https://github.com/RRZE-HPC/likwid/pull/200,https://github.com/davydden,2,https://github.com/RRZE-HPC/likwid/pull/200#issuecomment-462452292,"fixes #199
@phibel I checked this with likwid-mpirun and MEM_DP group with markers, but I know for sure in it's current form it won't work for likwid-perfct as it has a different output format for regions and groups. Hopefully this script can be improved/bended to cover that case, as well as likwid-powermeter. Feel free to create PRs to this branch.","@TomTheBear I looked at the CVS output, although it's easier to parse, it's still not user friendly in that one needs to manually separate data for different tables (specific regions, sum or events, etc).
Looking at the output, I have a feeling that it is not easier to parse because the output completely lacks any separators of actual tables. Namely it is just a single huge table (actually not):
Region,blabla,
Group,1,
Event,Counter,e0107:0:0
Runtime (RDTSC) [s],TSC,1.205799
Region calls,CTR,10
INSTR_RETIRED_ANY,FIXC0,5067253000
...
CAS_COUNT_RD,MBOX7C0,0
CAS_COUNT_WR,MBOX7C1,0
Metric,e0107:0:0,
Runtime (RDTSC) [s],1.2058,
...
Memory data volume [GBytes],9.5893,
Operational intensity,1.0240,
Region,BLABLABLA,
Group,1,
Event,Counter,e0107:0:0
...

One could of course add some keywords, i.e. we know that Region and Group are NOT tables.
But then I would need to add all possible keywords for other table headers, i.e. Event and Metric.
So I am not yet sure if it's easier to parse CVS or terminal output. Terminal output at least has separators for start/end of the actual table:
+--------------------------------------+---------+-------------+
|                 Event                | Counter |  e1109:0:0  |
+--------------------------------------+---------+-------------+
BLABLA
+--------------------------------------+---------+-------------+

so it's easier to catch the header of the table and the actual content without extra assumptions.
Bottom line is, I think python parser is still userful as it allows one to work with parsed results via
result['vmult']['Metric_Sum']['MFLOP/s']

For my needs, I would probably stick with parsing the beautified terminal output.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,200,2019-02-03T16:56:31Z,2020-01-02T21:37:33Z,2020-01-02T21:37:33Z,CLOSED,False,105,0,1,https://github.com/davydden,python: add terminal output parser of tables,1,[],https://github.com/RRZE-HPC/likwid/pull/200,https://github.com/TomTheBear,3,https://github.com/RRZE-HPC/likwid/pull/200#issuecomment-462669308,"fixes #199
@phibel I checked this with likwid-mpirun and MEM_DP group with markers, but I know for sure in it's current form it won't work for likwid-perfct as it has a different output format for regions and groups. Hopefully this script can be improved/bended to cover that case, as well as likwid-powermeter. Feel free to create PRs to this branch.","Hi,
I understand the need of such a parser but I don't see your arguments against the CSV output. It actually contains keywords already (STRUCT and TABLE):
STRUCT,Info,3,,,
CPU name:,Intel(R) Core(TM) i7-4770 CPU @ 3.40GHz,,,,
CPU type:,Intel Core Haswell processor,,,,
CPU clock:,3.392181359 GHz,,,,
TABLE,Region copy,Group 1 Raw,L3,5,
Region Info,Core 0,Core 1,,,
RDTSC Runtime [s],0.490816,0.461983,,,
call count,10,10,,,
Event,Counter,Core 0,Core 1,,
INSTR_RETIRED_ANY,FIXC0,602320300,600771400,,
CPU_CLK_UNHALTED_CORE,FIXC1,1503458000,1498534000,,
CPU_CLK_UNHALTED_REF,FIXC2,1503456000,1498554000,,
L2_LINES_IN_ALL,PMC0,49862770,50043380,,
L2_TRANS_L2_WB,PMC1,15348130,15296480,,
TABLE,Region copy,Group 1 Raw STAT,L3,5,
[...]",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,200,2019-02-03T16:56:31Z,2020-01-02T21:37:33Z,2020-01-02T21:37:33Z,CLOSED,False,105,0,1,https://github.com/davydden,python: add terminal output parser of tables,1,[],https://github.com/RRZE-HPC/likwid/pull/200,https://github.com/davydden,4,https://github.com/RRZE-HPC/likwid/pull/200#issuecomment-462671966,"fixes #199
@phibel I checked this with likwid-mpirun and MEM_DP group with markers, but I know for sure in it's current form it won't work for likwid-perfct as it has a different output format for regions and groups. Hopefully this script can be improved/bended to cover that case, as well as likwid-powermeter. Feel free to create PRs to this branch.","@TomTheBear

It actually contains keywords already (STRUCT and TABLE):

which version of LIKWID is that? I don't have those keywords in the output from 4.2.1.
p.s. the output is through likwid-mpirun.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,200,2019-02-03T16:56:31Z,2020-01-02T21:37:33Z,2020-01-02T21:37:33Z,CLOSED,False,105,0,1,https://github.com/davydden,python: add terminal output parser of tables,1,[],https://github.com/RRZE-HPC/likwid/pull/200,https://github.com/TomTheBear,5,https://github.com/RRZE-HPC/likwid/pull/200#issuecomment-462737742,"fixes #199
@phibel I checked this with likwid-mpirun and MEM_DP group with markers, but I know for sure in it's current form it won't work for likwid-perfct as it has a different output format for regions and groups. Hopefully this script can be improved/bended to cover that case, as well as likwid-powermeter. Feel free to create PRs to this branch.",A more recent one (4.3.3) ;) The markers in CSV were added in May 2015 (ea60dda),True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,200,2019-02-03T16:56:31Z,2020-01-02T21:37:33Z,2020-01-02T21:37:33Z,CLOSED,False,105,0,1,https://github.com/davydden,python: add terminal output parser of tables,1,[],https://github.com/RRZE-HPC/likwid/pull/200,https://github.com/davydden,6,https://github.com/RRZE-HPC/likwid/pull/200#issuecomment-462739977,"fixes #199
@phibel I checked this with likwid-mpirun and MEM_DP group with markers, but I know for sure in it's current form it won't work for likwid-perfct as it has a different output format for regions and groups. Hopefully this script can be improved/bended to cover that case, as well as likwid-powermeter. Feel free to create PRs to this branch.","A more recent one (4.3.3) ;) The markers in CSV were added in May 2015 (ea60dda)

👍
ah, ok, let me try with the most recent version and see what native python parsers do with such output...",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,200,2019-02-03T16:56:31Z,2020-01-02T21:37:33Z,2020-01-02T21:37:33Z,CLOSED,False,105,0,1,https://github.com/davydden,python: add terminal output parser of tables,1,[],https://github.com/RRZE-HPC/likwid/pull/200,https://github.com/davydden,7,https://github.com/RRZE-HPC/likwid/pull/200#issuecomment-462794870,"fixes #199
@phibel I checked this with likwid-mpirun and MEM_DP group with markers, but I know for sure in it's current form it won't work for likwid-perfct as it has a different output format for regions and groups. Hopefully this script can be improved/bended to cover that case, as well as likwid-powermeter. Feel free to create PRs to this branch.","@TomTheBear 4.3.3. is not there on Emmy, whereas 4.3.2 does NOT contain keywords on CVS output. At least not from
likwid-mpirun -np 1 -nperdomain S:10 -g MEM_DP -m -O

I will until 4.3.3. is available to see how CVS works and if it's easier to parse. Will keep the PR open for now...
EDIT: not to mention that 4.3.2 is broken on Emmy :-)",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,202,2019-02-13T22:49:10Z,2019-02-14T09:59:08Z,2019-08-22T07:10:34Z,MERGED,True,1,1,1,https://github.com/shkodm,Fix typo in likwid-mpirun,1,[],https://github.com/RRZE-HPC/likwid/pull/202,https://github.com/shkodm,1,https://github.com/RRZE-HPC/likwid/pull/202,measurments -> measurements,measurments -> measurements,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,205,2019-03-03T04:25:38Z,2019-03-04T15:30:30Z,2019-03-04T15:42:40Z,MERGED,True,760,332,20,https://github.com/termim,Check data,3,[],https://github.com/RRZE-HPC/likwid/pull/205,https://github.com/termim,1,https://github.com/RRZE-HPC/likwid/pull/205,"Add script for checking event files grammar and event/subevent names consistency.
Fix typos and inconsistencies discovered by the script.
There are still several grammar errors not fixed - I couldn't find corresponding event codes in Intel docs.","Add script for checking event files grammar and event/subevent names consistency.
Fix typos and inconsistencies discovered by the script.
There are still several grammar errors not fixed - I couldn't find corresponding event codes in Intel docs.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,205,2019-03-03T04:25:38Z,2019-03-04T15:30:30Z,2019-03-04T15:42:40Z,MERGED,True,760,332,20,https://github.com/termim,Check data,3,[],https://github.com/RRZE-HPC/likwid/pull/205,https://github.com/TomTheBear,2,https://github.com/RRZE-HPC/likwid/pull/205#issuecomment-469222435,"Add script for checking event files grammar and event/subevent names consistency.
Fix typos and inconsistencies discovered by the script.
There are still several grammar errors not fixed - I couldn't find corresponding event codes in Intel docs.","Wow, I'm impressed. Thanks! It would have take weeks for me to recheck all event files.
What do you mean with

There are still several grammar errors not fixed - I couldn't find corresponding event codes in Intel docs.

There are some events in the event lists that have been added by me for convenience and completeness. There are two kinds of these events:

If there exist UMASKs that seem to correspond to each other (e.g. evicts of clean cache lines and evicts of dirty cache lines) I derive a combined event (e.g. all evicted cache lines) by OR'ing the UMASKs. The event names are chosen by me.
Some events exist in the documentation for a previous microarchitecture but are not listed anymore for the current microarchitecture although it is known that there have been only slightly changes (e.g. SandyBridge/IvyBridge or Haswell/Broadwell). In some cases I try the event of the ""old"" generation on the ""new"" generation and if it works (with reasonable counts, sometimes validated with likwid-bench), I add them to the list with a suitable name, either the original name of the ""old"" architecture or a self-chosen one to fit the naming scheme of the ""new"" architecture.

The first case can probably be processed by your script but the second one is probably a lot of work. It would be probably easier to have some files with the special cases. I thought about getting the event list from the web at compile time but I would need additional files for the self-defined events. Unfortunately, just Intel provides the events in a machine readable format at an easily downloadable location.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,205,2019-03-03T04:25:38Z,2019-03-04T15:30:30Z,2019-03-04T15:42:40Z,MERGED,True,760,332,20,https://github.com/termim,Check data,3,[],https://github.com/RRZE-HPC/likwid/pull/205,https://github.com/TomTheBear,3,https://github.com/RRZE-HPC/likwid/pull/205#issuecomment-469236135,"Add script for checking event files grammar and event/subevent names consistency.
Fix typos and inconsistencies discovered by the script.
There are still several grammar errors not fixed - I couldn't find corresponding event codes in Intel docs.",Should I merge or do you want to add more stuff to the PR?,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,205,2019-03-03T04:25:38Z,2019-03-04T15:30:30Z,2019-03-04T15:42:40Z,MERGED,True,760,332,20,https://github.com/termim,Check data,3,[],https://github.com/RRZE-HPC/likwid/pull/205,https://github.com/termim,4,https://github.com/RRZE-HPC/likwid/pull/205#issuecomment-469280849,"Add script for checking event files grammar and event/subevent names consistency.
Fix typos and inconsistencies discovered by the script.
There are still several grammar errors not fixed - I couldn't find corresponding event codes in Intel docs.","What do you mean with
There are still several grammar errors not fixed - I couldn't find corresponding event codes in Intel docs.


There are only four cases actually. You'd see them if you run
python3 check_events_files.py events
They all about missing subsystem name. I'd guess that the subsystem is PMC in those cases but
I couldn't find event code in Intel's SDM. I could just miss them though. See for example:
 perfmon_nehalem_events.txt:206:40: Expected pipe (|) separated list of subsystem names (PMC, PBOX0|PBOX1 etc.): EVENT_UOPS_DECODED                 0x3D

Should I merge or do you want to add more stuff to the PR?

If you find the changes meaningful then yes.
As a next step I'd do something similar for the group files.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,205,2019-03-03T04:25:38Z,2019-03-04T15:30:30Z,2019-03-04T15:42:40Z,MERGED,True,760,332,20,https://github.com/termim,Check data,3,[],https://github.com/RRZE-HPC/likwid/pull/205,https://github.com/TomTheBear,5,https://github.com/RRZE-HPC/likwid/pull/205#issuecomment-469294667,"Add script for checking event files grammar and event/subevent names consistency.
Fix typos and inconsistencies discovered by the script.
There are still several grammar errors not fixed - I couldn't find corresponding event codes in Intel docs.","That's true, the event UOPS_DECODED is not well defined in the event file. Like you, I assume PMC for the event. But I cannot check it anymore because it is not listed in any of my documentation. But is was already present in LIKWID 2.x (also without counter definition), so I asked the former developer where he found the event and he will check the old documentation.
Of course the script and fixed event files are meaningful. I just wanted to wait whether you want to add more commits to this PR.
Thanks for considering the group files. There is already a script test/check_group_files.py but compared to your event file script, the script is more basic.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,205,2019-03-03T04:25:38Z,2019-03-04T15:30:30Z,2019-03-04T15:42:40Z,MERGED,True,760,332,20,https://github.com/termim,Check data,3,[],https://github.com/RRZE-HPC/likwid/pull/205,https://github.com/TomTheBear,6,https://github.com/RRZE-HPC/likwid/pull/205#issuecomment-469299639,"Add script for checking event files grammar and event/subevent names consistency.
Fix typos and inconsistencies discovered by the script.
There are still several grammar errors not fixed - I couldn't find corresponding event codes in Intel docs.","I just ran your script to fix the warnings (except Nehalem UOPS_DECODED) and found this in perfmon_zen_events.txt:
EVENT_RETIRED_CLFLUSH                   0x26 PMC
UMASK_RETIRED_CLFLUSH                   0x00

EVENT_RETIRED_CPUID                     0x26 PMC
UMASK_RETIRED_CPUID                     0x00

Both use the same event ID, which is wrong. EVENT_RETIRED_CPUID has ID 0x27 but I don't know how to detect this in a reasonable way because there are cases where it should be like this: same event ID but different names (commonly in combination with some default options).  An example for this is EVENT_CYCLE_ACTIVITY for Skylake/Haswell/Broadwell.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,212,2019-03-26T08:52:13Z,2019-10-25T10:34:56Z,2019-10-25T10:34:56Z,CLOSED,False,27,56,2,https://github.com/cod3monk,Moved initialization of vectors into bench.c:runTest(),1,[],https://github.com/RRZE-HPC/likwid/pull/212,https://github.com/cod3monk,1,https://github.com/RRZE-HPC/likwid/pull/212,This resolves #210,This resolves #210,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,212,2019-03-26T08:52:13Z,2019-10-25T10:34:56Z,2019-10-25T10:34:56Z,CLOSED,False,27,56,2,https://github.com/cod3monk,Moved initialization of vectors into bench.c:runTest(),1,[],https://github.com/RRZE-HPC/likwid/pull/212,https://github.com/TomTheBear,2,https://github.com/RRZE-HPC/likwid/pull/212#issuecomment-476541789,This resolves #210,"Generally, the fix should work but I think it breaks the feature to specify the location of streams like -t copy -w S0:100MB:1-0:S1,1:S1 where threads run in domain S0 and both input and output streams are located at S1. The thread in allocator.c get pinned to domain->processorList[0] => S1 while in bench.c it is myData->processors[threadId] => S0.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,212,2019-03-26T08:52:13Z,2019-10-25T10:34:56Z,2019-10-25T10:34:56Z,CLOSED,False,27,56,2,https://github.com/cod3monk,Moved initialization of vectors into bench.c:runTest(),1,[],https://github.com/RRZE-HPC/likwid/pull/212,https://github.com/TomTheBear,3,https://github.com/RRZE-HPC/likwid/pull/212#issuecomment-476544119,This resolves #210,"Moreover, the initialization of the streams is now included in the fallback timer (https://github.com/RRZE-HPC/likwid/blob/master/bench/likwid-bench.c#L505-L508). In most cases it uses the CPU cycles as base for timing but some archs (like ARM) do not provide a simple cycle counter and uses this fallback timer.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,212,2019-03-26T08:52:13Z,2019-10-25T10:34:56Z,2019-10-25T10:34:56Z,CLOSED,False,27,56,2,https://github.com/cod3monk,Moved initialization of vectors into bench.c:runTest(),1,[],https://github.com/RRZE-HPC/likwid/pull/212,https://github.com/cod3monk,4,https://github.com/RRZE-HPC/likwid/pull/212#issuecomment-476579670,This resolves #210,"From a usability point of view, I would expect first-touch to be used if no stream locations are specified. Would you agree to that? If so, both implementations could be used and selected depending on the -w string.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,217,2019-04-03T14:59:43Z,2019-11-09T17:27:47Z,2019-11-09T17:28:03Z,MERGED,True,10699,290,117,https://github.com/TomTheBear,LIKWID support for POWER8 and POWER9 systems,26,[],https://github.com/RRZE-HPC/likwid/pull/217,https://github.com/TomTheBear,1,https://github.com/RRZE-HPC/likwid/pull/217,"This version of LIKWID supports IBM POWER8 and POWER9 processors. Thanks to the IBM Labs @ Boeblingen and Carl Love from IBM the for their support. Thanks to TU Dresden to provide a test system. This version uses perf_event as backend, so no kernel driver is required like in the other ""POWER8 pull request""","This version of LIKWID supports IBM POWER8 and POWER9 processors. Thanks to the IBM Labs @ Boeblingen and Carl Love from IBM the for their support. Thanks to TU Dresden to provide a test system. This version uses perf_event as backend, so no kernel driver is required like in the other ""POWER8 pull request""",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,217,2019-04-03T14:59:43Z,2019-11-09T17:27:47Z,2019-11-09T17:28:03Z,MERGED,True,10699,290,117,https://github.com/TomTheBear,LIKWID support for POWER8 and POWER9 systems,26,[],https://github.com/RRZE-HPC/likwid/pull/217,https://github.com/frankicia,2,https://github.com/RRZE-HPC/likwid/pull/217#issuecomment-484414838,"This version of LIKWID supports IBM POWER8 and POWER9 processors. Thanks to the IBM Labs @ Boeblingen and Carl Love from IBM the for their support. Thanks to TU Dresden to provide a test system. This version uses perf_event as backend, so no kernel driver is required like in the other ""POWER8 pull request""","When trying to compile it, I get the following error:
./src/access_x86_msr.c: In function ‘test_rdpmc’:
./src/access_x86_msr.c:83:5: error: impossible register constraint in ‘asm’
     __asm__ volatile(""rdpmc"" : ""=a"" (low), ""=d"" (high) : ""c"" (counter));
     ^~~~~~~
make: *** [GCC/access_x86_msr.o] Error 1

GCC used is 6.4.0. OS is Red Hat Enterprise Linux Server 7.5",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,217,2019-04-03T14:59:43Z,2019-11-09T17:27:47Z,2019-11-09T17:28:03Z,MERGED,True,10699,290,117,https://github.com/TomTheBear,LIKWID support for POWER8 and POWER9 systems,26,[],https://github.com/RRZE-HPC/likwid/pull/217,https://github.com/TomTheBear,3,https://github.com/RRZE-HPC/likwid/pull/217#issuecomment-484416920,"This version of LIKWID supports IBM POWER8 and POWER9 processors. Thanks to the IBM Labs @ Boeblingen and Carl Love from IBM the for their support. Thanks to TU Dresden to provide a test system. This version uses perf_event as backend, so no kernel driver is required like in the other ""POWER8 pull request""",You have to switch the compiler setting in config.mk to GCCPOWER. This filters out the x86- and arm-specific files.,True,{'THUMBS_UP': ['https://github.com/frankicia']}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,217,2019-04-03T14:59:43Z,2019-11-09T17:27:47Z,2019-11-09T17:28:03Z,MERGED,True,10699,290,117,https://github.com/TomTheBear,LIKWID support for POWER8 and POWER9 systems,26,[],https://github.com/RRZE-HPC/likwid/pull/217,https://github.com/frankicia,4,https://github.com/RRZE-HPC/likwid/pull/217#issuecomment-484418163,"This version of LIKWID supports IBM POWER8 and POWER9 processors. Thanks to the IBM Labs @ Boeblingen and Carl Love from IBM the for their support. Thanks to TU Dresden to provide a test system. This version uses perf_event as backend, so no kernel driver is required like in the other ""POWER8 pull request""","Yes, I realized that.
With GCCPOWER there is a small error in file src/includes/perfmon_perfevent.h
Line 83:
#if defined(x86_64) || defined(i386) || define(_ARCH_PPC)
should be
#if defined(x86_64) || defined(i386) || defined(_ARCH_PPC)",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,217,2019-04-03T14:59:43Z,2019-11-09T17:27:47Z,2019-11-09T17:28:03Z,MERGED,True,10699,290,117,https://github.com/TomTheBear,LIKWID support for POWER8 and POWER9 systems,26,[],https://github.com/RRZE-HPC/likwid/pull/217,https://github.com/TomTheBear,5,https://github.com/RRZE-HPC/likwid/pull/217#issuecomment-507239992,"This version of LIKWID supports IBM POWER8 and POWER9 processors. Thanks to the IBM Labs @ Boeblingen and Carl Love from IBM the for their support. Thanks to TU Dresden to provide a test system. This version uses perf_event as backend, so no kernel driver is required like in the other ""POWER8 pull request""","For POWER9, there are still devices not supported by this PR. I have to see where I get enough documentation to integrate them into LIKWID.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,219,2019-05-20T12:58:25Z,2019-10-15T10:11:16Z,2019-10-15T10:13:54Z,MERGED,True,2727,2807,19,https://github.com/TomTheBear,Persistent freq daemon,22,[],https://github.com/RRZE-HPC/likwid/pull/219,https://github.com/TomTheBear,1,https://github.com/RRZE-HPC/likwid/pull/219,"I was asked to reimplement the CPU frequency functions because they have a high latency. This is caused by forwarding all requests to the frequency daemon, even the reads. Moreover, the frequency daemon always executed exactly one operation and exited, so each request caused a few process creations.
With the pull request, the daemon is started only once and the library communicates over a UNIX socket with the daemon. Moreover, all reads are performed by the library itself and only writes are forwarded to the daemon.","I was asked to reimplement the CPU frequency functions because they have a high latency. This is caused by forwarding all requests to the frequency daemon, even the reads. Moreover, the frequency daemon always executed exactly one operation and exited, so each request caused a few process creations.
With the pull request, the daemon is started only once and the library communicates over a UNIX socket with the daemon. Moreover, all reads are performed by the library itself and only writes are forwarded to the daemon.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,222,2019-05-31T05:25:04Z,2019-06-01T13:17:14Z,2019-06-01T13:17:14Z,MERGED,True,3,3,1,https://github.com/dkuts,Changing type of variable 'offset',2,[],https://github.com/RRZE-HPC/likwid/pull/222,https://github.com/dkuts,1,https://github.com/RRZE-HPC/likwid/pull/222,"Changing type from 'int' to 'size_t' to avoid overflowing.
At some cases, offset may be bigger than 2 147 483 647, that cause negative number and access to wrong memory address.
example:
likwid-bench -t copy_avx -w S0:48GB:48 −i 2048","Changing type from 'int' to 'size_t' to avoid overflowing.
At some cases, offset may be bigger than 2 147 483 647, that cause negative number and access to wrong memory address.
example:
likwid-bench -t copy_avx -w S0:48GB:48 −i 2048",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,222,2019-05-31T05:25:04Z,2019-06-01T13:17:14Z,2019-06-01T13:17:14Z,MERGED,True,3,3,1,https://github.com/dkuts,Changing type of variable 'offset',2,[],https://github.com/RRZE-HPC/likwid/pull/222,https://github.com/TomTheBear,2,https://github.com/RRZE-HPC/likwid/pull/222#issuecomment-497648397,"Changing type from 'int' to 'size_t' to avoid overflowing.
At some cases, offset may be bigger than 2 147 483 647, that cause negative number and access to wrong memory address.
example:
likwid-bench -t copy_avx -w S0:48GB:48 −i 2048","Thanks for the PR. There are more locations where we should do adjustments (printf in line 138 throws warnings with %d format and size_t variable, function getIterSingle() uses an int offset as well). How you want to do it? Do you want to integrate all changes in your PR or should I merge your PR and do the other changes myself?",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,222,2019-05-31T05:25:04Z,2019-06-01T13:17:14Z,2019-06-01T13:17:14Z,MERGED,True,3,3,1,https://github.com/dkuts,Changing type of variable 'offset',2,[],https://github.com/RRZE-HPC/likwid/pull/222,https://github.com/dkuts,3,https://github.com/RRZE-HPC/likwid/pull/222#issuecomment-497933905,"Changing type from 'int' to 'size_t' to avoid overflowing.
At some cases, offset may be bigger than 2 147 483 647, that cause negative number and access to wrong memory address.
example:
likwid-bench -t copy_avx -w S0:48GB:48 −i 2048","OK, I've fixed other usage and printf format.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,222,2019-05-31T05:25:04Z,2019-06-01T13:17:14Z,2019-06-01T13:17:14Z,MERGED,True,3,3,1,https://github.com/dkuts,Changing type of variable 'offset',2,[],https://github.com/RRZE-HPC/likwid/pull/222,https://github.com/TomTheBear,4,https://github.com/RRZE-HPC/likwid/pull/222#issuecomment-497944437,"Changing type from 'int' to 'size_t' to avoid overflowing.
At some cases, offset may be bigger than 2 147 483 647, that cause negative number and access to wrong memory address.
example:
likwid-bench -t copy_avx -w S0:48GB:48 −i 2048",Thanks for the update. Ready to merge.,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,229,2019-06-28T03:07:55Z,2019-06-28T14:16:15Z,2019-06-28T15:47:26Z,MERGED,True,52,21,1,https://github.com/termim,Add check for event name duplicates,2,[],https://github.com/RRZE-HPC/likwid/pull/229,https://github.com/termim,1,https://github.com/RRZE-HPC/likwid/pull/229,"Please consider this PR which introduces checks for event names uniqueness.
Running the updated script as
<path_to_likwid>/test/check_events_files.py events -v 
produces ~90 cases when the same name is used for events with different UMASK.","Please consider this PR which introduces checks for event names uniqueness.
Running the updated script as
<path_to_likwid>/test/check_events_files.py events -v 
produces ~90 cases when the same name is used for events with different UMASK.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,229,2019-06-28T03:07:55Z,2019-06-28T14:16:15Z,2019-06-28T15:47:26Z,MERGED,True,52,21,1,https://github.com/termim,Add check for event name duplicates,2,[],https://github.com/RRZE-HPC/likwid/pull/229,https://github.com/TomTheBear,2,https://github.com/RRZE-HPC/likwid/pull/229#issuecomment-506661853,"Please consider this PR which introduces checks for event names uniqueness.
Running the updated script as
<path_to_likwid>/test/check_events_files.py events -v 
produces ~90 cases when the same name is used for events with different UMASK.","Thanks for the PR. Such a script is very helpful.
I tried your script and got some problems. The first one was missing of the pyparsing module. Not the big deal. But after installing pyparsing the output is very limited (no output):
$ python3 check_events_files.py events -v
$

I tried the self test and one test fails:
$ python3 check_events_files.py self
======================================================================
ERROR: test_event (__main__.test_EventParser.<locals>.TestEventParser)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""check_events_files.py"", line 291, in test_event
    res = self.parser.Evt.parseString(""EVENT_C_LO_AD_CREDITS_EMPTY             0x22 RBOX0C0|RBOX0C1|RBOX1C0|RBOX1C1"").asDict()
  File ""/usr/local/lib/python3.6/dist-packages/pyparsing.py"", line 1804, in parseString
    loc, tokens = self._parse( instring, 0 )
  File ""/usr/local/lib/python3.6/dist-packages/pyparsing.py"", line 1581, in _parseNoCache
    tokens = fn( instring, tokensStart, retTokens )
  File ""/usr/local/lib/python3.6/dist-packages/pyparsing.py"", line 1203, in wrapper
    ret = func(*args[limit[0]:])
  File ""check_events_files.py"", line 140, in _set_event
    event_head.update(line_num = self.line_num)
AttributeError: 'EventParser' object has no attribute 'line_num'

----------------------------------------------------------------------",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,229,2019-06-28T03:07:55Z,2019-06-28T14:16:15Z,2019-06-28T15:47:26Z,MERGED,True,52,21,1,https://github.com/termim,Add check for event name duplicates,2,[],https://github.com/RRZE-HPC/likwid/pull/229,https://github.com/TomTheBear,3,https://github.com/RRZE-HPC/likwid/pull/229#issuecomment-506749957,"Please consider this PR which introduces checks for event names uniqueness.
Running the updated script as
<path_to_likwid>/test/check_events_files.py events -v 
produces ~90 cases when the same name is used for events with different UMASK.","Thanks, that fixed everything. I get output from the events command and the self tests work. Ready to merge.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,229,2019-06-28T03:07:55Z,2019-06-28T14:16:15Z,2019-06-28T15:47:26Z,MERGED,True,52,21,1,https://github.com/termim,Add check for event name duplicates,2,[],https://github.com/RRZE-HPC/likwid/pull/229,https://github.com/termim,4,https://github.com/RRZE-HPC/likwid/pull/229#issuecomment-506759821,"Please consider this PR which introduces checks for event names uniqueness.
Running the updated script as
<path_to_likwid>/test/check_events_files.py events -v 
produces ~90 cases when the same name is used for events with different UMASK.",You probably run the script from outside of the likwid workspace. The default search path for the input files is ../src/include. I've added a warning to reduce confusion. Please see  #230.,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,229,2019-06-28T03:07:55Z,2019-06-28T14:16:15Z,2019-06-28T15:47:26Z,MERGED,True,52,21,1,https://github.com/termim,Add check for event name duplicates,2,[],https://github.com/RRZE-HPC/likwid/pull/229,https://github.com/TomTheBear,5,https://github.com/RRZE-HPC/likwid/pull/229#issuecomment-506772632,"Please consider this PR which introduces checks for event names uniqueness.
Running the updated script as
<path_to_likwid>/test/check_events_files.py events -v 
produces ~90 cases when the same name is used for events with different UMASK.","From the main directory, yes, so ../src/include of course failed.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,229,2019-06-28T03:07:55Z,2019-06-28T14:16:15Z,2019-06-28T15:47:26Z,MERGED,True,52,21,1,https://github.com/termim,Add check for event name duplicates,2,[],https://github.com/RRZE-HPC/likwid/pull/229,https://github.com/TomTheBear,6,https://github.com/RRZE-HPC/likwid/pull/229#issuecomment-506773501,"Please consider this PR which introduces checks for event names uniqueness.
Running the updated script as
<path_to_likwid>/test/check_events_files.py events -v 
produces ~90 cases when the same name is used for events with different UMASK.",Is there a reason why the output is to stderr?,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,229,2019-06-28T03:07:55Z,2019-06-28T14:16:15Z,2019-06-28T15:47:26Z,MERGED,True,52,21,1,https://github.com/termim,Add check for event name duplicates,2,[],https://github.com/RRZE-HPC/likwid/pull/229,https://github.com/termim,7,https://github.com/RRZE-HPC/likwid/pull/229#issuecomment-506778085,"Please consider this PR which introduces checks for event names uniqueness.
Running the updated script as
<path_to_likwid>/test/check_events_files.py events -v 
produces ~90 cases when the same name is used for events with different UMASK.","Is there a reason why the output is to stderr?

Errors are supposed to go to stderr, aren't they?",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,229,2019-06-28T03:07:55Z,2019-06-28T14:16:15Z,2019-06-28T15:47:26Z,MERGED,True,52,21,1,https://github.com/termim,Add check for event name duplicates,2,[],https://github.com/RRZE-HPC/likwid/pull/229,https://github.com/TomTheBear,8,https://github.com/RRZE-HPC/likwid/pull/229#issuecomment-506782363,"Please consider this PR which introduces checks for event names uniqueness.
Running the updated script as
<path_to_likwid>/test/check_events_files.py events -v 
produces ~90 cases when the same name is used for events with different UMASK.","OK, accepted. Have a nice weekend.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,230,2019-06-28T14:42:31Z,2019-06-28T15:19:49Z,2019-06-28T15:19:49Z,MERGED,True,6,1,1,https://github.com/termim,Warn user if there is no any events files found in default directory.,1,[],https://github.com/RRZE-HPC/likwid/pull/230,https://github.com/termim,1,https://github.com/RRZE-HPC/likwid/pull/230,Prompt the user to use --input-dir option if no files found in the default input directory.,Prompt the user to use --input-dir option if no files found in the default input directory.,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,233,2019-07-20T17:50:57Z,2019-08-30T09:44:21Z,2019-08-30T09:44:21Z,MERGED,True,1262,860,245,https://github.com/termim,Group syntax,3,[],https://github.com/RRZE-HPC/likwid/pull/233,https://github.com/termim,1,https://github.com/RRZE-HPC/likwid/pull/233,"Please consider the following changes:

add syntax checker for group files
fix syntax/typo errors in the group files","Please consider the following changes:

add syntax checker for group files
fix syntax/typo errors in the group files",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,233,2019-07-20T17:50:57Z,2019-08-30T09:44:21Z,2019-08-30T09:44:21Z,MERGED,True,1262,860,245,https://github.com/termim,Group syntax,3,[],https://github.com/RRZE-HPC/likwid/pull/233,https://github.com/TomTheBear,2,https://github.com/RRZE-HPC/likwid/pull/233#issuecomment-517061773,"Please consider the following changes:

add syntax checker for group files
fix syntax/typo errors in the group files","The checker is quite strict but it's fine like that. For example, LIKWID requires the LONG section to be non-empty but all content is up to the group creator. So, if he/she doesn't want the formulas shown in the documentation section (LONG), that's fine. I always add the formulas, so that's why it is fine for me.
So, from my side it is ready to merge.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,233,2019-07-20T17:50:57Z,2019-08-30T09:44:21Z,2019-08-30T09:44:21Z,MERGED,True,1262,860,245,https://github.com/termim,Group syntax,3,[],https://github.com/RRZE-HPC/likwid/pull/233,https://github.com/termim,3,https://github.com/RRZE-HPC/likwid/pull/233#issuecomment-517753253,"Please consider the following changes:

add syntax checker for group files
fix syntax/typo errors in the group files","Please let me know if you want to relax this check or make it optional.
Actually the 'Formulas' part is somewhat redundant as it could be automatically produced from 'METRICS' and 'EVENTSET'. I was thinking even to verify formulas as I saw a discrepancy between formula and eventset somewhere.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,233,2019-07-20T17:50:57Z,2019-08-30T09:44:21Z,2019-08-30T09:44:21Z,MERGED,True,1262,860,245,https://github.com/termim,Group syntax,3,[],https://github.com/RRZE-HPC/likwid/pull/233,https://github.com/TomTheBear,4,https://github.com/RRZE-HPC/likwid/pull/233#issuecomment-518055230,"Please consider the following changes:

add syntax checker for group files
fix syntax/typo errors in the group files","I'm fine with the current handling in your parser. Formula verification would be good, though. I do copy&paste most of the time for the base skeleton and forget to adjust the formulas sometimes.
I already thought about a ""group creator"" where you add just a short description, eventset, metrics and the long documentation (without formulas) and the remaining stuff is added automatically but you still have to do the main work, so I thought adding the formulas manually doesn't hurt anymore after searching for the appropriate event and counter and wrote the metric formulas.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,239,2019-09-02T13:54:58Z,2019-09-03T08:22:35Z,2019-11-09T17:28:10Z,MERGED,True,31,0,2,https://github.com/cod3monk,added triad and daxpy bench kernels on armv8,1,[],https://github.com/RRZE-HPC/likwid/pull/239,https://github.com/cod3monk,1,https://github.com/RRZE-HPC/likwid/pull/239,currently without unrolling,currently without unrolling,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,239,2019-09-02T13:54:58Z,2019-09-03T08:22:35Z,2019-11-09T17:28:10Z,MERGED,True,31,0,2,https://github.com/cod3monk,added triad and daxpy bench kernels on armv8,1,[],https://github.com/RRZE-HPC/likwid/pull/239,https://github.com/TomTheBear,2,https://github.com/RRZE-HPC/likwid/pull/239#issuecomment-527357520,currently without unrolling,Thanks.,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,243,2019-10-15T17:57:42Z,2019-10-17T09:41:54Z,2019-10-24T15:50:17Z,MERGED,True,1621,531,10,https://github.com/TomTheBear,Switching from Lua-based calculator back to fast C-based calculator,4,[],https://github.com/RRZE-HPC/likwid/pull/243,https://github.com/TomTheBear,1,https://github.com/RRZE-HPC/likwid/pull/243,,,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,244,2019-10-22T15:13:50Z,2019-10-25T10:35:18Z,2019-10-25T10:35:18Z,MERGED,True,10,19,3,https://github.com/ohlmann,Allow arbitrary thread numbers per work group in likwid-bench,1,[],https://github.com/RRZE-HPC/likwid/pull/244,https://github.com/ohlmann,1,https://github.com/RRZE-HPC/likwid/pull/244,"Up to now, different work groups must have the same thread number for likwid-bench to work properly. With this change, different work groups can have different numbers of threads, which is useful for e.g., when one wants to have 2 threads on the first socket and only one on the second.
Example: likwid-bench -t copy -w S0:10MB:2 -w S1:10MB:1","Up to now, different work groups must have the same thread number for likwid-bench to work properly. With this change, different work groups can have different numbers of threads, which is useful for e.g., when one wants to have 2 threads on the first socket and only one on the second.
Example: likwid-bench -t copy -w S0:10MB:2 -w S1:10MB:1",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,244,2019-10-22T15:13:50Z,2019-10-25T10:35:18Z,2019-10-25T10:35:18Z,MERGED,True,10,19,3,https://github.com/ohlmann,Allow arbitrary thread numbers per work group in likwid-bench,1,[],https://github.com/RRZE-HPC/likwid/pull/244,https://github.com/ohlmann,2,https://github.com/RRZE-HPC/likwid/pull/244#issuecomment-545013823,"Up to now, different work groups must have the same thread number for likwid-bench to work properly. With this change, different work groups can have different numbers of threads, which is useful for e.g., when one wants to have 2 threads on the first socket and only one on the second.
Example: likwid-bench -t copy -w S0:10MB:2 -w S1:10MB:1",I just saw that this probably resolves #210. My motivation was similar to what is mentioned there.,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,244,2019-10-22T15:13:50Z,2019-10-25T10:35:18Z,2019-10-25T10:35:18Z,MERGED,True,10,19,3,https://github.com/ohlmann,Allow arbitrary thread numbers per work group in likwid-bench,1,[],https://github.com/RRZE-HPC/likwid/pull/244,https://github.com/TomTheBear,3,https://github.com/RRZE-HPC/likwid/pull/244#issuecomment-545024554,"Up to now, different work groups must have the same thread number for likwid-bench to work properly. With this change, different work groups can have different numbers of threads, which is useful for e.g., when one wants to have 2 threads on the first socket and only one on the second.
Example: likwid-bench -t copy -w S0:10MB:2 -w S1:10MB:1","Thanks for the PR. I can understand the need for this patch but I do not recommend to use different number of threads per workgroup. If you have one group with X threads that saturate the memory bandwidth and one group with Y (Y << X), the second group probably executes the benchmark with higher performance as there is less competition/pressure on the memory interface.
Moreover, the patch is not complete. Until now, the output just takes the max time of all threads and the size of group0. The size and iterations per thread are taken just from group0 but should be presented separately for each group with different thread counts.
The #210 is not affected by this PR. For #210, the initialization of the arrays needs to be delayed until the threads are started (https://github.com/RRZE-HPC/likwid/blob/master/bench/likwid-bench.c#L506).",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,244,2019-10-22T15:13:50Z,2019-10-25T10:35:18Z,2019-10-25T10:35:18Z,MERGED,True,10,19,3,https://github.com/ohlmann,Allow arbitrary thread numbers per work group in likwid-bench,1,[],https://github.com/RRZE-HPC/likwid/pull/244,https://github.com/ohlmann,4,https://github.com/RRZE-HPC/likwid/pull/244#issuecomment-545289819,"Up to now, different work groups must have the same thread number for likwid-bench to work properly. With this change, different work groups can have different numbers of threads, which is useful for e.g., when one wants to have 2 threads on the first socket and only one on the second.
Example: likwid-bench -t copy -w S0:10MB:2 -w S1:10MB:1","Regarding the first point: I agree that there will be different performance in different groups, but one can change the size of the data (i.e. the workload) accordingly. Moreover, one can also produce load imbalances right now by using different sizes for different groups.
Regarding the second point: as far as I understand the code, iters_per_thread should be the same for all threads. With this, the output of ""MFlops/s"" and ""MByte/s"" should be fine because they use as size the sum over all threads. But already right now, the size per thread can be different for different groups because the size can be different, so I guess this would need to be adapted anyway?
In any case, I think one has to know what happens on the system in order to understand the numbers.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,244,2019-10-22T15:13:50Z,2019-10-25T10:35:18Z,2019-10-25T10:35:18Z,MERGED,True,10,19,3,https://github.com/ohlmann,Allow arbitrary thread numbers per work group in likwid-bench,1,[],https://github.com/RRZE-HPC/likwid/pull/244,https://github.com/TomTheBear,5,https://github.com/RRZE-HPC/likwid/pull/244#issuecomment-545549954,"Up to now, different work groups must have the same thread number for likwid-bench to work properly. With this change, different work groups can have different numbers of threads, which is useful for e.g., when one wants to have 2 threads on the first socket and only one on the second.
Example: likwid-bench -t copy -w S0:10MB:2 -w S1:10MB:1",I'll merge the PR but add warnings for different sizes and different number of threads. Just to notice users that special attention is needed when using these features.,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,245,2019-10-23T15:25:14Z,2019-10-23T17:20:06Z,2019-10-24T15:50:24Z,MERGED,True,1773,312,19,https://github.com/TomTheBear,Adding AMD Zen2 microarch,8,[],https://github.com/RRZE-HPC/likwid/pull/245,https://github.com/TomTheBear,1,https://github.com/RRZE-HPC/likwid/pull/245,Thanks to LANL for providing CPU family and model numbers,Thanks to LANL for providing CPU family and model numbers,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,246,2019-10-23T15:27:59Z,2019-10-23T15:52:50Z,2019-10-23T15:52:55Z,MERGED,True,19573,12571,64,https://github.com/TomTheBear,Update hwloc to 2.1.0,3,[],https://github.com/RRZE-HPC/likwid/pull/246,https://github.com/TomTheBear,1,https://github.com/RRZE-HPC/likwid/pull/246,,,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,247,2019-10-25T10:25:17Z,2019-10-25T10:34:31Z,2019-11-07T10:00:57Z,MERGED,True,123,50,8,https://github.com/TomTheBear,Add initialization per thread ,1,[],https://github.com/RRZE-HPC/likwid/pull/247,https://github.com/TomTheBear,1,https://github.com/RRZE-HPC/likwid/pull/247,"with a new command line option and update documentation.
The first-touch mode can be activated with -W instead of -w for a group. Stream placement is not available in first-touch mode.
This PR is similar to #212 but enables both modes and introduces a command line option. In #212 the first-touch mode is made the default.","with a new command line option and update documentation.
The first-touch mode can be activated with -W instead of -w for a group. Stream placement is not available in first-touch mode.
This PR is similar to #212 but enables both modes and introduces a command line option. In #212 the first-touch mode is made the default.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,249,2019-10-31T21:18:52Z,2019-11-02T11:01:02Z,2019-11-02T11:01:10Z,MERGED,True,1861,13,13,https://github.com/TomTheBear,Likwid bench/dynload,5,[],https://github.com/RRZE-HPC/likwid/pull/249,https://github.com/TomTheBear,1,https://github.com/RRZE-HPC/likwid/pull/249,"This PR allows the addition of benchmark kernels to likwid-bench without recompilation. likwid-bench searches in $HOME/.likwid/bench/ for PTT files, converts them the arch-specific assembly and compiles the file.","This PR allows the addition of benchmark kernels to likwid-bench without recompilation. likwid-bench searches in $HOME/.likwid/bench/ for PTT files, converts them the arch-specific assembly and compiles the file.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,250,2019-11-01T17:26:02Z,2019-11-02T11:01:36Z,2019-11-07T10:00:53Z,MERGED,True,55,1,2,https://github.com/TomTheBear,Add support for generic event,1,[],https://github.com/RRZE-HPC/likwid/pull/250,https://github.com/TomTheBear,1,https://github.com/RRZE-HPC/likwid/pull/250,"Issue #57
This adds an event GENERIC_EVENT that can be used with all counters like:
GENERIC_EVENT::CONFIG=0x00:UMASK=0x00 (:other options available for the counter)","Issue #57
This adds an event GENERIC_EVENT that can be used with all counters like:
GENERIC_EVENT::CONFIG=0x00:UMASK=0x00 (:other options available for the counter)",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,251,2019-11-04T20:36:37Z,2019-11-07T09:58:17Z,2019-11-07T10:00:51Z,MERGED,True,317,86,4,https://github.com/TomTheBear,Add function to create and manipulate performance groups at runtime,2,[],https://github.com/RRZE-HPC/likwid/pull/251,https://github.com/TomTheBear,1,https://github.com/RRZE-HPC/likwid/pull/251,,,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,252,2019-11-07T10:56:06Z,2019-11-07T11:12:26Z,2019-11-09T17:28:06Z,MERGED,True,5477,16,40,https://github.com/TomTheBear,Add external dependency GOTCHA,3,[],https://github.com/RRZE-HPC/likwid/pull/252,https://github.com/TomTheBear,1,https://github.com/RRZE-HPC/likwid/pull/252,"Source at https://github.com/LLNL/GOTCHA
The cmake-based build system was replaced with the default one in LIKWID to avoid having cmake as dependency.","Source at https://github.com/LLNL/GOTCHA
The cmake-based build system was replaced with the default one in LIKWID to avoid having cmake as dependency.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,253,2019-11-09T21:34:00Z,2019-11-09T23:46:50Z,2019-11-09T23:47:19Z,MERGED,True,6258,172,32,https://github.com/TomTheBear,Add backend for Nvidia GPUs,11,[],https://github.com/RRZE-HPC/likwid/pull/253,https://github.com/TomTheBear,1,https://github.com/RRZE-HPC/likwid/pull/253,Current supports CUPTI Event and Metric API. The PerfWorks API seems not to be public.,Current supports CUPTI Event and Metric API. The PerfWorks API seems not to be public.,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,254,2019-11-19T20:56:56Z,2019-11-19T21:16:13Z,2019-11-20T09:33:05Z,MERGED,True,1,1,1,https://github.com/jrmadsen,Fixed likwid-markers.h -> likwid-marker.h in likwid.h,1,[],https://github.com/RRZE-HPC/likwid/pull/254,https://github.com/jrmadsen,1,https://github.com/RRZE-HPC/likwid/pull/254,"Typo here
#ifndef LIKWID_MARKER_INIT
#include <likwid-markers.h>
#endif
Changed to
#ifndef LIKWID_MARKER_INIT
#include <likwid-marker.h>
#endif","Typo here
#ifndef LIKWID_MARKER_INIT
#include <likwid-markers.h>
#endif
Changed to
#ifndef LIKWID_MARKER_INIT
#include <likwid-marker.h>
#endif",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,257,2019-12-06T13:46:17Z,2020-02-25T14:20:42Z,2020-02-25T14:20:42Z,MERGED,True,1530,1222,33,https://github.com/jimmysitu,Add temperature and voltage for Intel Core CPUs,15,['enhancement'],https://github.com/RRZE-HPC/likwid/pull/257,https://github.com/jimmysitu,1,https://github.com/RRZE-HPC/likwid/pull/257,"Hi, All
I add two kinds of event here

Temperature of Intel Core processor PP0(CPU) and PP1(GPU)
Core voltage

Both event are tested on broadwell and skylake CPU
Thanks","Hi, All
I add two kinds of event here

Temperature of Intel Core processor PP0(CPU) and PP1(GPU)
Core voltage

Both event are tested on broadwell and skylake CPU
Thanks",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,257,2019-12-06T13:46:17Z,2020-02-25T14:20:42Z,2020-02-25T14:20:42Z,MERGED,True,1530,1222,33,https://github.com/jimmysitu,Add temperature and voltage for Intel Core CPUs,15,['enhancement'],https://github.com/RRZE-HPC/likwid/pull/257,https://github.com/TomTheBear,2,https://github.com/RRZE-HPC/likwid/pull/257#issuecomment-562670685,"Hi, All
I add two kinds of event here

Temperature of Intel Core processor PP0(CPU) and PP1(GPU)
Core voltage

Both event are tested on broadwell and skylake CPU
Thanks","Many thanks for the PR. Expect some delay (1-2 weeks) until I report back, I'm currently quite busy.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,257,2019-12-06T13:46:17Z,2020-02-25T14:20:42Z,2020-02-25T14:20:42Z,MERGED,True,1530,1222,33,https://github.com/jimmysitu,Add temperature and voltage for Intel Core CPUs,15,['enhancement'],https://github.com/RRZE-HPC/likwid/pull/257,https://github.com/TomTheBear,3,https://github.com/RRZE-HPC/likwid/pull/257#issuecomment-566496780,"Hi, All
I add two kinds of event here

Temperature of Intel Core processor PP0(CPU) and PP1(GPU)
Core voltage

Both event are tested on broadwell and skylake CPU
Thanks","I checked your code and thanks for using similar coding style.
The PR consists of two features:

CPU voltage readings
Temperature readings for the Intel Desktop memory controllers

I found the CPU voltage registers and offsets in Intel SDM but I have not found the information for the temperature readings. Can you please point me to the documentation?
The CPU voltage readings are added to Intel Broadwell and Skylake. Why not the other architectures? According to SDM, it should be available since SandyBridge. Because you couldn't test it or are there other reasons?
Can you please make the shifting and masking in voltage.h file more precise? result >> 32 is too coarse. SDM tells us, the value is 16 bit wide, so (result >>32) & 0xFFFF would be sufficient.
You have added 8 new types MBOX0TMP to MBOX7TMP but your code uses only MBOX0TMP. Is there a reason for this?",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,257,2019-12-06T13:46:17Z,2020-02-25T14:20:42Z,2020-02-25T14:20:42Z,MERGED,True,1530,1222,33,https://github.com/jimmysitu,Add temperature and voltage for Intel Core CPUs,15,['enhancement'],https://github.com/RRZE-HPC/likwid/pull/257,https://github.com/jimmysitu,4,https://github.com/RRZE-HPC/likwid/pull/257#issuecomment-567029683,"Hi, All
I add two kinds of event here

Temperature of Intel Core processor PP0(CPU) and PP1(GPU)
Core voltage

Both event are tested on broadwell and skylake CPU
Thanks","Hi, @TomTheBear

Temperature readings are mentioned in Intel CPUs datasheet vol.2. Section 7.77 and 7.78. Although it is first mentioned on a 6th gen core datasheet. I tested it works in 5th gen core.
I only have Broadwell and Skylake CPUs, and I not sure if this update works for others CPU family.
I think the voltage reading should works since Sandy bridge.
MBOX0TMP to MBOX7TMP are copy cat as MBOX0 to MBOX7. Just for backup. I am not sure if there are so many MBOX on a multi socket server.
I update the PR to mask the voltage more precise",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,257,2019-12-06T13:46:17Z,2020-02-25T14:20:42Z,2020-02-25T14:20:42Z,MERGED,True,1530,1222,33,https://github.com/jimmysitu,Add temperature and voltage for Intel Core CPUs,15,['enhancement'],https://github.com/RRZE-HPC/likwid/pull/257,https://github.com/TomTheBear,5,https://github.com/RRZE-HPC/likwid/pull/257#issuecomment-567044904,"Hi, All
I add two kinds of event here

Temperature of Intel Core processor PP0(CPU) and PP1(GPU)
Core voltage

Both event are tested on broadwell and skylake CPU
Thanks","Hi,
thanks for the link to the datasheet. There is quite some useful information in there besides the temperature readings. Why have you added only PP0 and PP1 but not the PKG or EDRAM domain (7.75, 7.76)? Can you please use a bitmask as well when reading the temperature, it's only the lower 8 bits, so please add a line data &= 0xFF; after reading the value from hardware.
I'm fine with adding it for Skylake and Broadwell first. I have SandyBridge, Haswell and Coffeelake Desktop chips in my playground. I can test it after the merge of your PR.
The clientmem interface uses only MBOX0. The other types MBOX1-MBOX7 are only used for server-class chips which have 4 to 8 different PCI devices, one for each memory channel. The additional type MBOX0TMP is basically not needed, it just simplifies the calculation of the result. You can remove the additional types MBOX1TMP to MBOX7TMP.
The voltage part seems fine already and would be mergable but it's better to wait until the MBOXxTMP issues are resolved since it's a single PR.
I'm currently thinking about giving the clientmem interface a seperate type because it seems to work also on server-class chips (which use the MBOX0 type differently) because some of the information seems interesting for desktop and server chips (like the temperature readings).",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,257,2019-12-06T13:46:17Z,2020-02-25T14:20:42Z,2020-02-25T14:20:42Z,MERGED,True,1530,1222,33,https://github.com/jimmysitu,Add temperature and voltage for Intel Core CPUs,15,['enhancement'],https://github.com/RRZE-HPC/likwid/pull/257,https://github.com/jimmysitu,6,https://github.com/RRZE-HPC/likwid/pull/257#issuecomment-568188361,"Hi, All
I add two kinds of event here

Temperature of Intel Core processor PP0(CPU) and PP1(GPU)
Core voltage

Both event are tested on broadwell and skylake CPU
Thanks","Hi, @TomTheBear

Fix done
PKG temp seem can be read from MSR so I do not add it in MBOX0TMP
I am not sure EDRAM temp works since my CPUs are mobile version and do not have a EDRAM I suppose. Maybe you can try on your desktop",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,257,2019-12-06T13:46:17Z,2020-02-25T14:20:42Z,2020-02-25T14:20:42Z,MERGED,True,1530,1222,33,https://github.com/jimmysitu,Add temperature and voltage for Intel Core CPUs,15,['enhancement'],https://github.com/RRZE-HPC/likwid/pull/257,https://github.com/TomTheBear,7,https://github.com/RRZE-HPC/likwid/pull/257#issuecomment-569689670,"Hi, All
I add two kinds of event here

Temperature of Intel Core processor PP0(CPU) and PP1(GPU)
Core voltage

Both event are tested on broadwell and skylake CPU
Thanks","Looks good, Thanks.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,257,2019-12-06T13:46:17Z,2020-02-25T14:20:42Z,2020-02-25T14:20:42Z,MERGED,True,1530,1222,33,https://github.com/jimmysitu,Add temperature and voltage for Intel Core CPUs,15,['enhancement'],https://github.com/RRZE-HPC/likwid/pull/257,https://github.com/TomTheBear,8,https://github.com/RRZE-HPC/likwid/pull/257#issuecomment-570219319,"Hi, All
I add two kinds of event here

Temperature of Intel Core processor PP0(CPU) and PP1(GPU)
Core voltage

Both event are tested on broadwell and skylake CPU
Thanks","I installed your PR to extend it to Intel Haswell desktop chips.

Somehow the documentation of the voltage stuff is confusing. The bit field is 47:32 for the ""Core Voltage"" but the calculation contains only 37:32 (Table 2-20, Okt. 2019 version). I asked Intel about this.
In your whole PR, I don't find the conversion from raw register value to actual core voltage value (value * 1/(2^13)). It would be best to have a separate function in voltage.h and use that in calculateResult() and calculateMarkerResult(), similar to the power_getEnergyUnit() function for RAPL readings.
What is the meaning of VTG for the Core Voltage counter? Just for interest! I would have used something like CVC for Core Voltage Counters.

Just for info: I'm out of office until February, so don't expect any answers in January.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,257,2019-12-06T13:46:17Z,2020-02-25T14:20:42Z,2020-02-25T14:20:42Z,MERGED,True,1530,1222,33,https://github.com/jimmysitu,Add temperature and voltage for Intel Core CPUs,15,['enhancement'],https://github.com/RRZE-HPC/likwid/pull/257,https://github.com/jimmysitu,9,https://github.com/RRZE-HPC/likwid/pull/257#issuecomment-573093485,"Hi, All
I add two kinds of event here

Temperature of Intel Core processor PP0(CPU) and PP1(GPU)
Core voltage

Both event are tested on broadwell and skylake CPU
Thanks","Hi, @TomTheBear

I update the conversion from raw register value to actual core voltage value,
but I involvoed a warning here. I am not sure how to deal with it in a better way.

./src/libperfctr.c:139:18: warning: implicit declaration of function ‘voltage_value’ [-Wimplicit-function-declaration]
result = voltage_value(stop);
^~~~~~~~~~~~~

VTG is short for voltage. I think core voltage counter may not so good, since this is more like a sensor or meter.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,257,2019-12-06T13:46:17Z,2020-02-25T14:20:42Z,2020-02-25T14:20:42Z,MERGED,True,1530,1222,33,https://github.com/jimmysitu,Add temperature and voltage for Intel Core CPUs,15,['enhancement'],https://github.com/RRZE-HPC/likwid/pull/257,https://github.com/TomTheBear,10,https://github.com/RRZE-HPC/likwid/pull/257#issuecomment-581927679,"Hi, All
I add two kinds of event here

Temperature of Intel Core processor PP0(CPU) and PP1(GPU)
Core voltage

Both event are tested on broadwell and skylake CPU
Thanks","I got a response from Intel, the bitfield for the voltage readings is 47:32. So, no changes required.
To remove the warning, include the voltage.h file in libperfctr.c.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,257,2019-12-06T13:46:17Z,2020-02-25T14:20:42Z,2020-02-25T14:20:42Z,MERGED,True,1530,1222,33,https://github.com/jimmysitu,Add temperature and voltage for Intel Core CPUs,15,['enhancement'],https://github.com/RRZE-HPC/likwid/pull/257,https://github.com/TomTheBear,11,https://github.com/RRZE-HPC/likwid/pull/257#issuecomment-582473266,"Hi, All
I add two kinds of event here

Temperature of Intel Core processor PP0(CPU) and PP1(GPU)
Core voltage

Both event are tested on broadwell and skylake CPU
Thanks","The addition of voltage.h to libperfctr.c does not work -> multiple references.
I tested the voltage readings in MarkerAPI mode and it always returned 0. This is because the reference to voltage_value() is unresolved. I tested it by moving the calculation into libperfctr.c. This works. For the power module, there is power.c and power.h, so it might be beneficial to move the functions in a file voltage.c and just export the functions through voltage.h.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,257,2019-12-06T13:46:17Z,2020-02-25T14:20:42Z,2020-02-25T14:20:42Z,MERGED,True,1530,1222,33,https://github.com/jimmysitu,Add temperature and voltage for Intel Core CPUs,15,['enhancement'],https://github.com/RRZE-HPC/likwid/pull/257,https://github.com/jimmysitu,12,https://github.com/RRZE-HPC/likwid/pull/257#issuecomment-584145828,"Hi, All
I add two kinds of event here

Temperature of Intel Core processor PP0(CPU) and PP1(GPU)
Core voltage

Both event are tested on broadwell and skylake CPU
Thanks","HI, @TomTheBear
Fixed done. Thanks.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,257,2019-12-06T13:46:17Z,2020-02-25T14:20:42Z,2020-02-25T14:20:42Z,MERGED,True,1530,1222,33,https://github.com/jimmysitu,Add temperature and voltage for Intel Core CPUs,15,['enhancement'],https://github.com/RRZE-HPC/likwid/pull/257,https://github.com/TomTheBear,13,https://github.com/RRZE-HPC/likwid/pull/257#issuecomment-585226030,"Hi, All
I add two kinds of event here

Temperature of Intel Core processor PP0(CPU) and PP1(GPU)
Core voltage

Both event are tested on broadwell and skylake CPU
Thanks","In the last commit, I added voltage support for all architectures after Intel SandyBridge. I havn't added the temperature readings. We could add it for all Desktop chips but for server-class chips we have to re-work the mmap interface. At the moment you have either mmap (desktop) or PCIe-based devices (server). The mmap interface and PCI devices share the MBOX0 type, so we would need an extra type for the mmap interface.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,266,2020-02-02T16:17:44Z,2020-02-07T14:33:22Z,2020-02-08T14:40:51Z,MERGED,True,504,41,12,https://github.com/melven,likwid-bench: improve peakflops micro benchmark,5,[],https://github.com/RRZE-HPC/likwid/pull/266,https://github.com/melven,1,https://github.com/RRZE-HPC/likwid/pull/266,"add different variants AVX/AVX-512 with/without FMAs, similar to the other benchmarks
higher unrolling of AVX/SSE variants to obtain better results (on Haswell)
add missing description and annotation (number of instructions etc)","add different variants AVX/AVX-512 with/without FMAs, similar to the other benchmarks
higher unrolling of AVX/SSE variants to obtain better results (on Haswell)
add missing description and annotation (number of instructions etc)",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,266,2020-02-02T16:17:44Z,2020-02-07T14:33:22Z,2020-02-08T14:40:51Z,MERGED,True,504,41,12,https://github.com/melven,likwid-bench: improve peakflops micro benchmark,5,[],https://github.com/RRZE-HPC/likwid/pull/266,https://github.com/melven,2,https://github.com/RRZE-HPC/likwid/pull/266#issuecomment-581151420,"add different variants AVX/AVX-512 with/without FMAs, similar to the other benchmarks
higher unrolling of AVX/SSE variants to obtain better results (on Haswell)
add missing description and annotation (number of instructions etc)","I know this is not a very useful benchmark at all. But it gives an idea of the peak performance.
Of course, one can look up / calculate the peak flops but it is a bit tedious with AVX frequencies and one or two FMAs per core depending on the CPU model.
I've tested the different variants on a Haswell and on a Skylake Gold node (with AVX512) and got quite useful results (with a data size that fits into L1).
I hope that the number of instructions and uOps are correct, these seem to include some constant part from the generated code.
Background:
My goal is to write a small script that obtains all information for some simple (roofline based) performance models...",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,266,2020-02-02T16:17:44Z,2020-02-07T14:33:22Z,2020-02-08T14:40:51Z,MERGED,True,504,41,12,https://github.com/melven,likwid-bench: improve peakflops micro benchmark,5,[],https://github.com/RRZE-HPC/likwid/pull/266,https://github.com/TomTheBear,3,https://github.com/RRZE-HPC/likwid/pull/266#issuecomment-581454682,"add different variants AVX/AVX-512 with/without FMAs, similar to the other benchmarks
higher unrolling of AVX/SSE variants to obtain better results (on Haswell)
add missing description and annotation (number of instructions etc)","Thanks for the PR. You are right that the peakflops can be calculated from the data sheet values and some inputs are system/runtime dependent (FMA units and CPU clock).
The peakflops benchmark was committed accidentally by me, it was just a test from my side and somehow slipped in. My main problem with this type of benchmark in likwid-bench is that it basically does not need to have a stream, it can run completely in registers. likwid-bench's original purpose are streaming-like kernels. That's why the original peakflops benchmark uses a single stream (and traverses it). That's why you need to set a stream size that fits into L1.
I started already to add support for in-register benchmarks but there are still some open questions like how to specify the workgroup (domain:size:threads) if you don't need a size.
I'll take a look in the next days.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,266,2020-02-02T16:17:44Z,2020-02-07T14:33:22Z,2020-02-08T14:40:51Z,MERGED,True,504,41,12,https://github.com/melven,likwid-bench: improve peakflops micro benchmark,5,[],https://github.com/RRZE-HPC/likwid/pull/266,https://github.com/TomTheBear,4,https://github.com/RRZE-HPC/likwid/pull/266#issuecomment-582828004,"add different variants AVX/AVX-512 with/without FMAs, similar to the other benchmarks
higher unrolling of AVX/SSE variants to obtain better results (on Haswell)
add missing description and annotation (number of instructions etc)",Could you add SP variants as well? I can also do that after merging your PR.,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,266,2020-02-02T16:17:44Z,2020-02-07T14:33:22Z,2020-02-08T14:40:51Z,MERGED,True,504,41,12,https://github.com/melven,likwid-bench: improve peakflops micro benchmark,5,[],https://github.com/RRZE-HPC/likwid/pull/266,https://github.com/melven,5,https://github.com/RRZE-HPC/likwid/pull/266#issuecomment-582881457,"add different variants AVX/AVX-512 with/without FMAs, similar to the other benchmarks
higher unrolling of AVX/SSE variants to obtain better results (on Haswell)
add missing description and annotation (number of instructions etc)","I also added the corresponding single-precision variants.
Results on Haswell and Skylake seemed fine to me but please have a look if the code is correct (number of instructions/flops/bytes/loop counter etc). I'm not very used to programming assembler instructions...",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,266,2020-02-02T16:17:44Z,2020-02-07T14:33:22Z,2020-02-08T14:40:51Z,MERGED,True,504,41,12,https://github.com/melven,likwid-bench: improve peakflops micro benchmark,5,[],https://github.com/RRZE-HPC/likwid/pull/266,https://github.com/TomTheBear,6,https://github.com/RRZE-HPC/likwid/pull/266#issuecomment-582986267,"add different variants AVX/AVX-512 with/without FMAs, similar to the other benchmarks
higher unrolling of AVX/SSE variants to obtain better results (on Haswell)
add missing description and annotation (number of instructions etc)",The scalar versions (peakflops and peakflops_sp) are quite slow. Have you tested different register combinations to achieve higher flop rates?,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,266,2020-02-02T16:17:44Z,2020-02-07T14:33:22Z,2020-02-08T14:40:51Z,MERGED,True,504,41,12,https://github.com/melven,likwid-bench: improve peakflops micro benchmark,5,[],https://github.com/RRZE-HPC/likwid/pull/266,https://github.com/melven,7,https://github.com/RRZE-HPC/likwid/pull/266#issuecomment-583004795,"add different variants AVX/AVX-512 with/without FMAs, similar to the other benchmarks
higher unrolling of AVX/SSE variants to obtain better results (on Haswell)
add missing description and annotation (number of instructions etc)","No I didn't test different instruction/register combinations there.
On Haswell, I obtained quite accurately 2 Flops/Cycle independent of single/double-precision (as I expected).
On Skylake, I didn't really look closely enough for scalar operations... 2.3 Flops/Cycle on a Xeon Silver and 2.85 Flops/Cycle on a Xeon Gold. Should be 2 and 3 when I interpret the diagrams on wikichip correctly.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,266,2020-02-02T16:17:44Z,2020-02-07T14:33:22Z,2020-02-08T14:40:51Z,MERGED,True,504,41,12,https://github.com/melven,likwid-bench: improve peakflops micro benchmark,5,[],https://github.com/RRZE-HPC/likwid/pull/266,https://github.com/TomTheBear,8,https://github.com/RRZE-HPC/likwid/pull/266#issuecomment-583379072,"add different variants AVX/AVX-512 with/without FMAs, similar to the other benchmarks
higher unrolling of AVX/SSE variants to obtain better results (on Haswell)
add missing description and annotation (number of instructions etc)","I played around a bit (Skylake Gold 6148, single core, 15kB vector length)



benchmark
MFlops/s
scalars_per_vec
ops
ratio




peakflops
4786.83
1
1
1


peakflops_sse
9561.76
2
1
1.995


peakflops_axv
18991.50
4
1
3.963


peakflops_avx_fma
37972.02
4
2
7.924


peakflops_axv512
37890.97
8
1
7.907


peakflops_axv512_fma
75789.48
8
2
15.817



So, for scalar FP ops you get 1.995 FPops/cyc, for AVX  7.9 FPops/cyc and AVX512 15.8 FPops/cyc.



benchmark
MFlops/s
scalars_per_vec
ops
ratio




peakflops_sp
4791.48
1
1
1


peakflops_sp_sse
19117.01
4
1
3.989


peakflops_sp_axv
37974.61
8
1
7.925


peakflops_sp_avx_fma
75954.47
8
2
15.852


peakflops_sp_axv512
75540.67
16
1
15.766


peakflops_sp_axv512_fma
151602.06
16
2
31.640



So, with my changes to peakflops, peakflops_sp,  peakflops_sse and peakflops_sp_sse we are ready to merge. Thanks again for providing the benchmarks.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,278,2020-04-03T11:32:43Z,2020-11-11T16:02:48Z,2020-11-11T16:03:07Z,MERGED,True,932,0,14,https://github.com/TomTheBear,Adding support for ARM Neoverse N1,6,[],https://github.com/RRZE-HPC/likwid/pull/278,https://github.com/TomTheBear,1,https://github.com/RRZE-HPC/likwid/pull/278,See issue #277,See issue #277,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,296,2020-06-16T15:58:32Z,2020-10-30T12:02:17Z,2020-10-30T12:02:30Z,MERGED,True,2041,57,69,https://github.com/TomTheBear,Adding support for Fujitsu A64FX,19,[],https://github.com/RRZE-HPC/likwid/pull/296,https://github.com/TomTheBear,1,https://github.com/RRZE-HPC/likwid/pull/296,,,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,296,2020-06-16T15:58:32Z,2020-10-30T12:02:17Z,2020-10-30T12:02:30Z,MERGED,True,2041,57,69,https://github.com/TomTheBear,Adding support for Fujitsu A64FX,19,[],https://github.com/RRZE-HPC/likwid/pull/296,https://github.com/TomTheBear,2,https://github.com/RRZE-HPC/likwid/pull/296#issuecomment-671425101,,Works well on Fujitsu FX700 but not on FX1000 due to the extra unusable cores and the strange system topology.,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,299,2020-06-23T18:21:13Z,2020-08-24T10:27:43Z,2020-08-24T10:27:43Z,MERGED,True,223,114,6,https://github.com/Tobi29,Create virtual numa node in case detection fails,5,[],https://github.com/RRZE-HPC/likwid/pull/299,https://github.com/Tobi29,1,https://github.com/RRZE-HPC/likwid/pull/299,"This modifies the error handling to use a ""virtual"" NUMA node in case no proper one was found, in order to guarantee that there is always at least one, even on systems without any NUMA support (like on the Raspberry Pi 4).
Previously the hwloc backend already handled this on its own, so I extracted that code into a virtual ""backend"", which is used by both the proc and empty backends as well, in case no better info can be detected.
For memory usage the procfs is used, which was done by the hwloc backend as well, and for the  numberOfProcessors the cpuid_topology.numHWThreads  value is taken.
In order to avoid any behaviour changes the hwloc backend recomputes the numberOfProcessors on its own, not sure if that is a good or bad idea.
I have not gotten around to testing this on any machines with actual NUMA support, but the changes only cover previous error cases that should never occur with multiple NUMA nodes.
I added myself as an author in the two files I created, if it would be preferred without that, that would be fine as well. (The code is mostly pasted from existing parts anyways)
Comments on issues or better approaches to this would be very welcome :)
Fixes #290, showing sensible data there now (CPU type is still missing, but that should be unrelated):
--------------------------------------------------------------------------------
CPU name:       BCM2835
CPU type:       nil
CPU stepping:   3
********************************************************************************
Hardware Thread Topology
********************************************************************************
Sockets:                1
Cores per socket:       4
Threads per core:       1
--------------------------------------------------------------------------------
HWThread        Thread          Core            Socket          Available
0               0               0               0               *
1               0               1               0               *
2               0               2               0               *
3               0               3               0               *
--------------------------------------------------------------------------------
Socket 0:               ( 0 1 2 3 )
--------------------------------------------------------------------------------
********************************************************************************
Cache Topology
********************************************************************************
********************************************************************************
NUMA Topology
********************************************************************************
NUMA domains:           1
--------------------------------------------------------------------------------
Domain:                 0
Processors:             ( 0 1 2 3 )
Distances:              10
Free memory:            1570.78 MB
Total memory:           1865.91 MB
--------------------------------------------------------------------------------","This modifies the error handling to use a ""virtual"" NUMA node in case no proper one was found, in order to guarantee that there is always at least one, even on systems without any NUMA support (like on the Raspberry Pi 4).
Previously the hwloc backend already handled this on its own, so I extracted that code into a virtual ""backend"", which is used by both the proc and empty backends as well, in case no better info can be detected.
For memory usage the procfs is used, which was done by the hwloc backend as well, and for the  numberOfProcessors the cpuid_topology.numHWThreads  value is taken.
In order to avoid any behaviour changes the hwloc backend recomputes the numberOfProcessors on its own, not sure if that is a good or bad idea.
I have not gotten around to testing this on any machines with actual NUMA support, but the changes only cover previous error cases that should never occur with multiple NUMA nodes.
I added myself as an author in the two files I created, if it would be preferred without that, that would be fine as well. (The code is mostly pasted from existing parts anyways)
Comments on issues or better approaches to this would be very welcome :)
Fixes #290, showing sensible data there now (CPU type is still missing, but that should be unrelated):
--------------------------------------------------------------------------------
CPU name:       BCM2835
CPU type:       nil
CPU stepping:   3
********************************************************************************
Hardware Thread Topology
********************************************************************************
Sockets:                1
Cores per socket:       4
Threads per core:       1
--------------------------------------------------------------------------------
HWThread        Thread          Core            Socket          Available
0               0               0               0               *
1               0               1               0               *
2               0               2               0               *
3               0               3               0               *
--------------------------------------------------------------------------------
Socket 0:               ( 0 1 2 3 )
--------------------------------------------------------------------------------
********************************************************************************
Cache Topology
********************************************************************************
********************************************************************************
NUMA Topology
********************************************************************************
NUMA domains:           1
--------------------------------------------------------------------------------
Domain:                 0
Processors:             ( 0 1 2 3 )
Distances:              10
Free memory:            1570.78 MB
Total memory:           1865.91 MB
--------------------------------------------------------------------------------",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,299,2020-06-23T18:21:13Z,2020-08-24T10:27:43Z,2020-08-24T10:27:43Z,MERGED,True,223,114,6,https://github.com/Tobi29,Create virtual numa node in case detection fails,5,[],https://github.com/RRZE-HPC/likwid/pull/299,https://github.com/TomTheBear,2,https://github.com/RRZE-HPC/likwid/pull/299#issuecomment-650091580,"This modifies the error handling to use a ""virtual"" NUMA node in case no proper one was found, in order to guarantee that there is always at least one, even on systems without any NUMA support (like on the Raspberry Pi 4).
Previously the hwloc backend already handled this on its own, so I extracted that code into a virtual ""backend"", which is used by both the proc and empty backends as well, in case no better info can be detected.
For memory usage the procfs is used, which was done by the hwloc backend as well, and for the  numberOfProcessors the cpuid_topology.numHWThreads  value is taken.
In order to avoid any behaviour changes the hwloc backend recomputes the numberOfProcessors on its own, not sure if that is a good or bad idea.
I have not gotten around to testing this on any machines with actual NUMA support, but the changes only cover previous error cases that should never occur with multiple NUMA nodes.
I added myself as an author in the two files I created, if it would be preferred without that, that would be fine as well. (The code is mostly pasted from existing parts anyways)
Comments on issues or better approaches to this would be very welcome :)
Fixes #290, showing sensible data there now (CPU type is still missing, but that should be unrelated):
--------------------------------------------------------------------------------
CPU name:       BCM2835
CPU type:       nil
CPU stepping:   3
********************************************************************************
Hardware Thread Topology
********************************************************************************
Sockets:                1
Cores per socket:       4
Threads per core:       1
--------------------------------------------------------------------------------
HWThread        Thread          Core            Socket          Available
0               0               0               0               *
1               0               1               0               *
2               0               2               0               *
3               0               3               0               *
--------------------------------------------------------------------------------
Socket 0:               ( 0 1 2 3 )
--------------------------------------------------------------------------------
********************************************************************************
Cache Topology
********************************************************************************
********************************************************************************
NUMA Topology
********************************************************************************
NUMA domains:           1
--------------------------------------------------------------------------------
Domain:                 0
Processors:             ( 0 1 2 3 )
Distances:              10
Free memory:            1570.78 MB
Total memory:           1865.91 MB
--------------------------------------------------------------------------------","Thanks for the PR. I'm not 100% sure whether this extra code is needed or we just have to sanitize the NUMA nodes values to 1 somewhere in the hwloc backend. Also the copy of getFreeNodeMem and getTotalNodeMem is probably not required and could be just use the function from the hwloc file.
Of course you are the author, we would never change that.
Unfortunately, I don't have a RasPi4 accessible at the moment. As soon as I have one, I'll take a deeper look.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,299,2020-06-23T18:21:13Z,2020-08-24T10:27:43Z,2020-08-24T10:27:43Z,MERGED,True,223,114,6,https://github.com/Tobi29,Create virtual numa node in case detection fails,5,[],https://github.com/RRZE-HPC/likwid/pull/299,https://github.com/TomTheBear,3,https://github.com/RRZE-HPC/likwid/pull/299#issuecomment-666317336,"This modifies the error handling to use a ""virtual"" NUMA node in case no proper one was found, in order to guarantee that there is always at least one, even on systems without any NUMA support (like on the Raspberry Pi 4).
Previously the hwloc backend already handled this on its own, so I extracted that code into a virtual ""backend"", which is used by both the proc and empty backends as well, in case no better info can be detected.
For memory usage the procfs is used, which was done by the hwloc backend as well, and for the  numberOfProcessors the cpuid_topology.numHWThreads  value is taken.
In order to avoid any behaviour changes the hwloc backend recomputes the numberOfProcessors on its own, not sure if that is a good or bad idea.
I have not gotten around to testing this on any machines with actual NUMA support, but the changes only cover previous error cases that should never occur with multiple NUMA nodes.
I added myself as an author in the two files I created, if it would be preferred without that, that would be fine as well. (The code is mostly pasted from existing parts anyways)
Comments on issues or better approaches to this would be very welcome :)
Fixes #290, showing sensible data there now (CPU type is still missing, but that should be unrelated):
--------------------------------------------------------------------------------
CPU name:       BCM2835
CPU type:       nil
CPU stepping:   3
********************************************************************************
Hardware Thread Topology
********************************************************************************
Sockets:                1
Cores per socket:       4
Threads per core:       1
--------------------------------------------------------------------------------
HWThread        Thread          Core            Socket          Available
0               0               0               0               *
1               0               1               0               *
2               0               2               0               *
3               0               3               0               *
--------------------------------------------------------------------------------
Socket 0:               ( 0 1 2 3 )
--------------------------------------------------------------------------------
********************************************************************************
Cache Topology
********************************************************************************
********************************************************************************
NUMA Topology
********************************************************************************
NUMA domains:           1
--------------------------------------------------------------------------------
Domain:                 0
Processors:             ( 0 1 2 3 )
Distances:              10
Free memory:            1570.78 MB
Total memory:           1865.91 MB
--------------------------------------------------------------------------------","I havn't forgot your PR. I logged in to a RasPi4 but it was installed with a 32 Bit Raspbian and there was no chance to test your code. Since it's remote access, I have to see how I can install a more recent OS.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,299,2020-06-23T18:21:13Z,2020-08-24T10:27:43Z,2020-08-24T10:27:43Z,MERGED,True,223,114,6,https://github.com/Tobi29,Create virtual numa node in case detection fails,5,[],https://github.com/RRZE-HPC/likwid/pull/299,https://github.com/TomTheBear,4,https://github.com/RRZE-HPC/likwid/pull/299#issuecomment-672817366,"This modifies the error handling to use a ""virtual"" NUMA node in case no proper one was found, in order to guarantee that there is always at least one, even on systems without any NUMA support (like on the Raspberry Pi 4).
Previously the hwloc backend already handled this on its own, so I extracted that code into a virtual ""backend"", which is used by both the proc and empty backends as well, in case no better info can be detected.
For memory usage the procfs is used, which was done by the hwloc backend as well, and for the  numberOfProcessors the cpuid_topology.numHWThreads  value is taken.
In order to avoid any behaviour changes the hwloc backend recomputes the numberOfProcessors on its own, not sure if that is a good or bad idea.
I have not gotten around to testing this on any machines with actual NUMA support, but the changes only cover previous error cases that should never occur with multiple NUMA nodes.
I added myself as an author in the two files I created, if it would be preferred without that, that would be fine as well. (The code is mostly pasted from existing parts anyways)
Comments on issues or better approaches to this would be very welcome :)
Fixes #290, showing sensible data there now (CPU type is still missing, but that should be unrelated):
--------------------------------------------------------------------------------
CPU name:       BCM2835
CPU type:       nil
CPU stepping:   3
********************************************************************************
Hardware Thread Topology
********************************************************************************
Sockets:                1
Cores per socket:       4
Threads per core:       1
--------------------------------------------------------------------------------
HWThread        Thread          Core            Socket          Available
0               0               0               0               *
1               0               1               0               *
2               0               2               0               *
3               0               3               0               *
--------------------------------------------------------------------------------
Socket 0:               ( 0 1 2 3 )
--------------------------------------------------------------------------------
********************************************************************************
Cache Topology
********************************************************************************
********************************************************************************
NUMA Topology
********************************************************************************
NUMA domains:           1
--------------------------------------------------------------------------------
Domain:                 0
Processors:             ( 0 1 2 3 )
Distances:              10
Free memory:            1570.78 MB
Total memory:           1865.91 MB
--------------------------------------------------------------------------------","I tried today on a RasPi4 and as  I thought, a sanitation to 1 is basically enough:
if (numberOfNumaDomains < 1) { numberOfNumaDomains = 1; } in src/affiniy.c
But likwid-topology won't print the NUMA domain because numa_info.numberOfNodes is still zero. Other application that access the affinity domains (e.g. likwid-pin) work with the fix.
Since it is not a clean fix, I will check your virtual NUMA domain code again.
The detection of the micro architecture is no problem, the A72 is just missing in the big switch-case statements in src/topology.c and src/perfmon.c.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,299,2020-06-23T18:21:13Z,2020-08-24T10:27:43Z,2020-08-24T10:27:43Z,MERGED,True,223,114,6,https://github.com/Tobi29,Create virtual numa node in case detection fails,5,[],https://github.com/RRZE-HPC/likwid/pull/299,https://github.com/Tobi29,5,https://github.com/RRZE-HPC/likwid/pull/299#issuecomment-678349434,"This modifies the error handling to use a ""virtual"" NUMA node in case no proper one was found, in order to guarantee that there is always at least one, even on systems without any NUMA support (like on the Raspberry Pi 4).
Previously the hwloc backend already handled this on its own, so I extracted that code into a virtual ""backend"", which is used by both the proc and empty backends as well, in case no better info can be detected.
For memory usage the procfs is used, which was done by the hwloc backend as well, and for the  numberOfProcessors the cpuid_topology.numHWThreads  value is taken.
In order to avoid any behaviour changes the hwloc backend recomputes the numberOfProcessors on its own, not sure if that is a good or bad idea.
I have not gotten around to testing this on any machines with actual NUMA support, but the changes only cover previous error cases that should never occur with multiple NUMA nodes.
I added myself as an author in the two files I created, if it would be preferred without that, that would be fine as well. (The code is mostly pasted from existing parts anyways)
Comments on issues or better approaches to this would be very welcome :)
Fixes #290, showing sensible data there now (CPU type is still missing, but that should be unrelated):
--------------------------------------------------------------------------------
CPU name:       BCM2835
CPU type:       nil
CPU stepping:   3
********************************************************************************
Hardware Thread Topology
********************************************************************************
Sockets:                1
Cores per socket:       4
Threads per core:       1
--------------------------------------------------------------------------------
HWThread        Thread          Core            Socket          Available
0               0               0               0               *
1               0               1               0               *
2               0               2               0               *
3               0               3               0               *
--------------------------------------------------------------------------------
Socket 0:               ( 0 1 2 3 )
--------------------------------------------------------------------------------
********************************************************************************
Cache Topology
********************************************************************************
********************************************************************************
NUMA Topology
********************************************************************************
NUMA domains:           1
--------------------------------------------------------------------------------
Domain:                 0
Processors:             ( 0 1 2 3 )
Distances:              10
Free memory:            1570.78 MB
Total memory:           1865.91 MB
--------------------------------------------------------------------------------","I've updated my changes to address the comments.
With the hwloc case I dropped the ""old"" fallback entirely as that may cause severe issues if the number of cores actually changes (and if it is the same it's pointless).
The memory functions that I moved to numa.c only work on total numbers, not nodes, which is what I needed for the fallback, I renamed them to clarify that and made the hwloc backend reuse that code in case it tries to gather total numbers.
Lastly I reordered the virtual node code to avoid memory leaks on errors and they should now not modify any global state in that case.
If there is anything I missed or if squashing the commits is preferred, please do tell.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,302,2020-06-30T23:27:25Z,2020-07-01T12:25:03Z,2020-07-01T12:25:03Z,MERGED,True,21,6,1,https://github.com/paigeweber13,Improved doxygen comments,1,[],https://github.com/RRZE-HPC/likwid/pull/302,https://github.com/paigeweber13,1,https://github.com/RRZE-HPC/likwid/pull/302,"Corrected markerNextGroup comment: previously said it should be called
in a parallel region, corrected to say serial region.
Added hints on barriers when calling these functions in parallel regions
Resolves #292","Corrected markerNextGroup comment: previously said it should be called
in a parallel region, corrected to say serial region.
Added hints on barriers when calling these functions in parallel regions
Resolves #292",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,303,2020-07-06T22:05:41Z,2020-07-17T10:04:14Z,2020-07-17T10:04:14Z,MERGED,True,501,121,3,https://github.com/paigeweber13,#297 improve examples,17,[],https://github.com/RRZE-HPC/likwid/pull/303,https://github.com/paigeweber13,1,https://github.com/RRZE-HPC/likwid/pull/303,"C-markerAPI is a simple example and C-internalMarkerAPI is more complete. Examples now work with current version of likwid (v5.0.1) and comments have been dramatically improved.
Mentioned in #292
Part of #297","C-markerAPI is a simple example and C-internalMarkerAPI is more complete. Examples now work with current version of likwid (v5.0.1) and comments have been dramatically improved.
Mentioned in #292
Part of #297",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,303,2020-07-06T22:05:41Z,2020-07-17T10:04:14Z,2020-07-17T10:04:14Z,MERGED,True,501,121,3,https://github.com/paigeweber13,#297 improve examples,17,[],https://github.com/RRZE-HPC/likwid/pull/303,https://github.com/TomTheBear,2,https://github.com/RRZE-HPC/likwid/pull/303#issuecomment-654773032,"C-markerAPI is a simple example and C-internalMarkerAPI is more complete. Examples now work with current version of likwid (v5.0.1) and comments have been dramatically improved.
Mentioned in #292
Part of #297","Hi Riley. Thanks for the PR. The code looks well in general and is much more complete.
Some comments  for C-internalMarkerAPI.c:

Maybe we shouldn't register one of the regions to show that it is optional?
unsigned data types (ull) shouldn't be used as iterator variable (sometimes prevents vectorization)
Are you sure about the omp barriers in the loop? In my understanding of the MarkerAPI, they are not required. Only for some special cases like LIKWID_MARKER_SWITCH because they need to be executed in serial although being close to or in parallel regions (guarded with omp single/master).",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,303,2020-07-06T22:05:41Z,2020-07-17T10:04:14Z,2020-07-17T10:04:14Z,MERGED,True,501,121,3,https://github.com/paigeweber13,#297 improve examples,17,[],https://github.com/RRZE-HPC/likwid/pull/303,https://github.com/paigeweber13,3,https://github.com/RRZE-HPC/likwid/pull/303#issuecomment-655038366,"C-markerAPI is a simple example and C-internalMarkerAPI is more complete. Examples now work with current version of likwid (v5.0.1) and comments have been dramatically improved.
Mentioned in #292
Part of #297","Hey Thomas! I'll change it so one of the regions isn't registered and change the datatype to signed. Thanks for the tips.
As for the omp barriers, without them I get the unreasonably high values discussed in #292 . I suppose the barriers are more of a workaround than a fix, but in my case they were absolutely necessary because without them about 10% of the cores on a 48-core machine were giving garbage data in every trial. (Or, in the case of a development machine with 4 cores, one core would fail every 5-6 trials). That being said, I think it would be good to verify this, can you test it on your machine? If so, would you like for me to throw together a test case? Or is the example code discussed in #292 sufficient?
Also, about LIKWID_MARKER_SWITCH: as far as I know, #pragma omp single only synchronizes at the end of the block and if you try to switch before all threads have stopped then you get errors. Additionally, #pragma omp critical performs no synchronization. Therefore, the barrier is still necessary if you want to execute it in a single or critical block nested within a parallel region.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,303,2020-07-06T22:05:41Z,2020-07-17T10:04:14Z,2020-07-17T10:04:14Z,MERGED,True,501,121,3,https://github.com/paigeweber13,#297 improve examples,17,[],https://github.com/RRZE-HPC/likwid/pull/303,https://github.com/paigeweber13,4,https://github.com/RRZE-HPC/likwid/pull/303#issuecomment-655184388,"C-markerAPI is a simple example and C-internalMarkerAPI is more complete. Examples now work with current version of likwid (v5.0.1) and comments have been dramatically improved.
Mentioned in #292
Part of #297","Thomas,
I experimented a bit further today and I think I was wrong, actually. The file I used to demonstrate the unreasonably high values was likwid_minimal.c. Before I started using the LIKWID_MARKER_NEXT() = likwid_markerNextGroup() in a sequential region, the main loop of my code was the following:
#pragma omp parallel
  {
    for (int j = 0; j < 8; j++)
    {
#pragma omp barrier
      likwid_markerStartRegion(""double_flops"");
      do_flops(a, b, c, NUM_FLOPS);
      likwid_markerStopRegion(""double_flops"");
#pragma omp barrier
      likwid_markerStartRegion(""copy"");
      do_copy(arr, copy_arr, n, NUM_COPIES);
      likwid_markerStopRegion(""copy"");
#pragma omp barrier
      likwid_markerNextGroup();
    }
  }
Removing either the first or last barrier caused lots of problems with either WARN: Region <region> already stated, WARN: Stopping an unknown/not-started region <region>, or unreasonably high values. I'm not sure why I had the middle barrier, but I think it was leftover from earlier tests. Perhaps I had placed it before I had a barrier preceeding likwid_markerNextGroup() and it alleviated some of the problems, but it became unnecessary after adding the barrier before likwid_markerNextGroup().
Once you told me that group switching should take place in a serial region, I changed the code to the following:
#pragma omp parallel
  {
    for (int j = 0; j < 8; j++) 
    {
      likwid_markerStartRegion(""double_flops"");
      do_flops(a, b, c, NUM_FLOPS);
      likwid_markerStopRegion(""double_flops"");
#pragma omp barrier
      likwid_markerStartRegion(""copy"");
      do_copy(arr, copy_arr, n, NUM_COPIES);
      likwid_markerStopRegion(""copy"");

      #pragma omp barrier
      #pragma omp single
      {
        likwid_markerNextGroup();
      }
    }
  }
Just now I tested this without the barrier in the middle and didn't get any problems on my test machine after 100 iterations. I thought I had tested this already, hence my confidence from earlier, but I guess I was wrong.
I'm worried that this result is not conclusive, and that the barrier may still be needed at times. What if I remove the barriers in the example code, but make a note in the comments and in the docs that if multiple regions are in one parallel block, it may sometimes be helpful to have a barrier?",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,303,2020-07-06T22:05:41Z,2020-07-17T10:04:14Z,2020-07-17T10:04:14Z,MERGED,True,501,121,3,https://github.com/paigeweber13,#297 improve examples,17,[],https://github.com/RRZE-HPC/likwid/pull/303,https://github.com/TomTheBear,5,https://github.com/RRZE-HPC/likwid/pull/303#issuecomment-655428876,"C-markerAPI is a simple example and C-internalMarkerAPI is more complete. Examples now work with current version of likwid (v5.0.1) and comments have been dramatically improved.
Mentioned in #292
Part of #297","Hi Riley,
you are right about SWITCH, omp single (and the others) don't have an entry barrier. So, this barrier is definitely needed.
The barrier in between is not required because threads are allowed to execute the regions independently and can even be in a completely different iteration. That's how we planned it and (hopefully) implemented it.
How about we make the examples clean and simple but put a link to the wiki/README/APIdocs in there pointing to a page with possible pitfalls including short code snippets and explaination? I think users are searching for info in the wiki/README/APIdocs and not that much in code. Of course, that doesn't mean that we cannot document it in the example as well but we have multiple locations for the same information and have to update it accordingly in case of changes.
My main problem is to tell users that ""sometimes something is needed"" without being clear about the acutal situations. Multiple regions in a block are not the problem, multiple regions in block in combination with LIKWID_MARKER_SWITCH (or any other call that should be executed serially) can be a problem. I don't want users to put unneeded barriers in their code to be sure that LIKWID works always.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,303,2020-07-06T22:05:41Z,2020-07-17T10:04:14Z,2020-07-17T10:04:14Z,MERGED,True,501,121,3,https://github.com/paigeweber13,#297 improve examples,17,[],https://github.com/RRZE-HPC/likwid/pull/303,https://github.com/paigeweber13,6,https://github.com/RRZE-HPC/likwid/pull/303#issuecomment-656280263,"C-markerAPI is a simple example and C-internalMarkerAPI is more complete. Examples now work with current version of likwid (v5.0.1) and comments have been dramatically improved.
Mentioned in #292
Part of #297","I think the reason that I put ""sometimes you need this"" is that I've had so many stability issues with likwid that I'm not confident using the barrier with LIKWID_MARKER_NEXT and running it only by one thread are sufficient to prevent the problems I've experienced. However, since you have a much deeper understanding of the code, I'll defer to your judgment. I'll remove the comments about barriers, but I do think having a page for common pitfalls would be good. That being said, I don't feel well-equipped to write that page.
In general, would you like me to reduce the verbosity of comments and move that information to somewhere else? If so, is the README or doxygen pages a better place for that information?
Finally, keeping with your goal of having clean, simple examples, I think I'm going to have a separate loop to demonstrate GET/RESET, and remove the later calls to GET. I think that would improve readability and reduce the length of the example. What do you think?",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,303,2020-07-06T22:05:41Z,2020-07-17T10:04:14Z,2020-07-17T10:04:14Z,MERGED,True,501,121,3,https://github.com/paigeweber13,#297 improve examples,17,[],https://github.com/RRZE-HPC/likwid/pull/303,https://github.com/TomTheBear,7,https://github.com/RRZE-HPC/likwid/pull/303#issuecomment-656287734,"C-markerAPI is a simple example and C-internalMarkerAPI is more complete. Examples now work with current version of likwid (v5.0.1) and comments have been dramatically improved.
Mentioned in #292
Part of #297","Hi Riley,
sorry for my late comments after you did all that work. We keep it like it is including your comment about the barriers. As soon as I write the pitfalls page, we add a link in the comments as well, so it's easy to get deeper information when it's needed.
Your suggestion to have a separate loop for GET/RESET seems a good idea. That would clean the code up and we would have one loop with the basic macros and one with all capabilities.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,303,2020-07-06T22:05:41Z,2020-07-17T10:04:14Z,2020-07-17T10:04:14Z,MERGED,True,501,121,3,https://github.com/paigeweber13,#297 improve examples,17,[],https://github.com/RRZE-HPC/likwid/pull/303,https://github.com/paigeweber13,8,https://github.com/RRZE-HPC/likwid/pull/303#issuecomment-656306875,"C-markerAPI is a simple example and C-internalMarkerAPI is more complete. Examples now work with current version of likwid (v5.0.1) and comments have been dramatically improved.
Mentioned in #292
Part of #297","Okay, for now I'll keep the comments and just simplify the calls to GET/RESET.
No worries about the comments, I think it's important to get the example right since it conveys so much information about the intended usage. Also, I agreee that the documentation should be improved and I'd like to help with that.
I'll ping you again once I make the changes to the PR.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,303,2020-07-06T22:05:41Z,2020-07-17T10:04:14Z,2020-07-17T10:04:14Z,MERGED,True,501,121,3,https://github.com/paigeweber13,#297 improve examples,17,[],https://github.com/RRZE-HPC/likwid/pull/303,https://github.com/TomTheBear,9,https://github.com/RRZE-HPC/likwid/pull/303#issuecomment-656711915,"C-markerAPI is a simple example and C-internalMarkerAPI is more complete. Examples now work with current version of likwid (v5.0.1) and comments have been dramatically improved.
Mentioned in #292
Part of #297","I started with a pitfalls page: https://github.com/RRZE-HPC/likwid/wiki/LikwidMarkerAPIPitfalls
It is not included in the menu yet, I'll do that when I have covered all aspects.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,303,2020-07-06T22:05:41Z,2020-07-17T10:04:14Z,2020-07-17T10:04:14Z,MERGED,True,501,121,3,https://github.com/paigeweber13,#297 improve examples,17,[],https://github.com/RRZE-HPC/likwid/pull/303,https://github.com/paigeweber13,10,https://github.com/RRZE-HPC/likwid/pull/303#issuecomment-656794634,"C-markerAPI is a simple example and C-internalMarkerAPI is more complete. Examples now work with current version of likwid (v5.0.1) and comments have been dramatically improved.
Mentioned in #292
Part of #297","The pitfall page has some valuable information, thanks. Will you also mention something about measuring multiple groups across the same region? It's kind of selfish for me to ask, but it's an important use-case for me 😁
Also, I made a separate section for GET/RESET. I think this makes the example clearer. Is there anything else you'd like me to change?",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,303,2020-07-06T22:05:41Z,2020-07-17T10:04:14Z,2020-07-17T10:04:14Z,MERGED,True,501,121,3,https://github.com/paigeweber13,#297 improve examples,17,[],https://github.com/RRZE-HPC/likwid/pull/303,https://github.com/TomTheBear,11,https://github.com/RRZE-HPC/likwid/pull/303#issuecomment-656807194,"C-markerAPI is a simple example and C-internalMarkerAPI is more complete. Examples now work with current version of likwid (v5.0.1) and comments have been dramatically improved.
Mentioned in #292
Part of #297","Sure, I will add more and more info on the page. I wanted to start with basic stuff that most users need.
If you have more ideas or missing documentation, we could add a Todo page to the wiki.
The code looks good like that. I'll check it on the weekend.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,303,2020-07-06T22:05:41Z,2020-07-17T10:04:14Z,2020-07-17T10:04:14Z,MERGED,True,501,121,3,https://github.com/paigeweber13,#297 improve examples,17,[],https://github.com/RRZE-HPC/likwid/pull/303,https://github.com/paigeweber13,12,https://github.com/RRZE-HPC/likwid/pull/303#issuecomment-656820344,"C-markerAPI is a simple example and C-internalMarkerAPI is more complete. Examples now work with current version of likwid (v5.0.1) and comments have been dramatically improved.
Mentioned in #292
Part of #297","I think a todo wiki page would be good. The biggest things I would like to see are: 1) an explanation of the difference between the marker API and perfmon API and when to use each and 2) more complete function tips, like when to use each function in a parallel or serial region.
A ""todo"" page would also help me know how I can contribute to the documentation",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,303,2020-07-06T22:05:41Z,2020-07-17T10:04:14Z,2020-07-17T10:04:14Z,MERGED,True,501,121,3,https://github.com/paigeweber13,#297 improve examples,17,[],https://github.com/RRZE-HPC/likwid/pull/303,https://github.com/TomTheBear,13,https://github.com/RRZE-HPC/likwid/pull/303#issuecomment-657234098,"C-markerAPI is a simple example and C-internalMarkerAPI is more complete. Examples now work with current version of likwid (v5.0.1) and comments have been dramatically improved.
Mentioned in #292
Part of #297","Hi Riley, great examples.
I have two more minor comments:

Can you put a check in C-internalMarkerAPI.c when you run it wrapped by likwid-perfctr, so the environment variables are already set. Just print out an Error noting that this example should be run without likwid-perfctr and exit. If you run it with likwid-perfctr alone, you get numbers but they are not for the whole run. If you run with likwid-perfctr -m it complains in the end about the missing MarkerAPI file. You can only check the last case with certainty because likwid-perfctr alone does not always set an enviroment variable. My recommendation would be env variable LIKWID_PIN as likwid-perfctr is commonly run with pinning enabled.
Please add yourself to the header of C-markerAPI.c",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,303,2020-07-06T22:05:41Z,2020-07-17T10:04:14Z,2020-07-17T10:04:14Z,MERGED,True,501,121,3,https://github.com/paigeweber13,#297 improve examples,17,[],https://github.com/RRZE-HPC/likwid/pull/303,https://github.com/paigeweber13,14,https://github.com/RRZE-HPC/likwid/pull/303#issuecomment-658333972,"C-markerAPI is a simple example and C-internalMarkerAPI is more complete. Examples now work with current version of likwid (v5.0.1) and comments have been dramatically improved.
Mentioned in #292
Part of #297","I added a check, which I hope is sufficient. It checks if LIKWID_PIN is set, prints an error message, and then exits. Sometimes likwid-perfctr still presents counts, but I am not sure how to stop this.
I also added my name.
Let me know if there's anything else you need from me!",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,303,2020-07-06T22:05:41Z,2020-07-17T10:04:14Z,2020-07-17T10:04:14Z,MERGED,True,501,121,3,https://github.com/paigeweber13,#297 improve examples,17,[],https://github.com/RRZE-HPC/likwid/pull/303,https://github.com/TomTheBear,15,https://github.com/RRZE-HPC/likwid/pull/303#issuecomment-659993798,"C-markerAPI is a simple example and C-internalMarkerAPI is more complete. Examples now work with current version of likwid (v5.0.1) and comments have been dramatically improved.
Mentioned in #292
Part of #297","It's fine that likwid-perfctr prints numbers in some cases as long as there is the message that it doesn't work. We cannot catch all cases.
I think we are ready to merge.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,309,2020-07-30T12:51:12Z,2020-08-11T06:32:19Z,2020-08-11T06:35:56Z,MERGED,True,268,7,4,https://github.com/jrmadsen,Updates likwid-config.cmake to support find_package,8,[],https://github.com/RRZE-HPC/likwid/pull/309,https://github.com/jrmadsen,1,https://github.com/RRZE-HPC/likwid/pull/309,"added test/cmake for testing whether the find_package works
modified installation location (required for find_package to work
Validation test:

# build and install likwid
make && make install
# go to cmake test folder
cd test/cmake
# make build directory
mkdir build && cd build
# configure where PREFIX is the entry in config.mk
CMAKE_PREFIX_PATH=${PREFIX} cmake ..
# build the test executable
make
I had to change the installation location to get find_package(likwid) to work correctly, here are the options for Unix installs:
<prefix>/(lib/<arch>|lib*|share)/cmake/<name>*/                 
<prefix>/(lib/<arch>|lib*|share)/<name>*/                       
<prefix>/(lib/<arch>|lib*|share)/<name>*/(cmake|CMake)/         
<prefix>/<name>*/(lib/<arch>|lib*|share)/cmake/<name>*/         
<prefix>/<name>*/(lib/<arch>|lib*|share)/<name>*/               
<prefix>/<name>*/(lib/<arch>|lib*|share)/<name>*/(cmake|CMake)/","added test/cmake for testing whether the find_package works
modified installation location (required for find_package to work
Validation test:

# build and install likwid
make && make install
# go to cmake test folder
cd test/cmake
# make build directory
mkdir build && cd build
# configure where PREFIX is the entry in config.mk
CMAKE_PREFIX_PATH=${PREFIX} cmake ..
# build the test executable
make
I had to change the installation location to get find_package(likwid) to work correctly, here are the options for Unix installs:
<prefix>/(lib/<arch>|lib*|share)/cmake/<name>*/                 
<prefix>/(lib/<arch>|lib*|share)/<name>*/                       
<prefix>/(lib/<arch>|lib*|share)/<name>*/(cmake|CMake)/         
<prefix>/<name>*/(lib/<arch>|lib*|share)/cmake/<name>*/         
<prefix>/<name>*/(lib/<arch>|lib*|share)/<name>*/               
<prefix>/<name>*/(lib/<arch>|lib*|share)/<name>*/(cmake|CMake)/",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,309,2020-07-30T12:51:12Z,2020-08-11T06:32:19Z,2020-08-11T06:35:56Z,MERGED,True,268,7,4,https://github.com/jrmadsen,Updates likwid-config.cmake to support find_package,8,[],https://github.com/RRZE-HPC/likwid/pull/309,https://github.com/TomTheBear,2,https://github.com/RRZE-HPC/likwid/pull/309#issuecomment-666361301,"added test/cmake for testing whether the find_package works
modified installation location (required for find_package to work
Validation test:

# build and install likwid
make && make install
# go to cmake test folder
cd test/cmake
# make build directory
mkdir build && cd build
# configure where PREFIX is the entry in config.mk
CMAKE_PREFIX_PATH=${PREFIX} cmake ..
# build the test executable
make
I had to change the installation location to get find_package(likwid) to work correctly, here are the options for Unix installs:
<prefix>/(lib/<arch>|lib*|share)/cmake/<name>*/                 
<prefix>/(lib/<arch>|lib*|share)/<name>*/                       
<prefix>/(lib/<arch>|lib*|share)/<name>*/(cmake|CMake)/         
<prefix>/<name>*/(lib/<arch>|lib*|share)/cmake/<name>*/         
<prefix>/<name>*/(lib/<arch>|lib*|share)/<name>*/               
<prefix>/<name>*/(lib/<arch>|lib*|share)/<name>*/(cmake|CMake)/","Thanks. I asked my colleague to look at it because I have absolutely no clue about cmake. From my side, the PR mergable.
You mean the install location for the cmake file? That's fine. When I first read your post I thought shortly you changed the whole folder structure of installed LIKWID. 😅",True,{'LAUGH': ['https://github.com/jrmadsen']}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,309,2020-07-30T12:51:12Z,2020-08-11T06:32:19Z,2020-08-11T06:35:56Z,MERGED,True,268,7,4,https://github.com/jrmadsen,Updates likwid-config.cmake to support find_package,8,[],https://github.com/RRZE-HPC/likwid/pull/309,https://github.com/TomTheBear,3,https://github.com/RRZE-HPC/likwid/pull/309#issuecomment-666472341,"added test/cmake for testing whether the find_package works
modified installation location (required for find_package to work
Validation test:

# build and install likwid
make && make install
# go to cmake test folder
cd test/cmake
# make build directory
mkdir build && cd build
# configure where PREFIX is the entry in config.mk
CMAKE_PREFIX_PATH=${PREFIX} cmake ..
# build the test executable
make
I had to change the installation location to get find_package(likwid) to work correctly, here are the options for Unix installs:
<prefix>/(lib/<arch>|lib*|share)/cmake/<name>*/                 
<prefix>/(lib/<arch>|lib*|share)/<name>*/                       
<prefix>/(lib/<arch>|lib*|share)/<name>*/(cmake|CMake)/         
<prefix>/<name>*/(lib/<arch>|lib*|share)/cmake/<name>*/         
<prefix>/<name>*/(lib/<arch>|lib*|share)/<name>*/               
<prefix>/<name>*/(lib/<arch>|lib*|share)/<name>*/(cmake|CMake)/","During my first flight over your PR I saw
cmake_minimum_required(VERSION 3.11 FATAL_ERROR)

but thought, it's probably some really old version. Turns out it isn't. I have Ubuntu 18.04 installed and the latest cmake that is provided is 3.10.2. Is there a way to achieve the same functionality with ""legacy CMake""?",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,309,2020-07-30T12:51:12Z,2020-08-11T06:32:19Z,2020-08-11T06:35:56Z,MERGED,True,268,7,4,https://github.com/jrmadsen,Updates likwid-config.cmake to support find_package,8,[],https://github.com/RRZE-HPC/likwid/pull/309,https://github.com/jrmadsen,4,https://github.com/RRZE-HPC/likwid/pull/309#issuecomment-667139654,"added test/cmake for testing whether the find_package works
modified installation location (required for find_package to work
Validation test:

# build and install likwid
make && make install
# go to cmake test folder
cd test/cmake
# make build directory
mkdir build && cd build
# configure where PREFIX is the entry in config.mk
CMAKE_PREFIX_PATH=${PREFIX} cmake ..
# build the test executable
make
I had to change the installation location to get find_package(likwid) to work correctly, here are the options for Unix installs:
<prefix>/(lib/<arch>|lib*|share)/cmake/<name>*/                 
<prefix>/(lib/<arch>|lib*|share)/<name>*/                       
<prefix>/(lib/<arch>|lib*|share)/<name>*/(cmake|CMake)/         
<prefix>/<name>*/(lib/<arch>|lib*|share)/cmake/<name>*/         
<prefix>/<name>*/(lib/<arch>|lib*|share)/<name>*/               
<prefix>/<name>*/(lib/<arch>|lib*|share)/<name>*/(cmake|CMake)/","@TomTheBear Yea I forgot to change that. For whatever reason, my brain just cannot remember cmake_minimum_required(...)... I always end up typing cmake_required_version(...) so I've developed a habit of just doing a copy + paste from whatever cmake project I have open at the time.
Theoretically, v3.3.2 is the minimum but I could only find a pre-built 3.5 so I went with that:
$ cmake --version && cmake .. -G Ninja && ninja -v
cmake version 3.5.0

CMake suite maintained and supported by Kitware (kitware.com/cmake).
-- The C compiler identification is GNU 8.4.0
-- Check for working C compiler using: Ninja
-- Check for working C compiler using: Ninja -- works
-- Detecting C compiler ABI info
-- Detecting C compiler ABI info - done
-- Detecting C compile features
-- Detecting C compile features - done
-- Found likwid: /usr/local  found components:  marker nvmarker 
-- 
-- likwid_FOUND: 1
-- LIKWID_INCLUDES: /usr/local/include
-- LIKWID_LIBRARIES: /usr/local/lib/liblikwid.so
-- LIKWID_ROOT_DIR: /usr/local
-- LIKWID_NVIDIA_INTERFACE: true
-- LIKWID_FORTRAN_INTERFACE: false
-- LIKWID_INCLUDE_DIR: /usr/local/include
-- LIKWID_LIBRARY: /usr/local/lib/liblikwid.so
-- LIKWID_INCLUDE_DIRS: /usr/local/include
-- LIKWID_LIBRARIES: /usr/local/lib/liblikwid.so
-- LIKWID_LIBRARY_DIRS: /usr/local/lib
-- LIKWID_bench_EXECUTABLE: /usr/local/bin/likwid-bench
-- LIKWID_features_EXECUTABLE: /usr/local/bin/likwid-features
-- LIKWID_genTopoCfg_EXECUTABLE: /usr/local/bin/likwid-genTopoCfg
-- LIKWID_lua_EXECUTABLE: /usr/local/bin/likwid-lua
-- LIKWID_memsweeper_EXECUTABLE: /usr/local/bin/likwid-memsweeper
-- LIKWID_mpirun_EXECUTABLE: /usr/local/bin/likwid-mpirun
-- LIKWID_perfctr_EXECUTABLE: /usr/local/bin/likwid-perfctr
-- LIKWID_perfscope_EXECUTABLE: /usr/local/bin/likwid-perfscope
-- LIKWID_pin_EXECUTABLE: /usr/local/bin/likwid-pin
-- LIKWID_powermeter_EXECUTABLE: /usr/local/bin/likwid-powermeter
-- LIKWID_setFrequencies_EXECUTABLE: /usr/local/bin/likwid-setFrequencies
-- LIKWID_topology_EXECUTABLE: /usr/local/bin/likwid-topology
-- likwid_gotcha_FOUND: 
-- likwid_hwloc_FOUND: 
-- likwid_lua_FOUND: 
-- likwid_pin_FOUND: 
-- likwid_appDaemon_FOUND: 
-- likwid_marker_FOUND: ON
-- likwid_nvmarker_FOUND: ON
-- 
-- Configuring done
-- Generating done
-- Build files have been written to: /home/likwid/test/cmake/build
[1/2] /usr/bin/cc  -DLIKWID_NVMON -DLIKWID_PERFMON   -MMD -MT CMakeFiles/test_install_tree.dir/test.c.o -MF CMakeFiles/test_install_tree.dir/test.c.o.d -o CMakeFiles/test_install_tree.dir/test.c.o   -c ../test.c
[2/2] : && /usr/bin/cc     CMakeFiles/test_install_tree.dir/test.c.o  -o test_install_tree  /usr/local/lib/liblikwid.so -Wl,-rpath,/usr/local/lib && :",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,309,2020-07-30T12:51:12Z,2020-08-11T06:32:19Z,2020-08-11T06:35:56Z,MERGED,True,268,7,4,https://github.com/jrmadsen,Updates likwid-config.cmake to support find_package,8,[],https://github.com/RRZE-HPC/likwid/pull/309,https://github.com/TomTheBear,5,https://github.com/RRZE-HPC/likwid/pull/309#issuecomment-667166353,"added test/cmake for testing whether the find_package works
modified installation location (required for find_package to work
Validation test:

# build and install likwid
make && make install
# go to cmake test folder
cd test/cmake
# make build directory
mkdir build && cd build
# configure where PREFIX is the entry in config.mk
CMAKE_PREFIX_PATH=${PREFIX} cmake ..
# build the test executable
make
I had to change the installation location to get find_package(likwid) to work correctly, here are the options for Unix installs:
<prefix>/(lib/<arch>|lib*|share)/cmake/<name>*/                 
<prefix>/(lib/<arch>|lib*|share)/<name>*/                       
<prefix>/(lib/<arch>|lib*|share)/<name>*/(cmake|CMake)/         
<prefix>/<name>*/(lib/<arch>|lib*|share)/cmake/<name>*/         
<prefix>/<name>*/(lib/<arch>|lib*|share)/<name>*/               
<prefix>/<name>*/(lib/<arch>|lib*|share)/<name>*/(cmake|CMake)/","I just tried it and it works fine. Message is similar to yours and I get a warning that ""LIKWID_NVMON is not defined"" which is true for this installation.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,309,2020-07-30T12:51:12Z,2020-08-11T06:32:19Z,2020-08-11T06:35:56Z,MERGED,True,268,7,4,https://github.com/jrmadsen,Updates likwid-config.cmake to support find_package,8,[],https://github.com/RRZE-HPC/likwid/pull/309,https://github.com/jrmadsen,6,https://github.com/RRZE-HPC/likwid/pull/309#issuecomment-671557857,"added test/cmake for testing whether the find_package works
modified installation location (required for find_package to work
Validation test:

# build and install likwid
make && make install
# go to cmake test folder
cd test/cmake
# make build directory
mkdir build && cd build
# configure where PREFIX is the entry in config.mk
CMAKE_PREFIX_PATH=${PREFIX} cmake ..
# build the test executable
make
I had to change the installation location to get find_package(likwid) to work correctly, here are the options for Unix installs:
<prefix>/(lib/<arch>|lib*|share)/cmake/<name>*/                 
<prefix>/(lib/<arch>|lib*|share)/<name>*/                       
<prefix>/(lib/<arch>|lib*|share)/<name>*/(cmake|CMake)/         
<prefix>/<name>*/(lib/<arch>|lib*|share)/cmake/<name>*/         
<prefix>/<name>*/(lib/<arch>|lib*|share)/<name>*/               
<prefix>/<name>*/(lib/<arch>|lib*|share)/<name>*/(cmake|CMake)/",@christiealappatt,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,309,2020-07-30T12:51:12Z,2020-08-11T06:32:19Z,2020-08-11T06:35:56Z,MERGED,True,268,7,4,https://github.com/jrmadsen,Updates likwid-config.cmake to support find_package,8,[],https://github.com/RRZE-HPC/likwid/pull/309,https://github.com/christiealappatt,7,https://github.com/RRZE-HPC/likwid/pull/309#issuecomment-671758010,"added test/cmake for testing whether the find_package works
modified installation location (required for find_package to work
Validation test:

# build and install likwid
make && make install
# go to cmake test folder
cd test/cmake
# make build directory
mkdir build && cd build
# configure where PREFIX is the entry in config.mk
CMAKE_PREFIX_PATH=${PREFIX} cmake ..
# build the test executable
make
I had to change the installation location to get find_package(likwid) to work correctly, here are the options for Unix installs:
<prefix>/(lib/<arch>|lib*|share)/cmake/<name>*/                 
<prefix>/(lib/<arch>|lib*|share)/<name>*/                       
<prefix>/(lib/<arch>|lib*|share)/<name>*/(cmake|CMake)/         
<prefix>/<name>*/(lib/<arch>|lib*|share)/cmake/<name>*/         
<prefix>/<name>*/(lib/<arch>|lib*|share)/<name>*/               
<prefix>/<name>*/(lib/<arch>|lib*|share)/<name>*/(cmake|CMake)/",Sorry I forgot about that. PR has been merged.,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,325,2020-09-19T21:48:46Z,2020-11-06T16:00:15Z,2020-11-12T00:29:52Z,MERGED,True,2090,270,24,https://github.com/TomTheBear,Nvmon Interface for Nvidia Profiling API (for Nvidia Volta and newer),13,[],https://github.com/RRZE-HPC/likwid/pull/325,https://github.com/TomTheBear,1,https://github.com/RRZE-HPC/likwid/pull/325,Works but not validated. Currently only tested with Cuda 10.1. Some events require to measure multiple passes to get a single result. That's currently not supported.,Works but not validated. Currently only tested with Cuda 10.1. Some events require to measure multiple passes to get a single result. That's currently not supported.,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,325,2020-09-19T21:48:46Z,2020-11-06T16:00:15Z,2020-11-12T00:29:52Z,MERGED,True,2090,270,24,https://github.com/TomTheBear,Nvmon Interface for Nvidia Profiling API (for Nvidia Volta and newer),13,[],https://github.com/RRZE-HPC/likwid/pull/325,https://github.com/TomTheBear,2,https://github.com/RRZE-HPC/likwid/pull/325#issuecomment-695359640,Works but not validated. Currently only tested with Cuda 10.1. Some events require to measure multiple passes to get a single result. That's currently not supported.,"Related:

#317
#312",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,329,2020-10-05T01:47:59Z,2020-11-13T21:17:24Z,2020-11-13T21:17:30Z,MERGED,True,1213,2,8,https://github.com/TomTheBear,Add support for Intel Tigerlake,7,[],https://github.com/RRZE-HPC/likwid/pull/329,https://github.com/TomTheBear,1,https://github.com/RRZE-HPC/likwid/pull/329,"Currently supported counters:

Fixed-purpose counters without the new FIXC3 (event TOPDOWN_SLOTS)
PMC counters with all defined events in Perfmon JSON
Thermal counters
Voltage counters
RAPL (energy) counters

Completely untested as I don't have access to a Tigerlake system.","Currently supported counters:

Fixed-purpose counters without the new FIXC3 (event TOPDOWN_SLOTS)
PMC counters with all defined events in Perfmon JSON
Thermal counters
Voltage counters
RAPL (energy) counters

Completely untested as I don't have access to a Tigerlake system.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,329,2020-10-05T01:47:59Z,2020-11-13T21:17:24Z,2020-11-13T21:17:30Z,MERGED,True,1213,2,8,https://github.com/TomTheBear,Add support for Intel Tigerlake,7,[],https://github.com/RRZE-HPC/likwid/pull/329,https://github.com/TomTheBear,2,https://github.com/RRZE-HPC/likwid/pull/329#issuecomment-703366665,"Currently supported counters:

Fixed-purpose counters without the new FIXC3 (event TOPDOWN_SLOTS)
PMC counters with all defined events in Perfmon JSON
Thermal counters
Voltage counters
RAPL (energy) counters

Completely untested as I don't have access to a Tigerlake system.","Should the cmask/threshold be 1 or 2 for IDQ_MITE_CYCLES_ANY? Tigerlake JSON says 2, Icelake JSON and the other IDQ_*_CYCLES_ANY events from Tigerlake also use 1.
Update: It's also 1 in Tigerlake JSON, the 2 is from ""CollectPEBSRecord"": ""2"",",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,330,2020-10-05T02:44:46Z,2020-11-13T18:53:48Z,2021-05-27T10:22:47Z,MERGED,True,2748,8,32,https://github.com/TomTheBear,Add basic support for Intel Icelake,3,[],https://github.com/RRZE-HPC/likwid/pull/330,https://github.com/TomTheBear,1,https://github.com/RRZE-HPC/likwid/pull/330,"Currently supported counters:

Fixed-purpose counters without the new FIXC3 (event TOPDOWN_SLOTS)
PMC counters with all defined events in Perfmon JSON
Thermal counters
Voltage counters
RAPL (energy) counters

Completely untested as I don't have access to an Icelake system.","Currently supported counters:

Fixed-purpose counters without the new FIXC3 (event TOPDOWN_SLOTS)
PMC counters with all defined events in Perfmon JSON
Thermal counters
Voltage counters
RAPL (energy) counters

Completely untested as I don't have access to an Icelake system.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,337,2020-11-08T03:01:44Z,2020-12-08T14:40:54Z,2020-12-08T14:40:54Z,MERGED,True,99,7,8,https://github.com/jimmysitu,"Add mperf, aperf and pperf for skylake",7,[],https://github.com/RRZE-HPC/likwid/pull/337,https://github.com/jimmysitu,1,https://github.com/RRZE-HPC/likwid/pull/337,"Hi, All
I add mperf/aperf/pperf counter for Intel skylake.","Hi, All
I add mperf/aperf/pperf counter for Intel skylake.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,337,2020-11-08T03:01:44Z,2020-12-08T14:40:54Z,2020-12-08T14:40:54Z,MERGED,True,99,7,8,https://github.com/jimmysitu,"Add mperf, aperf and pperf for skylake",7,[],https://github.com/RRZE-HPC/likwid/pull/337,https://github.com/TomTheBear,2,https://github.com/RRZE-HPC/likwid/pull/337#issuecomment-723935059,"Hi, All
I add mperf/aperf/pperf counter for Intel skylake.","Thanks for the PR.
One thing is missing: You cannot use the events if built with perf_event backend. Since the units are named differently in LIKWID and perf_event, you have to add the appropriate relation in the translate_types for Skylake. Skylake currently uses the default translation types. You can copy the whole list and put it in src/includes/perfmon_skylake_counters.h (check other *_counter.h files for naming).
How about the other architectures? src/includes/skylake.h is also used for server class skylakeX but the PR only adds the events to the desktop class skylake. Are you willing to add the support to other architectures as well? When I remember corrently, the events are available since SandyBridge.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,337,2020-11-08T03:01:44Z,2020-12-08T14:40:54Z,2020-12-08T14:40:54Z,MERGED,True,99,7,8,https://github.com/jimmysitu,"Add mperf, aperf and pperf for skylake",7,[],https://github.com/RRZE-HPC/likwid/pull/337,https://github.com/TomTheBear,3,https://github.com/RRZE-HPC/likwid/pull/337#issuecomment-727918662,"Hi, All
I add mperf/aperf/pperf counter for Intel skylake.",This PR won't make it into the upcoming release. I don't want to add something for only one architecture and only with one access method. We have to generalize the support.,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,337,2020-11-08T03:01:44Z,2020-12-08T14:40:54Z,2020-12-08T14:40:54Z,MERGED,True,99,7,8,https://github.com/jimmysitu,"Add mperf, aperf and pperf for skylake",7,[],https://github.com/RRZE-HPC/likwid/pull/337,https://github.com/jimmysitu,4,https://github.com/RRZE-HPC/likwid/pull/337#issuecomment-735068896,"Hi, All
I add mperf/aperf/pperf counter for Intel skylake.","Hi, @TomTheBear
I'd like to help to make it support built with perf_event backend. And I followed the instructions you mention above.
But it seems I still missing something, and I only get all zero of mperf/aperf/pperf when using perf_event backend.
I try
sudo likwid-perfctr -C 0 -g PERF sleep 5
and got
--------------------------------------------------------------------------------
CPU name:	Intel(R) Core(TM) i5-8350U CPU @ 1.70GHz
CPU type:	Intel Kabylake processor
CPU clock:	1.90 GHz
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
Group 1: PERF
+-----------------------+---------+--------+
|         Event         | Counter | Core 0 |
+-----------------------+---------+--------+
|   INSTR_RETIRED_ANY   |  FIXC0  | 247145 |
| CPU_CLK_UNHALTED_CORE |  FIXC1  | 480119 |
|  CPU_CLK_UNHALTED_REF |  FIXC2  | 253511 |
|         MPERF         |  MPERF  |      0 |
|         APERF         |  APERF  |      0 |
|         PPERF         |  PPERF  |      0 |
+-----------------------+---------+--------+

+----------------------+-----------+
|        Metric        |   Core 0  |
+----------------------+-----------+
|  Runtime (RDTSC) [s] |    5.0013 |
| Runtime unhalted [s] |    0.0003 |
|      Clock [MHz]     | 3590.7354 |
|          CPI         |    1.9427 |
|    Aperf/Mperf [%]   |     -     |
|    Pperf/Aperf [%]   |     -     |
+----------------------+-----------+",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,337,2020-11-08T03:01:44Z,2020-12-08T14:40:54Z,2020-12-08T14:40:54Z,MERGED,True,99,7,8,https://github.com/jimmysitu,"Add mperf, aperf and pperf for skylake",7,[],https://github.com/RRZE-HPC/likwid/pull/337,https://github.com/TomTheBear,5,https://github.com/RRZE-HPC/likwid/pull/337#issuecomment-735230489,"Hi, All
I add mperf/aperf/pperf counter for Intel skylake.","Please run it like likwid-perfctr -V 3 .... This should give you some information where the problem resides. And if you don't see anything, I can (hopefully) point you to the issue in the code.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,337,2020-11-08T03:01:44Z,2020-12-08T14:40:54Z,2020-12-08T14:40:54Z,MERGED,True,99,7,8,https://github.com/jimmysitu,"Add mperf, aperf and pperf for skylake",7,[],https://github.com/RRZE-HPC/likwid/pull/337,https://github.com/TomTheBear,6,https://github.com/RRZE-HPC/likwid/pull/337#issuecomment-735295395,"Hi, All
I add mperf/aperf/pperf counter for Intel skylake.","I took a look in your code changes and the problem might be your event definitions:
EVENT_MPERF      0x00   MPERF
UMASK_MPERF      0x00

EVENT_APERF      0x00   APERF
UMASK_APERF      0x00

If you look at the event definition provided by perf_event, the event ID is 0x02 on my Haswell desktop:
$ cat /sys/bus/event_source/devices/msr/events/mperf
event=0x02

aperf should have event ID 0x01. I don't find the code for pperf, so it might not be provided by perf_event (or at least not on my Haswell system).
EVENT_MPERF      0x02   MPERF
UMASK_MPERF      0x00

EVENT_APERF      0x01   APERF
UMASK_APERF      0x00",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,337,2020-11-08T03:01:44Z,2020-12-08T14:40:54Z,2020-12-08T14:40:54Z,MERGED,True,99,7,8,https://github.com/jimmysitu,"Add mperf, aperf and pperf for skylake",7,[],https://github.com/RRZE-HPC/likwid/pull/337,https://github.com/TomTheBear,7,https://github.com/RRZE-HPC/likwid/pull/337#issuecomment-736591642,"Hi, All
I add mperf/aperf/pperf counter for Intel skylake.",Do the new counters/event work now with perf_event? Thanks for creating a performance group.,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,337,2020-11-08T03:01:44Z,2020-12-08T14:40:54Z,2020-12-08T14:40:54Z,MERGED,True,99,7,8,https://github.com/jimmysitu,"Add mperf, aperf and pperf for skylake",7,[],https://github.com/RRZE-HPC/likwid/pull/337,https://github.com/jimmysitu,8,https://github.com/RRZE-HPC/likwid/pull/337#issuecomment-737218110,"Hi, All
I add mperf/aperf/pperf counter for Intel skylake.","Hi, @TomTheBear
They do not work yet, I try to debug a little while, but fail to find anything meaning full. I attached the -V 3 log here.
DEBUG - [hwloc_init_cpuInfo:358] HWLOC CpuInfo Family 6 Model 142 Stepping 10 Vendor 0x0 Part 0x0 isIntel 1 numHWThreads 8 activeHWThreads 8
DEBUG - [hwloc_init_nodeTopology:531] HWLOC Thread Pool PU 0 Thread 0 Core 0 Socket 0 inCpuSet 1
DEBUG - [hwloc_init_nodeTopology:531] HWLOC Thread Pool PU 4 Thread 1 Core 0 Socket 0 inCpuSet 1
DEBUG - [hwloc_init_nodeTopology:531] HWLOC Thread Pool PU 1 Thread 0 Core 1 Socket 0 inCpuSet 1
DEBUG - [hwloc_init_nodeTopology:531] HWLOC Thread Pool PU 5 Thread 1 Core 1 Socket 0 inCpuSet 1
DEBUG - [hwloc_init_nodeTopology:531] HWLOC Thread Pool PU 2 Thread 0 Core 2 Socket 0 inCpuSet 1
DEBUG - [hwloc_init_nodeTopology:531] HWLOC Thread Pool PU 6 Thread 1 Core 2 Socket 0 inCpuSet 1
DEBUG - [hwloc_init_nodeTopology:531] HWLOC Thread Pool PU 3 Thread 0 Core 3 Socket 0 inCpuSet 1
DEBUG - [hwloc_init_nodeTopology:531] HWLOC Thread Pool PU 7 Thread 1 Core 3 Socket 0 inCpuSet 1
DEBUG - [hwloc_init_cacheTopology:748] HWLOC Cache Pool ID 0 Level 1 Size 32768 Threads 2
DEBUG - [hwloc_init_cacheTopology:748] HWLOC Cache Pool ID 1 Level 2 Size 262144 Threads 2
DEBUG - [hwloc_init_cacheTopology:748] HWLOC Cache Pool ID 2 Level 3 Size 6291456 Threads 8
DEBUG - [affinity_init:304] Affinity: Socket domains 1
DEBUG - [affinity_init:312] Affinity: NUMA domains 1
DEBUG - [affinity_init:315] Affinity: CPUs per socket 8
DEBUG - [affinity_init:325] Affinity: CPU cores per LLC 4
DEBUG - [affinity_init:329] Affinity: CPUs per LLC 8
DEBUG - [affinity_init:336] Affinity: Cache domains 1
DEBUG - [affinity_init:340] Affinity: All domains 4
DEBUG - [affinity_init:353] Affinity domain N: 8 HW threads on 4 cores
DEBUG - [affinity_init:392] Affinity domain S0: 8 HW threads on 4 cores
DEBUG - [affinity_init:422] Affinity domain C0: 8 HW threads on 4 cores
DEBUG - [affinity_init:494] Affinity domain M0: 8 HW threads on 4 cores
DEBUG - [create_lookups:252] affinity_thread2core_lookup[0] = 0
DEBUG - [create_lookups:254] affinity_thread2socket_lookup[0] = 0
DEBUG - [create_lookups:268] affinity_thread2numa_lookup[0] = 0
DEBUG - [create_lookups:276] affinity_thread2sharedl3_lookup[0] = 0
DEBUG - [create_lookups:252] affinity_thread2core_lookup[1] = 1
DEBUG - [create_lookups:254] affinity_thread2socket_lookup[1] = 0
DEBUG - [create_lookups:268] affinity_thread2numa_lookup[1] = 0
DEBUG - [create_lookups:276] affinity_thread2sharedl3_lookup[1] = 0
DEBUG - [create_lookups:252] affinity_thread2core_lookup[2] = 2
DEBUG - [create_lookups:254] affinity_thread2socket_lookup[2] = 0
DEBUG - [create_lookups:268] affinity_thread2numa_lookup[2] = 0
DEBUG - [create_lookups:276] affinity_thread2sharedl3_lookup[2] = 0
DEBUG - [create_lookups:252] affinity_thread2core_lookup[3] = 3
DEBUG - [create_lookups:254] affinity_thread2socket_lookup[3] = 0
DEBUG - [create_lookups:268] affinity_thread2numa_lookup[3] = 0
DEBUG - [create_lookups:276] affinity_thread2sharedl3_lookup[3] = 0
DEBUG - [create_lookups:252] affinity_thread2core_lookup[4] = 0
DEBUG - [create_lookups:254] affinity_thread2socket_lookup[4] = 0
DEBUG - [create_lookups:268] affinity_thread2numa_lookup[4] = 0
DEBUG - [create_lookups:276] affinity_thread2sharedl3_lookup[4] = 0
DEBUG - [create_lookups:252] affinity_thread2core_lookup[5] = 1
DEBUG - [create_lookups:254] affinity_thread2socket_lookup[5] = 0
DEBUG - [create_lookups:268] affinity_thread2numa_lookup[5] = 0
DEBUG - [create_lookups:276] affinity_thread2sharedl3_lookup[5] = 0
DEBUG - [create_lookups:252] affinity_thread2core_lookup[6] = 2
DEBUG - [create_lookups:254] affinity_thread2socket_lookup[6] = 0
DEBUG - [create_lookups:268] affinity_thread2numa_lookup[6] = 0
DEBUG - [create_lookups:276] affinity_thread2sharedl3_lookup[6] = 0
DEBUG - [create_lookups:252] affinity_thread2core_lookup[7] = 3
DEBUG - [create_lookups:254] affinity_thread2socket_lookup[7] = 0
DEBUG - [create_lookups:268] affinity_thread2numa_lookup[7] = 0
DEBUG - [create_lookups:276] affinity_thread2sharedl3_lookup[7] = 0
--------------------------------------------------------------------------------
CPU name:	Intel(R) Core(TM) i5-8350U CPU @ 1.70GHz
CPU type:	Intel Kabylake processor
CPU clock:	1.89 GHz
CPU family:	6
CPU model:	142
CPU short:	skylake
CPU stepping:	10
CPU features:	FP ACPI MMX SSE SSE2 HTT TM RDTSCP MONITOR VMX EIST TM2 SSSE FMA SSE4.1 SSE4.2 AES AVX RDRAND HLE AVX2 RTM RDSEED SSE3 
CPU arch:	x86_64
--------------------------------------------------------------------------------
PERFMON version:	4
PERFMON number of counters:	4
PERFMON width of counters:	48
PERFMON number of fixed counters:	3
--------------------------------------------------------------------------------
�[1;34m[likwid-pin] Main PID -> core 0 - OK�[0m
Executing: sleep 10
DEBUG - [perfmon_addEventSet:2001] Currently 1 groups of 2 active
DEBUG - [perfgroup_readGroup:836] Cannot read group file /usr/local/share/likwid/perfgroups/skylake/PERF.txt. Trying /home/jmst/.likwid/groups/skylake/PERF.txt
DEBUG - [perfgroup_readGroup:852] Reading group PERF from /home/jmst/.likwid/groups/skylake/PERF.txt
DEBUG - [perfmon_addEventSet:2182] Added event INSTR_RETIRED_ANY for counter FIXC0 to group 0
DEBUG - [perfmon_addEventSet:2182] Added event CPU_CLK_UNHALTED_CORE for counter FIXC1 to group 0
DEBUG - [perfmon_addEventSet:2182] Added event CPU_CLK_UNHALTED_REF for counter FIXC2 to group 0
DEBUG - [perfmon_addEventSet:2182] Added event MPERF for counter MPERF to group 0
DEBUG - [perfmon_addEventSet:2182] Added event APERF for counter APERF to group 0
DEBUG - [perfmon_addEventSet:2182] Added event PPERF for counter PPERF to group 0
DEBUG - [perfmon_setupCountersThread_perfevent:648] SETUP_FIXED [0] Register 0x0 , Flags: 0x1 
DEBUG - [perfmon_setupCountersThread_perfevent:789] perf_event_open: cpu_id=0 pid=26931 flags=0
DEBUG - [perfmon_setupCountersThread_perfevent:648] SETUP_FIXED [0] Register 0x1 , Flags: 0x0 
DEBUG - [perfmon_setupCountersThread_perfevent:789] perf_event_open: cpu_id=0 pid=26931 flags=0
DEBUG - [perfmon_setupCountersThread_perfevent:648] SETUP_FIXED [0] Register 0x2 , Flags: 0x9 
DEBUG - [perfmon_setupCountersThread_perfevent:789] perf_event_open: cpu_id=0 pid=26931 flags=0
--------------------------------------------------------------------------------
DEBUG - [perfmon_startCountersThread_perfevent:828] RESET_COUNTER [0] Register 0x0 , Flags: 0x0 
DEBUG - [perfmon_startCountersThread_perfevent:839] START_COUNTER [0] Register 0x0 , Flags: 0x0 
DEBUG - [perfmon_startCountersThread_perfevent:828] RESET_COUNTER [0] Register 0x0 , Flags: 0x0 
DEBUG - [perfmon_startCountersThread_perfevent:839] START_COUNTER [0] Register 0x0 , Flags: 0x0 
DEBUG - [perfmon_startCountersThread_perfevent:828] RESET_COUNTER [0] Register 0x0 , Flags: 0x0 
DEBUG - [perfmon_startCountersThread_perfevent:839] START_COUNTER [0] Register 0x0 , Flags: 0x0 
DEBUG - [perfmon_readCountersThread_perfevent:886] FREEZE_COUNTER [0] Register 0x3 , Flags: 0x0 
DEBUG - [perfmon_readCountersThread_perfevent:890] READ_COUNTER [0] Register 0x3 , Flags: 0x0 
DEBUG - [perfmon_readCountersThread_perfevent:895] UNFREEZE_COUNTER [0] Register 0x3 , Flags: 0x0 
DEBUG - [perfmon_readCountersThread_perfevent:886] FREEZE_COUNTER [0] Register 0x4 , Flags: 0x0 
DEBUG - [perfmon_readCountersThread_perfevent:890] READ_COUNTER [0] Register 0x4 , Flags: 0x0 
DEBUG - [perfmon_readCountersThread_perfevent:895] UNFREEZE_COUNTER [0] Register 0x4 , Flags: 0x0 
DEBUG - [perfmon_readCountersThread_perfevent:886] FREEZE_COUNTER [0] Register 0x5 , Flags: 0x0 
DEBUG - [perfmon_readCountersThread_perfevent:890] READ_COUNTER [0] Register 0x5 , Flags: 0x0 
DEBUG - [perfmon_readCountersThread_perfevent:895] UNFREEZE_COUNTER [0] Register 0x5 , Flags: 0x0 
DEBUG - [perfmon_stopCountersThread_perfevent:858] FREEZE_COUNTER [0] Register 0x3 , Flags: 0x0 
DEBUG - [perfmon_stopCountersThread_perfevent:862] READ_COUNTER [0] Register 0x3 , Flags: 0x3C55F 
DEBUG - [perfmon_stopCountersThread_perfevent:868] RESET_COUNTER [0] Register 0x3 , Flags: 0x0 
DEBUG - [perfmon_stopCountersThread_perfevent:858] FREEZE_COUNTER [0] Register 0x4 , Flags: 0x0 
DEBUG - [perfmon_stopCountersThread_perfevent:862] READ_COUNTER [0] Register 0x4 , Flags: 0x6C15E 
DEBUG - [perfmon_stopCountersThread_perfevent:868] RESET_COUNTER [0] Register 0x4 , Flags: 0x0 
DEBUG - [perfmon_stopCountersThread_perfevent:858] FREEZE_COUNTER [0] Register 0x5 , Flags: 0x0 
DEBUG - [perfmon_stopCountersThread_perfevent:862] READ_COUNTER [0] Register 0x5 , Flags: 0x390D2 
DEBUG - [perfmon_stopCountersThread_perfevent:868] RESET_COUNTER [0] Register 0x5 , Flags: 0x0 
--------------------------------------------------------------------------------
Group 1: PERF
+-----------------------+---------+--------+
|         Event         | Counter | Core 0 |
+-----------------------+---------+--------+
|   INSTR_RETIRED_ANY   |  FIXC0  | 247135 |
| CPU_CLK_UNHALTED_CORE |  FIXC1  | 442718 |
|  CPU_CLK_UNHALTED_REF |  FIXC2  | 233682 |
|         MPERF         |  MPERF  |      0 |
|         APERF         |  APERF  |      0 |
|         PPERF         |  PPERF  |      0 |
+-----------------------+---------+--------+

+----------------------+-----------+
|        Metric        |   Core 0  |
+----------------------+-----------+
|  Runtime (RDTSC) [s] |   10.0067 |
| Runtime unhalted [s] |    0.0002 |
|      Clock [MHz]     | 3589.9065 |
|          CPI         |    1.7914 |
|    Aperf/Mperf [%]   |     -     |
|    Pperf/Aperf [%]   |     -     |
+----------------------+-----------+",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,337,2020-11-08T03:01:44Z,2020-12-08T14:40:54Z,2020-12-08T14:40:54Z,MERGED,True,99,7,8,https://github.com/jimmysitu,"Add mperf, aperf and pperf for skylake",7,[],https://github.com/RRZE-HPC/likwid/pull/337,https://github.com/TomTheBear,9,https://github.com/RRZE-HPC/likwid/pull/337#issuecomment-737230999,"Hi, All
I add mperf/aperf/pperf counter for Intel skylake.","It looks like the PERF counters are never set up nor started or stopped by the perf_event backend. Similar to the architecture-specific files, there is a big switch-case statement in src/includes/perfmon_perfevent.h  to configure the counters. No changes in the start, stop or read functions required commonly.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,337,2020-11-08T03:01:44Z,2020-12-08T14:40:54Z,2020-12-08T14:40:54Z,MERGED,True,99,7,8,https://github.com/jimmysitu,"Add mperf, aperf and pperf for skylake",7,[],https://github.com/RRZE-HPC/likwid/pull/337,https://github.com/jimmysitu,10,https://github.com/RRZE-HPC/likwid/pull/337#issuecomment-739251758,"Hi, All
I add mperf/aperf/pperf counter for Intel skylake.","Hi, @TomTheBear
It seems the PERF registers are setup, but all PERF is reading the same value. Any idea?
DEBUG - [hwloc_init_cpuInfo:358] HWLOC CpuInfo Family 6 Model 142 Stepping 10 Vendor 0x0 Part 0x0 isIntel 1 numHWThreads 8 activeHWThreads 8
DEBUG - [hwloc_init_nodeTopology:531] HWLOC Thread Pool PU 0 Thread 0 Core 0 Socket 0 inCpuSet 1
DEBUG - [hwloc_init_nodeTopology:531] HWLOC Thread Pool PU 4 Thread 1 Core 0 Socket 0 inCpuSet 1
DEBUG - [hwloc_init_nodeTopology:531] HWLOC Thread Pool PU 1 Thread 0 Core 1 Socket 0 inCpuSet 1
DEBUG - [hwloc_init_nodeTopology:531] HWLOC Thread Pool PU 5 Thread 1 Core 1 Socket 0 inCpuSet 1
DEBUG - [hwloc_init_nodeTopology:531] HWLOC Thread Pool PU 2 Thread 0 Core 2 Socket 0 inCpuSet 1
DEBUG - [hwloc_init_nodeTopology:531] HWLOC Thread Pool PU 6 Thread 1 Core 2 Socket 0 inCpuSet 1
DEBUG - [hwloc_init_nodeTopology:531] HWLOC Thread Pool PU 3 Thread 0 Core 3 Socket 0 inCpuSet 1
DEBUG - [hwloc_init_nodeTopology:531] HWLOC Thread Pool PU 7 Thread 1 Core 3 Socket 0 inCpuSet 1
DEBUG - [hwloc_init_cacheTopology:748] HWLOC Cache Pool ID 0 Level 1 Size 32768 Threads 2
DEBUG - [hwloc_init_cacheTopology:748] HWLOC Cache Pool ID 1 Level 2 Size 262144 Threads 2
DEBUG - [hwloc_init_cacheTopology:748] HWLOC Cache Pool ID 2 Level 3 Size 6291456 Threads 8
DEBUG - [affinity_init:304] Affinity: Socket domains 1
DEBUG - [affinity_init:312] Affinity: NUMA domains 1
DEBUG - [affinity_init:315] Affinity: CPUs per socket 8
DEBUG - [affinity_init:325] Affinity: CPU cores per LLC 4
DEBUG - [affinity_init:329] Affinity: CPUs per LLC 8
DEBUG - [affinity_init:336] Affinity: Cache domains 1
DEBUG - [affinity_init:340] Affinity: All domains 4
DEBUG - [affinity_init:353] Affinity domain N: 8 HW threads on 4 cores
DEBUG - [affinity_init:392] Affinity domain S0: 8 HW threads on 4 cores
DEBUG - [affinity_init:422] Affinity domain C0: 8 HW threads on 4 cores
DEBUG - [affinity_init:494] Affinity domain M0: 8 HW threads on 4 cores
DEBUG - [create_lookups:252] affinity_thread2core_lookup[0] = 0
DEBUG - [create_lookups:254] affinity_thread2socket_lookup[0] = 0
DEBUG - [create_lookups:268] affinity_thread2numa_lookup[0] = 0
DEBUG - [create_lookups:276] affinity_thread2sharedl3_lookup[0] = 0
DEBUG - [create_lookups:252] affinity_thread2core_lookup[1] = 1
DEBUG - [create_lookups:254] affinity_thread2socket_lookup[1] = 0
DEBUG - [create_lookups:268] affinity_thread2numa_lookup[1] = 0
DEBUG - [create_lookups:276] affinity_thread2sharedl3_lookup[1] = 0
DEBUG - [create_lookups:252] affinity_thread2core_lookup[2] = 2
DEBUG - [create_lookups:254] affinity_thread2socket_lookup[2] = 0
DEBUG - [create_lookups:268] affinity_thread2numa_lookup[2] = 0
DEBUG - [create_lookups:276] affinity_thread2sharedl3_lookup[2] = 0
DEBUG - [create_lookups:252] affinity_thread2core_lookup[3] = 3
DEBUG - [create_lookups:254] affinity_thread2socket_lookup[3] = 0
DEBUG - [create_lookups:268] affinity_thread2numa_lookup[3] = 0
DEBUG - [create_lookups:276] affinity_thread2sharedl3_lookup[3] = 0
DEBUG - [create_lookups:252] affinity_thread2core_lookup[4] = 0
DEBUG - [create_lookups:254] affinity_thread2socket_lookup[4] = 0
DEBUG - [create_lookups:268] affinity_thread2numa_lookup[4] = 0
DEBUG - [create_lookups:276] affinity_thread2sharedl3_lookup[4] = 0
DEBUG - [create_lookups:252] affinity_thread2core_lookup[5] = 1
DEBUG - [create_lookups:254] affinity_thread2socket_lookup[5] = 0
DEBUG - [create_lookups:268] affinity_thread2numa_lookup[5] = 0
DEBUG - [create_lookups:276] affinity_thread2sharedl3_lookup[5] = 0
DEBUG - [create_lookups:252] affinity_thread2core_lookup[6] = 2
DEBUG - [create_lookups:254] affinity_thread2socket_lookup[6] = 0
DEBUG - [create_lookups:268] affinity_thread2numa_lookup[6] = 0
DEBUG - [create_lookups:276] affinity_thread2sharedl3_lookup[6] = 0
DEBUG - [create_lookups:252] affinity_thread2core_lookup[7] = 3
DEBUG - [create_lookups:254] affinity_thread2socket_lookup[7] = 0
DEBUG - [create_lookups:268] affinity_thread2numa_lookup[7] = 0
DEBUG - [create_lookups:276] affinity_thread2sharedl3_lookup[7] = 0
--------------------------------------------------------------------------------
CPU name:	Intel(R) Core(TM) i5-8350U CPU @ 1.70GHz
CPU type:	Intel Kabylake processor
CPU clock:	1.90 GHz
CPU family:	6
CPU model:	142
CPU short:	skylake
CPU stepping:	10
CPU features:	FP ACPI MMX SSE SSE2 HTT TM RDTSCP MONITOR VMX EIST TM2 SSSE FMA SSE4.1 SSE4.2 AES AVX RDRAND HLE AVX2 RTM RDSEED SSE3 
CPU arch:	x86_64
--------------------------------------------------------------------------------
PERFMON version:	4
PERFMON number of counters:	4
PERFMON width of counters:	48
PERFMON number of fixed counters:	3
--------------------------------------------------------------------------------
�[1;34m[likwid-pin] Main PID -> core 0 - OK�[0m
Executing: sleep 10
DEBUG - [perfmon_addEventSet:2001] Currently 1 groups of 2 active
DEBUG - [perfgroup_readGroup:852] Reading group PERF from /usr/local/share/likwid/perfgroups/skylake/PERF.txt
DEBUG - [perfmon_addEventSet:2182] Added event INSTR_RETIRED_ANY for counter FIXC0 to group 0
DEBUG - [perfmon_addEventSet:2182] Added event CPU_CLK_UNHALTED_CORE for counter FIXC1 to group 0
DEBUG - [perfmon_addEventSet:2182] Added event CPU_CLK_UNHALTED_REF for counter FIXC2 to group 0
DEBUG - [perfmon_addEventSet:2182] Added event MPERF for counter MPERF to group 0
DEBUG - [perfmon_addEventSet:2182] Added event APERF for counter APERF to group 0
DEBUG - [perfmon_addEventSet:2182] Added event PPERF for counter PPERF to group 0
DEBUG - [perfmon_setupCountersThread_perfevent:652] SETUP_FIXED [0] Register 0x0 , Flags: 0x1 
DEBUG - [perfmon_setupCountersThread_perfevent:801] perf_event_open: cpu_id=0 pid=9613 flags=0
DEBUG - [perfmon_setupCountersThread_perfevent:652] SETUP_FIXED [0] Register 0x1 , Flags: 0x0 
DEBUG - [perfmon_setupCountersThread_perfevent:801] perf_event_open: cpu_id=0 pid=9613 flags=0
DEBUG - [perfmon_setupCountersThread_perfevent:652] SETUP_FIXED [0] Register 0x2 , Flags: 0x9 
DEBUG - [perfmon_setupCountersThread_perfevent:801] perf_event_open: cpu_id=0 pid=9613 flags=0
DEBUG - [perfmon_setupCountersThread_perfevent:660] SETUP_PERF [0] Register 0x22 , Flags: 0x0 
DEBUG - [perfmon_setupCountersThread_perfevent:801] perf_event_open: cpu_id=0 pid=9613 flags=0
DEBUG - [perfmon_setupCountersThread_perfevent:660] SETUP_PERF [0] Register 0x23 , Flags: 0x0 
DEBUG - [perfmon_setupCountersThread_perfevent:801] perf_event_open: cpu_id=0 pid=9613 flags=0
DEBUG - [perfmon_setupCountersThread_perfevent:660] SETUP_PERF [0] Register 0x24 , Flags: 0x0 
DEBUG - [perfmon_setupCountersThread_perfevent:801] perf_event_open: cpu_id=0 pid=9613 flags=0
--------------------------------------------------------------------------------
DEBUG - [perfmon_startCountersThread_perfevent:840] RESET_COUNTER [0] Register 0x0 , Flags: 0x0 
DEBUG - [perfmon_startCountersThread_perfevent:851] START_COUNTER [0] Register 0x0 , Flags: 0x0 
DEBUG - [perfmon_startCountersThread_perfevent:840] RESET_COUNTER [0] Register 0x0 , Flags: 0x0 
DEBUG - [perfmon_startCountersThread_perfevent:851] START_COUNTER [0] Register 0x0 , Flags: 0x0 
DEBUG - [perfmon_startCountersThread_perfevent:840] RESET_COUNTER [0] Register 0x0 , Flags: 0x0 
DEBUG - [perfmon_startCountersThread_perfevent:851] START_COUNTER [0] Register 0x0 , Flags: 0x0 
DEBUG - [perfmon_startCountersThread_perfevent:840] RESET_COUNTER [0] Register 0x0 , Flags: 0x0 
DEBUG - [perfmon_startCountersThread_perfevent:851] START_COUNTER [0] Register 0x0 , Flags: 0x0 
DEBUG - [perfmon_startCountersThread_perfevent:840] RESET_COUNTER [0] Register 0x0 , Flags: 0x0 
DEBUG - [perfmon_startCountersThread_perfevent:851] START_COUNTER [0] Register 0x0 , Flags: 0x0 
DEBUG - [perfmon_startCountersThread_perfevent:840] RESET_COUNTER [0] Register 0x0 , Flags: 0x0 
DEBUG - [perfmon_startCountersThread_perfevent:851] START_COUNTER [0] Register 0x0 , Flags: 0x0 
DEBUG - [perfmon_readCountersThread_perfevent:898] FREEZE_COUNTER [0] Register 0x3 , Flags: 0x0 
DEBUG - [perfmon_readCountersThread_perfevent:902] READ_COUNTER [0] Register 0x3 , Flags: 0x0 
DEBUG - [perfmon_readCountersThread_perfevent:907] UNFREEZE_COUNTER [0] Register 0x3 , Flags: 0x0 
DEBUG - [perfmon_readCountersThread_perfevent:898] FREEZE_COUNTER [0] Register 0x4 , Flags: 0x0 
DEBUG - [perfmon_readCountersThread_perfevent:902] READ_COUNTER [0] Register 0x4 , Flags: 0x0 
DEBUG - [perfmon_readCountersThread_perfevent:907] UNFREEZE_COUNTER [0] Register 0x4 , Flags: 0x0 
DEBUG - [perfmon_readCountersThread_perfevent:898] FREEZE_COUNTER [0] Register 0x5 , Flags: 0x0 
DEBUG - [perfmon_readCountersThread_perfevent:902] READ_COUNTER [0] Register 0x5 , Flags: 0x0 
DEBUG - [perfmon_readCountersThread_perfevent:907] UNFREEZE_COUNTER [0] Register 0x5 , Flags: 0x0 
DEBUG - [perfmon_readCountersThread_perfevent:898] FREEZE_COUNTER [0] Register 0x6 , Flags: 0x0 
DEBUG - [perfmon_readCountersThread_perfevent:902] READ_COUNTER [0] Register 0x6 , Flags: 0x0 
DEBUG - [perfmon_readCountersThread_perfevent:907] UNFREEZE_COUNTER [0] Register 0x6 , Flags: 0x0 
DEBUG - [perfmon_readCountersThread_perfevent:898] FREEZE_COUNTER [0] Register 0x7 , Flags: 0x0 
DEBUG - [perfmon_readCountersThread_perfevent:902] READ_COUNTER [0] Register 0x7 , Flags: 0x0 
DEBUG - [perfmon_readCountersThread_perfevent:907] UNFREEZE_COUNTER [0] Register 0x7 , Flags: 0x0 
DEBUG - [perfmon_readCountersThread_perfevent:898] FREEZE_COUNTER [0] Register 0x8 , Flags: 0x0 
DEBUG - [perfmon_readCountersThread_perfevent:902] READ_COUNTER [0] Register 0x8 , Flags: 0x0 
DEBUG - [perfmon_readCountersThread_perfevent:907] UNFREEZE_COUNTER [0] Register 0x8 , Flags: 0x0 
DEBUG - [perfmon_stopCountersThread_perfevent:870] FREEZE_COUNTER [0] Register 0x3 , Flags: 0x0 
DEBUG - [perfmon_stopCountersThread_perfevent:874] READ_COUNTER [0] Register 0x3 , Flags: 0x3C562 
DEBUG - [perfmon_stopCountersThread_perfevent:880] RESET_COUNTER [0] Register 0x3 , Flags: 0x0 
DEBUG - [perfmon_stopCountersThread_perfevent:870] FREEZE_COUNTER [0] Register 0x4 , Flags: 0x0 
DEBUG - [perfmon_stopCountersThread_perfevent:874] READ_COUNTER [0] Register 0x4 , Flags: 0x6E64F 
DEBUG - [perfmon_stopCountersThread_perfevent:880] RESET_COUNTER [0] Register 0x4 , Flags: 0x0 
DEBUG - [perfmon_stopCountersThread_perfevent:870] FREEZE_COUNTER [0] Register 0x5 , Flags: 0x0 
DEBUG - [perfmon_stopCountersThread_perfevent:874] READ_COUNTER [0] Register 0x5 , Flags: 0x3A492 
DEBUG - [perfmon_stopCountersThread_perfevent:880] RESET_COUNTER [0] Register 0x5 , Flags: 0x0 
DEBUG - [perfmon_stopCountersThread_perfevent:870] FREEZE_COUNTER [0] Register 0x6 , Flags: 0x0 
DEBUG - [perfmon_stopCountersThread_perfevent:874] READ_COUNTER [0] Register 0x6 , Flags: 0x6E34E 
DEBUG - [perfmon_stopCountersThread_perfevent:880] RESET_COUNTER [0] Register 0x6 , Flags: 0x0 
DEBUG - [perfmon_stopCountersThread_perfevent:870] FREEZE_COUNTER [0] Register 0x7 , Flags: 0x0 
DEBUG - [perfmon_stopCountersThread_perfevent:874] READ_COUNTER [0] Register 0x7 , Flags: 0x6E34E 
DEBUG - [perfmon_stopCountersThread_perfevent:880] RESET_COUNTER [0] Register 0x7 , Flags: 0x0 
DEBUG - [perfmon_stopCountersThread_perfevent:870] FREEZE_COUNTER [0] Register 0x8 , Flags: 0x0 
DEBUG - [perfmon_stopCountersThread_perfevent:874] READ_COUNTER [0] Register 0x8 , Flags: 0x6E34E 
DEBUG - [perfmon_stopCountersThread_perfevent:880] RESET_COUNTER [0] Register 0x8 , Flags: 0x0 
--------------------------------------------------------------------------------
Group 1: PERF
+-----------------------+---------+--------+
|         Event         | Counter | Core 0 |
+-----------------------+---------+--------+
|   INSTR_RETIRED_ANY   |  FIXC0  | 247138 |
| CPU_CLK_UNHALTED_CORE |  FIXC1  | 452175 |
|  CPU_CLK_UNHALTED_REF |  FIXC2  | 238738 |
|         MPERF         |  MPERF  | 451406 |
|         APERF         |  APERF  | 451406 |
|         PPERF         |  PPERF  | 451406 |
+-----------------------+---------+--------+

+----------------------+-----------+
|        Metric        |   Core 0  |
+----------------------+-----------+
|  Runtime (RDTSC) [s] |   10.0023 |
| Runtime unhalted [s] |    0.0002 |
|      Clock [MHz]     | 3590.4569 |
|          CPI         |    1.8296 |
|    Aperf/Mperf [%]   |       100 |
|    Pperf/Aperf [%]   |       100 |
+----------------------+-----------+",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,337,2020-11-08T03:01:44Z,2020-12-08T14:40:54Z,2020-12-08T14:40:54Z,MERGED,True,99,7,8,https://github.com/jimmysitu,"Add mperf, aperf and pperf for skylake",7,[],https://github.com/RRZE-HPC/likwid/pull/337,https://github.com/TomTheBear,11,https://github.com/RRZE-HPC/likwid/pull/337#issuecomment-739289908,"Hi, All
I add mperf/aperf/pperf counter for Intel skylake.","So for me the events have different values.
|         MPERF         |  MPERF  |  8220753215 |
|         APERF         |  APERF  | 10422493511 |
|         PPERF         |  PPERF  |  6048975638 |

I attached a patch how I would have integrated them. We could keep your version or switch to my version, up to you.
PERF_perf_event.txt",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,337,2020-11-08T03:01:44Z,2020-12-08T14:40:54Z,2020-12-08T14:40:54Z,MERGED,True,99,7,8,https://github.com/jimmysitu,"Add mperf, aperf and pperf for skylake",7,[],https://github.com/RRZE-HPC/likwid/pull/337,https://github.com/TomTheBear,12,https://github.com/RRZE-HPC/likwid/pull/337#issuecomment-740659183,"Hi, All
I add mperf/aperf/pperf counter for Intel skylake.",Thanks for your work.,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,339,2020-11-16T11:21:38Z,2020-11-16T11:25:40Z,2020-11-16T11:25:46Z,MERGED,True,758,6,9,https://github.com/TomTheBear,Add support for AMD Zen3 (Ryzen and probably Milan). ,1,[],https://github.com/RRZE-HPC/likwid/pull/339,https://github.com/TomTheBear,1,https://github.com/RRZE-HPC/likwid/pull/339,"Counter logic included for:

Fixed-purpose counters
General-purpose counters
RAPL counters
L3 counters
Data fabric counters

Event list is currently empty but updated as soon as it is public","Counter logic included for:

Fixed-purpose counters
General-purpose counters
RAPL counters
L3 counters
Data fabric counters

Event list is currently empty but updated as soon as it is public",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,343,2020-11-30T12:50:57Z,2021-04-07T12:58:39Z,2021-04-07T12:58:43Z,MERGED,True,435,105,4,https://github.com/TomTheBear,Bypass daemon,7,[],https://github.com/RRZE-HPC/likwid/pull/343,https://github.com/TomTheBear,1,https://github.com/RRZE-HPC/likwid/pull/343,This PR adds a new access layer to the current access system. It can be used to bypass costly direct MSR or PCI reads or the accessdaemon when accessing the PMC and FIXC counters on Intel and AMD.,This PR adds a new access layer to the current access system. It can be used to bypass costly direct MSR or PCI reads or the accessdaemon when accessing the PMC and FIXC counters on Intel and AMD.,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,349,2020-12-10T07:39:50Z,2020-12-10T10:04:06Z,2020-12-10T10:04:06Z,MERGED,True,1,1,1,https://github.com/timgates42,"docs: fix simple typo, sccess -> access",1,[],https://github.com/RRZE-HPC/likwid/pull/349,https://github.com/timgates42,1,https://github.com/RRZE-HPC/likwid/pull/349,"There is a small typo in bench/includes/likwid.h, src/includes/likwid.h.
Should read access rather than sccess.
Semi-automated pull request generated by
https://github.com/timgates42/meticulous/blob/master/docs/NOTE.md","There is a small typo in bench/includes/likwid.h, src/includes/likwid.h.
Should read access rather than sccess.
Semi-automated pull request generated by
https://github.com/timgates42/meticulous/blob/master/docs/NOTE.md",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,349,2020-12-10T07:39:50Z,2020-12-10T10:04:06Z,2020-12-10T10:04:06Z,MERGED,True,1,1,1,https://github.com/timgates42,"docs: fix simple typo, sccess -> access",1,[],https://github.com/RRZE-HPC/likwid/pull/349,https://github.com/TomTheBear,2,https://github.com/RRZE-HPC/likwid/pull/349#issuecomment-742417834,"There is a small typo in bench/includes/likwid.h, src/includes/likwid.h.
Should read access rather than sccess.
Semi-automated pull request generated by
https://github.com/timgates42/meticulous/blob/master/docs/NOTE.md",Thanks for finding and fixing it.,True,{'THUMBS_UP': ['https://github.com/timgates42']}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,351,2020-12-15T15:05:21Z,2020-12-18T15:17:37Z,2020-12-18T15:17:42Z,MERGED,True,79,24,5,https://github.com/TomTheBear,Reliable base freq,4,[],https://github.com/RRZE-HPC/likwid/pull/351,https://github.com/TomTheBear,1,https://github.com/RRZE-HPC/likwid/pull/351,Add a reliable way to get the base frequency from register for Intel and AMD CPUs. This should reduce warnings printed by likwid-setFrequencies.,Add a reliable way to get the base frequency from register for Intel and AMD CPUs. This should reduce warnings printed by likwid-setFrequencies.,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,352,2020-12-15T16:28:46Z,2021-04-07T12:59:04Z,2021-04-07T12:59:07Z,MERGED,True,466,416,3,https://github.com/TomTheBear,Update cpu marker api,3,[],https://github.com/RRZE-HPC/likwid/pull/352,https://github.com/TomTheBear,1,https://github.com/RRZE-HPC/likwid/pull/352,"Update for the MarkerAPI for less overhead, especially for multi-socket runs","Update for the MarkerAPI for less overhead, especially for multi-socket runs",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,353,2020-12-17T17:51:49Z,2021-04-07T13:00:10Z,2021-04-07T13:01:20Z,MERGED,True,116,83,8,https://github.com/TomTheBear,Enable builds with system-level hwloc installation instead of internal hwloc,1,[],https://github.com/RRZE-HPC/likwid/pull/353,https://github.com/TomTheBear,1,https://github.com/RRZE-HPC/likwid/pull/353,"Similar to system-level lua, you can configure the HWLOC_INCLUDE_DIR, HWLOC_LIB_DIR and HWLOC_LIB_NAME. Based on these settings, the compilation of the internal hwloc version is skipped and the LIKWID library is linked to the supplied hwloc library.","Similar to system-level lua, you can configure the HWLOC_INCLUDE_DIR, HWLOC_LIB_DIR and HWLOC_LIB_NAME. Based on these settings, the compilation of the internal hwloc version is skipped and the LIKWID library is linked to the supplied hwloc library.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,355,2020-12-21T22:32:53Z,2021-01-11T13:04:54Z,2021-01-11T14:03:49Z,MERGED,True,14,5,3,https://github.com/TomTheBear,Fix argument parsing for startProgram in Lua interface,2,[],https://github.com/RRZE-HPC/likwid/pull/355,https://github.com/TomTheBear,1,https://github.com/RRZE-HPC/likwid/pull/355,"As shown in issue #354, empty arguments are not parsed properly. This PR fixes the issue by using | as separator in the execuable string so that in in can be split into argc and argv.","As shown in issue #354, empty arguments are not parsed properly. This PR fixes the issue by using | as separator in the execuable string so that in in can be split into argc and argv.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,357,2020-12-23T17:03:13Z,2021-01-11T14:03:29Z,2021-01-11T14:03:34Z,MERGED,True,21,16,3,https://github.com/TomTheBear,Export list of hwthreads to wrapped application,1,[],https://github.com/RRZE-HPC/likwid/pull/357,https://github.com/TomTheBear,1,https://github.com/RRZE-HPC/likwid/pull/357,"This PR adds the export of the used HW threads through the environment variable LIKWID_HWTHREADS so that applications can use this knowledge. There is already an environment variable LIKWID_THREADS but it only exported by likwid-perfctr in MarkerAPI mode. In some cases, you need the knowledge also in non-instrumented applications.","This PR adds the export of the used HW threads through the environment variable LIKWID_HWTHREADS so that applications can use this knowledge. There is already an environment variable LIKWID_THREADS but it only exported by likwid-perfctr in MarkerAPI mode. In some cases, you need the knowledge also in non-instrumented applications.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,360,2021-01-04T15:36:38Z,2021-01-11T14:37:32Z,2021-02-15T13:27:25Z,MERGED,True,62,37,6,https://github.com/TomTheBear,Add support for Intel Comet Lake,1,[],https://github.com/RRZE-HPC/likwid/pull/360,https://github.com/TomTheBear,1,https://github.com/RRZE-HPC/likwid/pull/360,"Intel Comet Lake in-core support is comparable with Intel Skylake/Kabylake or Cannonlake. It also uses the same event lists.
See issue #359 .","Intel Comet Lake in-core support is comparable with Intel Skylake/Kabylake or Cannonlake. It also uses the same event lists.
See issue #359 .",True,{'THUMBS_UP': ['https://github.com/jchia']}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,366,2021-01-12T22:04:11Z,2021-02-04T10:39:27Z,2021-02-04T10:39:27Z,MERGED,True,58,51,10,https://github.com/termim,Group check. Fix #314,4,[],https://github.com/RRZE-HPC/likwid/pull/366,https://github.com/termim,1,https://github.com/RRZE-HPC/likwid/pull/366,Fixes #314 and some group file fixes.,Fixes #314 and some group file fixes.,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,366,2021-01-12T22:04:11Z,2021-02-04T10:39:27Z,2021-02-04T10:39:27Z,MERGED,True,58,51,10,https://github.com/termim,Group check. Fix #314,4,[],https://github.com/RRZE-HPC/likwid/pull/366,https://github.com/TomTheBear,2,https://github.com/RRZE-HPC/likwid/pull/366#issuecomment-773209409,Fixes #314 and some group file fixes.,Thanks a lot,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,367,2021-01-12T23:20:47Z,2021-02-04T10:39:42Z,2021-02-04T10:39:42Z,MERGED,True,4,0,1,https://github.com/termim,check_data_files.py: ignore comments when parsing events,1,[],https://github.com/RRZE-HPC/likwid/pull/367,https://github.com/termim,1,https://github.com/RRZE-HPC/likwid/pull/367,Ignore comments at the end of lines in event description files.,Ignore comments at the end of lines in event description files.,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,368,2021-01-23T04:21:03Z,2021-02-04T10:40:10Z,2021-02-04T10:40:10Z,MERGED,True,5,3,1,https://github.com/jimmysitu,Fix perfscope when drawing y2title with multi-core,2,[],https://github.com/RRZE-HPC/likwid/pull/368,https://github.com/jimmysitu,1,https://github.com/RRZE-HPC/likwid/pull/368,"Hi, @TomTheBear
I found there is an issue when likwid-perfscope drawing multi-core events curves
likwid-perfscope -t 1s -g L3 -c 0,4 likwid-bench -s 5s -t stream_avx -w S0:1MB:2

Only one curve align to y2
Core events are not align to the right core legends

I fixed this issue with the PR","Hi, @TomTheBear
I found there is an issue when likwid-perfscope drawing multi-core events curves
likwid-perfscope -t 1s -g L3 -c 0,4 likwid-bench -s 5s -t stream_avx -w S0:1MB:2

Only one curve align to y2
Core events are not align to the right core legends

I fixed this issue with the PR",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,368,2021-01-23T04:21:03Z,2021-02-04T10:40:10Z,2021-02-04T10:40:10Z,MERGED,True,5,3,1,https://github.com/jimmysitu,Fix perfscope when drawing y2title with multi-core,2,[],https://github.com/RRZE-HPC/likwid/pull/368,https://github.com/TomTheBear,2,https://github.com/RRZE-HPC/likwid/pull/368#issuecomment-766714697,"Hi, @TomTheBear
I found there is an issue when likwid-perfscope drawing multi-core events curves
likwid-perfscope -t 1s -g L3 -c 0,4 likwid-bench -s 5s -t stream_avx -w S0:1MB:2

Only one curve align to y2
Core events are not align to the right core legends

I fixed this issue with the PR",Thanks for finding this and submitting a PR. I will add this to the 5.1.1 release.,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,369,2021-01-25T09:21:01Z,2021-05-10T14:09:18Z,2021-05-10T14:09:18Z,CLOSED,False,16,13,2,https://github.com/TomTheBear,Fix memory measurements for AMD Zen2,2,[],https://github.com/RRZE-HPC/likwid/pull/369,https://github.com/TomTheBear,1,https://github.com/RRZE-HPC/likwid/pull/369,"Memory measurements on AMD Zen2 need to be scaled dependent on the NPS mode (4.0/num_numadomains). This works well for single-socket servers but for multi-socket systems, the divisor needs to be the number of NUMA domains per socket. This patch fixes this by including the number of CPU sockets in the scaling factor: 4.0/(num_numadomains/num_sockets).","Memory measurements on AMD Zen2 need to be scaled dependent on the NPS mode (4.0/num_numadomains). This works well for single-socket servers but for multi-socket systems, the divisor needs to be the number of NUMA domains per socket. This patch fixes this by including the number of CPU sockets in the scaling factor: 4.0/(num_numadomains/num_sockets).",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,369,2021-01-25T09:21:01Z,2021-05-10T14:09:18Z,2021-05-10T14:09:18Z,CLOSED,False,16,13,2,https://github.com/TomTheBear,Fix memory measurements for AMD Zen2,2,[],https://github.com/RRZE-HPC/likwid/pull/369,https://github.com/TomTheBear,2,https://github.com/RRZE-HPC/likwid/pull/369#issuecomment-766837164,"Memory measurements on AMD Zen2 need to be scaled dependent on the NPS mode (4.0/num_numadomains). This works well for single-socket servers but for multi-socket systems, the divisor needs to be the number of NUMA domains per socket. This patch fixes this by including the number of CPU sockets in the scaling factor: 4.0/(num_numadomains/num_sockets).","The current state fixes the problem only partly. It works if allocation (and HW threads) are in the first NUMA domain of each socket. As soon as another NUMA domain is used, the measurements do not fit anymore.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,369,2021-01-25T09:21:01Z,2021-05-10T14:09:18Z,2021-05-10T14:09:18Z,CLOSED,False,16,13,2,https://github.com/TomTheBear,Fix memory measurements for AMD Zen2,2,[],https://github.com/RRZE-HPC/likwid/pull/369,https://github.com/TomTheBear,3,https://github.com/RRZE-HPC/likwid/pull/369#issuecomment-836747763,"Memory measurements on AMD Zen2 need to be scaled dependent on the NPS mode (4.0/num_numadomains). This works well for single-socket servers but for multi-socket systems, the divisor needs to be the number of NUMA domains per socket. This patch fixes this by including the number of CPU sockets in the scaling factor: 4.0/(num_numadomains/num_sockets).","I accidently committed the code of this PR to master. So, I close this PR.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,370,2021-01-26T12:19:10Z,2021-01-29T13:10:18Z,2021-01-29T13:10:18Z,MERGED,True,8,6,1,https://github.com/N-Coder,make quick install even quicker,1,[],https://github.com/RRZE-HPC/likwid/pull/370,https://github.com/N-Coder,1,https://github.com/RRZE-HPC/likwid/pull/370,,,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,370,2021-01-26T12:19:10Z,2021-01-29T13:10:18Z,2021-01-29T13:10:18Z,MERGED,True,8,6,1,https://github.com/N-Coder,make quick install even quicker,1,[],https://github.com/RRZE-HPC/likwid/pull/370,https://github.com/TomTheBear,2,https://github.com/RRZE-HPC/likwid/pull/370#issuecomment-769243515,,Thanks for the updated quick install.,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,371,2021-01-26T12:45:32Z,2021-02-04T10:40:24Z,2021-02-04T10:40:29Z,MERGED,True,33,0,1,https://github.com/TomTheBear,Adding group for FP pipeline rates for Fujitsu A64FX,1,[],https://github.com/RRZE-HPC/likwid/pull/371,https://github.com/TomTheBear,1,https://github.com/RRZE-HPC/likwid/pull/371,This group is inspired by metrics gathered by the Fujitsu Advanced Profiler fapp. The group measures how well the FP ports are utilized.,This group is inspired by metrics gathered by the Fujitsu Advanced Profiler fapp. The group measures how well the FP ports are utilized.,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,372,2021-01-26T12:56:08Z,2021-02-04T10:40:41Z,2021-02-04T10:40:44Z,MERGED,True,42,0,3,https://github.com/TomTheBear,Vector sum benchmarks with SVE,1,[],https://github.com/RRZE-HPC/likwid/pull/372,https://github.com/TomTheBear,1,https://github.com/RRZE-HPC/likwid/pull/372,"This PR adds the three kernels sum_sve128, sum_sve256 and sum_sve512 for ARM SVE","This PR adds the three kernels sum_sve128, sum_sve256 and sum_sve512 for ARM SVE",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,374,2021-02-04T11:01:51Z,2021-02-15T13:26:14Z,2021-02-15T13:27:23Z,MERGED,True,232,48,6,https://github.com/TomTheBear,Fugaku topology fix,2,[],https://github.com/RRZE-HPC/likwid/pull/374,https://github.com/TomTheBear,1,https://github.com/RRZE-HPC/likwid/pull/374,"This PR fixes topology issues on the Fugaku nodes. I'm not sure what the difference between the FX1000 I used before is.
One problem is the naming of affinity domains. The first 4 packages and NUMA domains do not contain any usable hardware thread (just management cores). If we name the affinity domains as normal, they would be called S4-S7 (and M4-M7). This PR uses zero-based numbering, so although the socket has e.g. the ID 4, the affinity domain is called S0.","This PR fixes topology issues on the Fugaku nodes. I'm not sure what the difference between the FX1000 I used before is.
One problem is the naming of affinity domains. The first 4 packages and NUMA domains do not contain any usable hardware thread (just management cores). If we name the affinity domains as normal, they would be called S4-S7 (and M4-M7). This PR uses zero-based numbering, so although the socket has e.g. the ID 4, the affinity domain is called S0.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,379,2021-03-12T15:04:56Z,2021-03-30T16:46:35Z,2021-03-30T16:46:38Z,MERGED,True,83,15,1,https://github.com/TomTheBear,Fix for perf_event multiplexing,5,[],https://github.com/RRZE-HPC/likwid/pull/379,https://github.com/TomTheBear,1,https://github.com/RRZE-HPC/likwid/pull/379,In most cases it is not required to do multiplexing because LIKWID never uses more events than there are physical counter registers for CPUs. The Intel Skylake SP architecture (and maybe Cascadelake SP) has a bug in the PMC3 if transactional memory is enabled (see #224 or likwid-users mailing list post). This causes that perf_event multiplexes on the remaining 3 counters and LIKWID has to evaluate the multiplexing information to calculate the real counter value.,In most cases it is not required to do multiplexing because LIKWID never uses more events than there are physical counter registers for CPUs. The Intel Skylake SP architecture (and maybe Cascadelake SP) has a bug in the PMC3 if transactional memory is enabled (see #224 or likwid-users mailing list post). This causes that perf_event multiplexes on the remaining 3 counters and LIKWID has to evaluate the multiplexing information to calculate the real counter value.,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,380,2021-03-12T15:15:35Z,2021-03-31T10:42:29Z,2021-03-31T10:42:33Z,MERGED,True,42,42,1,https://github.com/TomTheBear,Rename the function pointers in topology_gpu.c ,1,[],https://github.com/RRZE-HPC/likwid/pull/380,https://github.com/TomTheBear,1,https://github.com/RRZE-HPC/likwid/pull/380,to differ from the ones used in nvmon* . See likwid-users mailing list post.,to differ from the ones used in nvmon* . See likwid-users mailing list post.,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,381,2021-03-15T11:58:51Z,2021-04-07T13:01:02Z,2021-04-07T13:01:06Z,MERGED,True,272,52,13,https://github.com/TomTheBear,Cpu dies in topology and affinity domains,5,[],https://github.com/RRZE-HPC/likwid/pull/381,https://github.com/TomTheBear,1,https://github.com/RRZE-HPC/likwid/pull/381,"This PR introduces:

CPU dies to the topology module of LIKWID. The HWThread struct is extended by a dieId. likwid-topology prints the dieId in a separate column
The creation of affinity domains D0,D1, ... spanning all HW threads of a die
New locks and lookup arrays for use in perfmon
Use die locks in perfmon for Intel Cascadelake AP systems
cpu_to_cpulist functions know of CPU dies
Enabling likwid-mpirun to use dies as scheduling domain

CPU dies are not implemented for the deprecated cpuid topology backend.","This PR introduces:

CPU dies to the topology module of LIKWID. The HWThread struct is extended by a dieId. likwid-topology prints the dieId in a separate column
The creation of affinity domains D0,D1, ... spanning all HW threads of a die
New locks and lookup arrays for use in perfmon
Use die locks in perfmon for Intel Cascadelake AP systems
cpu_to_cpulist functions know of CPU dies
Enabling likwid-mpirun to use dies as scheduling domain

CPU dies are not implemented for the deprecated cpuid topology backend.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,383,2021-03-15T18:43:41Z,2021-03-16T10:26:46Z,2021-03-16T11:18:12Z,MERGED,True,61,11,1,https://github.com/aowenson,"Add more structure to C-likwidAPI.c, to better match use cases",1,[],https://github.com/RRZE-HPC/likwid/pull/383,https://github.com/aowenson,1,https://github.com/RRZE-HPC/likwid/pull/383,"I have added the concept of multiple 'work items' (e.g. multiple loops), and showcase perfmon_getLastResult() to print counts for each work item. Should match better with typical use cases.
I also removed use of strtok() - as it modified 'estr', it could only be used once. Replaced with a simple array.","I have added the concept of multiple 'work items' (e.g. multiple loops), and showcase perfmon_getLastResult() to print counts for each work item. Should match better with typical use cases.
I also removed use of strtok() - as it modified 'estr', it could only be used once. Replaced with a simple array.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,383,2021-03-15T18:43:41Z,2021-03-16T10:26:46Z,2021-03-16T11:18:12Z,MERGED,True,61,11,1,https://github.com/aowenson,"Add more structure to C-likwidAPI.c, to better match use cases",1,[],https://github.com/RRZE-HPC/likwid/pull/383,https://github.com/TomTheBear,2,https://github.com/RRZE-HPC/likwid/pull/383#issuecomment-800140139,"I have added the concept of multiple 'work items' (e.g. multiple loops), and showcase perfmon_getLastResult() to print counts for each work item. Should match better with typical use cases.
I also removed use of strtok() - as it modified 'estr', it could only be used once. Replaced with a simple array.","Looks good, thanks a lot.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,384,2021-03-16T11:29:46Z,2021-03-16T14:19:39Z,2021-03-16T14:19:44Z,MERGED,True,30,7,2,https://github.com/TomTheBear,Add static information about the cache topology of Fujitsu A64FX,2,[],https://github.com/RRZE-HPC/likwid/pull/384,https://github.com/TomTheBear,1,https://github.com/RRZE-HPC/likwid/pull/384,,,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,384,2021-03-16T11:29:46Z,2021-03-16T14:19:39Z,2021-03-16T14:19:44Z,MERGED,True,30,7,2,https://github.com/TomTheBear,Add static information about the cache topology of Fujitsu A64FX,2,[],https://github.com/RRZE-HPC/likwid/pull/384,https://github.com/TomTheBear,2,https://github.com/RRZE-HPC/likwid/pull/384#issuecomment-800299492,,Tested on FX700 (thx @cod3monk) and FX1000 (Fugaku),True,{'HEART': ['https://github.com/cod3monk']}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,385,2021-03-22T17:17:11Z,2021-03-23T09:57:52Z,2021-03-23T09:57:52Z,MERGED,True,1,0,1,https://github.com/blastmaster,Add missing build requirement for rpm specfile,1,[],https://github.com/RRZE-HPC/likwid/pull/385,https://github.com/blastmaster,1,https://github.com/RRZE-HPC/likwid/pull/385,"This commit, add the perl-Data-Dumper package as rpm build requirement.
Otherwise an rpmbuild with the provided specfile will fail.","This commit, add the perl-Data-Dumper package as rpm build requirement.
Otherwise an rpmbuild with the provided specfile will fail.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,385,2021-03-22T17:17:11Z,2021-03-23T09:57:52Z,2021-03-23T09:57:52Z,MERGED,True,1,0,1,https://github.com/blastmaster,Add missing build requirement for rpm specfile,1,[],https://github.com/RRZE-HPC/likwid/pull/385,https://github.com/TomTheBear,2,https://github.com/RRZE-HPC/likwid/pull/385#issuecomment-804770734,"This commit, add the perl-Data-Dumper package as rpm build requirement.
Otherwise an rpmbuild with the provided specfile will fail.",Thanks a lot.,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,388,2021-04-07T08:46:42Z,2021-04-07T12:58:17Z,2021-04-07T12:58:21Z,MERGED,True,99,157,3,https://github.com/TomTheBear,Fix likwid-perfctr filter and enable timeline mode to output file,2,[],https://github.com/RRZE-HPC/likwid/pull/388,https://github.com/TomTheBear,1,https://github.com/RRZE-HPC/likwid/pull/388,"Fixes parsing of likwid-topology and likwid-perfctr
Simplifies filter code
Enable output file with timeline mode
CLI Option (not in help output yet) to add output prefix to timeline mode lines. This is required to implement timeline mode for likwid-mpirun","Fixes parsing of likwid-topology and likwid-perfctr
Simplifies filter code
Enable output file with timeline mode
CLI Option (not in help output yet) to add output prefix to timeline mode lines. This is required to implement timeline mode for likwid-mpirun",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,389,2021-04-08T01:06:22Z,2021-04-08T10:20:08Z,2021-04-08T10:20:08Z,MERGED,True,6,6,1,https://github.com/estsaon,fix typo in skylake MEM_SP group file,1,[],https://github.com/RRZE-HPC/likwid/pull/389,https://github.com/estsaon,1,https://github.com/RRZE-HPC/likwid/pull/389,DP -> SP,DP -> SP,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,389,2021-04-08T01:06:22Z,2021-04-08T10:20:08Z,2021-04-08T10:20:08Z,MERGED,True,6,6,1,https://github.com/estsaon,fix typo in skylake MEM_SP group file,1,[],https://github.com/RRZE-HPC/likwid/pull/389,https://github.com/TomTheBear,2,https://github.com/RRZE-HPC/likwid/pull/389#issuecomment-815642712,DP -> SP,Thanks a lot.,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,390,2021-04-08T14:41:10Z,2021-06-07T09:45:16Z,2021-06-07T09:45:24Z,MERGED,True,10247,603,37,https://github.com/TomTheBear,Intel IcelakeSP Uncore support,52,[],https://github.com/RRZE-HPC/likwid/pull/390,https://github.com/TomTheBear,1,https://github.com/RRZE-HPC/likwid/pull/390,"Based on Ice Lake Uncore Performance Monitoring Reference Manual (Revision 0.60, June 2020)

New access method MMIO for direct and accessdaemon access
Add logic for Uncore counters in direct and accessdaemon mode
Translation for perf_event devices to LIKWID units

Problem: The offsets in the Uncore overflow registers are not available in the docs. A ""Global Status Position"" is required which is provided by a ""new PMON Discovery mechanism"". The ""Introduction"" lists ""Introduction to new Discovery mechanism"" and ""Some guidance to SW including how to manage a monitoring session, find the base address to the page of Discovery and find the base addresses for PMON registers addressed in PCICFG or MMIO space"" but there is no description of this discovery mechanism.","Based on Ice Lake Uncore Performance Monitoring Reference Manual (Revision 0.60, June 2020)

New access method MMIO for direct and accessdaemon access
Add logic for Uncore counters in direct and accessdaemon mode
Translation for perf_event devices to LIKWID units

Problem: The offsets in the Uncore overflow registers are not available in the docs. A ""Global Status Position"" is required which is provided by a ""new PMON Discovery mechanism"". The ""Introduction"" lists ""Introduction to new Discovery mechanism"" and ""Some guidance to SW including how to manage a monitoring session, find the base address to the page of Discovery and find the base addresses for PMON registers addressed in PCICFG or MMIO space"" but there is no description of this discovery mechanism.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,390,2021-04-08T14:41:10Z,2021-06-07T09:45:16Z,2021-06-07T09:45:24Z,MERGED,True,10247,603,37,https://github.com/TomTheBear,Intel IcelakeSP Uncore support,52,[],https://github.com/RRZE-HPC/likwid/pull/390,https://github.com/TomTheBear,2,https://github.com/RRZE-HPC/likwid/pull/390#issuecomment-817820913,"Based on Ice Lake Uncore Performance Monitoring Reference Manual (Revision 0.60, June 2020)

New access method MMIO for direct and accessdaemon access
Add logic for Uncore counters in direct and accessdaemon mode
Translation for perf_event devices to LIKWID units

Problem: The offsets in the Uncore overflow registers are not available in the docs. A ""Global Status Position"" is required which is provided by a ""new PMON Discovery mechanism"". The ""Introduction"" lists ""Introduction to new Discovery mechanism"" and ""Some guidance to SW including how to manage a monitoring session, find the base address to the page of Discovery and find the base addresses for PMON registers addressed in PCICFG or MMIO space"" but there is no description of this discovery mechanism.",The included MEM* groups does not work. They do not count any memory writes! The LIKWID events are in line with the public documentation.,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,390,2021-04-08T14:41:10Z,2021-06-07T09:45:16Z,2021-06-07T09:45:24Z,MERGED,True,10247,603,37,https://github.com/TomTheBear,Intel IcelakeSP Uncore support,52,[],https://github.com/RRZE-HPC/likwid/pull/390,https://github.com/TomTheBear,3,https://github.com/RRZE-HPC/likwid/pull/390#issuecomment-817827782,"Based on Ice Lake Uncore Performance Monitoring Reference Manual (Revision 0.60, June 2020)

New access method MMIO for direct and accessdaemon access
Add logic for Uncore counters in direct and accessdaemon mode
Translation for perf_event devices to LIKWID units

Problem: The offsets in the Uncore overflow registers are not available in the docs. A ""Global Status Position"" is required which is provided by a ""new PMON Discovery mechanism"". The ""Introduction"" lists ""Introduction to new Discovery mechanism"" and ""Some guidance to SW including how to manage a monitoring session, find the base address to the page of Discovery and find the base addresses for PMON registers addressed in PCICFG or MMIO space"" but there is no description of this discovery mechanism.","Currently missing:

Memory controller cycles counter
Memory controller free-running bytes_read and bytes_write counters",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,390,2021-04-08T14:41:10Z,2021-06-07T09:45:16Z,2021-06-07T09:45:24Z,MERGED,True,10247,603,37,https://github.com/TomTheBear,Intel IcelakeSP Uncore support,52,[],https://github.com/RRZE-HPC/likwid/pull/390,https://github.com/TomTheBear,4,https://github.com/RRZE-HPC/likwid/pull/390#issuecomment-840527148,"Based on Ice Lake Uncore Performance Monitoring Reference Manual (Revision 0.60, June 2020)

New access method MMIO for direct and accessdaemon access
Add logic for Uncore counters in direct and accessdaemon mode
Translation for perf_event devices to LIKWID units

Problem: The offsets in the Uncore overflow registers are not available in the docs. A ""Global Status Position"" is required which is provided by a ""new PMON Discovery mechanism"". The ""Introduction"" lists ""Introduction to new Discovery mechanism"" and ""Some guidance to SW including how to manage a monitoring session, find the base address to the page of Discovery and find the base addresses for PMON registers addressed in PCICFG or MMIO space"" but there is no description of this discovery mechanism.",Public documentation was released: https://cdrdv2.intel.com/v1/dl/getContent/639778,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,392,2021-04-13T13:00:23Z,2021-09-07T14:19:30Z,2021-12-27T15:48:49Z,MERGED,True,279,15,16,https://github.com/TomTheBear,Add support for Intel Rocketlake,12,[],https://github.com/RRZE-HPC/likwid/pull/392,https://github.com/TomTheBear,1,https://github.com/RRZE-HPC/likwid/pull/392,"Main contribution by @edisonchan , see issue #391
Intel Rocketlake is a ""backport"" of the Icelake performance monitoring but currently no public documentation available.","Main contribution by @edisonchan , see issue #391
Intel Rocketlake is a ""backport"" of the Icelake performance monitoring but currently no public documentation available.",True,"{'THUMBS_UP': ['https://github.com/carstenbauer'], 'HEART': ['https://github.com/carstenbauer']}"
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,392,2021-04-13T13:00:23Z,2021-09-07T14:19:30Z,2021-12-27T15:48:49Z,MERGED,True,279,15,16,https://github.com/TomTheBear,Add support for Intel Rocketlake,12,[],https://github.com/RRZE-HPC/likwid/pull/392,https://github.com/TomTheBear,2,https://github.com/RRZE-HPC/likwid/pull/392#issuecomment-825219969,"Main contribution by @edisonchan , see issue #391
Intel Rocketlake is a ""backport"" of the Icelake performance monitoring but currently no public documentation available.",I tested the TMA group on an Intel IcelakeSP system and all results looked reasonable.,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,392,2021-04-13T13:00:23Z,2021-09-07T14:19:30Z,2021-12-27T15:48:49Z,MERGED,True,279,15,16,https://github.com/TomTheBear,Add support for Intel Rocketlake,12,[],https://github.com/RRZE-HPC/likwid/pull/392,https://github.com/carstenbauer,3,https://github.com/RRZE-HPC/likwid/pull/392#issuecomment-913501532,"Main contribution by @edisonchan , see issue #391
Intel Rocketlake is a ""backport"" of the Icelake performance monitoring but currently no public documentation available.","FWIW, my local test system for developing LIKWID.jl has a Rocketlake CPU (11th Gen i7-11700K). Would be great to have this supported. Please let me know, if there is something that I can do on my side (running tests or similar).",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,392,2021-04-13T13:00:23Z,2021-09-07T14:19:30Z,2021-12-27T15:48:49Z,MERGED,True,279,15,16,https://github.com/TomTheBear,Add support for Intel Rocketlake,12,[],https://github.com/RRZE-HPC/likwid/pull/392,https://github.com/carstenbauer,4,https://github.com/RRZE-HPC/likwid/pull/392#issuecomment-913704629,"Main contribution by @edisonchan , see issue #391
Intel Rocketlake is a ""backport"" of the Icelake performance monitoring but currently no public documentation available.","Alright, first time trying out this branch. While I get
CPU name:       11th Gen Intel(R) Core(TM) i7-11700K @ 3.60GHz
CPU type:       Intel Rocketlake processor

I see a segmentation fault when trying to use likwid-perfctr:
# likwid.jl
using LIKWID
using LinearAlgebra

N = 100_000_000
a = 3.141f0
z = zeros(Float32, N)
x = rand(Float32, N)
y = rand(Float32, N)

function saxpy!(z,a,x,y)
    z .= a .* x .+ y
end

saxpy!(z,a,x,y)
LIKWID.Marker.startregion(""saxpy!"")
saxpy!(z,a,x,y)
LIKWID.Marker.stopregion(""saxpy!"")	
➜  crstnbr@cbserver likwid  likwid-perfctr -C 0 -g FLOPS_SP -m julia --project=. likwid.jl 
--------------------------------------------------------------------------------
CPU name:       11th Gen Intel(R) Core(TM) i7-11700K @ 3.60GHz
CPU type:       Intel Rocketlake processor
CPU clock:      3.60 GHz
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
Segmentation fault (core dumped)

I went through the Julia file line by line to ""debug"" this. I can execute all commands with no issue. The segfault only appears when closing Julia, i.e. (I guess) when the marker output / file is generated.
Note that not using the Marker API at all works fine:
➜  crstnbr@cbserver likwid  likwid-perfctr -C 0 -g FLOPS_SP -m julia -e '1+1'
--------------------------------------------------------------------------------
CPU name:       11th Gen Intel(R) Core(TM) i7-11700K @ 3.60GHz
CPU type:       Intel Rocketlake processor
CPU clock:      3.60 GHz
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
Marker API result file does not exist. This may happen if the application has not called LIKWID_MARKER_CLOSE.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,392,2021-04-13T13:00:23Z,2021-09-07T14:19:30Z,2021-12-27T15:48:49Z,MERGED,True,279,15,16,https://github.com/TomTheBear,Add support for Intel Rocketlake,12,[],https://github.com/RRZE-HPC/likwid/pull/392,https://github.com/TomTheBear,5,https://github.com/RRZE-HPC/likwid/pull/392#issuecomment-913743270,"Main contribution by @edisonchan , see issue #391
Intel Rocketlake is a ""backport"" of the Icelake performance monitoring but currently no public documentation available.","Please run it with -V 3 on the command line with and without the MarkerAPI flag (-m) for likwid-perfctr and attach both outputs. The outputs are quite long, so attach it as files please.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,392,2021-04-13T13:00:23Z,2021-09-07T14:19:30Z,2021-12-27T15:48:49Z,MERGED,True,279,15,16,https://github.com/TomTheBear,Add support for Intel Rocketlake,12,[],https://github.com/RRZE-HPC/likwid/pull/392,https://github.com/carstenbauer,6,https://github.com/RRZE-HPC/likwid/pull/392#issuecomment-913766105,"Main contribution by @edisonchan , see issue #391
Intel Rocketlake is a ""backport"" of the Icelake performance monitoring but currently no public documentation available.","output_marker.txt
output_nomarker.txt
(Note that the actual segfault message for the marker case, i.e. Segmentation fault (core dumped), is absent from the output file.)",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,392,2021-04-13T13:00:23Z,2021-09-07T14:19:30Z,2021-12-27T15:48:49Z,MERGED,True,279,15,16,https://github.com/TomTheBear,Add support for Intel Rocketlake,12,[],https://github.com/RRZE-HPC/likwid/pull/392,https://github.com/carstenbauer,7,https://github.com/RRZE-HPC/likwid/pull/392#issuecomment-914304613,"Main contribution by @edisonchan , see issue #391
Intel Rocketlake is a ""backport"" of the Icelake performance monitoring but currently no public documentation available.","Backtrace:
➜  crstnbr@cbserver likwid  gdb likwid-lua
GNU gdb (Ubuntu 10.1-2ubuntu2) 10.1.90.20210411-git
Copyright (C) 2021 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.
Type ""show copying"" and ""show warranty"" for details.
This GDB was configured as ""x86_64-linux-gnu"".
Type ""show configuration"" for configuration details.
For bug reporting instructions, please see:
<https://www.gnu.org/software/gdb/bugs/>.
Find the GDB manual and other documentation resources online at:
    <http://www.gnu.org/software/gdb/documentation/>.

For help, type ""help"".
Type ""apropos word"" to search for commands related to ""word""...
Reading symbols from likwid-lua...
(gdb) r /home/crstnbr/software/likwid/likwid-perfctr -C 0 -g FLOPS_SP -m julia --project=. likwid.jl
Starting program: /usr/local/bin/likwid-lua /home/crstnbr/software/likwid/likwid-perfctr -C 0 -g FLOPS_SP -m julia --project=. likwid.jl
[Thread debugging using libthread_db enabled]
Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".
[Detaching after vfork from child process 41708]
[New Thread 0x7fffef183640 (LWP 41717)]
--------------------------------------------------------------------------------
CPU name:       11th Gen Intel(R) Core(TM) i7-11700K @ 3.60GHz
CPU type:       Intel Rocketlake processor
CPU clock:      3.60 GHz
[Detaching after fork from child process 41718]
[Detaching after fork from child process 41719]
[Detaching after fork from child process 41720]
[Detaching after fork from child process 41732]
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------

Thread 1 ""likwid-lua"" received signal SIGSEGV, Segmentation fault.
perfmon_getEventName (groupId=134765952, eventId=0) at ./src/perfmon.c:3188
3188        if ((groupSet->groups[groupId].group.nevents == 0) ||
(gdb) bt
#0  perfmon_getEventName (groupId=134765952, eventId=0) at ./src/perfmon.c:3188
#1  0x00007ffff6e10d89 in lua_likwid_getNameOfEvent (L=0x55555555b2a8) at ./src/luawid.c:560
#2  0x00007ffff7f96e25 in luaD_precall (L=L@entry=0x55555555b2a8, func=func@entry=0x555555566c50, nresults=nresults@entry=1) at ./src/ldo.c:360
#3  0x00007ffff7fae70d in luaV_execute (L=L@entry=0x55555555b2a8) at ./src/lvm.c:1115
#4  0x00007ffff7f97338 in luaD_call (nResults=<optimized out>, func=<optimized out>, L=0x55555555b2a8) at ./src/ldo.c:491
#5  luaD_callnoyield (L=0x55555555b2a8, func=<optimized out>, nResults=<optimized out>) at ./src/ldo.c:501
#6  0x00007ffff7f96667 in luaD_rawrunprotected (L=L@entry=0x55555555b2a8, f=f@entry=0x7ffff7f8af70 <f_call>, ud=ud@entry=0x7fffffff9cf0) at ./src/ldo.c:142
#7  0x00007ffff7f975ef in luaD_pcall (L=L@entry=0x55555555b2a8, func=func@entry=0x7ffff7f8af70 <f_call>, u=u@entry=0x7fffffff9cf0, old_top=80,
    ef=<optimized out>) at ./src/ldo.c:722
#8  0x00007ffff7f8d6ae in lua_pcallk (L=L@entry=0x55555555b2a8, nargs=nargs@entry=8, nresults=nresults@entry=-1, errfunc=errfunc@entry=3, ctx=ctx@entry=0,
    k=k@entry=0x0) at ./src/lapi.c:968
#9  0x00005555555568af in docall (L=L@entry=0x55555555b2a8, narg=narg@entry=8, nres=nres@entry=-1) at ./src/lua.c:203
#10 0x00005555555575c7 in handle_script (argv=<optimized out>, L=0x55555555b2a8) at ./src/lua.c:443
#11 pmain (L=0x55555555b2a8) at ./src/lua.c:577
#12 0x00007ffff7f96e25 in luaD_precall (L=L@entry=0x55555555b2a8, func=0x55555555b8d0, nresults=1) at ./src/ldo.c:360
#13 0x00007ffff7f972ff in luaD_call (nResults=<optimized out>, func=<optimized out>, L=0x55555555b2a8) at ./src/ldo.c:490
#14 luaD_callnoyield (L=0x55555555b2a8, func=<optimized out>, nResults=<optimized out>) at ./src/ldo.c:501
#15 0x00007ffff7f96667 in luaD_rawrunprotected (L=L@entry=0x55555555b2a8, f=f@entry=0x7ffff7f8af70 <f_call>, ud=ud@entry=0x7fffffff9f70) at ./src/ldo.c:142
#16 0x00007ffff7f975ef in luaD_pcall (L=L@entry=0x55555555b2a8, func=func@entry=0x7ffff7f8af70 <f_call>, u=u@entry=0x7fffffff9f70, old_top=16,
    ef=<optimized out>) at ./src/ldo.c:722
#17 0x00007ffff7f8d6ae in lua_pcallk (L=L@entry=0x55555555b2a8, nargs=nargs@entry=2, nresults=nresults@entry=1, errfunc=errfunc@entry=0, ctx=ctx@entry=0,
    k=k@entry=0x0) at ./src/lapi.c:968
#18 0x000055555555665f in main (argc=10, argv=0x7fffffffa0b8) at ./src/lua.c:603
(gdb)",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,393,2021-04-16T12:20:24Z,2021-04-27T10:43:43Z,2021-05-27T10:18:31Z,MERGED,True,31,5,2,https://github.com/TomTheBear,New environment variable `LIKWID_IGNORE_CPUSET` to ignore the current cpuset,2,[],https://github.com/RRZE-HPC/likwid/pull/393,https://github.com/TomTheBear,1,https://github.com/RRZE-HPC/likwid/pull/393,"New environment variable LIKWID_IGNORE_CPUSET. The variable affects all tools and the library. Maybe fixes #358, not tested isolcpus explicitly.
System with 8 hardware threads (SMT active)
$ taskset -c -p $$
pid's current affinity list: 0-2
$ likwid-pin -c 0,1 -p
INFO: You are running LIKWID in a cpuset with 3 CPUs. Taking given IDs as logical ID in cpuset
0,1
$ likwid-pin -c 3,4 -p
INFO: You are running LIKWID in a cpuset with 3 CPUs. Taking given IDs as logical ID in cpuset
0,1
$ LIKWID_IGNORE_CPUSET=1 ./likwid-pin -c 3,4 -p
3,4

It does not ignore the CPUset but creates an own CPUset containing X online CPUs where X=sysconf(_SC_NPROCESSORS_CONF). This should be fine for almost all use-cases.","New environment variable LIKWID_IGNORE_CPUSET. The variable affects all tools and the library. Maybe fixes #358, not tested isolcpus explicitly.
System with 8 hardware threads (SMT active)
$ taskset -c -p $$
pid's current affinity list: 0-2
$ likwid-pin -c 0,1 -p
INFO: You are running LIKWID in a cpuset with 3 CPUs. Taking given IDs as logical ID in cpuset
0,1
$ likwid-pin -c 3,4 -p
INFO: You are running LIKWID in a cpuset with 3 CPUs. Taking given IDs as logical ID in cpuset
0,1
$ LIKWID_IGNORE_CPUSET=1 ./likwid-pin -c 3,4 -p
3,4

It does not ignore the CPUset but creates an own CPUset containing X online CPUs where X=sysconf(_SC_NPROCESSORS_CONF). This should be fine for almost all use-cases.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,394,2021-04-28T06:00:24Z,2021-04-28T12:06:02Z,2021-04-28T12:06:02Z,MERGED,True,98,100,4,https://github.com/breiters,Update arm64fx MEM groups bandwidth metrics,1,[],https://github.com/RRZE-HPC/likwid/pull/394,https://github.com/breiters,1,https://github.com/RRZE-HPC/likwid/pull/394,"Metrics and correction terms taken from the fujitsu a64fx microarchitectural manual v1.4 page 85 and the a64fx pmu events errata v1.0.
L2D_CACHE_REFILL (corrected) = L2D_CACHE_REFILL - L2D_SWAP_DM - L2D_CACHE_MIBMCH_PRF
Bandwidth (corrected) = (L2D_CACHE_REFILL - (L2D_SWAP_DM + L2D_CACHE_MIBMCH_PRF) + L2D_CACHE_WB) * 256 / time


https://github.com/fujitsu/A64FX/blob/master/doc/A64FX_Microarchitecture_Manual_en_1.4.pdf
https://github.com/fujitsu/A64FX/blob/master/doc/A64FX_PMU_Events_Errata_1.0.pdf","Metrics and correction terms taken from the fujitsu a64fx microarchitectural manual v1.4 page 85 and the a64fx pmu events errata v1.0.
L2D_CACHE_REFILL (corrected) = L2D_CACHE_REFILL - L2D_SWAP_DM - L2D_CACHE_MIBMCH_PRF
Bandwidth (corrected) = (L2D_CACHE_REFILL - (L2D_SWAP_DM + L2D_CACHE_MIBMCH_PRF) + L2D_CACHE_WB) * 256 / time


https://github.com/fujitsu/A64FX/blob/master/doc/A64FX_Microarchitecture_Manual_en_1.4.pdf
https://github.com/fujitsu/A64FX/blob/master/doc/A64FX_PMU_Events_Errata_1.0.pdf",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,394,2021-04-28T06:00:24Z,2021-04-28T12:06:02Z,2021-04-28T12:06:02Z,MERGED,True,98,100,4,https://github.com/breiters,Update arm64fx MEM groups bandwidth metrics,1,[],https://github.com/RRZE-HPC/likwid/pull/394,https://github.com/TomTheBear,2,https://github.com/RRZE-HPC/likwid/pull/394#issuecomment-828399638,"Metrics and correction terms taken from the fujitsu a64fx microarchitectural manual v1.4 page 85 and the a64fx pmu events errata v1.0.
L2D_CACHE_REFILL (corrected) = L2D_CACHE_REFILL - L2D_SWAP_DM - L2D_CACHE_MIBMCH_PRF
Bandwidth (corrected) = (L2D_CACHE_REFILL - (L2D_SWAP_DM + L2D_CACHE_MIBMCH_PRF) + L2D_CACHE_WB) * 256 / time


https://github.com/fujitsu/A64FX/blob/master/doc/A64FX_Microarchitecture_Manual_en_1.4.pdf
https://github.com/fujitsu/A64FX/blob/master/doc/A64FX_PMU_Events_Errata_1.0.pdf",Tested on OOKAMI. Thanks to Stony Brook University.,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,396,2021-05-11T17:38:00Z,2021-05-12T09:18:03Z,2021-05-12T09:18:03Z,MERGED,True,33,0,1,https://github.com/paigeweber13,Add gitignore,3,[],https://github.com/RRZE-HPC/likwid/pull/396,https://github.com/paigeweber13,1,https://github.com/RRZE-HPC/likwid/pull/396,"Hey Tom, it's been a while! Hope you're doing well :) Also, I'm changing my name from ""Riley"" to ""Paige"", sorry for the confusion.
I don't know if this aligns with your vision for this repo, but I frequently found myself wishing I had a gitignore while working on this repository, as a clean make generates hundreds of files that are picked up by git. So I created one that just ignores everything generated by Make
If this fits your goals I'd love to see it added into likwid.","Hey Tom, it's been a while! Hope you're doing well :) Also, I'm changing my name from ""Riley"" to ""Paige"", sorry for the confusion.
I don't know if this aligns with your vision for this repo, but I frequently found myself wishing I had a gitignore while working on this repository, as a clean make generates hundreds of files that are picked up by git. So I created one that just ignores everything generated by Make
If this fits your goals I'd love to see it added into likwid.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,396,2021-05-11T17:38:00Z,2021-05-12T09:18:03Z,2021-05-12T09:18:03Z,MERGED,True,33,0,1,https://github.com/paigeweber13,Add gitignore,3,[],https://github.com/RRZE-HPC/likwid/pull/396,https://github.com/TomTheBear,2,https://github.com/RRZE-HPC/likwid/pull/396#issuecomment-839611271,"Hey Tom, it's been a while! Hope you're doing well :) Also, I'm changing my name from ""Riley"" to ""Paige"", sorry for the confusion.
I don't know if this aligns with your vision for this repo, but I frequently found myself wishing I had a gitignore while working on this repository, as a clean make generates hundreds of files that are picked up by git. So I created one that just ignores everything generated by Make
If this fits your goals I'd love to see it added into likwid.","Hi Paige,
I see the need of such a better tailored .gitignore, so I'm happy to merge it.
Best,
Thomas
P.S. If you want, you can create a PR to change your name also in the file headers (like examples/C-markerAPI.c).",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,399,2021-05-21T09:26:24Z,2021-05-25T15:14:20Z,2021-05-25T15:14:24Z,MERGED,True,14,6,5,https://github.com/TomTheBear,"Add support for AMD Zen2 (family 0x17, model 0x60)",2,['new architecture'],https://github.com/RRZE-HPC/likwid/pull/399,https://github.com/TomTheBear,1,https://github.com/RRZE-HPC/likwid/pull/399,Like AMD Ryzen 7 4800H,Like AMD Ryzen 7 4800H,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,400,2021-05-25T10:53:10Z,2021-05-27T10:18:20Z,2021-05-27T10:18:33Z,MERGED,True,5,1,2,https://github.com/TomTheBear,Add dieId to likwid-genTopoCfg and to the relevant parser,1,[],https://github.com/RRZE-HPC/likwid/pull/400,https://github.com/TomTheBear,1,https://github.com/RRZE-HPC/likwid/pull/400,,,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,402,2021-06-07T16:45:42Z,2021-06-08T13:15:30Z,2021-06-08T13:15:32Z,MERGED,True,75,64,2,https://github.com/TomTheBear,Proper handling of `CORE` RAPL domain in `likwid-powermeter` for AMD Zen,2,[],https://github.com/RRZE-HPC/likwid/pull/402,https://github.com/TomTheBear,1,https://github.com/RRZE-HPC/likwid/pull/402,"For the CORE RAPL domain of AMD Zen1/2/3 chips, likwid-powermeter reads the data of all cores and sum it up.
Without this PR, only the first hwthread of each socket is measured.","For the CORE RAPL domain of AMD Zen1/2/3 chips, likwid-powermeter reads the data of all cores and sum it up.
Without this PR, only the first hwthread of each socket is measured.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,403,2021-06-07T16:52:03Z,2021-06-08T13:15:43Z,2021-06-08T13:15:46Z,MERGED,True,44,0,1,https://github.com/TomTheBear,Add likwid_gpuMarkerGetRegion,1,[],https://github.com/RRZE-HPC/likwid/pull/403,https://github.com/TomTheBear,1,https://github.com/RRZE-HPC/likwid/pull/403,,,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,405,2021-06-09T16:00:19Z,2021-06-10T11:56:51Z,2021-06-10T11:56:54Z,MERGED,True,1,1,1,https://github.com/TomTheBear,Fix for min. frequency after setting governor. See #404,1,[],https://github.com/RRZE-HPC/likwid/pull/405,https://github.com/TomTheBear,1,https://github.com/RRZE-HPC/likwid/pull/405,"When setting the governor with likwid-setFrequencies, the minimal and maximal CPU frequency of all selected HW threads is set to the minimal frequency. This PR fixes this behavior by leaving the CPU frequency untouched.","When setting the governor with likwid-setFrequencies, the minimal and maximal CPU frequency of all selected HW threads is set to the minimal frequency. This PR fixes this behavior by leaving the CPU frequency untouched.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,406,2021-06-09T16:00:36Z,2021-06-10T11:54:23Z,2021-06-10T11:54:25Z,MERGED,True,34,16,1,https://github.com/TomTheBear,Fix for affinity in reduced cpusets,1,[],https://github.com/RRZE-HPC/likwid/pull/406,https://github.com/TomTheBear,1,https://github.com/RRZE-HPC/likwid/pull/406,"Example for the bug:
$ likwid-pin -c S1:0 -q likwid-pin -p
Domain 0:
	Tag N: 12
Domain 1:
	Tag S0: 12
Domain 2:
	Tag C0:
Domain 3:
	Tag C1:
Domain 4:
	Tag M0:","Example for the bug:
$ likwid-pin -c S1:0 -q likwid-pin -p
Domain 0:
	Tag N: 12
Domain 1:
	Tag S0: 12
Domain 2:
	Tag C0:
Domain 3:
	Tag C1:
Domain 4:
	Tag M0:",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,407,2021-06-09T17:34:29Z,2021-06-10T11:55:24Z,2021-06-10T11:55:27Z,MERGED,True,54,2,2,https://github.com/TomTheBear,Some fixes for ARM7 and ARM8,2,[],https://github.com/RRZE-HPC/likwid/pull/407,https://github.com/TomTheBear,1,https://github.com/RRZE-HPC/likwid/pull/407,"This PR adds all ARM-reference implementation (A35, A53, A72, A73, Neoverse N1) for 32bit (aka ARMv7 in some cases) and 64bit (ARMv8) to the topology module.","This PR adds all ARM-reference implementation (A35, A53, A72, A73, Neoverse N1) for 32bit (aka ARMv7 in some cases) and 64bit (ARMv8) to the topology module.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,408,2021-06-09T17:56:49Z,2021-06-10T11:56:09Z,2021-06-10T11:56:15Z,MERGED,True,406,63,13,https://github.com/TomTheBear,Icelake desktop groups,3,[],https://github.com/RRZE-HPC/likwid/pull/408,https://github.com/TomTheBear,1,https://github.com/RRZE-HPC/likwid/pull/408,Some groups as template for (maybe) future fixes for Intel Icelake (desktop). It also deletes the TLB_DATA and TLB_INSTR groups for Intel IcelakeSP as the events are not available anymore.,Some groups as template for (maybe) future fixes for Intel Icelake (desktop). It also deletes the TLB_DATA and TLB_INSTR groups for Intel IcelakeSP as the events are not available anymore.,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,414,2021-07-05T12:15:05Z,2021-07-06T11:00:18Z,2021-07-06T11:00:18Z,MERGED,True,1073,0,16,https://github.com/JanLJL,Peakflops armv8,3,[],https://github.com/RRZE-HPC/likwid/pull/414,https://github.com/JanLJL,1,https://github.com/RRZE-HPC/likwid/pull/414,"Created peakflops benchmarks for likwid-bench on ARMv8. This includes

Benchmarks for SP and DP operands
A combination of MUL and ADD, or pure FMA instructions
Scalar, SVE128, SVE256, and SVE512 versions

When running those on a single core as likwid-bench -t BENCHMARK -w S0:40kB:1 and comparing the result with the expected peak performance, all benchmarks reach more than 99% of the theoretical peak performance:
benchmark               measured_MFLOPS expected_MFLOPS relative_performance_%
peakflops               3587.83         3600.0          99.66
peakflops_fma           7174.63         7200.0          99.65
peakflops_sve128        7170.39         7200.0          99.59
peakflops_sve128_fma    14340.99        14400.0         99.59
peakflops_sve256        14315.83        14400.0         99.42
peakflops_sve256_fma    28631.60        28800.0         99.42
peakflops_sve512        28527.05        28800.0         99.05
peakflops_sve512_fma    57035.30        57600.0         99.02
peakflops_sp            3589.91         3600.0          99.72
peakflops_sp_fma        7180.22         7200.0          99.73
peakflops_sp_sve128     14341.46        14400.0         99.59
peakflops_sp_sve128_fma 28628.94        28800.0         99.41
peakflops_sp_sve256     28633.55        28800.0         99.42
peakflops_sp_sve256_fma 57045.71        57600.0         99.04
peakflops_sp_sve512     57051.17        57600.0         99.05
peakflops_sp_sve512_fma 114103.75       115200.0        99.05","Created peakflops benchmarks for likwid-bench on ARMv8. This includes

Benchmarks for SP and DP operands
A combination of MUL and ADD, or pure FMA instructions
Scalar, SVE128, SVE256, and SVE512 versions

When running those on a single core as likwid-bench -t BENCHMARK -w S0:40kB:1 and comparing the result with the expected peak performance, all benchmarks reach more than 99% of the theoretical peak performance:
benchmark               measured_MFLOPS expected_MFLOPS relative_performance_%
peakflops               3587.83         3600.0          99.66
peakflops_fma           7174.63         7200.0          99.65
peakflops_sve128        7170.39         7200.0          99.59
peakflops_sve128_fma    14340.99        14400.0         99.59
peakflops_sve256        14315.83        14400.0         99.42
peakflops_sve256_fma    28631.60        28800.0         99.42
peakflops_sve512        28527.05        28800.0         99.05
peakflops_sve512_fma    57035.30        57600.0         99.02
peakflops_sp            3589.91         3600.0          99.72
peakflops_sp_fma        7180.22         7200.0          99.73
peakflops_sp_sve128     14341.46        14400.0         99.59
peakflops_sp_sve128_fma 28628.94        28800.0         99.41
peakflops_sp_sve256     28633.55        28800.0         99.42
peakflops_sp_sve256_fma 57045.71        57600.0         99.04
peakflops_sp_sve512     57051.17        57600.0         99.05
peakflops_sp_sve512_fma 114103.75       115200.0        99.05",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,417,2021-07-21T17:01:31Z,2021-07-22T09:53:50Z,2021-07-22T09:53:54Z,MERGED,True,11,4,1,https://github.com/TomTheBear,Don't set cpuset in unpinned case,1,[],https://github.com/RRZE-HPC/likwid/pull/417,https://github.com/TomTheBear,1,https://github.com/RRZE-HPC/likwid/pull/417,Fixes #411,Fixes #411,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,418,2021-07-22T03:59:48Z,2021-07-22T09:21:46Z,2021-07-22T09:21:46Z,MERGED,True,4,0,1,https://github.com/jenny-cheung,Fix a bug due to the unrelased lock before the method returns (the issue#416),1,[],https://github.com/RRZE-HPC/likwid/pull/418,https://github.com/jenny-cheung,1,https://github.com/RRZE-HPC/likwid/pull/418,Fix a bug due to the unreleased lock before the method likwid_markerStopRegion returns. Insert the unlock statement before returning.,Fix a bug due to the unreleased lock before the method likwid_markerStopRegion returns. Insert the unlock statement before returning.,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,419,2021-07-23T15:39:11Z,2021-07-27T13:52:07Z,2021-12-27T15:48:46Z,MERGED,True,15,101,1,https://github.com/TomTheBear,Revert multiplex code for perf_event as it seems not needed,2,[],https://github.com/RRZE-HPC/likwid/pull/419,https://github.com/TomTheBear,1,https://github.com/RRZE-HPC/likwid/pull/419,,,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,420,2021-07-27T14:57:16Z,2021-08-03T11:16:20Z,2021-08-03T11:16:21Z,MERGED,True,61,49,2,https://github.com/te42kyfo,Add multi GPU capability to test/triad.cu,1,[],https://github.com/RRZE-HPC/likwid/pull/420,https://github.com/te42kyfo,1,https://github.com/RRZE-HPC/likwid/pull/420,Starts an OpenMP thread for every GPU that is present and makes a separate benchmark for each GPU.,Starts an OpenMP thread for every GPU that is present and makes a separate benchmark for each GPU.,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,421,2021-08-01T07:39:33Z,2021-10-21T14:17:33Z,2021-10-21T14:17:33Z,MERGED,True,24,10,2,https://github.com/jrmadsen,Support spaces in marker API labels,2,[],https://github.com/RRZE-HPC/likwid/pull/421,https://github.com/jrmadsen,1,https://github.com/RRZE-HPC/likwid/pull/421,"replaces ""%s"" with ""%Nc"" where N is set to one minus
the size of the zeroed out.
added printout of regiontag to not valid region description msg

Hey @TomTheBear I was using the marker API and was generating some strings dynamically in timemory along the lines of: ""run/ex_cxx_overhead.cpp:314 [with timing = mode::manual]"" and was getting errors + a segfault at the end of the application like so:
Line 1:run/ex_cxx_overhead.cpp:314 [with timing = mode::none]-0
 not a valid region description
Line 2:run/ex_cxx_overhead.cpp:314 [with timing = mode::manual]-0
 not a valid region description
Line 3:run/ex_cxx_overhead.cpp:314 [with timing = mode::single]-0
 not a valid region description
Line 4:run/ex_cxx_overhead.cpp:314 [with timing = mode::blank]-0
 not a valid region description
Line 5:run/ex_cxx_overhead.cpp:314 [with timing = mode::blank_pointer]-0
 not a valid region description
Line 6:run/ex_cxx_overhead.cpp:314 [with timing = mode::chained]-0
 not a valid region description
Line 7:run/ex_cxx_overhead.cpp:314 [with timing = mode::basic]-0
 not a valid region description
Line 8:run/ex_cxx_overhead.cpp:314 [with timing = mode::basic_pointer]-0
 not a valid region description
Line 9:run/ex_cxx_overhead.cpp:314 [with timing = mode::invoke]-0
 not a valid region description
Segmentation fault (core dumped)
Which was a bit opaque since the string looked correct. But then I added regiontag to the ""not a valid region description"" message and realized what has happening with the spaces so I patched perfmon.c and nvmon.c to support spaces and I included that diagnostic as part of this PR since it was helpful.
If I were you, I'd verify my implementation... my C string manipulation skills are fairly rusty due to my predilection for C++ strings.","replaces ""%s"" with ""%Nc"" where N is set to one minus
the size of the zeroed out.
added printout of regiontag to not valid region description msg

Hey @TomTheBear I was using the marker API and was generating some strings dynamically in timemory along the lines of: ""run/ex_cxx_overhead.cpp:314 [with timing = mode::manual]"" and was getting errors + a segfault at the end of the application like so:
Line 1:run/ex_cxx_overhead.cpp:314 [with timing = mode::none]-0
 not a valid region description
Line 2:run/ex_cxx_overhead.cpp:314 [with timing = mode::manual]-0
 not a valid region description
Line 3:run/ex_cxx_overhead.cpp:314 [with timing = mode::single]-0
 not a valid region description
Line 4:run/ex_cxx_overhead.cpp:314 [with timing = mode::blank]-0
 not a valid region description
Line 5:run/ex_cxx_overhead.cpp:314 [with timing = mode::blank_pointer]-0
 not a valid region description
Line 6:run/ex_cxx_overhead.cpp:314 [with timing = mode::chained]-0
 not a valid region description
Line 7:run/ex_cxx_overhead.cpp:314 [with timing = mode::basic]-0
 not a valid region description
Line 8:run/ex_cxx_overhead.cpp:314 [with timing = mode::basic_pointer]-0
 not a valid region description
Line 9:run/ex_cxx_overhead.cpp:314 [with timing = mode::invoke]-0
 not a valid region description
Segmentation fault (core dumped)
Which was a bit opaque since the string looked correct. But then I added regiontag to the ""not a valid region description"" message and realized what has happening with the spaces so I patched perfmon.c and nvmon.c to support spaces and I included that diagnostic as part of this PR since it was helpful.
If I were you, I'd verify my implementation... my C string manipulation skills are fairly rusty due to my predilection for C++ strings.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,421,2021-08-01T07:39:33Z,2021-10-21T14:17:33Z,2021-10-21T14:17:33Z,MERGED,True,24,10,2,https://github.com/jrmadsen,Support spaces in marker API labels,2,[],https://github.com/RRZE-HPC/likwid/pull/421,https://github.com/TomTheBear,2,https://github.com/RRZE-HPC/likwid/pull/421#issuecomment-896716007,"replaces ""%s"" with ""%Nc"" where N is set to one minus
the size of the zeroed out.
added printout of regiontag to not valid region description msg

Hey @TomTheBear I was using the marker API and was generating some strings dynamically in timemory along the lines of: ""run/ex_cxx_overhead.cpp:314 [with timing = mode::manual]"" and was getting errors + a segfault at the end of the application like so:
Line 1:run/ex_cxx_overhead.cpp:314 [with timing = mode::none]-0
 not a valid region description
Line 2:run/ex_cxx_overhead.cpp:314 [with timing = mode::manual]-0
 not a valid region description
Line 3:run/ex_cxx_overhead.cpp:314 [with timing = mode::single]-0
 not a valid region description
Line 4:run/ex_cxx_overhead.cpp:314 [with timing = mode::blank]-0
 not a valid region description
Line 5:run/ex_cxx_overhead.cpp:314 [with timing = mode::blank_pointer]-0
 not a valid region description
Line 6:run/ex_cxx_overhead.cpp:314 [with timing = mode::chained]-0
 not a valid region description
Line 7:run/ex_cxx_overhead.cpp:314 [with timing = mode::basic]-0
 not a valid region description
Line 8:run/ex_cxx_overhead.cpp:314 [with timing = mode::basic_pointer]-0
 not a valid region description
Line 9:run/ex_cxx_overhead.cpp:314 [with timing = mode::invoke]-0
 not a valid region description
Segmentation fault (core dumped)
Which was a bit opaque since the string looked correct. But then I added regiontag to the ""not a valid region description"" message and realized what has happening with the spaces so I patched perfmon.c and nvmon.c to support spaces and I included that diagnostic as part of this PR since it was helpful.
If I were you, I'd verify my implementation... my C string manipulation skills are fairly rusty due to my predilection for C++ strings.",Are these two changes really enough? There is not a single change in src/libperfctr.c which implements the MarkerAPI.,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,421,2021-08-01T07:39:33Z,2021-10-21T14:17:33Z,2021-10-21T14:17:33Z,MERGED,True,24,10,2,https://github.com/jrmadsen,Support spaces in marker API labels,2,[],https://github.com/RRZE-HPC/likwid/pull/421,https://github.com/jrmadsen,3,https://github.com/RRZE-HPC/likwid/pull/421#issuecomment-897031318,"replaces ""%s"" with ""%Nc"" where N is set to one minus
the size of the zeroed out.
added printout of regiontag to not valid region description msg

Hey @TomTheBear I was using the marker API and was generating some strings dynamically in timemory along the lines of: ""run/ex_cxx_overhead.cpp:314 [with timing = mode::manual]"" and was getting errors + a segfault at the end of the application like so:
Line 1:run/ex_cxx_overhead.cpp:314 [with timing = mode::none]-0
 not a valid region description
Line 2:run/ex_cxx_overhead.cpp:314 [with timing = mode::manual]-0
 not a valid region description
Line 3:run/ex_cxx_overhead.cpp:314 [with timing = mode::single]-0
 not a valid region description
Line 4:run/ex_cxx_overhead.cpp:314 [with timing = mode::blank]-0
 not a valid region description
Line 5:run/ex_cxx_overhead.cpp:314 [with timing = mode::blank_pointer]-0
 not a valid region description
Line 6:run/ex_cxx_overhead.cpp:314 [with timing = mode::chained]-0
 not a valid region description
Line 7:run/ex_cxx_overhead.cpp:314 [with timing = mode::basic]-0
 not a valid region description
Line 8:run/ex_cxx_overhead.cpp:314 [with timing = mode::basic_pointer]-0
 not a valid region description
Line 9:run/ex_cxx_overhead.cpp:314 [with timing = mode::invoke]-0
 not a valid region description
Segmentation fault (core dumped)
Which was a bit opaque since the string looked correct. But then I added regiontag to the ""not a valid region description"" message and realized what has happening with the spaces so I patched perfmon.c and nvmon.c to support spaces and I included that diagnostic as part of this PR since it was helpful.
If I were you, I'd verify my implementation... my C string manipulation skills are fairly rusty due to my predilection for C++ strings.","I believe so. I didn't delve to deeply into it at the time because it fixed my issue and it was pretty clear from the message that up until these functions with the modifications were called, the string with the spaces was perfectly preserved, i.e. ""run/ex_cxx_overhead.cpp:314 [with timing = mode::invoke]"" from Line 9:run/ex_cxx_overhead.cpp:314 [with timing = mode::invoke]-0. Looking at src/libperfctr.c, it appears that is the case bc the register/start/stop region functions use bfromcstralloc which memcpy based on the strlen and thus the spaces are implicitly included there.
Side note: I did not test the nvmon backend unfortunately since I was running on a system with an AMD GPU (if you weren't aware, I left NERSC and took a position in AMD Research to work on their tooling about 1.5 months ago).",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,424,2021-08-24T11:45:04Z,2021-09-03T12:05:17Z,2021-09-03T12:05:21Z,MERGED,True,279,90,1,https://github.com/TomTheBear,Fix Cuda builds for version >= 11.4,2,[],https://github.com/RRZE-HPC/likwid/pull/424,https://github.com/TomTheBear,1,https://github.com/RRZE-HPC/likwid/pull/424,Nvidia changed the way how to determine the subevents required for a metric. Fixes #423,Nvidia changed the way how to determine the subevents required for a metric. Fixes #423,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,426,2021-08-25T13:28:40Z,2021-09-03T12:06:16Z,2021-12-27T15:48:48Z,MERGED,True,277,0,4,https://github.com/TomTheBear,Gitlab CI at NHR@FAU,44,[],https://github.com/RRZE-HPC/likwid/pull/426,https://github.com/TomTheBear,1,https://github.com/RRZE-HPC/likwid/pull/426,This PR adds CI checks again. It uses a Gitlab instance at our center to run the checks on local systems.,This PR adds CI checks again. It uses a Gitlab instance at our center to run the checks on local systems.,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,429,2021-09-08T13:53:33Z,,2021-09-08T15:39:54Z,OPEN,False,25,3,3,https://github.com/TomTheBear,Create buildtests.yml,10,[],https://github.com/RRZE-HPC/likwid/pull/429,https://github.com/TomTheBear,1,https://github.com/RRZE-HPC/likwid/pull/429,Simple build tests on x86_64,Simple build tests on x86_64,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,431,2021-09-22T16:49:52Z,2021-10-21T14:15:30Z,2021-10-21T14:15:30Z,MERGED,True,2,2,1,https://github.com/carstenbauer,Improve mention of Julia interface LIKWID.jl,1,[],https://github.com/RRZE-HPC/likwid/pull/431,https://github.com/carstenbauer,1,https://github.com/RRZE-HPC/likwid/pull/431,"Now that LIKWID.jl is really getting into shape, I suggest we update the mentions of LIKWID.jl. This PR is the first minor improvement in the README.md.
(Unfortunately, it doesn't seem to be possible to suggest changes to the WIKI - please enlighten me if there is a way - so I'll talk about those with @TomTheBear directly some time soon.)","Now that LIKWID.jl is really getting into shape, I suggest we update the mentions of LIKWID.jl. This PR is the first minor improvement in the README.md.
(Unfortunately, it doesn't seem to be possible to suggest changes to the WIKI - please enlighten me if there is a way - so I'll talk about those with @TomTheBear directly some time soon.)",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,431,2021-09-22T16:49:52Z,2021-10-21T14:15:30Z,2021-10-21T14:15:30Z,MERGED,True,2,2,1,https://github.com/carstenbauer,Improve mention of Julia interface LIKWID.jl,1,[],https://github.com/RRZE-HPC/likwid/pull/431,https://github.com/TomTheBear,2,https://github.com/RRZE-HPC/likwid/pull/431#issuecomment-927721935,"Now that LIKWID.jl is really getting into shape, I suggest we update the mentions of LIKWID.jl. This PR is the first minor improvement in the README.md.
(Unfortunately, it doesn't seem to be possible to suggest changes to the WIKI - please enlighten me if there is a way - so I'll talk about those with @TomTheBear directly some time soon.)","There is no way to suggest changes to the wiki through PRs or issues. You can clone the wiki repo and create branches but there is no way to give it back. That's unfortunately a missing feature of Github.
It depends how much you want to change. For bigger changes, I could give you repo access. For small changes it's probably easier you send me change requests as patches here or the Matrix chat.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,436,2021-10-24T09:15:18Z,2021-10-25T09:34:01Z,2021-10-25T09:36:39Z,MERGED,True,2,2,1,https://github.com/bugwelle,README: Fix variable assignment in quick install,1,[],https://github.com/RRZE-HPC/likwid/pull/436,https://github.com/bugwelle,1,https://github.com/RRZE-HPC/likwid/pull/436,"In bash (and other shells), the leading $ in $VERSION=stable will fail.
The correct variable assignment looks like:
VERSION=stable
Furthermore, if VERSION is stable, the directory will not be
called likwid-stable  but (at the moment) will be likwid-5.2.0.
A workaround is to simply use an * as that will be substituted
by the the correct directory, assuming that only one
likwid-xyz directory exists.","In bash (and other shells), the leading $ in $VERSION=stable will fail.
The correct variable assignment looks like:
VERSION=stable
Furthermore, if VERSION is stable, the directory will not be
called likwid-stable  but (at the moment) will be likwid-5.2.0.
A workaround is to simply use an * as that will be substituted
by the the correct directory, assuming that only one
likwid-xyz directory exists.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,436,2021-10-24T09:15:18Z,2021-10-25T09:34:01Z,2021-10-25T09:36:39Z,MERGED,True,2,2,1,https://github.com/bugwelle,README: Fix variable assignment in quick install,1,[],https://github.com/RRZE-HPC/likwid/pull/436,https://github.com/TomTheBear,2,https://github.com/RRZE-HPC/likwid/pull/436#issuecomment-950722295,"In bash (and other shells), the leading $ in $VERSION=stable will fail.
The correct variable assignment looks like:
VERSION=stable
Furthermore, if VERSION is stable, the directory will not be
called likwid-stable  but (at the moment) will be likwid-5.2.0.
A workaround is to simply use an * as that will be substituted
by the the correct directory, assuming that only one
likwid-xyz directory exists.","Correct, thanks.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,437,2021-10-26T13:50:22Z,,2021-11-11T13:22:13Z,OPEN,False,73,0,2,https://github.com/TomTheBear,Add functions to return support status and version of the library,1,[],https://github.com/RRZE-HPC/likwid/pull/437,https://github.com/TomTheBear,1,https://github.com/RRZE-HPC/likwid/pull/437,"Adds the following functions:

likwid_getMajorVersion()
likwid_getMinorVersion()
likwid_getBugfixVersion()
likwid_getNvidiaSupport()
likwid_getMaxSupportedThreads()
likwid_getMaxSupportedSockets()

See #428 and #430","Adds the following functions:

likwid_getMajorVersion()
likwid_getMinorVersion()
likwid_getBugfixVersion()
likwid_getNvidiaSupport()
likwid_getMaxSupportedThreads()
likwid_getMaxSupportedSockets()

See #428 and #430",True,{'THUMBS_UP': ['https://github.com/carstenbauer']}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,437,2021-10-26T13:50:22Z,,2021-11-11T13:22:13Z,OPEN,False,73,0,2,https://github.com/TomTheBear,Add functions to return support status and version of the library,1,[],https://github.com/RRZE-HPC/likwid/pull/437,https://github.com/TomTheBear,2,https://github.com/RRZE-HPC/likwid/pull/437#issuecomment-966298092,"Adds the following functions:

likwid_getMajorVersion()
likwid_getMinorVersion()
likwid_getBugfixVersion()
likwid_getNvidiaSupport()
likwid_getMaxSupportedThreads()
likwid_getMaxSupportedSockets()

See #428 and #430",This PR will be in the next major release since it changes the main header file likwid.h.,True,{'THUMBS_UP': ['https://github.com/carstenbauer']}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,438,2021-10-26T14:07:38Z,2021-11-11T13:27:43Z,2021-11-11T13:27:47Z,MERGED,True,12,0,2,https://github.com/TomTheBear,Check perf device path for ARM8 A72 with fallback. Fixes #425,2,[],https://github.com/RRZE-HPC/likwid/pull/438,https://github.com/TomTheBear,1,https://github.com/RRZE-HPC/likwid/pull/438,"If /sys/bus/event_source/devices/armv8_pmuv3 does not exist, use /sys/bus/event_source/devices/armv8_cortex_a72.","If /sys/bus/event_source/devices/armv8_pmuv3 does not exist, use /sys/bus/event_source/devices/armv8_cortex_a72.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,440,2021-10-28T13:53:27Z,2021-11-11T13:17:05Z,2021-11-11T13:17:08Z,MERGED,True,11,9,1,https://github.com/TomTheBear,Fallback to procfs based PCI detection if hwloc based detection fails.,1,[],https://github.com/RRZE-HPC/likwid/pull/440,https://github.com/TomTheBear,1,https://github.com/RRZE-HPC/likwid/pull/440,Fixes #435,Fixes #435,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,441,2021-10-28T16:12:03Z,2021-11-04T15:37:39Z,2021-12-27T15:48:51Z,MERGED,True,81,36,5,https://github.com/TomTheBear,Update Nvidia GPU support,3,[],https://github.com/RRZE-HPC/likwid/pull/441,https://github.com/TomTheBear,1,https://github.com/RRZE-HPC/likwid/pull/441,"This PR contains different updates:

Ability for the perfworks backend to use min,max,sum and spot values
Don't use fprintf in the code but the debug/error macros provided by LIKWID
likwid-perfctr: Initialize the Nvidia GPU modules only if needed (user wants to measure, print or search events). See #427","This PR contains different updates:

Ability for the perfworks backend to use min,max,sum and spot values
Don't use fprintf in the code but the debug/error macros provided by LIKWID
likwid-perfctr: Initialize the Nvidia GPU modules only if needed (user wants to measure, print or search events). See #427",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,442,2021-10-29T18:31:57Z,,2021-11-04T15:14:52Z,OPEN,False,65,68,4,https://github.com/melven,bench: avoid peakflops register dependencies,1,[],https://github.com/RRZE-HPC/likwid/pull/442,https://github.com/melven,1,https://github.com/RRZE-HPC/likwid/pull/442,"Improves results on Intel Westmere which was missing a factor of 2 before
due to latency/register dependencies in the peak flops benchmark.","Improves results on Intel Westmere which was missing a factor of 2 before
due to latency/register dependencies in the peak flops benchmark.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,442,2021-10-29T18:31:57Z,,2021-11-04T15:14:52Z,OPEN,False,65,68,4,https://github.com/melven,bench: avoid peakflops register dependencies,1,[],https://github.com/RRZE-HPC/likwid/pull/442,https://github.com/melven,2,https://github.com/RRZE-HPC/likwid/pull/442#issuecomment-954965485,"Improves results on Intel Westmere which was missing a factor of 2 before
due to latency/register dependencies in the peak flops benchmark.","Hi @TomTheBear
This reverses some of your changes from 2 years ago.
I didn't get the ""correct"" 2 flops/cycle (mult+add) for scalar operations on a Westmere, this improves it (but also only results in 1.75 flops/cycle on Westmere).
But I just tried to improve it without real insight into the .ptt format.",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,442,2021-10-29T18:31:57Z,,2021-11-04T15:14:52Z,OPEN,False,65,68,4,https://github.com/melven,bench: avoid peakflops register dependencies,1,[],https://github.com/RRZE-HPC/likwid/pull/442,https://github.com/TomTheBear,3,https://github.com/RRZE-HPC/likwid/pull/442#issuecomment-961142492,"Improves results on Intel Westmere which was missing a factor of 2 before
due to latency/register dependencies in the peak flops benchmark.","Thanks for the PR. So, it's just reordering of the instructions and registers?
PTT format is tricky. I tried to document it here: https://github.com/RRZE-HPC/likwid/wiki/Likwid-Bench#adding-benchmarks",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,444,2021-12-01T15:47:48Z,,2021-12-11T14:17:33Z,OPEN,False,633,0,3,https://github.com/TomTheBear,Support for ARM Neoverse N2,1,"['help wanted', 'new architecture']",https://github.com/RRZE-HPC/likwid/pull/444,https://github.com/TomTheBear,1,https://github.com/RRZE-HPC/likwid/pull/444,"Event list based on https://developer.arm.com/documentation/102099/0000/Performance-Monitors-Extension-support-/Performance-monitors-events
 Counter list with 6 counters per hardware thread
 Topology detection (/proc/cpuinfo)
 perf_event unit name(s)","Event list based on https://developer.arm.com/documentation/102099/0000/Performance-Monitors-Extension-support-/Performance-monitors-events
 Counter list with 6 counters per hardware thread
 Topology detection (/proc/cpuinfo)
 perf_event unit name(s)",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,444,2021-12-01T15:47:48Z,,2021-12-11T14:17:33Z,OPEN,False,633,0,3,https://github.com/TomTheBear,Support for ARM Neoverse N2,1,"['help wanted', 'new architecture']",https://github.com/RRZE-HPC/likwid/pull/444,https://github.com/TomTheBear,2,https://github.com/RRZE-HPC/likwid/pull/444#issuecomment-991659161,"Event list based on https://developer.arm.com/documentation/102099/0000/Performance-Monitors-Extension-support-/Performance-monitors-events
 Counter list with 6 counters per hardware thread
 Topology detection (/proc/cpuinfo)
 perf_event unit name(s)","If anyone has access to such a system:

Output of /proc/cpuinfo
File listing ls /sys/devices",True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,448,2022-01-31T16:14:44Z,,2022-01-31T16:14:44Z,OPEN,False,118,0,5,https://github.com/TomTheBear,Add HiSilicon TSV110 architecture,2,[],https://github.com/RRZE-HPC/likwid/pull/448,https://github.com/TomTheBear,1,https://github.com/RRZE-HPC/likwid/pull/448,,,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,449,2022-03-03T13:54:12Z,2022-03-03T13:55:48Z,2022-03-03T13:55:48Z,MERGED,True,16,14,2,https://github.com/ho-ob,Allow to configure sbin path,1,[],https://github.com/RRZE-HPC/likwid/pull/449,https://github.com/ho-ob,1,https://github.com/RRZE-HPC/likwid/pull/449,,,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,450,2022-03-03T15:00:37Z,2022-03-03T15:05:38Z,2022-03-03T15:05:39Z,CLOSED,False,59,0,1,https://github.com/ho-ob,Add PKGBUILD for ArchLinux,3,[],https://github.com/RRZE-HPC/likwid/pull/450,https://github.com/ho-ob,1,https://github.com/RRZE-HPC/likwid/pull/450,,,True,{}
RRZE-HPC/likwid,https://github.com/RRZE-HPC/likwid,451,2022-03-03T15:15:33Z,2022-03-03T15:32:37Z,2022-03-03T15:32:37Z,MERGED,True,59,0,1,https://github.com/ho-ob,Add PKGBUILD for ArchLinux,1,[],https://github.com/RRZE-HPC/likwid/pull/451,https://github.com/ho-ob,1,https://github.com/RRZE-HPC/likwid/pull/451,,,True,{}
