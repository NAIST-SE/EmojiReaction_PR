colmap/colmap,https://github.com/colmap/colmap,1,2016-04-07T08:13:02Z,2016-04-07T08:30:10Z,2016-04-07T08:30:10Z,MERGED,True,1,1,1,https://github.com/puzzlepaint,Fix typo in tutorial.rst,1,[],https://github.com/colmap/colmap/pull/1,https://github.com/puzzlepaint,1,https://github.com/colmap/colmap/pull/1,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,1,2016-04-07T08:13:02Z,2016-04-07T08:30:10Z,2016-04-07T08:30:10Z,MERGED,True,1,1,1,https://github.com/puzzlepaint,Fix typo in tutorial.rst,1,[],https://github.com/colmap/colmap/pull/1,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/1#issuecomment-206758674,,Thanks!,True,{}
colmap/colmap,https://github.com/colmap/colmap,2,2016-04-08T08:41:10Z,2016-04-08T08:41:43Z,2016-04-08T08:41:43Z,MERGED,True,1,1,1,https://github.com/puzzlepaint,Fix typo in tutorial.rst,1,[],https://github.com/colmap/colmap/pull/2,https://github.com/puzzlepaint,1,https://github.com/colmap/colmap/pull/2,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,4,2016-04-25T21:36:44Z,2016-04-26T07:28:10Z,2016-04-26T07:28:10Z,MERGED,True,147,2,3,https://github.com/puzzlepaint,Implement FOV camera model,3,[],https://github.com/colmap/colmap/pull/4,https://github.com/puzzlepaint,1,https://github.com/colmap/colmap/pull/4,"Implements the FOV camera model from Frederic Devernay, Olivier Faugeras. Straight lines have to be straight: Automatic calibration and removal of distortion from scenes of structured environments. Machine vision and applications, 2001.
Potential further work:

Determine the threshold for small numbers in a sensible way.
The term T(2) * ceres::tan(omega / T(2)) appearing in the distortion and undistortion could theoretically be cached in case omega is constant.","Implements the FOV camera model from Frederic Devernay, Olivier Faugeras. Straight lines have to be straight: Automatic calibration and removal of distortion from scenes of structured environments. Machine vision and applications, 2001.
Potential further work:

Determine the threshold for small numbers in a sensible way.
The term T(2) * ceres::tan(omega / T(2)) appearing in the distortion and undistortion could theoretically be cached in case omega is constant.",True,{}
colmap/colmap,https://github.com/colmap/colmap,4,2016-04-25T21:36:44Z,2016-04-26T07:28:10Z,2016-04-26T07:28:10Z,MERGED,True,147,2,3,https://github.com/puzzlepaint,Implement FOV camera model,3,[],https://github.com/colmap/colmap/pull/4,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/4#issuecomment-214652960,"Implements the FOV camera model from Frederic Devernay, Olivier Faugeras. Straight lines have to be straight: Automatic calibration and removal of distortion from scenes of structured environments. Machine vision and applications, 2001.
Potential further work:

Determine the threshold for small numbers in a sensible way.
The term T(2) * ceres::tan(omega / T(2)) appearing in the distortion and undistortion could theoretically be cached in case omega is constant.","Looks great! Thanks, Thomas.",True,{}
colmap/colmap,https://github.com/colmap/colmap,9,2016-05-11T08:30:42Z,,2019-05-29T23:39:34Z,OPEN,False,979,712,62,https://github.com/daleydeng,Sperical Central Camera Support,5,[],https://github.com/colmap/colmap/pull/9,https://github.com/daleydeng,1,https://github.com/colmap/colmap/pull/9,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,9,2016-05-11T08:30:42Z,,2019-05-29T23:39:34Z,OPEN,False,979,712,62,https://github.com/daleydeng,Sperical Central Camera Support,5,[],https://github.com/colmap/colmap/pull/9,https://github.com/daleydeng,2,https://github.com/colmap/colmap/pull/9#issuecomment-218395553,,"Notice that, some unused functions and related tests are commented out, apply needed parts~",True,{}
colmap/colmap,https://github.com/colmap/colmap,9,2016-05-11T08:30:42Z,,2019-05-29T23:39:34Z,OPEN,False,979,712,62,https://github.com/daleydeng,Sperical Central Camera Support,5,[],https://github.com/colmap/colmap/pull/9,https://github.com/ahojnnes,3,https://github.com/colmap/colmap/pull/9#issuecomment-220765146,,"Hi @daleydeng ,
I will get to this soon. Have to finish some other stuff first though.
Best, Johannes",True,{}
colmap/colmap,https://github.com/colmap/colmap,9,2016-05-11T08:30:42Z,,2019-05-29T23:39:34Z,OPEN,False,979,712,62,https://github.com/daleydeng,Sperical Central Camera Support,5,[],https://github.com/colmap/colmap/pull/9,https://github.com/daleydeng,4,https://github.com/colmap/colmap/pull/9#issuecomment-220907628,,"Allright, I found the ray based representation also needs to do the cheirality check and the angular error check is enough.
If the triangulated 3D point (by DLT method) is behind its observed ray directions (world points), the angular error will be large (near M_PI), so check the angular error is equivalent to cheriality check for the ray based representation.
angular_error(X) = ||ray - \frac{PX}{||PX||_2}||
new commit as:
daleydeng@9c6c309",True,{}
colmap/colmap,https://github.com/colmap/colmap,9,2016-05-11T08:30:42Z,,2019-05-29T23:39:34Z,OPEN,False,979,712,62,https://github.com/daleydeng,Sperical Central Camera Support,5,[],https://github.com/colmap/colmap/pull/9,https://github.com/spriglet66,5,https://github.com/colmap/colmap/pull/9#issuecomment-352254217,,"Would be amazing if spherical camera support could be implemented into the branch master as it would make my life so much easier! At the moment I have to process the spherical source images into cube map faces to then import into colmap which is a pain as it would be an unnessecary step!
Thank you so much!",True,"{'HEART': ['https://github.com/spriglet66', 'https://github.com/ryanismert', 'https://github.com/creniq']}"
colmap/colmap,https://github.com/colmap/colmap,9,2016-05-11T08:30:42Z,,2019-05-29T23:39:34Z,OPEN,False,979,712,62,https://github.com/daleydeng,Sperical Central Camera Support,5,[],https://github.com/colmap/colmap/pull/9,https://github.com/ahojnnes,6,https://github.com/colmap/colmap/pull/9#issuecomment-353143301,,"I don't have access to a spherical camera. If someone could capture a few datasets and share the data with me, I can try to implement this feature.",True,{}
colmap/colmap,https://github.com/colmap/colmap,9,2016-05-11T08:30:42Z,,2019-05-29T23:39:34Z,OPEN,False,979,712,62,https://github.com/daleydeng,Sperical Central Camera Support,5,[],https://github.com/colmap/colmap/pull/9,https://github.com/spriglet66,7,https://github.com/colmap/colmap/pull/9#issuecomment-353172472,,"Hi Johannes, I have a spherical camera and a lot of datasets of buildings I hope to be able to reconstruct a mesh from that I can share with you. The implementation of support for a spherical camera would be of great use to me as I currently have to work round this problem by converting the equirectangular source images into 6 seperate cube faces which essentially and unnesecarily multiplies the number of images i have to enter into colmap by 6!
What is the easiest way to share my datasets with you?
Thanks!
Ross.",True,{}
colmap/colmap,https://github.com/colmap/colmap,9,2016-05-11T08:30:42Z,,2019-05-29T23:39:34Z,OPEN,False,979,712,62,https://github.com/daleydeng,Sperical Central Camera Support,5,[],https://github.com/colmap/colmap/pull/9,https://github.com/ahojnnes,8,https://github.com/colmap/colmap/pull/9#issuecomment-353185872,,"I would just need the images along with additional parameters of the camera that you have. No need for the mesh. Maybe you can also share the 6 cube map images, so that I can compare the results. Thanks.",True,{}
colmap/colmap,https://github.com/colmap/colmap,9,2016-05-11T08:30:42Z,,2019-05-29T23:39:34Z,OPEN,False,979,712,62,https://github.com/daleydeng,Sperical Central Camera Support,5,[],https://github.com/colmap/colmap/pull/9,https://github.com/spriglet66,9,https://github.com/colmap/colmap/pull/9#issuecomment-353641844,,"Hi Johannes, Here is the link to download my dataset (unconverted to cube form). I have had good results from using the converted cubic images as input and could send a picture of the results so they can be compared against using the spherical images as input as soon as that feature is working?
https://1drv.ms/f/s!Ap7lni15eJp1h5EiqZEYYRo2ceTfpw
I will send another link to the cubic images as soon as I have organised them for you.
Thanks,
Ross.",True,{}
colmap/colmap,https://github.com/colmap/colmap,9,2016-05-11T08:30:42Z,,2019-05-29T23:39:34Z,OPEN,False,979,712,62,https://github.com/daleydeng,Sperical Central Camera Support,5,[],https://github.com/colmap/colmap/pull/9,https://github.com/ahojnnes,10,https://github.com/colmap/colmap/pull/9#issuecomment-354482894,,@spriglet66 The file does not seem to exist anymore. Could you reshare it?,True,{}
colmap/colmap,https://github.com/colmap/colmap,9,2016-05-11T08:30:42Z,,2019-05-29T23:39:34Z,OPEN,False,979,712,62,https://github.com/daleydeng,Sperical Central Camera Support,5,[],https://github.com/colmap/colmap/pull/9,https://github.com/spriglet66,11,https://github.com/colmap/colmap/pull/9#issuecomment-354483410,,"Hi sorry I've updated the link! Please let me know if you need anything else! I will send you a link to the converted cube images in the next hour!
https://1drv.ms/f/s!Ap7lni15eJp1h5EiriArFPTMI1MhmA
Thanks,
Ross.",True,{}
colmap/colmap,https://github.com/colmap/colmap,9,2016-05-11T08:30:42Z,,2019-05-29T23:39:34Z,OPEN,False,979,712,62,https://github.com/daleydeng,Sperical Central Camera Support,5,[],https://github.com/colmap/colmap/pull/9,https://github.com/ZenoWilson,12,https://github.com/colmap/colmap/pull/9#issuecomment-385204636,,I'm trying to make 3D point clouds from spherical images. Will this PR this get merged in?,True,{}
colmap/colmap,https://github.com/colmap/colmap,9,2016-05-11T08:30:42Z,,2019-05-29T23:39:34Z,OPEN,False,979,712,62,https://github.com/daleydeng,Sperical Central Camera Support,5,[],https://github.com/colmap/colmap/pull/9,https://github.com/ryanismert,13,https://github.com/colmap/colmap/pull/9#issuecomment-388260678,,"Hi @daleydeng and @ahojnnes any chance we can get this PR rebased to the head of dev? I'd love to kick the tires, and I'm happy to build my own, but my eyes start to swim trying to fix conflicts in camera_models.h, cost_functions.h, etc. :)
Better yet, actually merged?
Cheers! Ryan",True,"{'THUMBS_UP': ['https://github.com/ryanismert', 'https://github.com/oliver-batchelor', 'https://github.com/os-gabe']}"
colmap/colmap,https://github.com/colmap/colmap,9,2016-05-11T08:30:42Z,,2019-05-29T23:39:34Z,OPEN,False,979,712,62,https://github.com/daleydeng,Sperical Central Camera Support,5,[],https://github.com/colmap/colmap/pull/9,https://github.com/os-gabe,14,https://github.com/colmap/colmap/pull/9#issuecomment-497146814,,I'm also very interested in spherical camera support. Wondering what the chances of merging this are?,True,{}
colmap/colmap,https://github.com/colmap/colmap,14,2016-06-09T09:55:03Z,2016-06-09T10:03:21Z,2016-06-09T10:07:08Z,MERGED,True,1,0,1,https://github.com/soupault,Fixed list of commands for Linux installation,1,[],https://github.com/colmap/colmap/pull/14,https://github.com/soupault,1,https://github.com/colmap/colmap/pull/14,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,14,2016-06-09T09:55:03Z,2016-06-09T10:03:21Z,2016-06-09T10:07:08Z,MERGED,True,1,0,1,https://github.com/soupault,Fixed list of commands for Linux installation,1,[],https://github.com/colmap/colmap/pull/14,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/14#issuecomment-224852248,,Thanks!,True,{}
colmap/colmap,https://github.com/colmap/colmap,19,2016-07-18T15:54:11Z,2016-07-18T21:22:03Z,2016-07-18T21:27:04Z,MERGED,True,5,5,1,https://github.com/omigeot,Explicit namespace for std::isfinite(x),1,[],https://github.com/colmap/colmap/pull/19,https://github.com/omigeot,1,https://github.com/colmap/colmap/pull/19,Should fix compile problems on Ubuntu Xenial.,Should fix compile problems on Ubuntu Xenial.,True,{}
colmap/colmap,https://github.com/colmap/colmap,19,2016-07-18T15:54:11Z,2016-07-18T21:22:03Z,2016-07-18T21:27:04Z,MERGED,True,5,5,1,https://github.com/omigeot,Explicit namespace for std::isfinite(x),1,[],https://github.com/colmap/colmap/pull/19,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/19#issuecomment-233462770,Should fix compile problems on Ubuntu Xenial.,"Thanks very much for the fix. Before merging your fix, could you share on which platform this causes problems?
Thanks!",True,{}
colmap/colmap,https://github.com/colmap/colmap,19,2016-07-18T15:54:11Z,2016-07-18T21:22:03Z,2016-07-18T21:27:04Z,MERGED,True,5,5,1,https://github.com/omigeot,Explicit namespace for std::isfinite(x),1,[],https://github.com/colmap/colmap/pull/19,https://github.com/ahojnnes,3,https://github.com/colmap/colmap/pull/19#issuecomment-233462981,Should fix compile problems on Ubuntu Xenial.,"Okay, I should have read the commit message in full.",True,{}
colmap/colmap,https://github.com/colmap/colmap,19,2016-07-18T15:54:11Z,2016-07-18T21:22:03Z,2016-07-18T21:27:04Z,MERGED,True,5,5,1,https://github.com/omigeot,Explicit namespace for std::isfinite(x),1,[],https://github.com/colmap/colmap/pull/19,https://github.com/ahojnnes,4,https://github.com/colmap/colmap/pull/19#issuecomment-233464325,Should fix compile problems on Ubuntu Xenial.,"@omigeot Actually, now Clang/MSVC was complaining about a missing include. See my follow-up commit a2b5644
Thanks again for the fix!",True,{}
colmap/colmap,https://github.com/colmap/colmap,21,2016-08-09T11:28:08Z,2016-08-09T11:31:02Z,2016-08-09T11:31:02Z,MERGED,True,6,2,1,https://github.com/cbalint13,Enable BOOST in shared mode (optional).,1,[],https://github.com/colmap/colmap/pull/21,https://github.com/cbalint13,1,https://github.com/colmap/colmap/pull/21,"This little patch enables to build COLMAP with shared Boost library too without affecting current behaviour. Vast majority of distros ship shared boost library only, perhaps in future this shared mode may be considered as default.


To invoke this mode one can run:
cmake . -DBOOST_STATIC=OFF


Please notice the mandatory extra -DBOOST_TEST_DYN_LINK flag in this shared mode.","This little patch enables to build COLMAP with shared Boost library too without affecting current behaviour. Vast majority of distros ship shared boost library only, perhaps in future this shared mode may be considered as default.


To invoke this mode one can run:
cmake . -DBOOST_STATIC=OFF


Please notice the mandatory extra -DBOOST_TEST_DYN_LINK flag in this shared mode.",True,{}
colmap/colmap,https://github.com/colmap/colmap,21,2016-08-09T11:28:08Z,2016-08-09T11:31:02Z,2016-08-09T11:31:02Z,MERGED,True,6,2,1,https://github.com/cbalint13,Enable BOOST in shared mode (optional).,1,[],https://github.com/colmap/colmap/pull/21,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/21#issuecomment-238526322,"This little patch enables to build COLMAP with shared Boost library too without affecting current behaviour. Vast majority of distros ship shared boost library only, perhaps in future this shared mode may be considered as default.


To invoke this mode one can run:
cmake . -DBOOST_STATIC=OFF


Please notice the mandatory extra -DBOOST_TEST_DYN_LINK flag in this shared mode.",@cbalint13 Thanks very much for the patch!,True,{}
colmap/colmap,https://github.com/colmap/colmap,37,2016-10-04T11:32:05Z,2016-10-04T12:20:19Z,2016-10-04T12:27:27Z,MERGED,True,8,3,5,https://github.com/bjornpiltz,MSVC fixes,5,[],https://github.com/colmap/colmap/pull/37,https://github.com/bjornpiltz,1,https://github.com/colmap/colmap/pull/37,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,37,2016-10-04T11:32:05Z,2016-10-04T12:20:19Z,2016-10-04T12:27:27Z,MERGED,True,8,3,5,https://github.com/bjornpiltz,MSVC fixes,5,[],https://github.com/colmap/colmap/pull/37,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/37#issuecomment-251372519,,Thanks very much for the fixes!,True,{}
colmap/colmap,https://github.com/colmap/colmap,43,2016-10-28T11:10:38Z,2016-10-28T17:23:52Z,2018-12-30T09:24:31Z,MERGED,True,144,0,4,https://github.com/tsattler,adds functionality to align a reconstruction to a set of control points,1,[],https://github.com/colmap/colmap/pull/43,https://github.com/tsattler,1,https://github.com/colmap/colmap/pull/43,"Loads a list of image names with associated 3D coordinates and computes a similarity transform that aligns the cameras in the model with these control points. Writes out the resulting reconstruction in a directory specified by the user.
This has been tested on the Arts Quad dataset, where a reconstruction computed with Colmap was aligned with the east-north ground truth coordinates of a set of images. In order to facilitate the alignment, the y-coordinate of these ground truth points was set to 0.","Loads a list of image names with associated 3D coordinates and computes a similarity transform that aligns the cameras in the model with these control points. Writes out the resulting reconstruction in a directory specified by the user.
This has been tested on the Arts Quad dataset, where a reconstruction computed with Colmap was aligned with the east-north ground truth coordinates of a set of images. In order to facilitate the alignment, the y-coordinate of these ground truth points was set to 0.",True,{}
colmap/colmap,https://github.com/colmap/colmap,43,2016-10-28T11:10:38Z,2016-10-28T17:23:52Z,2018-12-30T09:24:31Z,MERGED,True,144,0,4,https://github.com/tsattler,adds functionality to align a reconstruction to a set of control points,1,[],https://github.com/colmap/colmap/pull/43,https://github.com/tsattler,2,https://github.com/colmap/colmap/pull/43#issuecomment-256895148,"Loads a list of image names with associated 3D coordinates and computes a similarity transform that aligns the cameras in the model with these control points. Writes out the resulting reconstruction in a directory specified by the user.
This has been tested on the Arts Quad dataset, where a reconstruction computed with Colmap was aligned with the east-north ground truth coordinates of a set of images. In order to facilitate the alignment, the y-coordinate of these ground truth points was set to 0.",@ahojnnes please take a look,True,{}
colmap/colmap,https://github.com/colmap/colmap,43,2016-10-28T11:10:38Z,2016-10-28T17:23:52Z,2018-12-30T09:24:31Z,MERGED,True,144,0,4,https://github.com/tsattler,adds functionality to align a reconstruction to a set of control points,1,[],https://github.com/colmap/colmap/pull/43,https://github.com/ahojnnes,3,https://github.com/colmap/colmap/pull/43#issuecomment-256988053,"Loads a list of image names with associated 3D coordinates and computes a similarity transform that aligns the cameras in the model with these control points. Writes out the resulting reconstruction in a directory specified by the user.
This has been tested on the Arts Quad dataset, where a reconstruction computed with Colmap was aligned with the east-north ground truth coordinates of a set of images. In order to facilitate the alignment, the y-coordinate of these ground truth points was set to 0.",@tsattler Thanks very much Torsten! Merged and changed a few minor things plus documented the functionality in the documentation.,True,{}
colmap/colmap,https://github.com/colmap/colmap,43,2016-10-28T11:10:38Z,2016-10-28T17:23:52Z,2018-12-30T09:24:31Z,MERGED,True,144,0,4,https://github.com/tsattler,adds functionality to align a reconstruction to a set of control points,1,[],https://github.com/colmap/colmap/pull/43,https://github.com/zzxp,4,https://github.com/colmap/colmap/pull/43#issuecomment-449679954,"Loads a list of image names with associated 3D coordinates and computes a similarity transform that aligns the cameras in the model with these control points. Writes out the resulting reconstruction in a directory specified by the user.
This has been tested on the Arts Quad dataset, where a reconstruction computed with Colmap was aligned with the east-north ground truth coordinates of a set of images. In order to facilitate the alignment, the y-coordinate of these ground truth points was set to 0.","@ahojnnes ,I use ""model_aligner"" to align the cameras ,I find the input is camera_position, if I have other control points(not camera_position),can I add them in?",True,{}
colmap/colmap,https://github.com/colmap/colmap,43,2016-10-28T11:10:38Z,2016-10-28T17:23:52Z,2018-12-30T09:24:31Z,MERGED,True,144,0,4,https://github.com/tsattler,adds functionality to align a reconstruction to a set of control points,1,[],https://github.com/colmap/colmap/pull/43,https://github.com/ahojnnes,5,https://github.com/colmap/colmap/pull/43#issuecomment-450548563,"Loads a list of image names with associated 3D coordinates and computes a similarity transform that aligns the cameras in the model with these control points. Writes out the resulting reconstruction in a directory specified by the user.
This has been tested on the Arts Quad dataset, where a reconstruction computed with Colmap was aligned with the east-north ground truth coordinates of a set of images. In order to facilitate the alignment, the y-coordinate of these ground truth points was set to 0.","@zzxp this is currently not possible, but should be easy to implement with a few code modifications to @tsattler’s contribution.",True,{}
colmap/colmap,https://github.com/colmap/colmap,61,2017-01-08T02:21:08Z,2017-01-08T15:31:54Z,2017-01-08T18:38:14Z,MERGED,True,21,14,2,https://github.com/cebe,added an option to build cmake without building the tests,1,[],https://github.com/colmap/colmap/pull/61,https://github.com/cebe,1,https://github.com/colmap/colmap/pull/61,"building colmap for just using it does not need the test binaries,
so here is an option to turn them off.
Not sure exactly about the default value, maybe off is better than on?","building colmap for just using it does not need the test binaries,
so here is an option to turn them off.
Not sure exactly about the default value, maybe off is better than on?",True,{}
colmap/colmap,https://github.com/colmap/colmap,61,2017-01-08T02:21:08Z,2017-01-08T15:31:54Z,2017-01-08T18:38:14Z,MERGED,True,21,14,2,https://github.com/cebe,added an option to build cmake without building the tests,1,[],https://github.com/colmap/colmap/pull/61,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/61#issuecomment-271157937,"building colmap for just using it does not need the test binaries,
so here is an option to turn them off.
Not sure exactly about the default value, maybe off is better than on?","This is a good option, thanks for the contribution!",True,{}
colmap/colmap,https://github.com/colmap/colmap,61,2017-01-08T02:21:08Z,2017-01-08T15:31:54Z,2017-01-08T18:38:14Z,MERGED,True,21,14,2,https://github.com/cebe,added an option to build cmake without building the tests,1,[],https://github.com/colmap/colmap/pull/61,https://github.com/cebe,3,https://github.com/colmap/colmap/pull/61#issuecomment-271169634,"building colmap for just using it does not need the test binaries,
so here is an option to turn them off.
Not sure exactly about the default value, maybe off is better than on?",You're welcome!,True,{}
colmap/colmap,https://github.com/colmap/colmap,88,2017-03-21T06:43:12Z,2017-03-21T07:50:15Z,2017-03-21T09:55:03Z,MERGED,True,1,1,1,https://github.com/bartoszek,Fix cmake>3.6 compilation bug,1,[],https://github.com/colmap/colmap/pull/88,https://github.com/bartoszek,1,https://github.com/colmap/colmap/pull/88,"Escaping COLMAN_VERSION string causes #53 issue.
Nvcc command line gets malformed
..we gets this
/opt/cuda/bin/nvcc -M -D__CUDACC__ /home/bartus/_src/colmap/src/ext/SiftGPU/ProgramCU.cu -o /home/bartus/_src/colmap/build-old/src/ext/SiftGPU/CMakeFiles/sift_gpu.dir//sift_gpu_generated_ProgramCU.cu.o.NVCC-depend -ccbin /usr/lib/colorgcc/bin/cc -m64 -DCOLMAP_VERSION= -D2.1\"" -DOPENMP_ENABLED -DCUDA_ENABLED -DCUDA_SIFTGPU_ENABLED -D_FORCE_INLINES\"" -Xcompiler ,\""-msse\"",\""-msse2\"",\""-msse3\"",\""-msse4.1\"",\""-msse4.2\"",\""-mavx\"",\""-Wno-maybe-uninitialized\"",\""-fopenmp\"",\""-fPIC\"",\""-march=core2\"",\""-mfpmath=sse\"",\""-DWINDOW_PREFER_GLUT\"",\""-DSIFTGPU_NO_DEVIL\"",\""-O2\"",\""-g\"",\""-DNDEBUG\"",\""-msse\"",\""-msse2\"",\""-msse3\"",\""-msse4.1\"",\""-msse4.2\"",\""-mavx\"" -gencode arch=compute_61,code=sm_61 -DNVCC -I/opt/cuda/include -I/home/bartus/_src/colmap/src/. -I/usr/include -I/usr/include/eigen3 -I/usr/include/qt -I/usr/include/qt/QtCore ""-I/usr/lib/qt/mkspecs/linux-g++ /usr/include/qt"" -I/usr/include/qt/QtOpenGL -I/usr/include/qt/QtWidgets -I/usr/include/qt/QtGui -I/usr/lib/qt/mkspecs/linux-g++
..and there should be this instead
/opt/cuda/bin/nvcc -M -D__CUDACC__ /home/bartus/_src/colmap/src/ext/SiftGPU/ProgramCU.cu -o /home/bartus/_src/colmap/build/src/ext/SiftGPU/CMakeFiles/sift_gpu.dir//sift_gpu_generated_ProgramCU.cu.o.NVCC-depend -ccbin /usr/bin/gcc-5 -m64 -DCOLMAP_VERSION=2.1 -DBOOST_TEST_DYN_LINK -DOPENMP_ENABLED -DCUDA_ENABLED -DCUDA_SIFTGPU_ENABLED -D_FORCE_INLINES -Xcompiler ,\""-msse\"",\""-msse2\"",\""-msse3\"",\""-msse4.1\"",\""-msse4.2\"",\""-mavx\"",\""-Wno-maybe-uninitialized\"",\""-fopenmp\"",\""-fPIC\"",\""-march=core2\"",\""-mfpmath=sse\"",\""-DWINDOW_PREFER_GLUT\"",\""-DSIFTGPU_NO_DEVIL\"",\""-O2\"",\""-g\"",\""-DNDEBUG\"",\""-msse\"",\""-msse2\"",\""-msse3\"",\""-msse4.1\"",\""-msse4.2\"",\""-mavx\"" -gencode arch=compute_61,code=sm_61 -DNVCC -I/opt/cuda/include -I/home/bartus/_src/colmap/src/. -I/usr/include -I/usr/include/eigen3 -I/usr/include/qt -I/usr/include/qt/QtCore ""-I/usr/lib/qt/mkspecs/linux-g++ /usr/include/qt"" -I/usr/include/qt/QtOpenGL -I/usr/include/qt/QtWidgets -I/usr/include/qt/QtGui -I/usr/lib/qt/mkspecs/linux-g++
The difference starts at -DCOLMAP_VERSION and messes up the succeeding part of invocation.
Removing the escaping fixes the issue #53","Escaping COLMAN_VERSION string causes #53 issue.
Nvcc command line gets malformed
..we gets this
/opt/cuda/bin/nvcc -M -D__CUDACC__ /home/bartus/_src/colmap/src/ext/SiftGPU/ProgramCU.cu -o /home/bartus/_src/colmap/build-old/src/ext/SiftGPU/CMakeFiles/sift_gpu.dir//sift_gpu_generated_ProgramCU.cu.o.NVCC-depend -ccbin /usr/lib/colorgcc/bin/cc -m64 -DCOLMAP_VERSION= -D2.1\"" -DOPENMP_ENABLED -DCUDA_ENABLED -DCUDA_SIFTGPU_ENABLED -D_FORCE_INLINES\"" -Xcompiler ,\""-msse\"",\""-msse2\"",\""-msse3\"",\""-msse4.1\"",\""-msse4.2\"",\""-mavx\"",\""-Wno-maybe-uninitialized\"",\""-fopenmp\"",\""-fPIC\"",\""-march=core2\"",\""-mfpmath=sse\"",\""-DWINDOW_PREFER_GLUT\"",\""-DSIFTGPU_NO_DEVIL\"",\""-O2\"",\""-g\"",\""-DNDEBUG\"",\""-msse\"",\""-msse2\"",\""-msse3\"",\""-msse4.1\"",\""-msse4.2\"",\""-mavx\"" -gencode arch=compute_61,code=sm_61 -DNVCC -I/opt/cuda/include -I/home/bartus/_src/colmap/src/. -I/usr/include -I/usr/include/eigen3 -I/usr/include/qt -I/usr/include/qt/QtCore ""-I/usr/lib/qt/mkspecs/linux-g++ /usr/include/qt"" -I/usr/include/qt/QtOpenGL -I/usr/include/qt/QtWidgets -I/usr/include/qt/QtGui -I/usr/lib/qt/mkspecs/linux-g++
..and there should be this instead
/opt/cuda/bin/nvcc -M -D__CUDACC__ /home/bartus/_src/colmap/src/ext/SiftGPU/ProgramCU.cu -o /home/bartus/_src/colmap/build/src/ext/SiftGPU/CMakeFiles/sift_gpu.dir//sift_gpu_generated_ProgramCU.cu.o.NVCC-depend -ccbin /usr/bin/gcc-5 -m64 -DCOLMAP_VERSION=2.1 -DBOOST_TEST_DYN_LINK -DOPENMP_ENABLED -DCUDA_ENABLED -DCUDA_SIFTGPU_ENABLED -D_FORCE_INLINES -Xcompiler ,\""-msse\"",\""-msse2\"",\""-msse3\"",\""-msse4.1\"",\""-msse4.2\"",\""-mavx\"",\""-Wno-maybe-uninitialized\"",\""-fopenmp\"",\""-fPIC\"",\""-march=core2\"",\""-mfpmath=sse\"",\""-DWINDOW_PREFER_GLUT\"",\""-DSIFTGPU_NO_DEVIL\"",\""-O2\"",\""-g\"",\""-DNDEBUG\"",\""-msse\"",\""-msse2\"",\""-msse3\"",\""-msse4.1\"",\""-msse4.2\"",\""-mavx\"" -gencode arch=compute_61,code=sm_61 -DNVCC -I/opt/cuda/include -I/home/bartus/_src/colmap/src/. -I/usr/include -I/usr/include/eigen3 -I/usr/include/qt -I/usr/include/qt/QtCore ""-I/usr/lib/qt/mkspecs/linux-g++ /usr/include/qt"" -I/usr/include/qt/QtOpenGL -I/usr/include/qt/QtWidgets -I/usr/include/qt/QtGui -I/usr/lib/qt/mkspecs/linux-g++
The difference starts at -DCOLMAP_VERSION and messes up the succeeding part of invocation.
Removing the escaping fixes the issue #53",True,{}
colmap/colmap,https://github.com/colmap/colmap,88,2017-03-21T06:43:12Z,2017-03-21T07:50:15Z,2017-03-21T09:55:03Z,MERGED,True,1,1,1,https://github.com/bartoszek,Fix cmake>3.6 compilation bug,1,[],https://github.com/colmap/colmap/pull/88,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/88#issuecomment-288001023,"Escaping COLMAN_VERSION string causes #53 issue.
Nvcc command line gets malformed
..we gets this
/opt/cuda/bin/nvcc -M -D__CUDACC__ /home/bartus/_src/colmap/src/ext/SiftGPU/ProgramCU.cu -o /home/bartus/_src/colmap/build-old/src/ext/SiftGPU/CMakeFiles/sift_gpu.dir//sift_gpu_generated_ProgramCU.cu.o.NVCC-depend -ccbin /usr/lib/colorgcc/bin/cc -m64 -DCOLMAP_VERSION= -D2.1\"" -DOPENMP_ENABLED -DCUDA_ENABLED -DCUDA_SIFTGPU_ENABLED -D_FORCE_INLINES\"" -Xcompiler ,\""-msse\"",\""-msse2\"",\""-msse3\"",\""-msse4.1\"",\""-msse4.2\"",\""-mavx\"",\""-Wno-maybe-uninitialized\"",\""-fopenmp\"",\""-fPIC\"",\""-march=core2\"",\""-mfpmath=sse\"",\""-DWINDOW_PREFER_GLUT\"",\""-DSIFTGPU_NO_DEVIL\"",\""-O2\"",\""-g\"",\""-DNDEBUG\"",\""-msse\"",\""-msse2\"",\""-msse3\"",\""-msse4.1\"",\""-msse4.2\"",\""-mavx\"" -gencode arch=compute_61,code=sm_61 -DNVCC -I/opt/cuda/include -I/home/bartus/_src/colmap/src/. -I/usr/include -I/usr/include/eigen3 -I/usr/include/qt -I/usr/include/qt/QtCore ""-I/usr/lib/qt/mkspecs/linux-g++ /usr/include/qt"" -I/usr/include/qt/QtOpenGL -I/usr/include/qt/QtWidgets -I/usr/include/qt/QtGui -I/usr/lib/qt/mkspecs/linux-g++
..and there should be this instead
/opt/cuda/bin/nvcc -M -D__CUDACC__ /home/bartus/_src/colmap/src/ext/SiftGPU/ProgramCU.cu -o /home/bartus/_src/colmap/build/src/ext/SiftGPU/CMakeFiles/sift_gpu.dir//sift_gpu_generated_ProgramCU.cu.o.NVCC-depend -ccbin /usr/bin/gcc-5 -m64 -DCOLMAP_VERSION=2.1 -DBOOST_TEST_DYN_LINK -DOPENMP_ENABLED -DCUDA_ENABLED -DCUDA_SIFTGPU_ENABLED -D_FORCE_INLINES -Xcompiler ,\""-msse\"",\""-msse2\"",\""-msse3\"",\""-msse4.1\"",\""-msse4.2\"",\""-mavx\"",\""-Wno-maybe-uninitialized\"",\""-fopenmp\"",\""-fPIC\"",\""-march=core2\"",\""-mfpmath=sse\"",\""-DWINDOW_PREFER_GLUT\"",\""-DSIFTGPU_NO_DEVIL\"",\""-O2\"",\""-g\"",\""-DNDEBUG\"",\""-msse\"",\""-msse2\"",\""-msse3\"",\""-msse4.1\"",\""-msse4.2\"",\""-mavx\"" -gencode arch=compute_61,code=sm_61 -DNVCC -I/opt/cuda/include -I/home/bartus/_src/colmap/src/. -I/usr/include -I/usr/include/eigen3 -I/usr/include/qt -I/usr/include/qt/QtCore ""-I/usr/lib/qt/mkspecs/linux-g++ /usr/include/qt"" -I/usr/include/qt/QtOpenGL -I/usr/include/qt/QtWidgets -I/usr/include/qt/QtGui -I/usr/lib/qt/mkspecs/linux-g++
The difference starts at -DCOLMAP_VERSION and messes up the succeeding part of invocation.
Removing the escaping fixes the issue #53","Great, thanks very much for this fix!",True,{}
colmap/colmap,https://github.com/colmap/colmap,95,2017-03-26T12:52:50Z,2017-03-30T10:59:52Z,2017-03-30T10:59:52Z,MERGED,True,11,5,4,https://github.com/bartoszek,add nvm export full path to image.,2,[],https://github.com/colmap/colmap/pull/95,https://github.com/bartoszek,1,https://github.com/colmap/colmap/pull/95,"Nvm exported file should include full image path for cameras.
Also whitespace need to be replaced with double quote character, at least this is default behavior of visual-sfm on linux system.
#92","Nvm exported file should include full image path for cameras.
Also whitespace need to be replaced with double quote character, at least this is default behavior of visual-sfm on linux system.
#92",True,{}
colmap/colmap,https://github.com/colmap/colmap,114,2017-05-02T17:41:29Z,2017-05-02T17:54:11Z,2017-05-02T17:54:11Z,MERGED,True,1,1,1,https://github.com/trueprice,Fixed minor typo in image viewer widget.,1,[],https://github.com/colmap/colmap/pull/114,https://github.com/trueprice,1,https://github.com/colmap/colmap/pull/114,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,114,2017-05-02T17:41:29Z,2017-05-02T17:54:11Z,2017-05-02T17:54:11Z,MERGED,True,1,1,1,https://github.com/trueprice,Fixed minor typo in image viewer widget.,1,[],https://github.com/colmap/colmap/pull/114,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/114#issuecomment-298711150,,Thanks True!,True,{}
colmap/colmap,https://github.com/colmap/colmap,127,2017-05-28T13:08:03Z,2017-11-21T19:19:40Z,2017-11-21T19:19:40Z,CLOSED,False,260,0,2,https://github.com/pablospe,Snap for Colmap,8,[],https://github.com/colmap/colmap/pull/127,https://github.com/pablospe,1,https://github.com/colmap/colmap/pull/127,"Currently working version (even with GPU). Compilation details:

Ubuntu 16.04.2 (almost vanilla ubuntu iso, in a virtualbox)
snap 2.24
snapcraft 2.29

Some steps are still needed in order to properly publish it to the snap store:
https://snapcraft.io/docs/build-snaps/publish
Explanation of snap, from Mark Shuttleworth:
Why we need a different container purely for apps (youtube)","Currently working version (even with GPU). Compilation details:

Ubuntu 16.04.2 (almost vanilla ubuntu iso, in a virtualbox)
snap 2.24
snapcraft 2.29

Some steps are still needed in order to properly publish it to the snap store:
https://snapcraft.io/docs/build-snaps/publish
Explanation of snap, from Mark Shuttleworth:
Why we need a different container purely for apps (youtube)",True,{}
colmap/colmap,https://github.com/colmap/colmap,127,2017-05-28T13:08:03Z,2017-11-21T19:19:40Z,2017-11-21T19:19:40Z,CLOSED,False,260,0,2,https://github.com/pablospe,Snap for Colmap,8,[],https://github.com/colmap/colmap/pull/127,https://github.com/pablospe,2,https://github.com/colmap/colmap/pull/127#issuecomment-304939552,"Currently working version (even with GPU). Compilation details:

Ubuntu 16.04.2 (almost vanilla ubuntu iso, in a virtualbox)
snap 2.24
snapcraft 2.29

Some steps are still needed in order to properly publish it to the snap store:
https://snapcraft.io/docs/build-snaps/publish
Explanation of snap, from Mark Shuttleworth:
Why we need a different container purely for apps (youtube)","Automatic buildings can be done using Travis CI, that would be awesome. Anyway it should not be too much to compile only the stable versions. Here the documentation:
https://snapcraft.io/docs/build-snaps/ci-integration
In order to specific a branch, you need to change ""source-tag: '3.0'"" to ""source-branch: <branch_name>"". But I think it make senses to leave the source-tag in the snapcraft.yaml configuration file, and to figure it out how to configure in the Travis CI side which branch should be used.
Btw, you will need to register the colmap name in the snap store, so it is reserved by you.",True,{}
colmap/colmap,https://github.com/colmap/colmap,127,2017-05-28T13:08:03Z,2017-11-21T19:19:40Z,2017-11-21T19:19:40Z,CLOSED,False,260,0,2,https://github.com/pablospe,Snap for Colmap,8,[],https://github.com/colmap/colmap/pull/127,https://github.com/pablospe,3,https://github.com/colmap/colmap/pull/127#issuecomment-304939851,"Currently working version (even with GPU). Compilation details:

Ubuntu 16.04.2 (almost vanilla ubuntu iso, in a virtualbox)
snap 2.24
snapcraft 2.29

Some steps are still needed in order to properly publish it to the snap store:
https://snapcraft.io/docs/build-snaps/publish
Explanation of snap, from Mark Shuttleworth:
Why we need a different container purely for apps (youtube)","Regarding the non-cuda version I would suggest to have to branches: snap and snap-non-cuda (or snap-cpu), and non-cuda branch only having the following two changes:

the name of the package ""colmap-non-cuda"" (or colmap-cpu);
-DCUDA_ENABLE=OFF in the cmake of the colmap parts.

In this way, you just update one branch (the 'snap' branch) and then for the non-cuda branch it is just a fast-forward merge.",True,{}
colmap/colmap,https://github.com/colmap/colmap,127,2017-05-28T13:08:03Z,2017-11-21T19:19:40Z,2017-11-21T19:19:40Z,CLOSED,False,260,0,2,https://github.com/pablospe,Snap for Colmap,8,[],https://github.com/colmap/colmap/pull/127,https://github.com/pablospe,4,https://github.com/colmap/colmap/pull/127#issuecomment-304944130,"Currently working version (even with GPU). Compilation details:

Ubuntu 16.04.2 (almost vanilla ubuntu iso, in a virtualbox)
snap 2.24
snapcraft 2.29

Some steps are still needed in order to properly publish it to the snap store:
https://snapcraft.io/docs/build-snaps/publish
Explanation of snap, from Mark Shuttleworth:
Why we need a different container purely for apps (youtube)","Forgot to say, once everything is done and working properly I would try to modify the colmap documentation in order to explain how to install it using snap. And even add a short note that snapcraft could be used for easy compilations with the command: ""snapcraft prime"", which greatly simplifies the compilation process.
In addition, I think it would be interesting to add in the compilation: gflags, google-glog and suitesparse, in the 'snapcraft.yaml' file in order to have control over the exact versions which colmap is compiled against (probably you will have less random bugs reported as issues, if you have a more controlled environment). But this complicates a bit the compilation. Anyway, it is almost done in the end of the 'snapcraft.yaml' file you have it but it has been commented out (needs more testing).",True,{}
colmap/colmap,https://github.com/colmap/colmap,127,2017-05-28T13:08:03Z,2017-11-21T19:19:40Z,2017-11-21T19:19:40Z,CLOSED,False,260,0,2,https://github.com/pablospe,Snap for Colmap,8,[],https://github.com/colmap/colmap/pull/127,https://github.com/ahojnnes,5,https://github.com/colmap/colmap/pull/127#issuecomment-346132568,"Currently working version (even with GPU). Compilation details:

Ubuntu 16.04.2 (almost vanilla ubuntu iso, in a virtualbox)
snap 2.24
snapcraft 2.29

Some steps are still needed in order to properly publish it to the snap store:
https://snapcraft.io/docs/build-snaps/publish
Explanation of snap, from Mark Shuttleworth:
Why we need a different container purely for apps (youtube)","@pablospe Thanks, with the new scripts/python/build.py it should be much easier to compile COLMAP and all its dependencies. Since snap does not support CUDA, I will close this for now. Thanks in any case :-)",True,{}
colmap/colmap,https://github.com/colmap/colmap,138,2017-06-06T12:24:35Z,2017-06-09T09:49:05Z,2017-06-09T10:00:47Z,CLOSED,False,27634,18,250,https://github.com/fedeDev,Feature/Serialization,8,[],https://github.com/colmap/colmap/pull/138,https://github.com/fedeDev,1,https://github.com/colmap/colmap/pull/138,"This PR implements serialization of several of Colmap's data types:

Point2D
Point3D
TrackElement
Track
Camera
Image
VisibilityPyramid
SceneGraph::Correspondence
SceneGraph::Image
SceneGraph
Reconstruction

They're all unit tested.
The backend itself, YAS, is also unit tested and I wrote a wrapper to make those unit tests available to Colmap's framework. YAS is aimed to be as fast as possible for i/o (as you can see on its GitHub), but it is quite inefficient regarding memory consumption (a binarized Colmap reconstruction is about 1.5x larger than a text-based one). The serialization is implemented such that we can easily swap YAS for something else such as Cereal or Boost Serialize. Take a look at Cereal, I can easily swap the backend to that one if you feel its better.
I also include two executables (textify and binarize models) that work on reconstructions.","This PR implements serialization of several of Colmap's data types:

Point2D
Point3D
TrackElement
Track
Camera
Image
VisibilityPyramid
SceneGraph::Correspondence
SceneGraph::Image
SceneGraph
Reconstruction

They're all unit tested.
The backend itself, YAS, is also unit tested and I wrote a wrapper to make those unit tests available to Colmap's framework. YAS is aimed to be as fast as possible for i/o (as you can see on its GitHub), but it is quite inefficient regarding memory consumption (a binarized Colmap reconstruction is about 1.5x larger than a text-based one). The serialization is implemented such that we can easily swap YAS for something else such as Cereal or Boost Serialize. Take a look at Cereal, I can easily swap the backend to that one if you feel its better.
I also include two executables (textify and binarize models) that work on reconstructions.",True,{}
colmap/colmap,https://github.com/colmap/colmap,138,2017-06-06T12:24:35Z,2017-06-09T09:49:05Z,2017-06-09T10:00:47Z,CLOSED,False,27634,18,250,https://github.com/fedeDev,Feature/Serialization,8,[],https://github.com/colmap/colmap/pull/138,https://github.com/fedeDev,2,https://github.com/colmap/colmap/pull/138#issuecomment-306470826,"This PR implements serialization of several of Colmap's data types:

Point2D
Point3D
TrackElement
Track
Camera
Image
VisibilityPyramid
SceneGraph::Correspondence
SceneGraph::Image
SceneGraph
Reconstruction

They're all unit tested.
The backend itself, YAS, is also unit tested and I wrote a wrapper to make those unit tests available to Colmap's framework. YAS is aimed to be as fast as possible for i/o (as you can see on its GitHub), but it is quite inefficient regarding memory consumption (a binarized Colmap reconstruction is about 1.5x larger than a text-based one). The serialization is implemented such that we can easily swap YAS for something else such as Cereal or Boost Serialize. Take a look at Cereal, I can easily swap the backend to that one if you feel its better.
I also include two executables (textify and binarize models) that work on reconstructions.","FYI, YAS is included into Colmap as a git subtree.",True,{}
colmap/colmap,https://github.com/colmap/colmap,138,2017-06-06T12:24:35Z,2017-06-09T09:49:05Z,2017-06-09T10:00:47Z,CLOSED,False,27634,18,250,https://github.com/fedeDev,Feature/Serialization,8,[],https://github.com/colmap/colmap/pull/138,https://github.com/ahojnnes,3,https://github.com/colmap/colmap/pull/138#issuecomment-307346582,"This PR implements serialization of several of Colmap's data types:

Point2D
Point3D
TrackElement
Track
Camera
Image
VisibilityPyramid
SceneGraph::Correspondence
SceneGraph::Image
SceneGraph
Reconstruction

They're all unit tested.
The backend itself, YAS, is also unit tested and I wrote a wrapper to make those unit tests available to Colmap's framework. YAS is aimed to be as fast as possible for i/o (as you can see on its GitHub), but it is quite inefficient regarding memory consumption (a binarized Colmap reconstruction is about 1.5x larger than a text-based one). The serialization is implemented such that we can easily swap YAS for something else such as Cereal or Boost Serialize. Take a look at Cereal, I can easily swap the backend to that one if you feel its better.
I also include two executables (textify and binarize models) that work on reconstructions.","Thanks Fede, I didn't want to add another huge dependency for serialization and I also compared the performance of YAS vs. my own binary file reader/writer. COLMAP now uses binary files by default for reading/writing. It should be fully backwards compatible and you can convert between the two formats using the already existing model_converter executable. Documentation about this can be found in https://colmap.github.io/format.html
Thanks again and sorry for not merging this.",True,{}
colmap/colmap,https://github.com/colmap/colmap,138,2017-06-06T12:24:35Z,2017-06-09T09:49:05Z,2017-06-09T10:00:47Z,CLOSED,False,27634,18,250,https://github.com/fedeDev,Feature/Serialization,8,[],https://github.com/colmap/colmap/pull/138,https://github.com/ahojnnes,4,https://github.com/colmap/colmap/pull/138#issuecomment-307346815,"This PR implements serialization of several of Colmap's data types:

Point2D
Point3D
TrackElement
Track
Camera
Image
VisibilityPyramid
SceneGraph::Correspondence
SceneGraph::Image
SceneGraph
Reconstruction

They're all unit tested.
The backend itself, YAS, is also unit tested and I wrote a wrapper to make those unit tests available to Colmap's framework. YAS is aimed to be as fast as possible for i/o (as you can see on its GitHub), but it is quite inefficient regarding memory consumption (a binarized Colmap reconstruction is about 1.5x larger than a text-based one). The serialization is implemented such that we can easily swap YAS for something else such as Cereal or Boost Serialize. Take a look at Cereal, I can easily swap the backend to that one if you feel its better.
I also include two executables (textify and binarize models) that work on reconstructions.","Ah, the code is only in the dev branch for now and will be merged sometime soon into master.",True,{}
colmap/colmap,https://github.com/colmap/colmap,138,2017-06-06T12:24:35Z,2017-06-09T09:49:05Z,2017-06-09T10:00:47Z,CLOSED,False,27634,18,250,https://github.com/fedeDev,Feature/Serialization,8,[],https://github.com/colmap/colmap/pull/138,https://github.com/fedeDev,5,https://github.com/colmap/colmap/pull/138#issuecomment-307349194,"This PR implements serialization of several of Colmap's data types:

Point2D
Point3D
TrackElement
Track
Camera
Image
VisibilityPyramid
SceneGraph::Correspondence
SceneGraph::Image
SceneGraph
Reconstruction

They're all unit tested.
The backend itself, YAS, is also unit tested and I wrote a wrapper to make those unit tests available to Colmap's framework. YAS is aimed to be as fast as possible for i/o (as you can see on its GitHub), but it is quite inefficient regarding memory consumption (a binarized Colmap reconstruction is about 1.5x larger than a text-based one). The serialization is implemented such that we can easily swap YAS for something else such as Cereal or Boost Serialize. Take a look at Cereal, I can easily swap the backend to that one if you feel its better.
I also include two executables (textify and binarize models) that work on reconstructions.",@ahojnnes awesome. All that matters is that I can load/write reconstruction faster now :),True,{}
colmap/colmap,https://github.com/colmap/colmap,139,2017-06-06T12:31:57Z,2017-06-06T12:38:08Z,2017-06-06T12:38:19Z,CLOSED,False,27634,18,250,https://github.com/fedeDev,Fix/Cuda Version,8,[],https://github.com/colmap/colmap/pull/139,https://github.com/fedeDev,1,https://github.com/colmap/colmap/pull/139,"The bug: If having CUDA < 7.0, Colmap's build files will try to build CUDA-enabled libriaries but Colmap uses std=c++11 with nvcc, which CUDA < 7.0 doesn't handle. This results in a compilation error if the system compiling has CUDA < 7.0.
This PR adds a bit of logic to the main CMakeLists file to detect that we have the minimum CUDA version required for colmap to build with Cuda enabled.","The bug: If having CUDA < 7.0, Colmap's build files will try to build CUDA-enabled libriaries but Colmap uses std=c++11 with nvcc, which CUDA < 7.0 doesn't handle. This results in a compilation error if the system compiling has CUDA < 7.0.
This PR adds a bit of logic to the main CMakeLists file to detect that we have the minimum CUDA version required for colmap to build with Cuda enabled.",True,{}
colmap/colmap,https://github.com/colmap/colmap,139,2017-06-06T12:31:57Z,2017-06-06T12:38:08Z,2017-06-06T12:38:19Z,CLOSED,False,27634,18,250,https://github.com/fedeDev,Fix/Cuda Version,8,[],https://github.com/colmap/colmap/pull/139,https://github.com/fedeDev,2,https://github.com/colmap/colmap/pull/139#issuecomment-306473252,"The bug: If having CUDA < 7.0, Colmap's build files will try to build CUDA-enabled libriaries but Colmap uses std=c++11 with nvcc, which CUDA < 7.0 doesn't handle. This results in a compilation error if the system compiling has CUDA < 7.0.
This PR adds a bit of logic to the main CMakeLists file to detect that we have the minimum CUDA version required for colmap to build with Cuda enabled.",I was lazy and didn't revert some commits for this branch. The result is that this PR depends on #138 being merged.,True,{}
colmap/colmap,https://github.com/colmap/colmap,140,2017-06-06T12:39:47Z,2017-06-06T13:53:37Z,2017-06-06T13:53:37Z,MERGED,True,7,2,1,https://github.com/fedeDev,Fix cuda version,1,[],https://github.com/colmap/colmap/pull/140,https://github.com/fedeDev,1,https://github.com/colmap/colmap/pull/140,"The bug: If having CUDA < 7.0, Colmap's build files will try to build CUDA-enabled libriaries but Colmap uses std=c++11 with nvcc, which CUDA < 7.0 doesn't handle. This results in a compilation error if the system compiling has CUDA < 7.0.
This PR adds a bit of logic to the main CMakeLists file to detect that we have the minimum CUDA version required for colmap to build with Cuda enabled.","The bug: If having CUDA < 7.0, Colmap's build files will try to build CUDA-enabled libriaries but Colmap uses std=c++11 with nvcc, which CUDA < 7.0 doesn't handle. This results in a compilation error if the system compiling has CUDA < 7.0.
This PR adds a bit of logic to the main CMakeLists file to detect that we have the minimum CUDA version required for colmap to build with Cuda enabled.",True,{}
colmap/colmap,https://github.com/colmap/colmap,140,2017-06-06T12:39:47Z,2017-06-06T13:53:37Z,2017-06-06T13:53:37Z,MERGED,True,7,2,1,https://github.com/fedeDev,Fix cuda version,1,[],https://github.com/colmap/colmap/pull/140,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/140#issuecomment-306492915,"The bug: If having CUDA < 7.0, Colmap's build files will try to build CUDA-enabled libriaries but Colmap uses std=c++11 with nvcc, which CUDA < 7.0 doesn't handle. This results in a compilation error if the system compiling has CUDA < 7.0.
This PR adds a bit of logic to the main CMakeLists file to detect that we have the minimum CUDA version required for colmap to build with Cuda enabled.","Looks great, thanks!",True,{}
colmap/colmap,https://github.com/colmap/colmap,141,2017-06-07T03:38:52Z,2017-07-28T06:58:06Z,2017-07-28T06:58:06Z,CLOSED,False,62,29,6,https://github.com/is03wlei,Multi-GPU support for feature extraction,8,[],https://github.com/colmap/colmap/pull/141,https://github.com/is03wlei,1,https://github.com/colmap/colmap/pull/141,"Now the logs are messy due to multi threads. I want to discuss with you how to resolve it.
Would you like to omit the details for feature extraction just like feature matching or use a string to cache logs in ImageReader.Next()?","Now the logs are messy due to multi threads. I want to discuss with you how to resolve it.
Would you like to omit the details for feature extraction just like feature matching or use a string to cache logs in ImageReader.Next()?",True,{}
colmap/colmap,https://github.com/colmap/colmap,141,2017-06-07T03:38:52Z,2017-07-28T06:58:06Z,2017-07-28T06:58:06Z,CLOSED,False,62,29,6,https://github.com/is03wlei,Multi-GPU support for feature extraction,8,[],https://github.com/colmap/colmap/pull/141,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/141#issuecomment-318576738,"Now the logs are messy due to multi threads. I want to discuss with you how to resolve it.
Would you like to omit the details for feature extraction just like feature matching or use a string to cache logs in ImageReader.Next()?","Thanks for your efforts, but I already had some existing code on my machine. I finally had some time to polish it up and committed the changes to the dev branch. Closing this. Thanks again and sorry for not including your contribution.",True,{}
colmap/colmap,https://github.com/colmap/colmap,142,2017-06-07T21:22:25Z,2017-06-07T21:24:22Z,2017-06-07T21:24:22Z,MERGED,True,1,0,1,https://github.com/queue-b,Add missing directory change to Mac build instructions.,1,[],https://github.com/colmap/colmap/pull/142,https://github.com/queue-b,1,https://github.com/colmap/colmap/pull/142,"Mac build instructions were missing
cd build
after
mkdir build
before running CMAKE","Mac build instructions were missing
cd build
after
mkdir build
before running CMAKE",True,{}
colmap/colmap,https://github.com/colmap/colmap,142,2017-06-07T21:22:25Z,2017-06-07T21:24:22Z,2017-06-07T21:24:22Z,MERGED,True,1,0,1,https://github.com/queue-b,Add missing directory change to Mac build instructions.,1,[],https://github.com/colmap/colmap/pull/142,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/142#issuecomment-306929483,"Mac build instructions were missing
cd build
after
mkdir build
before running CMAKE","Great, thanks!",True,{}
colmap/colmap,https://github.com/colmap/colmap,147,2017-06-12T08:33:47Z,2017-06-12T10:51:52Z,2017-06-12T10:51:52Z,MERGED,True,1,1,1,https://github.com/heimsi,Minor correction of input argument for *_matcher's,1,[],https://github.com/colmap/colmap/pull/147,https://github.com/heimsi,1,https://github.com/colmap/colmap/pull/147,"The documentation advises to use the option ""--use_gpu true"" or ""--use_gpu false"", but the *_matcher's have instead as input argument ""--SiftMatching.use_gpu"".","The documentation advises to use the option ""--use_gpu true"" or ""--use_gpu false"", but the *_matcher's have instead as input argument ""--SiftMatching.use_gpu"".",True,{}
colmap/colmap,https://github.com/colmap/colmap,147,2017-06-12T08:33:47Z,2017-06-12T10:51:52Z,2017-06-12T10:51:52Z,MERGED,True,1,1,1,https://github.com/heimsi,Minor correction of input argument for *_matcher's,1,[],https://github.com/colmap/colmap/pull/147,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/147#issuecomment-307756139,"The documentation advises to use the option ""--use_gpu true"" or ""--use_gpu false"", but the *_matcher's have instead as input argument ""--SiftMatching.use_gpu"".","Great, thanks for the fix!",True,{}
colmap/colmap,https://github.com/colmap/colmap,154,2017-06-15T12:13:14Z,2017-06-15T12:28:14Z,2017-06-15T12:28:19Z,MERGED,True,8,6,1,https://github.com/heimsi,Naming changed?,2,[],https://github.com/colmap/colmap/pull/154,https://github.com/heimsi,1,https://github.com/colmap/colmap/pull/154,"I think the naming of the files changed, but the documentation was not adjusted until now.","I think the naming of the files changed, but the documentation was not adjusted until now.",True,{}
colmap/colmap,https://github.com/colmap/colmap,154,2017-06-15T12:13:14Z,2017-06-15T12:28:14Z,2017-06-15T12:28:19Z,MERGED,True,8,6,1,https://github.com/heimsi,Naming changed?,2,[],https://github.com/colmap/colmap/pull/154,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/154#issuecomment-308715637,"I think the naming of the files changed, but the documentation was not adjusted until now.",Thanks.,True,{}
colmap/colmap,https://github.com/colmap/colmap,155,2017-06-15T12:43:36Z,2017-06-15T14:28:35Z,2017-06-15T14:33:26Z,MERGED,True,10,0,1,https://github.com/heimsi,Indicate possibility of dense output visualization,1,[],https://github.com/colmap/colmap/pull/155,https://github.com/heimsi,1,https://github.com/colmap/colmap/pull/155,"It was not clear to me whether COLMAP could visualize a dense reconstruction obtained via the CLI. I think it does no harm to indicate clearly that COLMAP has this feature.
Regarding the third point about mesh.ply: There I'm actually not sure if it's not possible. In the doc there is written that the surface normals cannot be visualized, but these are just a ""part"" of the dense_mesher output, right? Anyway, COLMAP in my case crashes when I try to load mesh.ply, that's why I wrote it like this.","It was not clear to me whether COLMAP could visualize a dense reconstruction obtained via the CLI. I think it does no harm to indicate clearly that COLMAP has this feature.
Regarding the third point about mesh.ply: There I'm actually not sure if it's not possible. In the doc there is written that the surface normals cannot be visualized, but these are just a ""part"" of the dense_mesher output, right? Anyway, COLMAP in my case crashes when I try to load mesh.ply, that's why I wrote it like this.",True,{}
colmap/colmap,https://github.com/colmap/colmap,155,2017-06-15T12:43:36Z,2017-06-15T14:28:35Z,2017-06-15T14:33:26Z,MERGED,True,10,0,1,https://github.com/heimsi,Indicate possibility of dense output visualization,1,[],https://github.com/colmap/colmap/pull/155,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/155#issuecomment-308751938,"It was not clear to me whether COLMAP could visualize a dense reconstruction obtained via the CLI. I think it does no harm to indicate clearly that COLMAP has this feature.
Regarding the third point about mesh.ply: There I'm actually not sure if it's not possible. In the doc there is written that the surface normals cannot be visualized, but these are just a ""part"" of the dense_mesher output, right? Anyway, COLMAP in my case crashes when I try to load mesh.ply, that's why I wrote it like this.",Thanks!,True,{}
colmap/colmap,https://github.com/colmap/colmap,197,2017-08-07T11:15:43Z,2017-08-09T07:41:15Z,2017-08-09T07:41:15Z,MERGED,True,218,23,2,https://github.com/SBCV,Python Script to Parse Colmaps Binary Model Output,1,[],https://github.com/colmap/colmap/pull/197,https://github.com/SBCV,1,https://github.com/colmap/colmap/pull/197,"Hi Johannes,
I've noticed that Colmap uses now binary model output files by default.
I've extended your python script 'read_model' to parse also Colmap's binary model output files. The new binary parsing functions return the same data structures as your text parsing functions.
I added a script to compare the binary and text parsing results generated from the same reconstruction to verify the correctness of this extension. I've tested the script with Python 2.7.13 and Python 3.5.3.
If you have any further remarks/questions/change requests let me know.
Best regards,
Sebastian","Hi Johannes,
I've noticed that Colmap uses now binary model output files by default.
I've extended your python script 'read_model' to parse also Colmap's binary model output files. The new binary parsing functions return the same data structures as your text parsing functions.
I added a script to compare the binary and text parsing results generated from the same reconstruction to verify the correctness of this extension. I've tested the script with Python 2.7.13 and Python 3.5.3.
If you have any further remarks/questions/change requests let me know.
Best regards,
Sebastian",True,{}
colmap/colmap,https://github.com/colmap/colmap,197,2017-08-07T11:15:43Z,2017-08-09T07:41:15Z,2017-08-09T07:41:15Z,MERGED,True,218,23,2,https://github.com/SBCV,Python Script to Parse Colmaps Binary Model Output,1,[],https://github.com/colmap/colmap/pull/197,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/197#issuecomment-321178939,"Hi Johannes,
I've noticed that Colmap uses now binary model output files by default.
I've extended your python script 'read_model' to parse also Colmap's binary model output files. The new binary parsing functions return the same data structures as your text parsing functions.
I added a script to compare the binary and text parsing results generated from the same reconstruction to verify the correctness of this extension. I've tested the script with Python 2.7.13 and Python 3.5.3.
If you have any further remarks/questions/change requests let me know.
Best regards,
Sebastian","This is very useful, thanks very much for the contribution! Merging this and making a few tweaks to it afterwards.",True,{}
colmap/colmap,https://github.com/colmap/colmap,215,2017-09-07T00:01:10Z,2017-09-08T08:47:58Z,2017-09-08T08:47:58Z,CLOSED,False,3,3,1,https://github.com/asmaloney,"Fix comments (""FreeImage"" -> ""Qt5"") [skip ci]",1,[],https://github.com/colmap/colmap/pull/215,https://github.com/asmaloney,1,https://github.com/colmap/colmap/pull/215,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,234,2017-10-13T17:46:38Z,2017-10-14T16:18:18Z,2017-10-15T20:46:54Z,CLOSED,False,199,37,8,None,use alpha channel to filter sift keypoints -- initial commit,1,[],https://github.com/colmap/colmap/pull/234,None,1,https://github.com/colmap/colmap/pull/234,"Adds boolean option ""use_alpha"" to the feature extractor and image reader classes.
Changes the Bitmap class to hold alpha channels.
Adds a function in feature_extraction.cc, ""RemoveKeypointsByAlpha"" which can be called in ""Sift[GPU|CPU]FeatureExtractorThread::Run()"" and removes a keypoint if the alpha channel at its coordinate is less than 255.
util/bitmap.h: Changes many loop iterators from ""int"" to ""unsigned int"" to avoid compiler warnings resulting from adding the function Bitmap::GetAlphaPixel(...)
If all this is to your liking I can improve the code a bit to handle cases where Alpha channel is requested but does not actually exist. And whatever else I've overlooked.","Adds boolean option ""use_alpha"" to the feature extractor and image reader classes.
Changes the Bitmap class to hold alpha channels.
Adds a function in feature_extraction.cc, ""RemoveKeypointsByAlpha"" which can be called in ""Sift[GPU|CPU]FeatureExtractorThread::Run()"" and removes a keypoint if the alpha channel at its coordinate is less than 255.
util/bitmap.h: Changes many loop iterators from ""int"" to ""unsigned int"" to avoid compiler warnings resulting from adding the function Bitmap::GetAlphaPixel(...)
If all this is to your liking I can improve the code a bit to handle cases where Alpha channel is requested but does not actually exist. And whatever else I've overlooked.",True,{}
colmap/colmap,https://github.com/colmap/colmap,240,2017-10-17T17:28:39Z,2017-11-21T19:01:09Z,2017-11-21T19:01:09Z,CLOSED,False,23,4,1,https://github.com/SBCV,Added support for range specification given by option timages in pmvs,1,[],https://github.com/colmap/colmap/pull/240,https://github.com/SBCV,1,https://github.com/colmap/colmap/pull/240,"Hi Johannes,
according to http://www.di.ens.fr/pmvs/documentation.html there are two possible value options for timages

Enumeration (already implemented)
Range specification (not implemented)
For instance, the latter is used by OpenMVG when exporting PMVS files.

This pull requests contains the functionality to parse range specifications.
Cheers,
Sebastian","Hi Johannes,
according to http://www.di.ens.fr/pmvs/documentation.html there are two possible value options for timages

Enumeration (already implemented)
Range specification (not implemented)
For instance, the latter is used by OpenMVG when exporting PMVS files.

This pull requests contains the functionality to parse range specifications.
Cheers,
Sebastian",True,{}
colmap/colmap,https://github.com/colmap/colmap,240,2017-10-17T17:28:39Z,2017-11-21T19:01:09Z,2017-11-21T19:01:09Z,CLOSED,False,23,4,1,https://github.com/SBCV,Added support for range specification given by option timages in pmvs,1,[],https://github.com/colmap/colmap/pull/240,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/240#issuecomment-346127334,"Hi Johannes,
according to http://www.di.ens.fr/pmvs/documentation.html there are two possible value options for timages

Enumeration (already implemented)
Range specification (not implemented)
For instance, the latter is used by OpenMVG when exporting PMVS files.

This pull requests contains the functionality to parse range specifications.
Cheers,
Sebastian","Hi Sebastion,
Thanks for the contribution. I had actually implemented this feature recently as well but did not have time to commit the changes yet due to a project deadline. The same functionality should be in the dev branch now.
Thanks again,
Johannes",True,{}
colmap/colmap,https://github.com/colmap/colmap,250,2017-11-21T14:48:00Z,2018-02-14T22:37:03Z,2018-02-14T22:37:08Z,MERGED,True,1,0,1,https://github.com/alexmyczko,Update on the README.md on binary distributions not for mac/windows,4,[],https://github.com/colmap/colmap/pull/250,https://github.com/alexmyczko,1,https://github.com/colmap/colmap/pull/250,Using links with repology and debian packaging,Using links with repology and debian packaging,True,{}
colmap/colmap,https://github.com/colmap/colmap,250,2017-11-21T14:48:00Z,2018-02-14T22:37:03Z,2018-02-14T22:37:08Z,MERGED,True,1,0,1,https://github.com/alexmyczko,Update on the README.md on binary distributions not for mac/windows,4,[],https://github.com/colmap/colmap/pull/250,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/250#issuecomment-365768247,Using links with repology and debian packaging,Thanks @alexmyczko,True,{}
colmap/colmap,https://github.com/colmap/colmap,255,2017-12-10T22:31:59Z,2017-12-11T17:09:49Z,2017-12-11T17:09:49Z,MERGED,True,1,1,1,https://github.com/puzzlepaint,Update a comment in camera_models.h,1,[],https://github.com/colmap/colmap/pull/255,https://github.com/puzzlepaint,1,https://github.com/colmap/colmap/pull/255,This updates the comment to the changes in commit f69dc87,This updates the comment to the changes in commit f69dc87,True,{}
colmap/colmap,https://github.com/colmap/colmap,256,2017-12-12T11:31:01Z,2017-12-30T04:01:14Z,2017-12-30T04:13:37Z,MERGED,True,26,0,1,https://github.com/alexmyczko,add a manual page,1,[],https://github.com/colmap/colmap/pull/256,https://github.com/alexmyczko,1,https://github.com/colmap/colmap/pull/256,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,256,2017-12-12T11:31:01Z,2017-12-30T04:01:14Z,2017-12-30T04:13:37Z,MERGED,True,26,0,1,https://github.com/alexmyczko,add a manual page,1,[],https://github.com/colmap/colmap/pull/256,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/256#issuecomment-354526186,,Thanks for the contribution. Made a few small changes.,True,{}
colmap/colmap,https://github.com/colmap/colmap,266,2018-01-05T09:13:30Z,2018-01-05T16:57:36Z,2018-01-05T16:57:37Z,MERGED,True,2,2,1,https://github.com/alexmyczko,fix typo,1,[],https://github.com/colmap/colmap/pull/266,https://github.com/alexmyczko,1,https://github.com/colmap/colmap/pull/266,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,267,2018-01-05T09:14:54Z,2018-01-05T16:57:17Z,2018-01-05T16:57:17Z,MERGED,True,1,1,1,https://github.com/alexmyczko,fix typo,1,[],https://github.com/colmap/colmap/pull/267,https://github.com/alexmyczko,1,https://github.com/colmap/colmap/pull/267,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,268,2018-01-05T09:16:06Z,2018-01-05T16:57:02Z,2018-01-05T16:57:02Z,MERGED,True,2,2,1,https://github.com/alexmyczko,fix typo,1,[],https://github.com/colmap/colmap/pull/268,https://github.com/alexmyczko,1,https://github.com/colmap/colmap/pull/268,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,269,2018-01-05T09:17:29Z,2018-01-05T16:56:47Z,2018-01-05T16:56:47Z,MERGED,True,2,2,1,https://github.com/alexmyczko,fix typos,1,[],https://github.com/colmap/colmap/pull/269,https://github.com/alexmyczko,1,https://github.com/colmap/colmap/pull/269,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,271,2018-01-07T16:50:05Z,2018-01-08T04:50:08Z,2018-01-08T14:12:06Z,MERGED,True,7,7,1,https://github.com/shinsumicco,Fix CameraModel tuples in read_model.py according to camera_models.h,1,[],https://github.com/colmap/colmap/pull/271,https://github.com/shinsumicco,1,https://github.com/colmap/colmap/pull/271,"model_name and num_params of CameraModel namedtuples in scripts/python/read_model.py had not been identical with the ones in src/base/camera_models.h, so that sparse reconstruction outputs had not been parsed correctly.
I have corrected read_model.py according to camera_models.h.","model_name and num_params of CameraModel namedtuples in scripts/python/read_model.py had not been identical with the ones in src/base/camera_models.h, so that sparse reconstruction outputs had not been parsed correctly.
I have corrected read_model.py according to camera_models.h.",True,{}
colmap/colmap,https://github.com/colmap/colmap,271,2018-01-07T16:50:05Z,2018-01-08T04:50:08Z,2018-01-08T14:12:06Z,MERGED,True,7,7,1,https://github.com/shinsumicco,Fix CameraModel tuples in read_model.py according to camera_models.h,1,[],https://github.com/colmap/colmap/pull/271,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/271#issuecomment-355883985,"model_name and num_params of CameraModel namedtuples in scripts/python/read_model.py had not been identical with the ones in src/base/camera_models.h, so that sparse reconstruction outputs had not been parsed correctly.
I have corrected read_model.py according to camera_models.h.","LGTM, thanks for the fix.",True,{}
colmap/colmap,https://github.com/colmap/colmap,275,2018-01-19T12:25:32Z,2018-01-20T07:42:49Z,2018-01-23T20:37:07Z,MERGED,True,5,0,1,https://github.com/tompollok,enable high dpi scaling for qt > 5.6.0,1,[],https://github.com/colmap/colmap/pull/275,https://github.com/tompollok,1,https://github.com/colmap/colmap/pull/275,This fix enables highdpi scaling of the qt widgets for high dpi monitors,This fix enables highdpi scaling of the qt widgets for high dpi monitors,True,{}
colmap/colmap,https://github.com/colmap/colmap,275,2018-01-19T12:25:32Z,2018-01-20T07:42:49Z,2018-01-23T20:37:07Z,MERGED,True,5,0,1,https://github.com/tompollok,enable high dpi scaling for qt > 5.6.0,1,[],https://github.com/colmap/colmap/pull/275,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/275#issuecomment-359030173,This fix enables highdpi scaling of the qt widgets for high dpi monitors,"Thanks for the contribution. Can you please make this change against the dev branch? Otherwise I can also do it.
Since I don't have a High DPI monitor, can you show the difference between the before/after? Can you also make sure that you can still double click points/cameras for selection in the viewer? Thanks!",True,{}
colmap/colmap,https://github.com/colmap/colmap,275,2018-01-19T12:25:32Z,2018-01-20T07:42:49Z,2018-01-23T20:37:07Z,MERGED,True,5,0,1,https://github.com/tompollok,enable high dpi scaling for qt > 5.6.0,1,[],https://github.com/colmap/colmap/pull/275,https://github.com/tompollok,3,https://github.com/colmap/colmap/pull/275#issuecomment-359047639,This fix enables highdpi scaling of the qt widgets for high dpi monitors,"It should be dev

Or what do you mean?
Ive got two 4K displays and with qt you have to add this extra line to make widgets appear properly. In my case all icons of your toolbar look very tiny and probabl also some labels arent rendered correctly.
This is before the patch:

Unfortunately i havent compiled the project yet on my machine. I hoped that i could download build artifacts but its not possible. Is it possible to download your precompiled 3rdparty dependency libraries somewhere? Im using the same msvc2015 64 compiler with qt 5.9",True,{}
colmap/colmap,https://github.com/colmap/colmap,275,2018-01-19T12:25:32Z,2018-01-20T07:42:49Z,2018-01-23T20:37:07Z,MERGED,True,5,0,1,https://github.com/tompollok,enable high dpi scaling for qt > 5.6.0,1,[],https://github.com/colmap/colmap/pull/275,https://github.com/ahojnnes,4,https://github.com/colmap/colmap/pull/275#issuecomment-359064875,This fix enables highdpi scaling of the qt widgets for high dpi monitors,"Ah okay, I thought you made your changes in the master instead of the dev branch. My mistake, so all is fine. Thanks for the fix. It should be very easy to compile COLMAP yourself under Windows, see https://colmap.github.io/install.html#build-script",True,{}
colmap/colmap,https://github.com/colmap/colmap,275,2018-01-19T12:25:32Z,2018-01-20T07:42:49Z,2018-01-23T20:37:07Z,MERGED,True,5,0,1,https://github.com/tompollok,enable high dpi scaling for qt > 5.6.0,1,[],https://github.com/colmap/colmap/pull/275,https://github.com/ahojnnes,5,https://github.com/colmap/colmap/pull/275#issuecomment-359153239,This fix enables highdpi scaling of the qt widgets for high dpi monitors,Thanks.,True,{}
colmap/colmap,https://github.com/colmap/colmap,275,2018-01-19T12:25:32Z,2018-01-20T07:42:49Z,2018-01-23T20:37:07Z,MERGED,True,5,0,1,https://github.com/tompollok,enable high dpi scaling for qt > 5.6.0,1,[],https://github.com/colmap/colmap/pull/275,https://github.com/tompollok,6,https://github.com/colmap/colmap/pull/275#issuecomment-359870897,This fix enables highdpi scaling of the qt widgets for high dpi monitors,"Just a follow up, the difference between HighDPI enabled and disabled on a 4K display:",True,{}
colmap/colmap,https://github.com/colmap/colmap,275,2018-01-19T12:25:32Z,2018-01-20T07:42:49Z,2018-01-23T20:37:07Z,MERGED,True,5,0,1,https://github.com/tompollok,enable high dpi scaling for qt > 5.6.0,1,[],https://github.com/colmap/colmap/pull/275,https://github.com/ahojnnes,7,https://github.com/colmap/colmap/pull/275#issuecomment-359922250,This fix enables highdpi scaling of the qt widgets for high dpi monitors,Looks much better indeed. Thanks for the PR.,True,{}
colmap/colmap,https://github.com/colmap/colmap,279,2018-01-21T23:19:15Z,2018-01-23T17:22:43Z,2018-01-23T17:22:43Z,MERGED,True,66,68,4,https://github.com/tompollok,image viewer enhancement,1,[],https://github.com/colmap/colmap/pull/279,https://github.com/tompollok,1,https://github.com/colmap/colmap/pull/279,"Enhanced image viewer that automatically expands the image over the whole available display area while keeping the same aspectratio. Also works when the image viewer is resized/maximized.
QLabel usage has been removed and instead a GraphicsView is used. This will allow to later render even the correspondences and feature points as graphicsitems instead of rendering them directly to the pixmap.
I tested it and it works really nice on my system.","Enhanced image viewer that automatically expands the image over the whole available display area while keeping the same aspectratio. Also works when the image viewer is resized/maximized.
QLabel usage has been removed and instead a GraphicsView is used. This will allow to later render even the correspondences and feature points as graphicsitems instead of rendering them directly to the pixmap.
I tested it and it works really nice on my system.",True,{}
colmap/colmap,https://github.com/colmap/colmap,279,2018-01-21T23:19:15Z,2018-01-23T17:22:43Z,2018-01-23T17:22:43Z,MERGED,True,66,68,4,https://github.com/tompollok,image viewer enhancement,1,[],https://github.com/colmap/colmap/pull/279,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/279#issuecomment-359332501,"Enhanced image viewer that automatically expands the image over the whole available display area while keeping the same aspectratio. Also works when the image viewer is resized/maximized.
QLabel usage has been removed and instead a GraphicsView is used. This will allow to later render even the correspondences and feature points as graphicsitems instead of rendering them directly to the pixmap.
I tested it and it works really nice on my system.","Looks great, left a few comments for you. Please also format all code using clang-format. Thanks!",True,{}
colmap/colmap,https://github.com/colmap/colmap,279,2018-01-21T23:19:15Z,2018-01-23T17:22:43Z,2018-01-23T17:22:43Z,MERGED,True,66,68,4,https://github.com/tompollok,image viewer enhancement,1,[],https://github.com/colmap/colmap/pull/279,https://github.com/tompollok,3,https://github.com/colmap/colmap/pull/279#issuecomment-359785687,"Enhanced image viewer that automatically expands the image over the whole available display area while keeping the same aspectratio. Also works when the image viewer is resized/maximized.
QLabel usage has been removed and instead a GraphicsView is used. This will allow to later render even the correspondences and feature points as graphicsitems instead of rendering them directly to the pixmap.
I tested it and it works really nice on my system.",PR is updated,True,{}
colmap/colmap,https://github.com/colmap/colmap,279,2018-01-21T23:19:15Z,2018-01-23T17:22:43Z,2018-01-23T17:22:43Z,MERGED,True,66,68,4,https://github.com/tompollok,image viewer enhancement,1,[],https://github.com/colmap/colmap/pull/279,https://github.com/ahojnnes,4,https://github.com/colmap/colmap/pull/279#issuecomment-359865179,"Enhanced image viewer that automatically expands the image over the whole available display area while keeping the same aspectratio. Also works when the image viewer is resized/maximized.
QLabel usage has been removed and instead a GraphicsView is used. This will allow to later render even the correspondences and feature points as graphicsitems instead of rendering them directly to the pixmap.
I tested it and it works really nice on my system.","LGTM, thanks.",True,{}
colmap/colmap,https://github.com/colmap/colmap,282,2018-01-22T21:34:47Z,,2022-01-26T12:22:15Z,OPEN,False,235,1,7,https://github.com/abhishek-carbon3d,Export SfM data to MVE format by implementing an MVEUndistorter class.,3,[],https://github.com/colmap/colmap/pull/282,https://github.com/abhishek-carbon3d,1,https://github.com/colmap/colmap/pull/282,"This is not quite working yet on my sample data. MVE is rejecting all the exported features because apparently the exported cameras don't see them.
I will appreciate if you can take a look and spot any issues.  For reference here is more info about the  mve camera model.
https://github.com/simonfuhrmann/mve/wiki/Math-Cookbook
https://github.com/simonfuhrmann/mve/wiki/MVE-File-Format","This is not quite working yet on my sample data. MVE is rejecting all the exported features because apparently the exported cameras don't see them.
I will appreciate if you can take a look and spot any issues.  For reference here is more info about the  mve camera model.
https://github.com/simonfuhrmann/mve/wiki/Math-Cookbook
https://github.com/simonfuhrmann/mve/wiki/MVE-File-Format",True,{}
colmap/colmap,https://github.com/colmap/colmap,282,2018-01-22T21:34:47Z,,2022-01-26T12:22:15Z,OPEN,False,235,1,7,https://github.com/abhishek-carbon3d,Export SfM data to MVE format by implementing an MVEUndistorter class.,3,[],https://github.com/colmap/colmap/pull/282,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/282#issuecomment-359868445,"This is not quite working yet on my sample data. MVE is rejecting all the exported features because apparently the exported cameras don't see them.
I will appreciate if you can take a look and spot any issues.  For reference here is more info about the  mve camera model.
https://github.com/simonfuhrmann/mve/wiki/Math-Cookbook
https://github.com/simonfuhrmann/mve/wiki/MVE-File-Format",I will have a look these days. Looks great on first sight though. Thanks.,True,{}
colmap/colmap,https://github.com/colmap/colmap,282,2018-01-22T21:34:47Z,,2022-01-26T12:22:15Z,OPEN,False,235,1,7,https://github.com/abhishek-carbon3d,Export SfM data to MVE format by implementing an MVEUndistorter class.,3,[],https://github.com/colmap/colmap/pull/282,https://github.com/abhishek-carbon3d,3,https://github.com/colmap/colmap/pull/282#issuecomment-361842119,"This is not quite working yet on my sample data. MVE is rejecting all the exported features because apparently the exported cameras don't see them.
I will appreciate if you can take a look and spot any issues.  For reference here is more info about the  mve camera model.
https://github.com/simonfuhrmann/mve/wiki/Math-Cookbook
https://github.com/simonfuhrmann/mve/wiki/MVE-File-Format",Anything else to be taken care of in this pull request?,True,{}
colmap/colmap,https://github.com/colmap/colmap,282,2018-01-22T21:34:47Z,,2022-01-26T12:22:15Z,OPEN,False,235,1,7,https://github.com/abhishek-carbon3d,Export SfM data to MVE format by implementing an MVEUndistorter class.,3,[],https://github.com/colmap/colmap/pull/282,https://github.com/ahojnnes,4,https://github.com/colmap/colmap/pull/282#issuecomment-361845731,"This is not quite working yet on my sample data. MVE is rejecting all the exported features because apparently the exported cameras don't see them.
I will appreciate if you can take a look and spot any issues.  For reference here is more info about the  mve camera model.
https://github.com/simonfuhrmann/mve/wiki/Math-Cookbook
https://github.com/simonfuhrmann/mve/wiki/MVE-File-Format","No, it all looks good. Just haven't had time to test it myself. Can you confirm that this works and the dense reconstruction using MVE works with this exporter?",True,{}
colmap/colmap,https://github.com/colmap/colmap,282,2018-01-22T21:34:47Z,,2022-01-26T12:22:15Z,OPEN,False,235,1,7,https://github.com/abhishek-carbon3d,Export SfM data to MVE format by implementing an MVEUndistorter class.,3,[],https://github.com/colmap/colmap/pull/282,https://github.com/abhishek-carbon3d,5,https://github.com/colmap/colmap/pull/282#issuecomment-361847933,"This is not quite working yet on my sample data. MVE is rejecting all the exported features because apparently the exported cameras don't see them.
I will appreciate if you can take a look and spot any issues.  For reference here is more info about the  mve camera model.
https://github.com/simonfuhrmann/mve/wiki/Math-Cookbook
https://github.com/simonfuhrmann/mve/wiki/MVE-File-Format","On the one sample that I tested, MVE failed to register any features, which
makes me think something is wrong in the export of the camera parameters.
…
On Tue, Jan 30, 2018 at 11:21 PM, Johannes Schönberger < ***@***.***> wrote:
 No, it all looks good. Just haven't had time to test it myself. Can you
 confirm that this works and the dense reconstruction using MVE works with
 this exporter?

 —
 You are receiving this because you authored the thread.
 Reply to this email directly, view it on GitHub
 <#282 (comment)>, or mute
 the thread
 <https://github.com/notifications/unsubscribe-auth/AJNkXhDw1FdSABo5ODBl84ObN3Yff-ugks5tQBRogaJpZM4Roq-P>
 .


-- 
-Abhishek",True,{}
colmap/colmap,https://github.com/colmap/colmap,282,2018-01-22T21:34:47Z,,2022-01-26T12:22:15Z,OPEN,False,235,1,7,https://github.com/abhishek-carbon3d,Export SfM data to MVE format by implementing an MVEUndistorter class.,3,[],https://github.com/colmap/colmap/pull/282,https://github.com/ahojnnes,6,https://github.com/colmap/colmap/pull/282#issuecomment-361848454,"This is not quite working yet on my sample data. MVE is rejecting all the exported features because apparently the exported cameras don't see them.
I will appreciate if you can take a look and spot any issues.  For reference here is more info about the  mve camera model.
https://github.com/simonfuhrmann/mve/wiki/Math-Cookbook
https://github.com/simonfuhrmann/mve/wiki/MVE-File-Format","Okay, so before merging this, we would have to resolve that issue of course. I am a little busy these days, so it will take some time for me to look into this. Maybe you can investigate a little further and fix the problem?",True,{}
colmap/colmap,https://github.com/colmap/colmap,282,2018-01-22T21:34:47Z,,2022-01-26T12:22:15Z,OPEN,False,235,1,7,https://github.com/abhishek-carbon3d,Export SfM data to MVE format by implementing an MVEUndistorter class.,3,[],https://github.com/colmap/colmap/pull/282,https://github.com/abhishek-carbon3d,7,https://github.com/colmap/colmap/pull/282#issuecomment-361848678,"This is not quite working yet on my sample data. MVE is rejecting all the exported features because apparently the exported cameras don't see them.
I will appreciate if you can take a look and spot any issues.  For reference here is more info about the  mve camera model.
https://github.com/simonfuhrmann/mve/wiki/Math-Cookbook
https://github.com/simonfuhrmann/mve/wiki/MVE-File-Format","Okay. I will dig through some more and report back.
…
On Tue, Jan 30, 2018 at 11:35 PM, Johannes Schönberger < ***@***.***> wrote:
 Okay, so before merging this, we would have to resolve that issue of
 course. I am a little busy these days, so it will take some time for me to
 look into this. Maybe you can investigate a little further and fix the
 problem?


 —
 You are receiving this because you authored the thread.
 Reply to this email directly, view it on GitHub
 <#282 (comment)>, or mute
 the thread
 <https://github.com/notifications/unsubscribe-auth/AJNkXmpm3vHHKZMbnTZvnTv1tH4uF60Kks5tQBfCgaJpZM4Roq-P>
 .


-- 
-Abhishek",True,{}
colmap/colmap,https://github.com/colmap/colmap,282,2018-01-22T21:34:47Z,,2022-01-26T12:22:15Z,OPEN,False,235,1,7,https://github.com/abhishek-carbon3d,Export SfM data to MVE format by implementing an MVEUndistorter class.,3,[],https://github.com/colmap/colmap/pull/282,https://github.com/SBCV,8,https://github.com/colmap/colmap/pull/282#issuecomment-685092631,"This is not quite working yet on my sample data. MVE is rejecting all the exported features because apparently the exported cameras don't see them.
I will appreciate if you can take a look and spot any issues.  For reference here is more info about the  mve camera model.
https://github.com/simonfuhrmann/mve/wiki/Math-Cookbook
https://github.com/simonfuhrmann/mve/wiki/MVE-File-Format","MVE allows now to import Colmap models/workspaces
See here:
simonfuhrmann/mve#514
simonfuhrmann/mve#509",True,{}
colmap/colmap,https://github.com/colmap/colmap,290,2018-01-31T01:35:48Z,2018-06-04T09:20:09Z,2018-06-04T09:20:09Z,CLOSED,False,18,0,1,https://github.com/insikk,update install documentation to support CentOS,1,[],https://github.com/colmap/colmap/pull/290,https://github.com/insikk,1,https://github.com/colmap/colmap/pull/290,"CentOS uses different names for installing dependencies. To help users easily install colmap in CentOS Linux distribution, I added install commands in documentation.
I also tested on CentOS 7 machine.","CentOS uses different names for installing dependencies. To help users easily install colmap in CentOS Linux distribution, I added install commands in documentation.
I also tested on CentOS 7 machine.",True,"{'THUMBS_UP': ['https://github.com/HustHB', 'https://github.com/snorlaxhqc'], 'HOORAY': ['https://github.com/HustHB']}"
colmap/colmap,https://github.com/colmap/colmap,298,2018-02-07T10:38:36Z,2018-02-08T17:13:10Z,2018-02-08T17:13:10Z,MERGED,True,2,2,1,https://github.com/magickenshin,fix counter matrix of effective inlier,1,[],https://github.com/colmap/colmap/pull/298,https://github.com/magickenshin,1,https://github.com/colmap/colmap/pull/298,fix counter matrix of effective inlier,fix counter matrix of effective inlier,True,{}
colmap/colmap,https://github.com/colmap/colmap,298,2018-02-07T10:38:36Z,2018-02-08T17:13:10Z,2018-02-08T17:13:10Z,MERGED,True,2,2,1,https://github.com/magickenshin,fix counter matrix of effective inlier,1,[],https://github.com/colmap/colmap/pull/298,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/298#issuecomment-364148857,fix counter matrix of effective inlier,Thanks for the fix.,True,{}
colmap/colmap,https://github.com/colmap/colmap,307,2018-02-17T19:26:16Z,2018-02-19T17:33:51Z,2018-02-19T17:33:51Z,MERGED,True,9,0,1,https://github.com/alexmyczko,Create colmap.desktop,1,[],https://github.com/colmap/colmap/pull/307,https://github.com/alexmyczko,1,https://github.com/colmap/colmap/pull/307,to be installed in /usr/share/applications for menu oriented window managers to display. you might want to provide an icon as svg or png called colmap.svg for display where supported.,to be installed in /usr/share/applications for menu oriented window managers to display. you might want to provide an icon as svg or png called colmap.svg for display where supported.,True,{}
colmap/colmap,https://github.com/colmap/colmap,310,2018-02-19T17:34:27Z,2018-02-19T17:34:45Z,2018-02-19T17:39:52Z,CLOSED,False,0,9,1,https://github.com/ahojnnes,"Revert ""Create colmap.desktop""",1,[],https://github.com/colmap/colmap/pull/310,https://github.com/ahojnnes,1,https://github.com/colmap/colmap/pull/310,Reverts #307,Reverts #307,True,{}
colmap/colmap,https://github.com/colmap/colmap,314,2018-02-25T07:56:41Z,2018-02-26T08:55:33Z,2018-02-26T08:55:33Z,MERGED,True,414,133,14,https://github.com/trueprice,1-to-1 Matching for Spatial Verification,5,[],https://github.com/colmap/colmap/pull/314,https://github.com/trueprice,1,https://github.com/colmap/colmap/pull/314,"Along with the other changes we've recently pushed, this change provides a significant increase in mAP versus pure retrieval on VGG's Oxford5k with a 200k-word vocabulary learned from Paris6k, (end-to-end in COLMAP, using upright affine features). I reverted the change of using affine feature geometry because, in the end, it didn't seem to offer too much of an improvement over the similarity feature geometry already implemented.
I've also pushed out a Python script to compute mAP from COLMAP's output (assumes VGG's label format). There are other small changes throughout, including switching the IDF weighting to use log from log1p (minor change that could be reverted), new command-line arguments for vocab tree checks and enabling verification, and an option to save the index to speed up future retrievals.","Along with the other changes we've recently pushed, this change provides a significant increase in mAP versus pure retrieval on VGG's Oxford5k with a 200k-word vocabulary learned from Paris6k, (end-to-end in COLMAP, using upright affine features). I reverted the change of using affine feature geometry because, in the end, it didn't seem to offer too much of an improvement over the similarity feature geometry already implemented.
I've also pushed out a Python script to compute mAP from COLMAP's output (assumes VGG's label format). There are other small changes throughout, including switching the IDF weighting to use log from log1p (minor change that could be reverted), new command-line arguments for vocab tree checks and enabling verification, and an option to save the index to speed up future retrievals.",True,{}
colmap/colmap,https://github.com/colmap/colmap,314,2018-02-25T07:56:41Z,2018-02-26T08:55:33Z,2018-02-26T08:55:33Z,MERGED,True,414,133,14,https://github.com/trueprice,1-to-1 Matching for Spatial Verification,5,[],https://github.com/colmap/colmap/pull/314,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/314#issuecomment-368430806,"Along with the other changes we've recently pushed, this change provides a significant increase in mAP versus pure retrieval on VGG's Oxford5k with a 200k-word vocabulary learned from Paris6k, (end-to-end in COLMAP, using upright affine features). I reverted the change of using affine feature geometry because, in the end, it didn't seem to offer too much of an improvement over the similarity feature geometry already implemented.
I've also pushed out a Python script to compute mAP from COLMAP's output (assumes VGG's label format). There are other small changes throughout, including switching the IDF weighting to use log from log1p (minor change that could be reverted), new command-line arguments for vocab tree checks and enabling verification, and an option to save the index to speed up future retrievals.","Looks great, thanks!",True,{}
colmap/colmap,https://github.com/colmap/colmap,315,2018-02-28T05:08:38Z,2018-02-28T09:16:53Z,2018-02-28T09:16:53Z,MERGED,True,31,31,6,https://github.com/trueprice,Additional minor changes for spatial verification,7,[],https://github.com/colmap/colmap/pull/315,https://github.com/trueprice,1,https://github.com/colmap/colmap/pull/315,"I realized that having a spatial verification boolean flag for matching is useless -- it will just reorder the retrieved images. So, I added in a new flag called ""num_images_after_verification"".
I also fixed a small parameter ordering bug for a function in matching.cc.","I realized that having a spatial verification boolean flag for matching is useless -- it will just reorder the retrieved images. So, I added in a new flag called ""num_images_after_verification"".
I also fixed a small parameter ordering bug for a function in matching.cc.",True,{}
colmap/colmap,https://github.com/colmap/colmap,317,2018-02-28T12:33:21Z,2019-02-03T11:40:31Z,2019-02-03T15:07:34Z,MERGED,True,306,34,4,https://github.com/DmitriyKorchemkin,FOV-based undistortion,1,[],https://github.com/colmap/colmap/pull/317,https://github.com/DmitriyKorchemkin,1,https://github.com/colmap/colmap/pull/317,"This pull request adds additional mode for undistorting, which might be used with fisheye images.
I've tried to solve the following problems:

Focal length: previously focal length was copied from original camera; for some camera models (i.e. OPENCV_FISHEYE) focal length parameters are not directly connected with focal length of undistorted camera
Valid region estimation: frequently fisheye images contain valid image data only in some circular region; moreover, model validity (i.e. monothonicity of distance-to-principal-point and angle-to-optical axis) is not guaranteed outside of this region (due to no data available during calibration)

With estimate_fov enabled, field-of-view of undistorted camera is estimated by iteratively testing monotonicity of angle-distance relationship (optionally, clamped by max_fov; and horizontal or vertical field-of-view if clip_by_hfov or clip_by_vfov are enabled).
Then, undistorted camera focal length is set to estimated diagonal field-of-view.
During inscribed/circumscribed valid region estimation, border points are clamped to maximal valid radius estimated during FOV estimation.
estimate_fov, clip_by_hfov, clip_by_vfov are disabled by default; max_fov is set to 150 degrees.","This pull request adds additional mode for undistorting, which might be used with fisheye images.
I've tried to solve the following problems:

Focal length: previously focal length was copied from original camera; for some camera models (i.e. OPENCV_FISHEYE) focal length parameters are not directly connected with focal length of undistorted camera
Valid region estimation: frequently fisheye images contain valid image data only in some circular region; moreover, model validity (i.e. monothonicity of distance-to-principal-point and angle-to-optical axis) is not guaranteed outside of this region (due to no data available during calibration)

With estimate_fov enabled, field-of-view of undistorted camera is estimated by iteratively testing monotonicity of angle-distance relationship (optionally, clamped by max_fov; and horizontal or vertical field-of-view if clip_by_hfov or clip_by_vfov are enabled).
Then, undistorted camera focal length is set to estimated diagonal field-of-view.
During inscribed/circumscribed valid region estimation, border points are clamped to maximal valid radius estimated during FOV estimation.
estimate_fov, clip_by_hfov, clip_by_vfov are disabled by default; max_fov is set to 150 degrees.",True,{}
colmap/colmap,https://github.com/colmap/colmap,317,2018-02-28T12:33:21Z,2019-02-03T11:40:31Z,2019-02-03T15:07:34Z,MERGED,True,306,34,4,https://github.com/DmitriyKorchemkin,FOV-based undistortion,1,[],https://github.com/colmap/colmap/pull/317,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/317#issuecomment-369229380,"This pull request adds additional mode for undistorting, which might be used with fisheye images.
I've tried to solve the following problems:

Focal length: previously focal length was copied from original camera; for some camera models (i.e. OPENCV_FISHEYE) focal length parameters are not directly connected with focal length of undistorted camera
Valid region estimation: frequently fisheye images contain valid image data only in some circular region; moreover, model validity (i.e. monothonicity of distance-to-principal-point and angle-to-optical axis) is not guaranteed outside of this region (due to no data available during calibration)

With estimate_fov enabled, field-of-view of undistorted camera is estimated by iteratively testing monotonicity of angle-distance relationship (optionally, clamped by max_fov; and horizontal or vertical field-of-view if clip_by_hfov or clip_by_vfov are enabled).
Then, undistorted camera focal length is set to estimated diagonal field-of-view.
During inscribed/circumscribed valid region estimation, border points are clamped to maximal valid radius estimated during FOV estimation.
estimate_fov, clip_by_hfov, clip_by_vfov are disabled by default; max_fov is set to 150 degrees.",Looks great! Could you post a few examples of the different options enabled/disabled and compared to the existing implementation? Could you also implement a few unit tests to ensure correct behavior?,True,{}
colmap/colmap,https://github.com/colmap/colmap,317,2018-02-28T12:33:21Z,2019-02-03T11:40:31Z,2019-02-03T15:07:34Z,MERGED,True,306,34,4,https://github.com/DmitriyKorchemkin,FOV-based undistortion,1,[],https://github.com/colmap/colmap/pull/317,https://github.com/DmitriyKorchemkin,3,https://github.com/colmap/colmap/pull/317#issuecomment-369592123,"This pull request adds additional mode for undistorting, which might be used with fisheye images.
I've tried to solve the following problems:

Focal length: previously focal length was copied from original camera; for some camera models (i.e. OPENCV_FISHEYE) focal length parameters are not directly connected with focal length of undistorted camera
Valid region estimation: frequently fisheye images contain valid image data only in some circular region; moreover, model validity (i.e. monothonicity of distance-to-principal-point and angle-to-optical axis) is not guaranteed outside of this region (due to no data available during calibration)

With estimate_fov enabled, field-of-view of undistorted camera is estimated by iteratively testing monotonicity of angle-distance relationship (optionally, clamped by max_fov; and horizontal or vertical field-of-view if clip_by_hfov or clip_by_vfov are enabled).
Then, undistorted camera focal length is set to estimated diagonal field-of-view.
During inscribed/circumscribed valid region estimation, border points are clamped to maximal valid radius estimated during FOV estimation.
estimate_fov, clip_by_hfov, clip_by_vfov are disabled by default; max_fov is set to 150 degrees.","I've updated pull request with tests.
Below are some examples of fisheye image undistortion [using synthetic images for simplicity of undistorted image quality guesstimation]
Source image
Fisheye-distorted image

Undistortion: default

As you can see, this image contains significantly less data than initially available
Undistortion: estimate_fov=1

FOV is estimated and clipped to ~150 degrees (since max_fov=150 by default).
This image depicts large portion if initial data, though there are some interpolation artifacts near the boundaries.
Undistortion: estimate_fov=1 and max_fov=120

FOV is estimated and clipped to ~120 degrees (since max_fov=120).
This image depicts smaller portion if initial data, but there are less interpolation artifacts near the boundaries.
Undistortion: estimate_fov=1 and clip_by_vfov=1

FOV is estimated and clipped to vertical FOV
Undistortion: estimate_fov=1, max_fov=179.9 and clip_by_hfov=1

FOV is estimated and clipped to horizontal FOV (note that we also changed max_fov to its maximal value). These settings are invalid for the image, since the whole 180 degrees of half-subspace can be mapped horizontally. Default max_fov value prevents you from getting such results.",True,{}
colmap/colmap,https://github.com/colmap/colmap,317,2018-02-28T12:33:21Z,2019-02-03T11:40:31Z,2019-02-03T15:07:34Z,MERGED,True,306,34,4,https://github.com/DmitriyKorchemkin,FOV-based undistortion,1,[],https://github.com/colmap/colmap/pull/317,https://github.com/ahojnnes,4,https://github.com/colmap/colmap/pull/317#issuecomment-369600003,"This pull request adds additional mode for undistorting, which might be used with fisheye images.
I've tried to solve the following problems:

Focal length: previously focal length was copied from original camera; for some camera models (i.e. OPENCV_FISHEYE) focal length parameters are not directly connected with focal length of undistorted camera
Valid region estimation: frequently fisheye images contain valid image data only in some circular region; moreover, model validity (i.e. monothonicity of distance-to-principal-point and angle-to-optical axis) is not guaranteed outside of this region (due to no data available during calibration)

With estimate_fov enabled, field-of-view of undistorted camera is estimated by iteratively testing monotonicity of angle-distance relationship (optionally, clamped by max_fov; and horizontal or vertical field-of-view if clip_by_hfov or clip_by_vfov are enabled).
Then, undistorted camera focal length is set to estimated diagonal field-of-view.
During inscribed/circumscribed valid region estimation, border points are clamped to maximal valid radius estimated during FOV estimation.
estimate_fov, clip_by_hfov, clip_by_vfov are disabled by default; max_fov is set to 150 degrees.","This looks great! Thanks. One final idea: I suggest to replace the current set of max_fov, clip_by_hfov, clip_by_vfov with max_horizontal_fov, max_vertical_fov. By default, both of them could be set to 180, which disables the clipping. What do you think?",True,{}
colmap/colmap,https://github.com/colmap/colmap,317,2018-02-28T12:33:21Z,2019-02-03T11:40:31Z,2019-02-03T15:07:34Z,MERGED,True,306,34,4,https://github.com/DmitriyKorchemkin,FOV-based undistortion,1,[],https://github.com/colmap/colmap/pull/317,https://github.com/DmitriyKorchemkin,5,https://github.com/colmap/colmap/pull/317#issuecomment-369613145,"This pull request adds additional mode for undistorting, which might be used with fisheye images.
I've tried to solve the following problems:

Focal length: previously focal length was copied from original camera; for some camera models (i.e. OPENCV_FISHEYE) focal length parameters are not directly connected with focal length of undistorted camera
Valid region estimation: frequently fisheye images contain valid image data only in some circular region; moreover, model validity (i.e. monothonicity of distance-to-principal-point and angle-to-optical axis) is not guaranteed outside of this region (due to no data available during calibration)

With estimate_fov enabled, field-of-view of undistorted camera is estimated by iteratively testing monotonicity of angle-distance relationship (optionally, clamped by max_fov; and horizontal or vertical field-of-view if clip_by_hfov or clip_by_vfov are enabled).
Then, undistorted camera focal length is set to estimated diagonal field-of-view.
During inscribed/circumscribed valid region estimation, border points are clamped to maximal valid radius estimated during FOV estimation.
estimate_fov, clip_by_hfov, clip_by_vfov are disabled by default; max_fov is set to 150 degrees.","Yes, my solution looks a bit confusing:

max_fov limits diagonal field-of-view by a user-specified constant
clip_by_vfov [additionally] limits diagonal field-of-view by current horizontal field-of-view
clip_by_hfov [additionally] limits diagonal field-of-view by current vertical field-of-view

I'll think how to make it more clear and update pull request",True,{}
colmap/colmap,https://github.com/colmap/colmap,317,2018-02-28T12:33:21Z,2019-02-03T11:40:31Z,2019-02-03T15:07:34Z,MERGED,True,306,34,4,https://github.com/DmitriyKorchemkin,FOV-based undistortion,1,[],https://github.com/colmap/colmap/pull/317,https://github.com/DmitriyKorchemkin,6,https://github.com/colmap/colmap/pull/317#issuecomment-369940552,"This pull request adds additional mode for undistorting, which might be used with fisheye images.
I've tried to solve the following problems:

Focal length: previously focal length was copied from original camera; for some camera models (i.e. OPENCV_FISHEYE) focal length parameters are not directly connected with focal length of undistorted camera
Valid region estimation: frequently fisheye images contain valid image data only in some circular region; moreover, model validity (i.e. monothonicity of distance-to-principal-point and angle-to-optical axis) is not guaranteed outside of this region (due to no data available during calibration)

With estimate_fov enabled, field-of-view of undistorted camera is estimated by iteratively testing monotonicity of angle-distance relationship (optionally, clamped by max_fov; and horizontal or vertical field-of-view if clip_by_hfov or clip_by_vfov are enabled).
Then, undistorted camera focal length is set to estimated diagonal field-of-view.
During inscribed/circumscribed valid region estimation, border points are clamped to maximal valid radius estimated during FOV estimation.
estimate_fov, clip_by_hfov, clip_by_vfov are disabled by default; max_fov is set to 150 degrees.","So far, I've decided to organize the process in a following way:

estimate_focal_length_from_fov (boolean) controls if focal lengths are copied or estimated from angular measurements
max_fov, max_horizontal_fov max_vertical_fov are applied independently of estimate_focal_length_from_fov, by marking pixels 'blank':

max_fov controls maximal angle w.r.t. optical axis; default value is set to 179.9 in order to eliminate almost-parallel rays
max_horizontal_fov, max_vertical_fov control  for angle between projections of ray and optical axis on a corresponding plane; default values are 180 degrees



With max_fov=179.9 by default, I am able to obtain reasonable rectification on my fisheye dataset even without enabling focal length estimation and constraining horizontal/vertical fields of view.
Tuning additional parameters allows to decrease amount of interpolation artifacts present in the rectified images.
It also seems reasonable to me to add ""forced fixed rectified camera model"" argument to rectification, should I?",True,{}
colmap/colmap,https://github.com/colmap/colmap,317,2018-02-28T12:33:21Z,2019-02-03T11:40:31Z,2019-02-03T15:07:34Z,MERGED,True,306,34,4,https://github.com/DmitriyKorchemkin,FOV-based undistortion,1,[],https://github.com/colmap/colmap/pull/317,https://github.com/ahojnnes,7,https://github.com/colmap/colmap/pull/317#issuecomment-386527526,"This pull request adds additional mode for undistorting, which might be used with fisheye images.
I've tried to solve the following problems:

Focal length: previously focal length was copied from original camera; for some camera models (i.e. OPENCV_FISHEYE) focal length parameters are not directly connected with focal length of undistorted camera
Valid region estimation: frequently fisheye images contain valid image data only in some circular region; moreover, model validity (i.e. monothonicity of distance-to-principal-point and angle-to-optical axis) is not guaranteed outside of this region (due to no data available during calibration)

With estimate_fov enabled, field-of-view of undistorted camera is estimated by iteratively testing monotonicity of angle-distance relationship (optionally, clamped by max_fov; and horizontal or vertical field-of-view if clip_by_hfov or clip_by_vfov are enabled).
Then, undistorted camera focal length is set to estimated diagonal field-of-view.
During inscribed/circumscribed valid region estimation, border points are clamped to maximal valid radius estimated during FOV estimation.
estimate_fov, clip_by_hfov, clip_by_vfov are disabled by default; max_fov is set to 150 degrees.",@DmitriyKorchemkin Sorry for not following up on this pull request. I just have not had time to look into this again. I will get in touch sometime over the next weeks again. Thanks for your patience.,True,{}
colmap/colmap,https://github.com/colmap/colmap,317,2018-02-28T12:33:21Z,2019-02-03T11:40:31Z,2019-02-03T15:07:34Z,MERGED,True,306,34,4,https://github.com/DmitriyKorchemkin,FOV-based undistortion,1,[],https://github.com/colmap/colmap/pull/317,https://github.com/DmitriyKorchemkin,8,https://github.com/colmap/colmap/pull/317#issuecomment-395131671,"This pull request adds additional mode for undistorting, which might be used with fisheye images.
I've tried to solve the following problems:

Focal length: previously focal length was copied from original camera; for some camera models (i.e. OPENCV_FISHEYE) focal length parameters are not directly connected with focal length of undistorted camera
Valid region estimation: frequently fisheye images contain valid image data only in some circular region; moreover, model validity (i.e. monothonicity of distance-to-principal-point and angle-to-optical axis) is not guaranteed outside of this region (due to no data available during calibration)

With estimate_fov enabled, field-of-view of undistorted camera is estimated by iteratively testing monotonicity of angle-distance relationship (optionally, clamped by max_fov; and horizontal or vertical field-of-view if clip_by_hfov or clip_by_vfov are enabled).
Then, undistorted camera focal length is set to estimated diagonal field-of-view.
During inscribed/circumscribed valid region estimation, border points are clamped to maximal valid radius estimated during FOV estimation.
estimate_fov, clip_by_hfov, clip_by_vfov are disabled by default; max_fov is set to 150 degrees.","@ahojnnes should I update my pull request in order to resolve these conflicts, or this feature makes too little sense?
Thanks",True,{}
colmap/colmap,https://github.com/colmap/colmap,317,2018-02-28T12:33:21Z,2019-02-03T11:40:31Z,2019-02-03T15:07:34Z,MERGED,True,306,34,4,https://github.com/DmitriyKorchemkin,FOV-based undistortion,1,[],https://github.com/colmap/colmap/pull/317,https://github.com/ahojnnes,9,https://github.com/colmap/colmap/pull/317#issuecomment-395155685,"This pull request adds additional mode for undistorting, which might be used with fisheye images.
I've tried to solve the following problems:

Focal length: previously focal length was copied from original camera; for some camera models (i.e. OPENCV_FISHEYE) focal length parameters are not directly connected with focal length of undistorted camera
Valid region estimation: frequently fisheye images contain valid image data only in some circular region; moreover, model validity (i.e. monothonicity of distance-to-principal-point and angle-to-optical axis) is not guaranteed outside of this region (due to no data available during calibration)

With estimate_fov enabled, field-of-view of undistorted camera is estimated by iteratively testing monotonicity of angle-distance relationship (optionally, clamped by max_fov; and horizontal or vertical field-of-view if clip_by_hfov or clip_by_vfov are enabled).
Then, undistorted camera focal length is set to estimated diagonal field-of-view.
During inscribed/circumscribed valid region estimation, border points are clamped to maximal valid radius estimated during FOV estimation.
estimate_fov, clip_by_hfov, clip_by_vfov are disabled by default; max_fov is set to 150 degrees.","I think, this would be a very useful feature. If you have time, it would be great if you could rebase the pull request. Thanks!",True,{}
colmap/colmap,https://github.com/colmap/colmap,317,2018-02-28T12:33:21Z,2019-02-03T11:40:31Z,2019-02-03T15:07:34Z,MERGED,True,306,34,4,https://github.com/DmitriyKorchemkin,FOV-based undistortion,1,[],https://github.com/colmap/colmap/pull/317,https://github.com/ahojnnes,10,https://github.com/colmap/colmap/pull/317#issuecomment-405170259,"This pull request adds additional mode for undistorting, which might be used with fisheye images.
I've tried to solve the following problems:

Focal length: previously focal length was copied from original camera; for some camera models (i.e. OPENCV_FISHEYE) focal length parameters are not directly connected with focal length of undistorted camera
Valid region estimation: frequently fisheye images contain valid image data only in some circular region; moreover, model validity (i.e. monothonicity of distance-to-principal-point and angle-to-optical axis) is not guaranteed outside of this region (due to no data available during calibration)

With estimate_fov enabled, field-of-view of undistorted camera is estimated by iteratively testing monotonicity of angle-distance relationship (optionally, clamped by max_fov; and horizontal or vertical field-of-view if clip_by_hfov or clip_by_vfov are enabled).
Then, undistorted camera focal length is set to estimated diagonal field-of-view.
During inscribed/circumscribed valid region estimation, border points are clamped to maximal valid radius estimated during FOV estimation.
estimate_fov, clip_by_hfov, clip_by_vfov are disabled by default; max_fov is set to 150 degrees.","@DmitriyKorchemkin Did you have time to revisit this? I think, this would be a very useful feature!",True,{}
colmap/colmap,https://github.com/colmap/colmap,317,2018-02-28T12:33:21Z,2019-02-03T11:40:31Z,2019-02-03T15:07:34Z,MERGED,True,306,34,4,https://github.com/DmitriyKorchemkin,FOV-based undistortion,1,[],https://github.com/colmap/colmap/pull/317,https://github.com/DmitriyKorchemkin,11,https://github.com/colmap/colmap/pull/317#issuecomment-406295752,"This pull request adds additional mode for undistorting, which might be used with fisheye images.
I've tried to solve the following problems:

Focal length: previously focal length was copied from original camera; for some camera models (i.e. OPENCV_FISHEYE) focal length parameters are not directly connected with focal length of undistorted camera
Valid region estimation: frequently fisheye images contain valid image data only in some circular region; moreover, model validity (i.e. monothonicity of distance-to-principal-point and angle-to-optical axis) is not guaranteed outside of this region (due to no data available during calibration)

With estimate_fov enabled, field-of-view of undistorted camera is estimated by iteratively testing monotonicity of angle-distance relationship (optionally, clamped by max_fov; and horizontal or vertical field-of-view if clip_by_hfov or clip_by_vfov are enabled).
Then, undistorted camera focal length is set to estimated diagonal field-of-view.
During inscribed/circumscribed valid region estimation, border points are clamped to maximal valid radius estimated during FOV estimation.
estimate_fov, clip_by_hfov, clip_by_vfov are disabled by default; max_fov is set to 150 degrees.",@ahojnnes  I'll rebase this to current dev branch at the beginning of August.,True,{}
colmap/colmap,https://github.com/colmap/colmap,317,2018-02-28T12:33:21Z,2019-02-03T11:40:31Z,2019-02-03T15:07:34Z,MERGED,True,306,34,4,https://github.com/DmitriyKorchemkin,FOV-based undistortion,1,[],https://github.com/colmap/colmap/pull/317,https://github.com/ahojnnes,12,https://github.com/colmap/colmap/pull/317#issuecomment-406366137,"This pull request adds additional mode for undistorting, which might be used with fisheye images.
I've tried to solve the following problems:

Focal length: previously focal length was copied from original camera; for some camera models (i.e. OPENCV_FISHEYE) focal length parameters are not directly connected with focal length of undistorted camera
Valid region estimation: frequently fisheye images contain valid image data only in some circular region; moreover, model validity (i.e. monothonicity of distance-to-principal-point and angle-to-optical axis) is not guaranteed outside of this region (due to no data available during calibration)

With estimate_fov enabled, field-of-view of undistorted camera is estimated by iteratively testing monotonicity of angle-distance relationship (optionally, clamped by max_fov; and horizontal or vertical field-of-view if clip_by_hfov or clip_by_vfov are enabled).
Then, undistorted camera focal length is set to estimated diagonal field-of-view.
During inscribed/circumscribed valid region estimation, border points are clamped to maximal valid radius estimated during FOV estimation.
estimate_fov, clip_by_hfov, clip_by_vfov are disabled by default; max_fov is set to 150 degrees.","Sounds great, thanks!",True,{}
colmap/colmap,https://github.com/colmap/colmap,317,2018-02-28T12:33:21Z,2019-02-03T11:40:31Z,2019-02-03T15:07:34Z,MERGED,True,306,34,4,https://github.com/DmitriyKorchemkin,FOV-based undistortion,1,[],https://github.com/colmap/colmap/pull/317,https://github.com/DmitriyKorchemkin,13,https://github.com/colmap/colmap/pull/317#issuecomment-414991381,"This pull request adds additional mode for undistorting, which might be used with fisheye images.
I've tried to solve the following problems:

Focal length: previously focal length was copied from original camera; for some camera models (i.e. OPENCV_FISHEYE) focal length parameters are not directly connected with focal length of undistorted camera
Valid region estimation: frequently fisheye images contain valid image data only in some circular region; moreover, model validity (i.e. monothonicity of distance-to-principal-point and angle-to-optical axis) is not guaranteed outside of this region (due to no data available during calibration)

With estimate_fov enabled, field-of-view of undistorted camera is estimated by iteratively testing monotonicity of angle-distance relationship (optionally, clamped by max_fov; and horizontal or vertical field-of-view if clip_by_hfov or clip_by_vfov are enabled).
Then, undistorted camera focal length is set to estimated diagonal field-of-view.
During inscribed/circumscribed valid region estimation, border points are clamped to maximal valid radius estimated during FOV estimation.
estimate_fov, clip_by_hfov, clip_by_vfov are disabled by default; max_fov is set to 150 degrees.","@ahojnnes What is the correct way to combine these changes with ones from #362 (rectangular ROI selection): should we estimate field of view of the whole source model, or only of selected ROI?
Should I also add new options to undistortion_widget.cc?",True,{}
colmap/colmap,https://github.com/colmap/colmap,317,2018-02-28T12:33:21Z,2019-02-03T11:40:31Z,2019-02-03T15:07:34Z,MERGED,True,306,34,4,https://github.com/DmitriyKorchemkin,FOV-based undistortion,1,[],https://github.com/colmap/colmap/pull/317,https://github.com/ahojnnes,14,https://github.com/colmap/colmap/pull/317#issuecomment-415097844,"This pull request adds additional mode for undistorting, which might be used with fisheye images.
I've tried to solve the following problems:

Focal length: previously focal length was copied from original camera; for some camera models (i.e. OPENCV_FISHEYE) focal length parameters are not directly connected with focal length of undistorted camera
Valid region estimation: frequently fisheye images contain valid image data only in some circular region; moreover, model validity (i.e. monothonicity of distance-to-principal-point and angle-to-optical axis) is not guaranteed outside of this region (due to no data available during calibration)

With estimate_fov enabled, field-of-view of undistorted camera is estimated by iteratively testing monotonicity of angle-distance relationship (optionally, clamped by max_fov; and horizontal or vertical field-of-view if clip_by_hfov or clip_by_vfov are enabled).
Then, undistorted camera focal length is set to estimated diagonal field-of-view.
During inscribed/circumscribed valid region estimation, border points are clamped to maximal valid radius estimated during FOV estimation.
estimate_fov, clip_by_hfov, clip_by_vfov are disabled by default; max_fov is set to 150 degrees.","I guess, field of view of whole model and then cropping. What do you think?",True,{}
colmap/colmap,https://github.com/colmap/colmap,317,2018-02-28T12:33:21Z,2019-02-03T11:40:31Z,2019-02-03T15:07:34Z,MERGED,True,306,34,4,https://github.com/DmitriyKorchemkin,FOV-based undistortion,1,[],https://github.com/colmap/colmap/pull/317,https://github.com/ahojnnes,15,https://github.com/colmap/colmap/pull/317#issuecomment-415098005,"This pull request adds additional mode for undistorting, which might be used with fisheye images.
I've tried to solve the following problems:

Focal length: previously focal length was copied from original camera; for some camera models (i.e. OPENCV_FISHEYE) focal length parameters are not directly connected with focal length of undistorted camera
Valid region estimation: frequently fisheye images contain valid image data only in some circular region; moreover, model validity (i.e. monothonicity of distance-to-principal-point and angle-to-optical axis) is not guaranteed outside of this region (due to no data available during calibration)

With estimate_fov enabled, field-of-view of undistorted camera is estimated by iteratively testing monotonicity of angle-distance relationship (optionally, clamped by max_fov; and horizontal or vertical field-of-view if clip_by_hfov or clip_by_vfov are enabled).
Then, undistorted camera focal length is set to estimated diagonal field-of-view.
During inscribed/circumscribed valid region estimation, border points are clamped to maximal valid radius estimated during FOV estimation.
estimate_fov, clip_by_hfov, clip_by_vfov are disabled by default; max_fov is set to 150 degrees.",Please also update the undistortion widget and the command line interface with the new options. Thanks!,True,{}
colmap/colmap,https://github.com/colmap/colmap,317,2018-02-28T12:33:21Z,2019-02-03T11:40:31Z,2019-02-03T15:07:34Z,MERGED,True,306,34,4,https://github.com/DmitriyKorchemkin,FOV-based undistortion,1,[],https://github.com/colmap/colmap/pull/317,https://github.com/ahojnnes,16,https://github.com/colmap/colmap/pull/317#issuecomment-460044262,"This pull request adds additional mode for undistorting, which might be used with fisheye images.
I've tried to solve the following problems:

Focal length: previously focal length was copied from original camera; for some camera models (i.e. OPENCV_FISHEYE) focal length parameters are not directly connected with focal length of undistorted camera
Valid region estimation: frequently fisheye images contain valid image data only in some circular region; moreover, model validity (i.e. monothonicity of distance-to-principal-point and angle-to-optical axis) is not guaranteed outside of this region (due to no data available during calibration)

With estimate_fov enabled, field-of-view of undistorted camera is estimated by iteratively testing monotonicity of angle-distance relationship (optionally, clamped by max_fov; and horizontal or vertical field-of-view if clip_by_hfov or clip_by_vfov are enabled).
Then, undistorted camera focal length is set to estimated diagonal field-of-view.
During inscribed/circumscribed valid region estimation, border points are clamped to maximal valid radius estimated during FOV estimation.
estimate_fov, clip_by_hfov, clip_by_vfov are disabled by default; max_fov is set to 150 degrees.","Thanks, finally had time to merge this. I made a few changes to get this integrated with the other PR that enabled ROI in the undistortion. If you have time, it would be great if you could verify those changes. Thanks!",True,{}
colmap/colmap,https://github.com/colmap/colmap,317,2018-02-28T12:33:21Z,2019-02-03T11:40:31Z,2019-02-03T15:07:34Z,MERGED,True,306,34,4,https://github.com/DmitriyKorchemkin,FOV-based undistortion,1,[],https://github.com/colmap/colmap/pull/317,https://github.com/ahojnnes,17,https://github.com/colmap/colmap/pull/317#issuecomment-460044268,"This pull request adds additional mode for undistorting, which might be used with fisheye images.
I've tried to solve the following problems:

Focal length: previously focal length was copied from original camera; for some camera models (i.e. OPENCV_FISHEYE) focal length parameters are not directly connected with focal length of undistorted camera
Valid region estimation: frequently fisheye images contain valid image data only in some circular region; moreover, model validity (i.e. monothonicity of distance-to-principal-point and angle-to-optical axis) is not guaranteed outside of this region (due to no data available during calibration)

With estimate_fov enabled, field-of-view of undistorted camera is estimated by iteratively testing monotonicity of angle-distance relationship (optionally, clamped by max_fov; and horizontal or vertical field-of-view if clip_by_hfov or clip_by_vfov are enabled).
Then, undistorted camera focal length is set to estimated diagonal field-of-view.
During inscribed/circumscribed valid region estimation, border points are clamped to maximal valid radius estimated during FOV estimation.
estimate_fov, clip_by_hfov, clip_by_vfov are disabled by default; max_fov is set to 150 degrees.",@DmitriyKorchemkin,True,{}
colmap/colmap,https://github.com/colmap/colmap,317,2018-02-28T12:33:21Z,2019-02-03T11:40:31Z,2019-02-03T15:07:34Z,MERGED,True,306,34,4,https://github.com/DmitriyKorchemkin,FOV-based undistortion,1,[],https://github.com/colmap/colmap/pull/317,https://github.com/ahojnnes,18,https://github.com/colmap/colmap/pull/317#issuecomment-460059638,"This pull request adds additional mode for undistorting, which might be used with fisheye images.
I've tried to solve the following problems:

Focal length: previously focal length was copied from original camera; for some camera models (i.e. OPENCV_FISHEYE) focal length parameters are not directly connected with focal length of undistorted camera
Valid region estimation: frequently fisheye images contain valid image data only in some circular region; moreover, model validity (i.e. monothonicity of distance-to-principal-point and angle-to-optical axis) is not guaranteed outside of this region (due to no data available during calibration)

With estimate_fov enabled, field-of-view of undistorted camera is estimated by iteratively testing monotonicity of angle-distance relationship (optionally, clamped by max_fov; and horizontal or vertical field-of-view if clip_by_hfov or clip_by_vfov are enabled).
Then, undistorted camera focal length is set to estimated diagonal field-of-view.
During inscribed/circumscribed valid region estimation, border points are clamped to maximal valid radius estimated during FOV estimation.
estimate_fov, clip_by_hfov, clip_by_vfov are disabled by default; max_fov is set to 150 degrees.","@DmitriyKorchemkin There seems to be a bug in the unit tests in TestUndistortFOVEstimation. The tests are passing, even though the values are not matching (expected vs undistorted focal lengths). Could you please double check and fix the issues?",True,{}
colmap/colmap,https://github.com/colmap/colmap,348,2018-04-16T01:19:57Z,2018-04-16T07:43:09Z,2018-04-16T07:43:09Z,MERGED,True,48,197,9,https://github.com/jbeich,Unbreak packaging on BSD and non-x86_64,6,[],https://github.com/colmap/colmap/pull/348,https://github.com/jbeich,1,https://github.com/colmap/colmap/pull/348,"cmake/CheckSSEExtensions.cmake magic can be replaced by export CFLAGS=""-march=native"" CXXFLAGS=""-march=native""
PBA defaults to SSE2 even with -mno-sse or on non-x86, see also #890106
VLfeat wants only specific files built with -mavx or -msse2

Tested on FreeBSD downstream: 10.3 amd64, 10.3 i386, 10.4 amd64, 10.4 i386, 11.1 aarch64, 11.1 amd64, 11.1 armv6, 11.1 i386, 12.0 aarch64, 12.0 amd64, 12.0 armv6, 12.0 armv7","cmake/CheckSSEExtensions.cmake magic can be replaced by export CFLAGS=""-march=native"" CXXFLAGS=""-march=native""
PBA defaults to SSE2 even with -mno-sse or on non-x86, see also #890106
VLfeat wants only specific files built with -mavx or -msse2

Tested on FreeBSD downstream: 10.3 amd64, 10.3 i386, 10.4 amd64, 10.4 i386, 11.1 aarch64, 11.1 amd64, 11.1 armv6, 11.1 i386, 12.0 aarch64, 12.0 amd64, 12.0 armv6, 12.0 armv7",True,{}
colmap/colmap,https://github.com/colmap/colmap,348,2018-04-16T01:19:57Z,2018-04-16T07:43:09Z,2018-04-16T07:43:09Z,MERGED,True,48,197,9,https://github.com/jbeich,Unbreak packaging on BSD and non-x86_64,6,[],https://github.com/colmap/colmap/pull/348,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/348#issuecomment-381508644,"cmake/CheckSSEExtensions.cmake magic can be replaced by export CFLAGS=""-march=native"" CXXFLAGS=""-march=native""
PBA defaults to SSE2 even with -mno-sse or on non-x86, see also #890106
VLfeat wants only specific files built with -mavx or -msse2

Tested on FreeBSD downstream: 10.3 amd64, 10.3 i386, 10.4 amd64, 10.4 i386, 11.1 aarch64, 11.1 amd64, 11.1 armv6, 11.1 i386, 12.0 aarch64, 12.0 amd64, 12.0 armv6, 12.0 armv7",Fantastic! Thanks very much.,True,{}
colmap/colmap,https://github.com/colmap/colmap,357,2018-05-03T05:39:44Z,2018-05-03T10:55:50Z,2019-04-03T09:39:31Z,CLOSED,False,1638,777,60,https://github.com/dadung,colmap gui is unable to run on Ubuntu 16.04,59,[],https://github.com/colmap/colmap/pull/357,https://github.com/dadung,1,https://github.com/colmap/colmap/pull/357,"Hello, thank you very much for the amazing SfM tool.
I have installed from source in my machine running Ubuntu 16.04. Everything went very well, then I run ""colmap gui"" and it shows the errors as bellow:
QOpenGLWidget: Failed to create context
QOpenGLWidget: Failed to create context
composeAndFlush: makeCurrent() failed
composeAndFlush: makeCurrent() failed
composeAndFlush: makeCurrent() failed
I attach my cmake configuration here. Can you please help me to resolve the problem? Thank you","Hello, thank you very much for the amazing SfM tool.
I have installed from source in my machine running Ubuntu 16.04. Everything went very well, then I run ""colmap gui"" and it shows the errors as bellow:
QOpenGLWidget: Failed to create context
QOpenGLWidget: Failed to create context
composeAndFlush: makeCurrent() failed
composeAndFlush: makeCurrent() failed
composeAndFlush: makeCurrent() failed
I attach my cmake configuration here. Can you please help me to resolve the problem? Thank you",True,{}
colmap/colmap,https://github.com/colmap/colmap,357,2018-05-03T05:39:44Z,2018-05-03T10:55:50Z,2019-04-03T09:39:31Z,CLOSED,False,1638,777,60,https://github.com/dadung,colmap gui is unable to run on Ubuntu 16.04,59,[],https://github.com/colmap/colmap/pull/357,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/357#issuecomment-386207417,"Hello, thank you very much for the amazing SfM tool.
I have installed from source in my machine running Ubuntu 16.04. Everything went very well, then I run ""colmap gui"" and it shows the errors as bellow:
QOpenGLWidget: Failed to create context
QOpenGLWidget: Failed to create context
composeAndFlush: makeCurrent() failed
composeAndFlush: makeCurrent() failed
composeAndFlush: makeCurrent() failed
I attach my cmake configuration here. Can you please help me to resolve the problem? Thank you","I guess, this shouldn’t be a pull request. I assume, you don’t have a dedicated GPU in your system?",True,{'LAUGH': ['https://github.com/dadung']}
colmap/colmap,https://github.com/colmap/colmap,357,2018-05-03T05:39:44Z,2018-05-03T10:55:50Z,2019-04-03T09:39:31Z,CLOSED,False,1638,777,60,https://github.com/dadung,colmap gui is unable to run on Ubuntu 16.04,59,[],https://github.com/colmap/colmap/pull/357,https://github.com/dadung,3,https://github.com/colmap/colmap/pull/357#issuecomment-386252364,"Hello, thank you very much for the amazing SfM tool.
I have installed from source in my machine running Ubuntu 16.04. Everything went very well, then I run ""colmap gui"" and it shows the errors as bellow:
QOpenGLWidget: Failed to create context
QOpenGLWidget: Failed to create context
composeAndFlush: makeCurrent() failed
composeAndFlush: makeCurrent() failed
composeAndFlush: makeCurrent() failed
I attach my cmake configuration here. Can you please help me to resolve the problem? Thank you","Hi, you are right! I reinstall NVIDIA driver and CUDA and then reinstall COLMAP, it works now.
Thank you for your help",True,{}
colmap/colmap,https://github.com/colmap/colmap,357,2018-05-03T05:39:44Z,2018-05-03T10:55:50Z,2019-04-03T09:39:31Z,CLOSED,False,1638,777,60,https://github.com/dadung,colmap gui is unable to run on Ubuntu 16.04,59,[],https://github.com/colmap/colmap/pull/357,https://github.com/jsYangCode,4,https://github.com/colmap/colmap/pull/357#issuecomment-479416421,"Hello, thank you very much for the amazing SfM tool.
I have installed from source in my machine running Ubuntu 16.04. Everything went very well, then I run ""colmap gui"" and it shows the errors as bellow:
QOpenGLWidget: Failed to create context
QOpenGLWidget: Failed to create context
composeAndFlush: makeCurrent() failed
composeAndFlush: makeCurrent() failed
composeAndFlush: makeCurrent() failed
I attach my cmake configuration here. Can you please help me to resolve the problem? Thank you","@dadung @ahojnnes  hello, friends! i am facing the same problem， after install the NVIDIA(GeForce-1050Ti) driver and CUDA 8.0. The colmap gui does not work, as follow.  before installation, it works well. would you please give me some advice ???  thank you very much !!!",True,{}
colmap/colmap,https://github.com/colmap/colmap,362,2018-05-09T06:08:15Z,2018-06-04T06:54:58Z,2018-06-04T06:54:58Z,MERGED,True,74,19,4,https://github.com/XieDufang,Add rectangular ROI for undistortion,6,[],https://github.com/colmap/colmap/pull/362,https://github.com/XieDufang,1,https://github.com/colmap/colmap/pull/362,"Hello Johannes,
I have some datasets captured by cameras mounted on a vehicle.
After SfM, only the bottom half image (mostly road area) is needed, since I want to generate dense clouds of road surface.
Therefore I added rectangular ROI for undistortion. Hope it's helpful in different applications.
Mit freundlichen Gruessen！
Xie Dufang","Hello Johannes,
I have some datasets captured by cameras mounted on a vehicle.
After SfM, only the bottom half image (mostly road area) is needed, since I want to generate dense clouds of road surface.
Therefore I added rectangular ROI for undistortion. Hope it's helpful in different applications.
Mit freundlichen Gruessen！
Xie Dufang",True,{'THUMBS_UP': ['https://github.com/gerardobort']}
colmap/colmap,https://github.com/colmap/colmap,362,2018-05-09T06:08:15Z,2018-06-04T06:54:58Z,2018-06-04T06:54:58Z,MERGED,True,74,19,4,https://github.com/XieDufang,Add rectangular ROI for undistortion,6,[],https://github.com/colmap/colmap/pull/362,https://github.com/XieDufang,2,https://github.com/colmap/colmap/pull/362#issuecomment-387632364,"Hello Johannes,
I have some datasets captured by cameras mounted on a vehicle.
After SfM, only the bottom half image (mostly road area) is needed, since I want to generate dense clouds of road surface.
Therefore I added rectangular ROI for undistortion. Hope it's helpful in different applications.
Mit freundlichen Gruessen！
Xie Dufang","Example usage for bottom half image:
colmap image_undistorter \
--image_path $DATASET_PATH/images \
--input_path $DATASET_PATH/sparse \
--output_path $DATASET_PATH/dense \
--roi_min_y 0.5 \
--roi_max_y 1.0",True,{}
colmap/colmap,https://github.com/colmap/colmap,362,2018-05-09T06:08:15Z,2018-06-04T06:54:58Z,2018-06-04T06:54:58Z,MERGED,True,74,19,4,https://github.com/XieDufang,Add rectangular ROI for undistortion,6,[],https://github.com/colmap/colmap/pull/362,https://github.com/XieDufang,3,https://github.com/colmap/colmap/pull/362#issuecomment-392420188,"Hello Johannes,
I have some datasets captured by cameras mounted on a vehicle.
After SfM, only the bottom half image (mostly road area) is needed, since I want to generate dense clouds of road surface.
Therefore I added rectangular ROI for undistortion. Hope it's helpful in different applications.
Mit freundlichen Gruessen！
Xie Dufang","@ahojnnes
Extra ""roi"" parameter has been removed.
The roi is enabled if min/max bounding box coordinates are greater/less than 0/1.",True,{}
colmap/colmap,https://github.com/colmap/colmap,362,2018-05-09T06:08:15Z,2018-06-04T06:54:58Z,2018-06-04T06:54:58Z,MERGED,True,74,19,4,https://github.com/XieDufang,Add rectangular ROI for undistortion,6,[],https://github.com/colmap/colmap/pull/362,https://github.com/ahojnnes,4,https://github.com/colmap/colmap/pull/362#issuecomment-393818015,"Hello Johannes,
I have some datasets captured by cameras mounted on a vehicle.
After SfM, only the bottom half image (mostly road area) is needed, since I want to generate dense clouds of road surface.
Therefore I added rectangular ROI for undistortion. Hope it's helpful in different applications.
Mit freundlichen Gruessen！
Xie Dufang","Thanks, I had a look at the logic again. We should make sure that the image has at least 1px in size. This might not be the case of the min/max values are very close. We should also make sure that rounding issues don’t cause the ROI to be outside of the original image size. Thanks! I could either implement those changes myself or I will wait for you. Please let me know.",True,{}
colmap/colmap,https://github.com/colmap/colmap,362,2018-05-09T06:08:15Z,2018-06-04T06:54:58Z,2018-06-04T06:54:58Z,MERGED,True,74,19,4,https://github.com/XieDufang,Add rectangular ROI for undistortion,6,[],https://github.com/colmap/colmap/pull/362,https://github.com/XieDufang,5,https://github.com/colmap/colmap/pull/362#issuecomment-393820285,"Hello Johannes,
I have some datasets captured by cameras mounted on a vehicle.
After SfM, only the bottom half image (mostly road area) is needed, since I want to generate dense clouds of road surface.
Therefore I added rectangular ROI for undistortion. Hope it's helpful in different applications.
Mit freundlichen Gruessen！
Xie Dufang",I will implement it this weekend,True,{}
colmap/colmap,https://github.com/colmap/colmap,362,2018-05-09T06:08:15Z,2018-06-04T06:54:58Z,2018-06-04T06:54:58Z,MERGED,True,74,19,4,https://github.com/XieDufang,Add rectangular ROI for undistortion,6,[],https://github.com/colmap/colmap/pull/362,https://github.com/XieDufang,6,https://github.com/colmap/colmap/pull/362#issuecomment-394075267,"Hello Johannes,
I have some datasets captured by cameras mounted on a vehicle.
After SfM, only the bottom half image (mostly road area) is needed, since I want to generate dense clouds of road surface.
Therefore I added rectangular ROI for undistortion. Hope it's helpful in different applications.
Mit freundlichen Gruessen！
Xie Dufang",OK. It is more readable. Thanks for the suggestion,True,{}
colmap/colmap,https://github.com/colmap/colmap,362,2018-05-09T06:08:15Z,2018-06-04T06:54:58Z,2018-06-04T06:54:58Z,MERGED,True,74,19,4,https://github.com/XieDufang,Add rectangular ROI for undistortion,6,[],https://github.com/colmap/colmap/pull/362,https://github.com/XieDufang,7,https://github.com/colmap/colmap/pull/362#issuecomment-394213985,"Hello Johannes,
I have some datasets captured by cameras mounted on a vehicle.
After SfM, only the bottom half image (mostly road area) is needed, since I want to generate dense clouds of road surface.
Therefore I added rectangular ROI for undistortion. Hope it's helpful in different applications.
Mit freundlichen Gruessen！
Xie Dufang",ROI validity check added ^_^,True,{}
colmap/colmap,https://github.com/colmap/colmap,362,2018-05-09T06:08:15Z,2018-06-04T06:54:58Z,2018-06-04T06:54:58Z,MERGED,True,74,19,4,https://github.com/XieDufang,Add rectangular ROI for undistortion,6,[],https://github.com/colmap/colmap/pull/362,https://github.com/ahojnnes,8,https://github.com/colmap/colmap/pull/362#issuecomment-394252516,"Hello Johannes,
I have some datasets captured by cameras mounted on a vehicle.
After SfM, only the bottom half image (mostly road area) is needed, since I want to generate dense clouds of road surface.
Therefore I added rectangular ROI for undistortion. Hope it's helpful in different applications.
Mit freundlichen Gruessen！
Xie Dufang","Looks great to me, thanks for the contribution!",True,{}
colmap/colmap,https://github.com/colmap/colmap,367,2018-05-18T09:20:40Z,2018-05-18T10:14:05Z,2018-05-18T10:17:57Z,MERGED,True,2,2,1,https://github.com/veloman-yunkan,Fix for Issue#365,1,[],https://github.com/colmap/colmap/pull/367,https://github.com/veloman-yunkan,1,https://github.com/colmap/colmap/pull/367,"Because of this bug the principal point of the first camera was always set
to (0, 0). Principal point of every subsequent camera was being set to the
center of the previous image, which could be a problem for input images of
different size.","Because of this bug the principal point of the first camera was always set
to (0, 0). Principal point of every subsequent camera was being set to the
center of the previous image, which could be a problem for input images of
different size.",True,{}
colmap/colmap,https://github.com/colmap/colmap,367,2018-05-18T09:20:40Z,2018-05-18T10:14:05Z,2018-05-18T10:17:57Z,MERGED,True,2,2,1,https://github.com/veloman-yunkan,Fix for Issue#365,1,[],https://github.com/colmap/colmap/pull/367,https://github.com/fishcu,2,https://github.com/colmap/colmap/pull/367#issuecomment-390154294,"Because of this bug the principal point of the first camera was always set
to (0, 0). Principal point of every subsequent camera was being set to the
center of the previous image, which could be a problem for input images of
different size.","Thanks a lot. Does this work for camera models that optimize the principal point (like OPENCV should, at least)? Or is it going to be fixed at resolution / 2?",True,{}
colmap/colmap,https://github.com/colmap/colmap,367,2018-05-18T09:20:40Z,2018-05-18T10:14:05Z,2018-05-18T10:17:57Z,MERGED,True,2,2,1,https://github.com/veloman-yunkan,Fix for Issue#365,1,[],https://github.com/colmap/colmap/pull/367,https://github.com/veloman-yunkan,3,https://github.com/colmap/colmap/pull/367#issuecomment-390156176,"Because of this bug the principal point of the first camera was always set
to (0, 0). Principal point of every subsequent camera was being set to the
center of the previous image, which could be a problem for input images of
different size.",I haven't tested it except on a single flow that I am currently running. However the logic of that code seems quite simple to me and in my understanding it shouldn't break any previous functionality.,True,{}
colmap/colmap,https://github.com/colmap/colmap,367,2018-05-18T09:20:40Z,2018-05-18T10:14:05Z,2018-05-18T10:17:57Z,MERGED,True,2,2,1,https://github.com/veloman-yunkan,Fix for Issue#365,1,[],https://github.com/colmap/colmap/pull/367,https://github.com/ahojnnes,4,https://github.com/colmap/colmap/pull/367#issuecomment-390162433,"Because of this bug the principal point of the first camera was always set
to (0, 0). Principal point of every subsequent camera was being set to the
center of the previous image, which could be a problem for input images of
different size.","LGTM, thanks for the fix!",True,{}
colmap/colmap,https://github.com/colmap/colmap,393,2018-06-20T09:44:18Z,2018-06-20T14:36:11Z,2018-06-20T14:36:11Z,MERGED,True,3,3,1,https://github.com/SBCV,Fix bug in python db.add_camera() function,1,[],https://github.com/colmap/colmap/pull/393,https://github.com/SBCV,1,https://github.com/colmap/colmap/pull/393,"Using ""db.add_camera(...)"" writes currently the parameters as np.float32 to the database file. This causes the following error when opening the database file with colmap: "" database.cc:207 Check failed:  num_params == camera.NumParams() (2 vs. 4)"" (because database.cc expects double values)","Using ""db.add_camera(...)"" writes currently the parameters as np.float32 to the database file. This causes the following error when opening the database file with colmap: "" database.cc:207 Check failed:  num_params == camera.NumParams() (2 vs. 4)"" (because database.cc expects double values)",True,{}
colmap/colmap,https://github.com/colmap/colmap,393,2018-06-20T09:44:18Z,2018-06-20T14:36:11Z,2018-06-20T14:36:11Z,MERGED,True,3,3,1,https://github.com/SBCV,Fix bug in python db.add_camera() function,1,[],https://github.com/colmap/colmap/pull/393,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/393#issuecomment-398772581,"Using ""db.add_camera(...)"" writes currently the parameters as np.float32 to the database file. This causes the following error when opening the database file with colmap: "" database.cc:207 Check failed:  num_params == camera.NumParams() (2 vs. 4)"" (because database.cc expects double values)","Great, thanks for spitting this bug and for the fix!",True,{}
colmap/colmap,https://github.com/colmap/colmap,396,2018-06-20T17:43:09Z,2018-06-21T13:41:51Z,2018-06-21T13:41:51Z,MERGED,True,8,1,1,https://github.com/mgprt,Fix SiftGPU bug with skipped levels.,1,[],https://github.com/colmap/colmap/pull/396,https://github.com/mgprt,1,https://github.com/colmap/colmap/pull/396,"If a image level is skipped due to a limit on the number of features, its feature counter can still contain data from the last image. This can lead to invalid features being returned and in the worst case a heap corruption since the total feature number does not match the sum of features per level.","If a image level is skipped due to a limit on the number of features, its feature counter can still contain data from the last image. This can lead to invalid features being returned and in the worst case a heap corruption since the total feature number does not match the sum of features per level.",True,{}
colmap/colmap,https://github.com/colmap/colmap,396,2018-06-20T17:43:09Z,2018-06-21T13:41:51Z,2018-06-21T13:41:51Z,MERGED,True,8,1,1,https://github.com/mgprt,Fix SiftGPU bug with skipped levels.,1,[],https://github.com/colmap/colmap/pull/396,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/396#issuecomment-399107572,"If a image level is skipped due to a limit on the number of features, its feature counter can still contain data from the last image. This can lead to invalid features being returned and in the worst case a heap corruption since the total feature number does not match the sum of features per level.","Great, thanks for the fix!",True,{}
colmap/colmap,https://github.com/colmap/colmap,399,2018-06-22T03:42:21Z,2018-06-22T19:34:42Z,2018-06-22T19:34:49Z,MERGED,True,362,358,13,https://github.com/XieDufang,Fix #392 and small fix for visibility vector,14,[],https://github.com/colmap/colmap/pull/399,https://github.com/XieDufang,1,https://github.com/colmap/colmap/pull/399,"Correct variable/function names for image index in the whole mvs module.
Rename variables/functions if they actually refer to contiguous zero-based index, not unordered id.


Clear/shrink visibility vector in accordance with point vector.
Small fix for visibility vector. Clear/shrink also visibility vector while clearing/shrinking fused point vector.","Correct variable/function names for image index in the whole mvs module.
Rename variables/functions if they actually refer to contiguous zero-based index, not unordered id.


Clear/shrink visibility vector in accordance with point vector.
Small fix for visibility vector. Clear/shrink also visibility vector while clearing/shrinking fused point vector.",True,{}
colmap/colmap,https://github.com/colmap/colmap,399,2018-06-22T03:42:21Z,2018-06-22T19:34:42Z,2018-06-22T19:34:49Z,MERGED,True,362,358,13,https://github.com/XieDufang,Fix #392 and small fix for visibility vector,14,[],https://github.com/colmap/colmap/pull/399,https://github.com/XieDufang,2,https://github.com/colmap/colmap/pull/399#issuecomment-399313246,"Correct variable/function names for image index in the whole mvs module.
Rename variables/functions if they actually refer to contiguous zero-based index, not unordered id.


Clear/shrink visibility vector in accordance with point vector.
Small fix for visibility vector. Clear/shrink also visibility vector while clearing/shrinking fused point vector.","The older commits (ROI in undistortion) are also listed here. But they have already been merged before. I think it's just because they were not merged directly from my commits but from your own commit.
Anyway, the actual file changes are only from the recent commits.",True,{}
colmap/colmap,https://github.com/colmap/colmap,399,2018-06-22T03:42:21Z,2018-06-22T19:34:42Z,2018-06-22T19:34:49Z,MERGED,True,362,358,13,https://github.com/XieDufang,Fix #392 and small fix for visibility vector,14,[],https://github.com/colmap/colmap/pull/399,https://github.com/ahojnnes,3,https://github.com/colmap/colmap/pull/399#issuecomment-399325682,"Correct variable/function names for image index in the whole mvs module.
Rename variables/functions if they actually refer to contiguous zero-based index, not unordered id.


Clear/shrink visibility vector in accordance with point vector.
Small fix for visibility vector. Clear/shrink also visibility vector while clearing/shrinking fused point vector.","This looks great. One minor change request: Throughout colmap I use the convention that the plural of idx is idxs, so could you please rename indices to idxs? Thanks very much!",True,{}
colmap/colmap,https://github.com/colmap/colmap,399,2018-06-22T03:42:21Z,2018-06-22T19:34:42Z,2018-06-22T19:34:49Z,MERGED,True,362,358,13,https://github.com/XieDufang,Fix #392 and small fix for visibility vector,14,[],https://github.com/colmap/colmap/pull/399,https://github.com/XieDufang,4,https://github.com/colmap/colmap/pull/399#issuecomment-399326808,"Correct variable/function names for image index in the whole mvs module.
Rename variables/functions if they actually refer to contiguous zero-based index, not unordered id.


Clear/shrink visibility vector in accordance with point vector.
Small fix for visibility vector. Clear/shrink also visibility vector while clearing/shrinking fused point vector.","Ok, I'll change ""indices"" to ""idxs""",True,{}
colmap/colmap,https://github.com/colmap/colmap,399,2018-06-22T03:42:21Z,2018-06-22T19:34:42Z,2018-06-22T19:34:49Z,MERGED,True,362,358,13,https://github.com/XieDufang,Fix #392 and small fix for visibility vector,14,[],https://github.com/colmap/colmap/pull/399,https://github.com/XieDufang,5,https://github.com/colmap/colmap/pull/399#issuecomment-399337702,"Correct variable/function names for image index in the whole mvs module.
Rename variables/functions if they actually refer to contiguous zero-based index, not unordered id.


Clear/shrink visibility vector in accordance with point vector.
Small fix for visibility vector. Clear/shrink also visibility vector while clearing/shrinking fused point vector.","""Indices"" has been renamed to ""idxs""    ^_^",True,{}
colmap/colmap,https://github.com/colmap/colmap,399,2018-06-22T03:42:21Z,2018-06-22T19:34:42Z,2018-06-22T19:34:49Z,MERGED,True,362,358,13,https://github.com/XieDufang,Fix #392 and small fix for visibility vector,14,[],https://github.com/colmap/colmap/pull/399,https://github.com/ahojnnes,6,https://github.com/colmap/colmap/pull/399#issuecomment-399558778,"Correct variable/function names for image index in the whole mvs module.
Rename variables/functions if they actually refer to contiguous zero-based index, not unordered id.


Clear/shrink visibility vector in accordance with point vector.
Small fix for visibility vector. Clear/shrink also visibility vector while clearing/shrinking fused point vector.","Looks great, thanks!",True,{}
colmap/colmap,https://github.com/colmap/colmap,407,2018-06-28T06:03:55Z,2018-06-29T03:49:12Z,2018-06-29T03:49:12Z,CLOSED,False,1,1,1,https://github.com/is03wlei,fix issue of finding best local model,1,[],https://github.com/colmap/colmap/pull/407,https://github.com/is03wlei,1,https://github.com/colmap/colmap/pull/407,Refer to #401 for more discussions.,Refer to #401 for more discussions.,True,{}
colmap/colmap,https://github.com/colmap/colmap,407,2018-06-28T06:03:55Z,2018-06-29T03:49:12Z,2018-06-29T03:49:12Z,CLOSED,False,1,1,1,https://github.com/is03wlei,fix issue of finding best local model,1,[],https://github.com/colmap/colmap/pull/407,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/407#issuecomment-401190802,Refer to #401 for more discussions.,This fix looks good but you should start off from the dev branch rather than the master branch.,True,{}
colmap/colmap,https://github.com/colmap/colmap,408,2018-06-29T01:24:30Z,2018-06-29T03:49:00Z,2018-06-29T03:51:37Z,MERGED,True,1,1,1,https://github.com/is03wlei,fix issue of finding best local model for loransac,1,[],https://github.com/colmap/colmap/pull/408,https://github.com/is03wlei,1,https://github.com/colmap/colmap/pull/408,Refer to #401 for more discussions.,Refer to #401 for more discussions.,True,{}
colmap/colmap,https://github.com/colmap/colmap,408,2018-06-29T01:24:30Z,2018-06-29T03:49:00Z,2018-06-29T03:51:37Z,MERGED,True,1,1,1,https://github.com/is03wlei,fix issue of finding best local model for loransac,1,[],https://github.com/colmap/colmap/pull/408,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/408#issuecomment-401239700,Refer to #401 for more discussions.,Thanks for the fix!,True,{}
colmap/colmap,https://github.com/colmap/colmap,413,2018-07-03T13:32:01Z,2018-07-03T15:10:16Z,2018-07-03T20:44:07Z,MERGED,True,6,5,1,https://github.com/mgprt,Do not pass boost dependencies to linking lib when on Windows.,1,[],https://github.com/colmap/colmap/pull/413,https://github.com/mgprt,1,https://github.com/colmap/colmap/pull/413,This prevents boost symbol redefinition errors as the symbols are already included in the COLMAP libs.,This prevents boost symbol redefinition errors as the symbols are already included in the COLMAP libs.,True,{}
colmap/colmap,https://github.com/colmap/colmap,413,2018-07-03T13:32:01Z,2018-07-03T15:10:16Z,2018-07-03T20:44:07Z,MERGED,True,6,5,1,https://github.com/mgprt,Do not pass boost dependencies to linking lib when on Windows.,1,[],https://github.com/colmap/colmap/pull/413,https://github.com/mgprt,2,https://github.com/colmap/colmap/pull/413#issuecomment-402162906,This prevents boost symbol redefinition errors as the symbols are already included in the COLMAP libs.,"You might also consider providing absolute paths to the internal libraries or even generate imported targets. The use of link_directories() should not be necessary.
https://cmake.org/cmake/help/v3.11/command/link_directories.html",True,{}
colmap/colmap,https://github.com/colmap/colmap,413,2018-07-03T13:32:01Z,2018-07-03T15:10:16Z,2018-07-03T20:44:07Z,MERGED,True,6,5,1,https://github.com/mgprt,Do not pass boost dependencies to linking lib when on Windows.,1,[],https://github.com/colmap/colmap/pull/413,https://github.com/ahojnnes,3,https://github.com/colmap/colmap/pull/413#issuecomment-402191638,This prevents boost symbol redefinition errors as the symbols are already included in the COLMAP libs.,"@mgprt If you have time to add the ""imported target"" feature that would be great?",True,{}
colmap/colmap,https://github.com/colmap/colmap,413,2018-07-03T13:32:01Z,2018-07-03T15:10:16Z,2018-07-03T20:44:07Z,MERGED,True,6,5,1,https://github.com/mgprt,Do not pass boost dependencies to linking lib when on Windows.,1,[],https://github.com/colmap/colmap/pull/413,https://github.com/ahojnnes,4,https://github.com/colmap/colmap/pull/413#issuecomment-402191682,This prevents boost symbol redefinition errors as the symbols are already included in the COLMAP libs.,Thanks for the fix.,True,{}
colmap/colmap,https://github.com/colmap/colmap,439,2018-07-25T12:53:39Z,2018-07-25T15:00:07Z,2018-07-25T15:00:13Z,MERGED,True,10,1,2,https://github.com/mgprt,Add CGAL dependency to config file,3,[],https://github.com/colmap/colmap/pull/439,https://github.com/mgprt,1,https://github.com/colmap/colmap/pull/439,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,439,2018-07-25T12:53:39Z,2018-07-25T15:00:07Z,2018-07-25T15:00:13Z,MERGED,True,10,1,2,https://github.com/mgprt,Add CGAL dependency to config file,3,[],https://github.com/colmap/colmap/pull/439,https://github.com/mgprt,2,https://github.com/colmap/colmap/pull/439#issuecomment-407771700,,I missed that before. Now it also handles the case when CGAL is enabled but not found.,True,{}
colmap/colmap,https://github.com/colmap/colmap,439,2018-07-25T12:53:39Z,2018-07-25T15:00:07Z,2018-07-25T15:00:13Z,MERGED,True,10,1,2,https://github.com/mgprt,Add CGAL dependency to config file,3,[],https://github.com/colmap/colmap/pull/439,https://github.com/ahojnnes,3,https://github.com/colmap/colmap/pull/439#issuecomment-407785428,,"Great, thanks!",True,{}
colmap/colmap,https://github.com/colmap/colmap,457,2018-08-15T13:42:57Z,2018-08-15T16:49:55Z,2018-08-15T16:49:55Z,MERGED,True,25,2,4,https://github.com/fishcu,Allow partial image prefix for nested subfolder rig BA,3,[],https://github.com/colmap/colmap/pull/457,https://github.com/fishcu,1,https://github.com/colmap/colmap/pull/457,"I made this small change so that the following folder structure can be supported by rig BA:
dataset:
- sub_dataset1:
  - left:
    - img0001.png
    - ...
  - right:
- sub_dataset2:
  - left:
  - right:
...

This was previously not possible, because the ""sub_dataset"" string would prevent image names from matching.","I made this small change so that the following folder structure can be supported by rig BA:
dataset:
- sub_dataset1:
  - left:
    - img0001.png
    - ...
  - right:
- sub_dataset2:
  - left:
  - right:
...

This was previously not possible, because the ""sub_dataset"" string would prevent image names from matching.",True,{}
colmap/colmap,https://github.com/colmap/colmap,457,2018-08-15T13:42:57Z,2018-08-15T16:49:55Z,2018-08-15T16:49:55Z,MERGED,True,25,2,4,https://github.com/fishcu,Allow partial image prefix for nested subfolder rig BA,3,[],https://github.com/colmap/colmap/pull/457,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/457#issuecomment-413232597,"I made this small change so that the following folder structure can be supported by rig BA:
dataset:
- sub_dataset1:
  - left:
    - img0001.png
    - ...
  - right:
- sub_dataset2:
  - left:
  - right:
...

This was previously not possible, because the ""sub_dataset"" string would prevent image names from matching.","Looks good to me, but could you please add a short unit test for the new function? Thanks.",True,{}
colmap/colmap,https://github.com/colmap/colmap,457,2018-08-15T13:42:57Z,2018-08-15T16:49:55Z,2018-08-15T16:49:55Z,MERGED,True,25,2,4,https://github.com/fishcu,Allow partial image prefix for nested subfolder rig BA,3,[],https://github.com/colmap/colmap/pull/457,https://github.com/fishcu,3,https://github.com/colmap/colmap/pull/457#issuecomment-413249584,"I made this small change so that the following folder structure can be supported by rig BA:
dataset:
- sub_dataset1:
  - left:
    - img0001.png
    - ...
  - right:
- sub_dataset2:
  - left:
  - right:
...

This was previously not possible, because the ""sub_dataset"" string would prevent image names from matching.","I added a unit test. Did you mean the string function, or the modified way that the rig is initialized? I think string function is enough -- the other would be more of an integration test",True,{}
colmap/colmap,https://github.com/colmap/colmap,457,2018-08-15T13:42:57Z,2018-08-15T16:49:55Z,2018-08-15T16:49:55Z,MERGED,True,25,2,4,https://github.com/fishcu,Allow partial image prefix for nested subfolder rig BA,3,[],https://github.com/colmap/colmap/pull/457,https://github.com/ahojnnes,4,https://github.com/colmap/colmap/pull/457#issuecomment-413260254,"I made this small change so that the following folder structure can be supported by rig BA:
dataset:
- sub_dataset1:
  - left:
    - img0001.png
    - ...
  - right:
- sub_dataset2:
  - left:
  - right:
...

This was previously not possible, because the ""sub_dataset"" string would prevent image names from matching.","I meant exactly what you added. Great, thanks very much.",True,{}
colmap/colmap,https://github.com/colmap/colmap,472,2018-08-29T15:31:19Z,,2022-01-26T12:22:15Z,OPEN,False,29,0,1,https://github.com/DmitriyKorchemkin,Automatically downgrade gcc for cuda compilation,1,[],https://github.com/colmap/colmap/pull/472,https://github.com/DmitriyKorchemkin,1,https://github.com/colmap/colmap/pull/472,"CUDA compilation is possible only with a limited set of gcc versions.
This pull request adds automatic ""downgrading"" gcc version (via CUDA_HOST_COMPILER) if CUDA_HOST_COMPILER is set to its default value (CMAKE_C_COMPILER).","CUDA compilation is possible only with a limited set of gcc versions.
This pull request adds automatic ""downgrading"" gcc version (via CUDA_HOST_COMPILER) if CUDA_HOST_COMPILER is set to its default value (CMAKE_C_COMPILER).",True,{}
colmap/colmap,https://github.com/colmap/colmap,472,2018-08-29T15:31:19Z,,2022-01-26T12:22:15Z,OPEN,False,29,0,1,https://github.com/DmitriyKorchemkin,Automatically downgrade gcc for cuda compilation,1,[],https://github.com/colmap/colmap/pull/472,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/472#issuecomment-418450517,"CUDA compilation is possible only with a limited set of gcc versions.
This pull request adds automatic ""downgrading"" gcc version (via CUDA_HOST_COMPILER) if CUDA_HOST_COMPILER is set to its default value (CMAKE_C_COMPILER).","This looks great, thanks! One issue is that you hardcoded the paths to the compilers, which can be an issue especially on cluster machines, etc. Not sure if there is a standardized way in CMake to find specific versions of GCC. An alternative approach would be to simply exit the CMake script with an error/warning message, when an incompatible combination of CUDA/GCC is detected. What do you think?",True,{'THUMBS_UP': ['https://github.com/alexmyczko']}
colmap/colmap,https://github.com/colmap/colmap,472,2018-08-29T15:31:19Z,,2022-01-26T12:22:15Z,OPEN,False,29,0,1,https://github.com/DmitriyKorchemkin,Automatically downgrade gcc for cuda compilation,1,[],https://github.com/colmap/colmap/pull/472,https://github.com/alexmyczko,3,https://github.com/colmap/colmap/pull/472#issuecomment-546892591,"CUDA compilation is possible only with a limited set of gcc versions.
This pull request adds automatic ""downgrading"" gcc version (via CUDA_HOST_COMPILER) if CUDA_HOST_COMPILER is set to its default value (CMAKE_C_COMPILER).",please add support for cuda-10 as well?,True,{}
colmap/colmap,https://github.com/colmap/colmap,472,2018-08-29T15:31:19Z,,2022-01-26T12:22:15Z,OPEN,False,29,0,1,https://github.com/DmitriyKorchemkin,Automatically downgrade gcc for cuda compilation,1,[],https://github.com/colmap/colmap/pull/472,https://github.com/DmitriyKorchemkin,4,https://github.com/colmap/colmap/pull/472#issuecomment-547442826,"CUDA compilation is possible only with a limited set of gcc versions.
This pull request adds automatic ""downgrading"" gcc version (via CUDA_HOST_COMPILER) if CUDA_HOST_COMPILER is set to its default value (CMAKE_C_COMPILER).","@alexmyczko do you know a way to get paths to the compilers without much hassle?
To be honest, I've abandoned this pull-request  just because auto-finding correct paths seemed too painful way, and just issuing warning seemed kinda useless (since you will get error from nvcc simply by ignoring this stuff completely).",True,{'THUMBS_UP': ['https://github.com/alexmyczko']}
colmap/colmap,https://github.com/colmap/colmap,472,2018-08-29T15:31:19Z,,2022-01-26T12:22:15Z,OPEN,False,29,0,1,https://github.com/DmitriyKorchemkin,Automatically downgrade gcc for cuda compilation,1,[],https://github.com/colmap/colmap/pull/472,https://github.com/alexmyczko,5,https://github.com/colmap/colmap/pull/472#issuecomment-547778003,"CUDA compilation is possible only with a limited set of gcc versions.
This pull request adds automatic ""downgrading"" gcc version (via CUDA_HOST_COMPILER) if CUDA_HOST_COMPILER is set to its default value (CMAKE_C_COMPILER).","That's what I added to README.Debian
You might want to rebuild with this added to debian/rules
# with cuda-10-0
override_dh_auto_configure:
        dh_auto_configure -- -DCUDA_SDK_ROOT_DIR=/usr/local/cuda-10.0 -DCUDA_TOOLKIT_ROOT_DIR=/usr/local/cuda-10.0
 
# or if you have cuda-10-1
override_dh_auto_configure:
        dh_auto_configure -- -DCUDA_SDK_ROOT_DIR=/usr/local/cuda-10.1 -DCUDA_TOOLKIT_ROOT_DIR=/usr/local/cuda-10.1

basically the two defines when you use nvidia cuda repos
$ cat /etc/apt/sources.list.d/cuda.list 
deb http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64 /",True,{'THUMBS_UP': ['https://github.com/yuanyang7']}
colmap/colmap,https://github.com/colmap/colmap,473,2018-08-30T08:01:10Z,2019-06-20T14:47:52Z,2019-06-20T14:47:52Z,CLOSED,False,19116,53,6,https://github.com/fishcu,"Implement importing rig intrinsics from JSON (using tvec, qvec, rmat)",10,[],https://github.com/colmap/colmap/pull/473,https://github.com/fishcu,1,https://github.com/colmap/colmap/pull/473,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,473,2018-08-30T08:01:10Z,2019-06-20T14:47:52Z,2019-06-20T14:47:52Z,CLOSED,False,19116,53,6,https://github.com/fishcu,"Implement importing rig intrinsics from JSON (using tvec, qvec, rmat)",10,[],https://github.com/colmap/colmap/pull/473,https://github.com/puzzlepaint,2,https://github.com/colmap/colmap/pull/473#issuecomment-439709632,,"I also have a use-case for this. Since I was unaware of this PR, I independently wrote an implementation for it that seems to be quite similar to the one in this PR, but doesn't pull in another dependency. I could provide the code in case this helps getting this merged.",True,{}
colmap/colmap,https://github.com/colmap/colmap,473,2018-08-30T08:01:10Z,2019-06-20T14:47:52Z,2019-06-20T14:47:52Z,CLOSED,False,19116,53,6,https://github.com/fishcu,"Implement importing rig intrinsics from JSON (using tvec, qvec, rmat)",10,[],https://github.com/colmap/colmap/pull/473,https://github.com/fishcu,3,https://github.com/colmap/colmap/pull/473#issuecomment-439717919,,"@puzzlepaint is your code online?
I know it's bad to pull in dependencies in a PR like that, but I was in a hurry to get results back then and I figured it might be of use to some people at least. But I guess it's not visible enough to make a difference, since you re-implemented it anyway! ;)",True,{}
colmap/colmap,https://github.com/colmap/colmap,473,2018-08-30T08:01:10Z,2019-06-20T14:47:52Z,2019-06-20T14:47:52Z,CLOSED,False,19116,53,6,https://github.com/fishcu,"Implement importing rig intrinsics from JSON (using tvec, qvec, rmat)",10,[],https://github.com/colmap/colmap/pull/473,https://github.com/puzzlepaint,4,https://github.com/colmap/colmap/pull/473#issuecomment-439732760,,"I had the code as a part of some larger local changes. I now extracted it and pushed it here:
puzzlepaint@e870163
In this form, this is untested. Also, I didn't tidy it up for a PR. For example, there is no warning about possible scale inconsistency if multiple rigs are given.
Once this PR gets merged the functionality should become more visible :)",True,{}
colmap/colmap,https://github.com/colmap/colmap,473,2018-08-30T08:01:10Z,2019-06-20T14:47:52Z,2019-06-20T14:47:52Z,CLOSED,False,19116,53,6,https://github.com/fishcu,"Implement importing rig intrinsics from JSON (using tvec, qvec, rmat)",10,[],https://github.com/colmap/colmap/pull/473,https://github.com/os-gabe,5,https://github.com/colmap/colmap/pull/473#issuecomment-497866199,,I'm quite interested in this functionality. What are the chances of getting this merged?,True,{}
colmap/colmap,https://github.com/colmap/colmap,473,2018-08-30T08:01:10Z,2019-06-20T14:47:52Z,2019-06-20T14:47:52Z,CLOSED,False,19116,53,6,https://github.com/fishcu,"Implement importing rig intrinsics from JSON (using tvec, qvec, rmat)",10,[],https://github.com/colmap/colmap/pull/473,https://github.com/fishcu,6,https://github.com/colmap/colmap/pull/473#issuecomment-497874353,,"IIRC I used another json library for this. I think if someone got rid of that dependency, changes of a merge would be higher.

You can still checkout this PR and compile it yourself if you want to have the functionality. But you will miss out on the latest commits unless you rebase.
…
On May 31, 2019, 23:29, at 23:29, os-gabe ***@***.***> wrote:
I'm quite interested in this functionality. What are the chances of
getting this merged?

--
You are receiving this because you authored the thread.
Reply to this email directly or view it on GitHub:
#473 (comment)",True,{}
colmap/colmap,https://github.com/colmap/colmap,473,2018-08-30T08:01:10Z,2019-06-20T14:47:52Z,2019-06-20T14:47:52Z,CLOSED,False,19116,53,6,https://github.com/fishcu,"Implement importing rig intrinsics from JSON (using tvec, qvec, rmat)",10,[],https://github.com/colmap/colmap/pull/473,https://github.com/fishcu,7,https://github.com/colmap/colmap/pull/473#issuecomment-504055493,,"I will maybe try to submit a better pull request. This one was pretty terrible, but at least I have a reference now to quickly code a better one!",True,{'THUMBS_UP': ['https://github.com/os-gabe']}
colmap/colmap,https://github.com/colmap/colmap,486,2018-09-29T09:09:14Z,2018-09-29T10:21:46Z,2018-09-29T10:22:01Z,MERGED,True,1,0,1,https://github.com/is03wlei,enable local_ba_num_images configurable from command line,1,[],https://github.com/colmap/colmap/pull/486,https://github.com/is03wlei,1,https://github.com/colmap/colmap/pull/486,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,486,2018-09-29T09:09:14Z,2018-09-29T10:21:46Z,2018-09-29T10:22:01Z,MERGED,True,1,0,1,https://github.com/is03wlei,enable local_ba_num_images configurable from command line,1,[],https://github.com/colmap/colmap/pull/486,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/486#issuecomment-425634188,,"Great, thanks for the fix.",True,{}
colmap/colmap,https://github.com/colmap/colmap,492,2018-10-08T07:12:12Z,2020-01-09T20:56:24Z,2020-01-09T20:56:25Z,CLOSED,False,3,3,1,https://github.com/is03wlei,not refine camera intrinsics in local BA,1,[],https://github.com/colmap/colmap/pull/492,https://github.com/is03wlei,1,https://github.com/colmap/colmap/pull/492,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,492,2018-10-08T07:12:12Z,2020-01-09T20:56:24Z,2020-01-09T20:56:25Z,CLOSED,False,3,3,1,https://github.com/is03wlei,not refine camera intrinsics in local BA,1,[],https://github.com/colmap/colmap/pull/492,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/492#issuecomment-428164051,,"Thanks for your pull request, but this will not work, unfortunately. We just don't want to refine the intrinsics if not all of the images of a camera are included in the local bundle. If all the images of a camera are included, the intrinsics should be optimized.",True,{}
colmap/colmap,https://github.com/colmap/colmap,492,2018-10-08T07:12:12Z,2020-01-09T20:56:24Z,2020-01-09T20:56:25Z,CLOSED,False,3,3,1,https://github.com/is03wlei,not refine camera intrinsics in local BA,1,[],https://github.com/colmap/colmap/pull/492,https://github.com/is03wlei,3,https://github.com/colmap/colmap/pull/492#issuecomment-430076659,,"Should we extend refined_cameras to unordered_map and make use of it.
Besides, we need to decrease refined_cameras in DeRegisterImageEvent.
Although it would affect configurations of RefineAbsolutePose, it shouldn't be worse.",True,{}
colmap/colmap,https://github.com/colmap/colmap,492,2018-10-08T07:12:12Z,2020-01-09T20:56:24Z,2020-01-09T20:56:25Z,CLOSED,False,3,3,1,https://github.com/is03wlei,not refine camera intrinsics in local BA,1,[],https://github.com/colmap/colmap/pull/492,https://github.com/ahojnnes,4,https://github.com/colmap/colmap/pull/492#issuecomment-430128351,,"This will take more effort, because bundle adjustment currently does not allow to specify constant intrinsics for individual images.",True,{}
colmap/colmap,https://github.com/colmap/colmap,492,2018-10-08T07:12:12Z,2020-01-09T20:56:24Z,2020-01-09T20:56:25Z,CLOSED,False,3,3,1,https://github.com/is03wlei,not refine camera intrinsics in local BA,1,[],https://github.com/colmap/colmap/pull/492,https://github.com/is03wlei,5,https://github.com/colmap/colmap/pull/492#issuecomment-430132417,,"You mean we need to handle such case:
local bundle contains all images of camera 1 but some of images of camera 2.",True,{}
colmap/colmap,https://github.com/colmap/colmap,492,2018-10-08T07:12:12Z,2020-01-09T20:56:24Z,2020-01-09T20:56:25Z,CLOSED,False,3,3,1,https://github.com/is03wlei,not refine camera intrinsics in local BA,1,[],https://github.com/colmap/colmap/pull/492,https://github.com/ahojnnes,6,https://github.com/colmap/colmap/pull/492#issuecomment-430188581,,"@is03wlei Yes, exactly.",True,{}
colmap/colmap,https://github.com/colmap/colmap,492,2018-10-08T07:12:12Z,2020-01-09T20:56:24Z,2020-01-09T20:56:25Z,CLOSED,False,3,3,1,https://github.com/is03wlei,not refine camera intrinsics in local BA,1,[],https://github.com/colmap/colmap/pull/492,https://github.com/ahojnnes,7,https://github.com/colmap/colmap/pull/492#issuecomment-572751642,,The issue is now fixed in the latest commit in the dev branch. Thanks.,True,{}
colmap/colmap,https://github.com/colmap/colmap,495,2018-10-10T04:07:49Z,2018-10-11T05:56:58Z,2018-10-11T05:56:58Z,MERGED,True,1,0,1,https://github.com/is03wlei,not refine extra camera params in RefineAbsolutePose when they have a…,1,[],https://github.com/colmap/colmap/pull/495,https://github.com/is03wlei,1,https://github.com/colmap/colmap/pull/495,…lready been refined,…lready been refined,True,{}
colmap/colmap,https://github.com/colmap/colmap,495,2018-10-10T04:07:49Z,2018-10-11T05:56:58Z,2018-10-11T05:56:58Z,MERGED,True,1,0,1,https://github.com/is03wlei,not refine extra camera params in RefineAbsolutePose when they have a…,1,[],https://github.com/colmap/colmap/pull/495,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/495#issuecomment-428830113,…lready been refined,"Great, thanks for the fix.",True,{}
colmap/colmap,https://github.com/colmap/colmap,501,2018-10-24T10:38:09Z,2018-10-31T07:46:58Z,2018-10-31T12:39:20Z,MERGED,True,1,0,1,https://github.com/tompollok,enable Qt::AA_UseHighDpiPixmaps for better less pixeled button icons,1,[],https://github.com/colmap/colmap/pull/501,https://github.com/tompollok,1,https://github.com/colmap/colmap/pull/501,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,501,2018-10-24T10:38:09Z,2018-10-31T07:46:58Z,2018-10-31T12:39:20Z,MERGED,True,1,0,1,https://github.com/tompollok,enable Qt::AA_UseHighDpiPixmaps for better less pixeled button icons,1,[],https://github.com/colmap/colmap/pull/501,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/501#issuecomment-432654843,,"Thanks for the pull request. Just to make sure I understand what this is doing, can you please post two screenshots with before/after this change?",True,{}
colmap/colmap,https://github.com/colmap/colmap,501,2018-10-24T10:38:09Z,2018-10-31T07:46:58Z,2018-10-31T12:39:20Z,MERGED,True,1,0,1,https://github.com/tompollok,enable Qt::AA_UseHighDpiPixmaps for better less pixeled button icons,1,[],https://github.com/colmap/colmap/pull/501,https://github.com/ahojnnes,3,https://github.com/colmap/colmap/pull/501#issuecomment-434591483,,"Merging this, thanks!",True,{}
colmap/colmap,https://github.com/colmap/colmap,501,2018-10-24T10:38:09Z,2018-10-31T07:46:58Z,2018-10-31T12:39:20Z,MERGED,True,1,0,1,https://github.com/tompollok,enable Qt::AA_UseHighDpiPixmaps for better less pixeled button icons,1,[],https://github.com/colmap/colmap/pull/501,https://github.com/tompollok,4,https://github.com/colmap/colmap/pull/501#issuecomment-434671268,,"Sorry for my late response. I did not test it with COLMAP but in my own software.
If your icons are high dpi like 128x128 resolution then they look better on your GUI than without using AA_UseHighDpiPixmaps
If your icons are of low quality then you should not notice a difference.
Here a comparision. Both use the same icon files, but without AA_UseHighDpiPixmaps it looks worse.

I contributed this to a couple of open source applications that i use. Like CppCheck to improve the UX for 4K displays.",True,{}
colmap/colmap,https://github.com/colmap/colmap,507,2018-11-02T02:27:37Z,2018-11-05T13:12:58Z,2018-11-05T13:13:04Z,MERGED,True,43,11,5,https://github.com/json87, bug fix for building with vs 2013 on windows OS ,5,[],https://github.com/colmap/colmap/pull/507,https://github.com/json87,1,https://github.com/colmap/colmap/pull/507,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,507,2018-11-02T02:27:37Z,2018-11-05T13:12:58Z,2018-11-05T13:13:04Z,MERGED,True,43,11,5,https://github.com/json87, bug fix for building with vs 2013 on windows OS ,5,[],https://github.com/colmap/colmap/pull/507,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/507#issuecomment-435868973,,Thanks!,True,{}
colmap/colmap,https://github.com/colmap/colmap,516,2018-11-08T13:56:25Z,2018-11-08T21:01:43Z,2018-11-08T21:01:43Z,MERGED,True,1,1,1,https://github.com/tsattler,Update export_to_visualsfm.py,1,[],https://github.com/colmap/colmap/pull/516,https://github.com/tsattler,1,https://github.com/colmap/colmap/pull/516,"Running the current version of the script leads to a crash since calling .reshape(-1, 4) in Line 103 leads to more keypoint positions that descriptors, resulting in an out-of-bound access in Line 114. Changing .reshape(-1, 4) to .reshape(-1, 6) should solve this problem as it takes into account that keypoints are stored with 6 attributes.","Running the current version of the script leads to a crash since calling .reshape(-1, 4) in Line 103 leads to more keypoint positions that descriptors, resulting in an out-of-bound access in Line 114. Changing .reshape(-1, 4) to .reshape(-1, 6) should solve this problem as it takes into account that keypoints are stored with 6 attributes.",True,{}
colmap/colmap,https://github.com/colmap/colmap,516,2018-11-08T13:56:25Z,2018-11-08T21:01:43Z,2018-11-08T21:01:43Z,MERGED,True,1,1,1,https://github.com/tsattler,Update export_to_visualsfm.py,1,[],https://github.com/colmap/colmap/pull/516,https://github.com/tsattler,2,https://github.com/colmap/colmap/pull/516#issuecomment-437136086,"Running the current version of the script leads to a crash since calling .reshape(-1, 4) in Line 103 leads to more keypoint positions that descriptors, resulting in an out-of-bound access in Line 114. Changing .reshape(-1, 4) to .reshape(-1, 6) should solve this problem as it takes into account that keypoints are stored with 6 attributes.",Not sure why the continuous integration is failing. My changes are in a python file that I don't think is actually checked.,True,{}
colmap/colmap,https://github.com/colmap/colmap,516,2018-11-08T13:56:25Z,2018-11-08T21:01:43Z,2018-11-08T21:01:43Z,MERGED,True,1,1,1,https://github.com/tsattler,Update export_to_visualsfm.py,1,[],https://github.com/colmap/colmap/pull/516,https://github.com/ahojnnes,3,https://github.com/colmap/colmap/pull/516#issuecomment-437154401,"Running the current version of the script leads to a crash since calling .reshape(-1, 4) in Line 103 leads to more keypoint positions that descriptors, resulting in an out-of-bound access in Line 114. Changing .reshape(-1, 4) to .reshape(-1, 6) should solve this problem as it takes into account that keypoints are stored with 6 attributes.",Thanks!,True,{}
colmap/colmap,https://github.com/colmap/colmap,517,2018-11-09T16:34:33Z,2018-11-28T21:51:51Z,2018-11-28T21:53:47Z,MERGED,True,28,6,1,https://github.com/tsattler,Binary descriptors export in export_to_visualsfm.py,1,[],https://github.com/colmap/colmap/pull/517,https://github.com/tsattler,1,https://github.com/colmap/colmap/pull/517,This PR enables exporting the descriptors to the binary file format used by Visual SfM.,This PR enables exporting the descriptors to the binary file format used by Visual SfM.,True,{}
colmap/colmap,https://github.com/colmap/colmap,517,2018-11-09T16:34:33Z,2018-11-28T21:51:51Z,2018-11-28T21:53:47Z,MERGED,True,28,6,1,https://github.com/tsattler,Binary descriptors export in export_to_visualsfm.py,1,[],https://github.com/colmap/colmap/pull/517,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/517#issuecomment-442619121,This PR enables exporting the descriptors to the binary file format used by Visual SfM.,Thanks!,True,{}
colmap/colmap,https://github.com/colmap/colmap,518,2018-11-15T09:53:46Z,,2022-01-26T12:22:15Z,OPEN,False,22,25,2,https://github.com/andijcr,compability fix for ubuntu 18.10,2,[],https://github.com/colmap/colmap/pull/518,https://github.com/andijcr,1,https://github.com/colmap/colmap/pull/518,"Hi, i was having trouble linking under the combination Ubuntu 18.10, cuda-8 and g++-5, so i made these two small changes.
The first commit unifies in the CMakeLists.txt the OPENGL_gl_LIBRARY and OPENGL_glu_LIBRARY into OPENGL_LIBRARIES, and in Debug build mode this builds fine.
the second commit removes the dependency to boost::regex, it was causing troubles in Release build mode.
I simply switched the c++11 mode on, and moved from boost::regex to std::regex.","Hi, i was having trouble linking under the combination Ubuntu 18.10, cuda-8 and g++-5, so i made these two small changes.
The first commit unifies in the CMakeLists.txt the OPENGL_gl_LIBRARY and OPENGL_glu_LIBRARY into OPENGL_LIBRARIES, and in Debug build mode this builds fine.
the second commit removes the dependency to boost::regex, it was causing troubles in Release build mode.
I simply switched the c++11 mode on, and moved from boost::regex to std::regex.",True,{}
colmap/colmap,https://github.com/colmap/colmap,518,2018-11-15T09:53:46Z,,2022-01-26T12:22:15Z,OPEN,False,22,25,2,https://github.com/andijcr,compability fix for ubuntu 18.10,2,[],https://github.com/colmap/colmap/pull/518,https://github.com/alexmyczko,2,https://github.com/colmap/colmap/pull/518#issuecomment-546892256,"Hi, i was having trouble linking under the combination Ubuntu 18.10, cuda-8 and g++-5, so i made these two small changes.
The first commit unifies in the CMakeLists.txt the OPENGL_gl_LIBRARY and OPENGL_glu_LIBRARY into OPENGL_LIBRARIES, and in Debug build mode this builds fine.
the second commit removes the dependency to boost::regex, it was causing troubles in Release build mode.
I simply switched the c++11 mode on, and moved from boost::regex to std::regex.",it works fine with gcc-7 + cuda-10-0 on ubuntu 18.04 here,True,{}
colmap/colmap,https://github.com/colmap/colmap,520,2018-11-16T18:58:10Z,2020-08-30T19:09:38Z,2020-08-30T19:09:38Z,CLOSED,False,24,26,2,https://github.com/BertaBescos,remove boost::regex dependency,3,[],https://github.com/colmap/colmap/pull/520,https://github.com/BertaBescos,1,https://github.com/colmap/colmap/pull/520,"I was able to compile by removing the boost/regex dependency (I just replaced every boost:: for std:: in the bitmap.cc file, similar to what is suggested in this issue (#36), and removing the regex dependency in the CMakeLists.txt. Actually, since this is the only place where boost/regex is used, and since it seems to be of an issue for other people, I will make a pull request with this change if that's ok.","I was able to compile by removing the boost/regex dependency (I just replaced every boost:: for std:: in the bitmap.cc file, similar to what is suggested in this issue (#36), and removing the regex dependency in the CMakeLists.txt. Actually, since this is the only place where boost/regex is used, and since it seems to be of an issue for other people, I will make a pull request with this change if that's ok.",True,"{'THUMBS_UP': ['https://github.com/areong', 'https://github.com/attilaolah', 'https://github.com/Eberty']}"
colmap/colmap,https://github.com/colmap/colmap,520,2018-11-16T18:58:10Z,2020-08-30T19:09:38Z,2020-08-30T19:09:38Z,CLOSED,False,24,26,2,https://github.com/BertaBescos,remove boost::regex dependency,3,[],https://github.com/colmap/colmap/pull/520,https://github.com/mgprt,2,https://github.com/colmap/colmap/pull/520#issuecomment-439921415,"I was able to compile by removing the boost/regex dependency (I just replaced every boost:: for std:: in the bitmap.cc file, similar to what is suggested in this issue (#36), and removing the regex dependency in the CMakeLists.txt. Actually, since this is the only place where boost/regex is used, and since it seems to be of an issue for other people, I will make a pull request with this change if that's ok.","Note that std::regex support was experimental and basically broken for GCC < 4.9 (see https://stackoverflow.com/a/12665408), so this could lead to bugs on older systems (e.g. Ubuntu 14.04, which is still supported).",True,{}
colmap/colmap,https://github.com/colmap/colmap,520,2018-11-16T18:58:10Z,2020-08-30T19:09:38Z,2020-08-30T19:09:38Z,CLOSED,False,24,26,2,https://github.com/BertaBescos,remove boost::regex dependency,3,[],https://github.com/colmap/colmap/pull/520,https://github.com/tompollok,3,https://github.com/colmap/colmap/pull/520#issuecomment-444227130,"I was able to compile by removing the boost/regex dependency (I just replaced every boost:: for std:: in the bitmap.cc file, similar to what is suggested in this issue (#36), and removing the regex dependency in the CMakeLists.txt. Actually, since this is the only place where boost/regex is used, and since it seems to be of an issue for other people, I will make a pull request with this change if that's ok.","Ubuntu 14.04 LTS is supported only until April 2019, which is very soon. There is already 16.04 and 18.04. I dont see why anybody should care to much about supporting old compilers in favour of using std library functionality.",True,{}
colmap/colmap,https://github.com/colmap/colmap,520,2018-11-16T18:58:10Z,2020-08-30T19:09:38Z,2020-08-30T19:09:38Z,CLOSED,False,24,26,2,https://github.com/BertaBescos,remove boost::regex dependency,3,[],https://github.com/colmap/colmap/pull/520,https://github.com/ahojnnes,4,https://github.com/colmap/colmap/pull/520#issuecomment-444778386,"I was able to compile by removing the boost/regex dependency (I just replaced every boost:: for std:: in the bitmap.cc file, similar to what is suggested in this issue (#36), and removing the regex dependency in the CMakeLists.txt. Actually, since this is the only place where boost/regex is used, and since it seems to be of an issue for other people, I will make a pull request with this change if that's ok.","I am against breaking Ubuntu 14.04 for no reason and even if we break Ubuntu 14.04, then we should make sure there is a warning or something, because this is a silent bug that is not visible to the user. The regex just doesn’t work. In any case, there should be a way to make this work both under 14.04 and 18.10 - worst case with separate ifdef branches.",True,{}
colmap/colmap,https://github.com/colmap/colmap,520,2018-11-16T18:58:10Z,2020-08-30T19:09:38Z,2020-08-30T19:09:38Z,CLOSED,False,24,26,2,https://github.com/BertaBescos,remove boost::regex dependency,3,[],https://github.com/colmap/colmap/pull/520,https://github.com/Eberty,5,https://github.com/colmap/colmap/pull/520#issuecomment-640068521,"I was able to compile by removing the boost/regex dependency (I just replaced every boost:: for std:: in the bitmap.cc file, similar to what is suggested in this issue (#36), and removing the regex dependency in the CMakeLists.txt. Actually, since this is the only place where boost/regex is used, and since it seems to be of an issue for other people, I will make a pull request with this change if that's ok.",It is possible make an ifdef on bitmap.cc to solve this issue?,True,{}
colmap/colmap,https://github.com/colmap/colmap,520,2018-11-16T18:58:10Z,2020-08-30T19:09:38Z,2020-08-30T19:09:38Z,CLOSED,False,24,26,2,https://github.com/BertaBescos,remove boost::regex dependency,3,[],https://github.com/colmap/colmap/pull/520,https://github.com/attilaolah,6,https://github.com/colmap/colmap/pull/520#issuecomment-651846611,"I was able to compile by removing the boost/regex dependency (I just replaced every boost:: for std:: in the bitmap.cc file, similar to what is suggested in this issue (#36), and removing the regex dependency in the CMakeLists.txt. Actually, since this is the only place where boost/regex is used, and since it seems to be of an issue for other people, I will make a pull request with this change if that's ok.","I am against breaking Ubuntu 14.04 for no reason […]

I think the reason was the compilation error. That said, 14.04 is no longer supported, I don't think it's worth the complexity introduced by adding an #ifdef guard.
At some point, this pull request should probably be merged, and people who have trouble compiling it on old systems can still reverse-apply the patch.",True,{}
colmap/colmap,https://github.com/colmap/colmap,520,2018-11-16T18:58:10Z,2020-08-30T19:09:38Z,2020-08-30T19:09:38Z,CLOSED,False,24,26,2,https://github.com/BertaBescos,remove boost::regex dependency,3,[],https://github.com/colmap/colmap/pull/520,https://github.com/ahojnnes,7,https://github.com/colmap/colmap/pull/520#issuecomment-683458235,"I was able to compile by removing the boost/regex dependency (I just replaced every boost:: for std:: in the bitmap.cc file, similar to what is suggested in this issue (#36), and removing the regex dependency in the CMakeLists.txt. Actually, since this is the only place where boost/regex is used, and since it seems to be of an issue for other people, I will make a pull request with this change if that's ok.",Resolved with the latest commit in the dev branch. Thanks!,True,{}
colmap/colmap,https://github.com/colmap/colmap,521,2018-11-17T18:03:37Z,2018-11-19T21:42:35Z,2018-11-19T21:42:35Z,MERGED,True,2,2,1,https://github.com/puzzlepaint,SiftGPU: Fix mismatched malloc-delete,1,[],https://github.com/colmap/colmap/pull/521,https://github.com/puzzlepaint,1,https://github.com/colmap/colmap/pull/521,"According to valgrind, for the allocation in __matcher = new SiftMatchCU(__max_sift); in SiftMatch.cpp, the custom new operator overload of SiftMatchGPU seems to be used. It uses malloc() internally. However, in the SiftMatchGPU destructor, the __matcher object is deleted using delete. This means that the malloc is mismatched with delete instead of free.
One possible solution is to use the global new to allocate __matcher, as proposed in this PR. However, I'm not entirely sure what the custom new's purpose is - the reasoning in a header file has something to do with some MSVC compiler flags I am not familiar with, but it seems like it might only be intended for allocation of SiftMatchGPU objects:
	//overload the new operator because delete operator is virtual
	//and it is operating on the heap inside the dll (due to the
	//compiler setting of /MT and /MTd). Without the overloaded operator
	//deleting a SiftGPU object will cause a heap corruption in the
	//static link case (but not for the runtime dll loading).

The alternative solution if it is desired to keep using the custom new would be to replace the delete in the destructor with free.","According to valgrind, for the allocation in __matcher = new SiftMatchCU(__max_sift); in SiftMatch.cpp, the custom new operator overload of SiftMatchGPU seems to be used. It uses malloc() internally. However, in the SiftMatchGPU destructor, the __matcher object is deleted using delete. This means that the malloc is mismatched with delete instead of free.
One possible solution is to use the global new to allocate __matcher, as proposed in this PR. However, I'm not entirely sure what the custom new's purpose is - the reasoning in a header file has something to do with some MSVC compiler flags I am not familiar with, but it seems like it might only be intended for allocation of SiftMatchGPU objects:
	//overload the new operator because delete operator is virtual
	//and it is operating on the heap inside the dll (due to the
	//compiler setting of /MT and /MTd). Without the overloaded operator
	//deleting a SiftGPU object will cause a heap corruption in the
	//static link case (but not for the runtime dll loading).

The alternative solution if it is desired to keep using the custom new would be to replace the delete in the destructor with free.",True,{}
colmap/colmap,https://github.com/colmap/colmap,521,2018-11-17T18:03:37Z,2018-11-19T21:42:35Z,2018-11-19T21:42:35Z,MERGED,True,2,2,1,https://github.com/puzzlepaint,SiftGPU: Fix mismatched malloc-delete,1,[],https://github.com/colmap/colmap/pull/521,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/521#issuecomment-440051776,"According to valgrind, for the allocation in __matcher = new SiftMatchCU(__max_sift); in SiftMatch.cpp, the custom new operator overload of SiftMatchGPU seems to be used. It uses malloc() internally. However, in the SiftMatchGPU destructor, the __matcher object is deleted using delete. This means that the malloc is mismatched with delete instead of free.
One possible solution is to use the global new to allocate __matcher, as proposed in this PR. However, I'm not entirely sure what the custom new's purpose is - the reasoning in a header file has something to do with some MSVC compiler flags I am not familiar with, but it seems like it might only be intended for allocation of SiftMatchGPU objects:
	//overload the new operator because delete operator is virtual
	//and it is operating on the heap inside the dll (due to the
	//compiler setting of /MT and /MTd). Without the overloaded operator
	//deleting a SiftGPU object will cause a heap corruption in the
	//static link case (but not for the runtime dll loading).

The alternative solution if it is desired to keep using the custom new would be to replace the delete in the destructor with free.","Thanks very much Thomas, looks good to me!",True,{}
colmap/colmap,https://github.com/colmap/colmap,522,2018-11-18T17:10:46Z,2018-11-28T20:22:27Z,2018-11-29T11:55:18Z,MERGED,True,146,8,8,https://github.com/puzzlepaint,Implement masking of images in feature extraction,1,[],https://github.com/colmap/colmap/pull/522,https://github.com/puzzlepaint,1,https://github.com/colmap/colmap/pull/522,"This implements masking of images for feature extraction (by removing extracted features at masked-out image locations). Corresponds to issue #208 (regarding sparse features; does not implement masking for dense reconstruction).
Two new image extraction parameters are introduced:

ImageReader.mask_path to specify a root directory for per-image masks:

  // Optional root path to folder which contains image masks. For a given image,
  // the corresponding mask must have the same sub-path below this root as the
  // image has below image_path. The filename must be equal, aside from the
  // added extension .png. For example, for an image image_path/abc/012.jpg, the
  // mask would be mask_path/abc/012.jpg.png. No features will be extracted in
  // regions where the mask image is black (pixel intensity value 0 in
  // grayscale).


ImageReader.camera_mask_path to specify the file path of a mask that globally applies to all images:

  // Optional path to an image file specifying a mask for all images. No
  // features will be extracted in regions where the mask is black (pixel
  // intensity value 0 in grayscale).

Open points:

I did not run clang-format, since the version I have installed outputs the following error:

[...]/colmap/.clang-format: Invalid argument
Can't find usable .clang-format, using LLVM style
YAML:21:29: error: invalid boolean
BreakBeforeBinaryOperators: None
                            ^~~~


The two new options are not self-explanatory. In the options list widget for feature extraction, there should ideally be some documentation on them.
The options list for feature extraction becomes quite long vertically. At some point it will reach or has reached a point where it won't fit on small screens. Introducing a scroll bar would help.","This implements masking of images for feature extraction (by removing extracted features at masked-out image locations). Corresponds to issue #208 (regarding sparse features; does not implement masking for dense reconstruction).
Two new image extraction parameters are introduced:

ImageReader.mask_path to specify a root directory for per-image masks:

  // Optional root path to folder which contains image masks. For a given image,
  // the corresponding mask must have the same sub-path below this root as the
  // image has below image_path. The filename must be equal, aside from the
  // added extension .png. For example, for an image image_path/abc/012.jpg, the
  // mask would be mask_path/abc/012.jpg.png. No features will be extracted in
  // regions where the mask image is black (pixel intensity value 0 in
  // grayscale).


ImageReader.camera_mask_path to specify the file path of a mask that globally applies to all images:

  // Optional path to an image file specifying a mask for all images. No
  // features will be extracted in regions where the mask is black (pixel
  // intensity value 0 in grayscale).

Open points:

I did not run clang-format, since the version I have installed outputs the following error:

[...]/colmap/.clang-format: Invalid argument
Can't find usable .clang-format, using LLVM style
YAML:21:29: error: invalid boolean
BreakBeforeBinaryOperators: None
                            ^~~~


The two new options are not self-explanatory. In the options list widget for feature extraction, there should ideally be some documentation on them.
The options list for feature extraction becomes quite long vertically. At some point it will reach or has reached a point where it won't fit on small screens. Introducing a scroll bar would help.",True,{}
colmap/colmap,https://github.com/colmap/colmap,522,2018-11-18T17:10:46Z,2018-11-28T20:22:27Z,2018-11-29T11:55:18Z,MERGED,True,146,8,8,https://github.com/puzzlepaint,Implement masking of images in feature extraction,1,[],https://github.com/colmap/colmap/pull/522,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/522#issuecomment-442593448,"This implements masking of images for feature extraction (by removing extracted features at masked-out image locations). Corresponds to issue #208 (regarding sparse features; does not implement masking for dense reconstruction).
Two new image extraction parameters are introduced:

ImageReader.mask_path to specify a root directory for per-image masks:

  // Optional root path to folder which contains image masks. For a given image,
  // the corresponding mask must have the same sub-path below this root as the
  // image has below image_path. The filename must be equal, aside from the
  // added extension .png. For example, for an image image_path/abc/012.jpg, the
  // mask would be mask_path/abc/012.jpg.png. No features will be extracted in
  // regions where the mask image is black (pixel intensity value 0 in
  // grayscale).


ImageReader.camera_mask_path to specify the file path of a mask that globally applies to all images:

  // Optional path to an image file specifying a mask for all images. No
  // features will be extracted in regions where the mask is black (pixel
  // intensity value 0 in grayscale).

Open points:

I did not run clang-format, since the version I have installed outputs the following error:

[...]/colmap/.clang-format: Invalid argument
Can't find usable .clang-format, using LLVM style
YAML:21:29: error: invalid boolean
BreakBeforeBinaryOperators: None
                            ^~~~


The two new options are not self-explanatory. In the options list widget for feature extraction, there should ideally be some documentation on them.
The options list for feature extraction becomes quite long vertically. At some point it will reach or has reached a point where it won't fit on small screens. Introducing a scroll bar would help.",Thanks again Thomas. Made the changes myself.,True,{}
colmap/colmap,https://github.com/colmap/colmap,522,2018-11-18T17:10:46Z,2018-11-28T20:22:27Z,2018-11-29T11:55:18Z,MERGED,True,146,8,8,https://github.com/puzzlepaint,Implement masking of images in feature extraction,1,[],https://github.com/colmap/colmap/pull/522,https://github.com/puzzlepaint,3,https://github.com/colmap/colmap/pull/522#issuecomment-442800490,"This implements masking of images for feature extraction (by removing extracted features at masked-out image locations). Corresponds to issue #208 (regarding sparse features; does not implement masking for dense reconstruction).
Two new image extraction parameters are introduced:

ImageReader.mask_path to specify a root directory for per-image masks:

  // Optional root path to folder which contains image masks. For a given image,
  // the corresponding mask must have the same sub-path below this root as the
  // image has below image_path. The filename must be equal, aside from the
  // added extension .png. For example, for an image image_path/abc/012.jpg, the
  // mask would be mask_path/abc/012.jpg.png. No features will be extracted in
  // regions where the mask image is black (pixel intensity value 0 in
  // grayscale).


ImageReader.camera_mask_path to specify the file path of a mask that globally applies to all images:

  // Optional path to an image file specifying a mask for all images. No
  // features will be extracted in regions where the mask is black (pixel
  // intensity value 0 in grayscale).

Open points:

I did not run clang-format, since the version I have installed outputs the following error:

[...]/colmap/.clang-format: Invalid argument
Can't find usable .clang-format, using LLVM style
YAML:21:29: error: invalid boolean
BreakBeforeBinaryOperators: None
                            ^~~~


The two new options are not self-explanatory. In the options list widget for feature extraction, there should ideally be some documentation on them.
The options list for feature extraction becomes quite long vertically. At some point it will reach or has reached a point where it won't fit on small screens. Introducing a scroll bar would help.","Thanks for picking this up. I intended to implement your comments, but had not re-gained my motivation after the recent CVPR supplementary material deadline yet.",True,{}
colmap/colmap,https://github.com/colmap/colmap,545,2018-12-27T11:00:45Z,2019-01-08T20:05:13Z,2019-01-08T20:05:59Z,CLOSED,False,1,1,1,https://github.com/is03wlei,Fix image viewer widget.,3,[],https://github.com/colmap/colmap/pull/545,https://github.com/is03wlei,1,https://github.com/colmap/colmap/pull/545,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,545,2018-12-27T11:00:45Z,2019-01-08T20:05:13Z,2019-01-08T20:05:59Z,CLOSED,False,1,1,1,https://github.com/is03wlei,Fix image viewer widget.,3,[],https://github.com/colmap/colmap/pull/545,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/545#issuecomment-450548939,,"Thanks for the pull request, but the intention of the viewer is to show the image with and without keypoints. The two different colors for keypoints indicate whether they are triangulated or not. To make them better distinguishable, we could change the color from red to green. What was the motivation for the change here?",True,{}
colmap/colmap,https://github.com/colmap/colmap,545,2018-12-27T11:00:45Z,2019-01-08T20:05:13Z,2019-01-08T20:05:59Z,CLOSED,False,1,1,1,https://github.com/is03wlei,Fix image viewer widget.,3,[],https://github.com/colmap/colmap/pull/545,https://github.com/is03wlei,3,https://github.com/colmap/colmap/pull/545#issuecomment-451344340,,"Sorry, I thought it was to switch between 2D and 3D points.
As you said, now it's very difficult to see 3D points among lots of 2D points.",True,{}
colmap/colmap,https://github.com/colmap/colmap,545,2018-12-27T11:00:45Z,2019-01-08T20:05:13Z,2019-01-08T20:05:59Z,CLOSED,False,1,1,1,https://github.com/is03wlei,Fix image viewer widget.,3,[],https://github.com/colmap/colmap/pull/545,https://github.com/ahojnnes,4,https://github.com/colmap/colmap/pull/545#issuecomment-452433767,,"No problem, thanks for bringing this up anyway. If you have an idea on how to improve the visualization, a new PR or enhancement proposal would be welcome.",True,{}
colmap/colmap,https://github.com/colmap/colmap,549,2019-01-09T16:17:17Z,2019-01-09T20:29:45Z,2019-01-09T20:29:45Z,MERGED,True,6,2,1,https://github.com/trueprice,Avoid using database transactions during vocabulary tree matching,4,[],https://github.com/colmap/colmap/pull/549,https://github.com/trueprice,1,https://github.com/colmap/colmap/pull/549,"Addresses Issue #527.
I added transactions for the other matching methods that don't have multithreaded database accesses, so the behavior should be the same as before for those. In addition to checking vocabulary tree matching on a large dataset, I also checked that exhaustive and sequential matching still work on the South Building dataset.","Addresses Issue #527.
I added transactions for the other matching methods that don't have multithreaded database accesses, so the behavior should be the same as before for those. In addition to checking vocabulary tree matching on a large dataset, I also checked that exhaustive and sequential matching still work on the South Building dataset.",True,{}
colmap/colmap,https://github.com/colmap/colmap,549,2019-01-09T16:17:17Z,2019-01-09T20:29:45Z,2019-01-09T20:29:45Z,MERGED,True,6,2,1,https://github.com/trueprice,Avoid using database transactions during vocabulary tree matching,4,[],https://github.com/colmap/colmap/pull/549,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/549#issuecomment-452845155,"Addresses Issue #527.
I added transactions for the other matching methods that don't have multithreaded database accesses, so the behavior should be the same as before for those. In addition to checking vocabulary tree matching on a large dataset, I also checked that exhaustive and sequential matching still work on the South Building dataset.","Wonderful, thanks very much!",True,{}
colmap/colmap,https://github.com/colmap/colmap,561,2019-01-28T21:50:25Z,2019-01-31T07:18:31Z,2019-07-03T08:53:44Z,MERGED,True,20,5,1,https://github.com/byungsoo-motion,updated readme file for recon from known camera poses.,1,[],https://github.com/colmap/colmap/pull/561,https://github.com/byungsoo-motion,1,https://github.com/colmap/colmap/pull/561,Added detailed instruction how to prepare data properly for recon with known camera poses for newbies (including myself).,Added detailed instruction how to prepare data properly for recon with known camera poses for newbies (including myself).,True,{}
colmap/colmap,https://github.com/colmap/colmap,561,2019-01-28T21:50:25Z,2019-01-31T07:18:31Z,2019-07-03T08:53:44Z,MERGED,True,20,5,1,https://github.com/byungsoo-motion,updated readme file for recon from known camera poses.,1,[],https://github.com/colmap/colmap/pull/561,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/561#issuecomment-459241851,Added detailed instruction how to prepare data properly for recon with known camera poses for newbies (including myself).,Thanks!,True,{}
colmap/colmap,https://github.com/colmap/colmap,563,2019-01-30T08:58:14Z,2019-01-31T07:31:04Z,2019-01-31T07:31:13Z,MERGED,True,1,1,1,https://github.com/drkoller,Fix pathname for delaunay_mesher example in CLI docs,1,[],https://github.com/colmap/colmap/pull/563,https://github.com/drkoller,1,https://github.com/colmap/colmap/pull/563,This PR fixes an error in the delaunay_mesher command-line example in the documentation.,This PR fixes an error in the delaunay_mesher command-line example in the documentation.,True,{}
colmap/colmap,https://github.com/colmap/colmap,563,2019-01-30T08:58:14Z,2019-01-31T07:31:04Z,2019-01-31T07:31:13Z,MERGED,True,1,1,1,https://github.com/drkoller,Fix pathname for delaunay_mesher example in CLI docs,1,[],https://github.com/colmap/colmap/pull/563,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/563#issuecomment-459244666,This PR fixes an error in the delaunay_mesher command-line example in the documentation.,Thanks for the fix!,True,{}
colmap/colmap,https://github.com/colmap/colmap,577,2019-02-17T08:45:08Z,2019-02-17T09:40:23Z,2019-02-17T09:40:24Z,MERGED,True,4,4,1,https://github.com/sniklaus,fix compare_points,1,[],https://github.com/colmap/colmap/pull/577,https://github.com/sniklaus,1,https://github.com/colmap/colmap/pull/577,This is a really minor fix but I might as well make you aware of it. Huge thanks Johannes!,This is a really minor fix but I might as well make you aware of it. Huge thanks Johannes!,True,{}
colmap/colmap,https://github.com/colmap/colmap,577,2019-02-17T08:45:08Z,2019-02-17T09:40:23Z,2019-02-17T09:40:24Z,MERGED,True,4,4,1,https://github.com/sniklaus,fix compare_points,1,[],https://github.com/colmap/colmap/pull/577,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/577#issuecomment-464434741,This is a really minor fix but I might as well make you aware of it. Huge thanks Johannes!,Thanks for the fix!,True,{}
colmap/colmap,https://github.com/colmap/colmap,586,2019-03-03T18:26:48Z,2019-08-15T19:12:48Z,2021-01-05T10:13:11Z,MERGED,True,173,0,3,https://github.com/tsattler,added functionality to undistort images without the need for a 3D model,1,[],https://github.com/colmap/colmap/pull/586,https://github.com/tsattler,1,https://github.com/colmap/colmap/pull/586,"Implements functionality to undistort images without a 3D reconstruction by adding a new option to the colmap executable: colmap image_undistorter_standalone.
Rather than reading the image names and camera parameters from a reconstruction, colmap image_undistorter_standalone loads this information from a text file (paramter --input_file. Each line in the text file specifies the filename of an image and its camera parameters. Here is an example:
day_hq/day_hq_00013.jpg SIMPLE_RADIAL_FISHEYE 1280 720 467.338 640 360 0.20964","Implements functionality to undistort images without a 3D reconstruction by adding a new option to the colmap executable: colmap image_undistorter_standalone.
Rather than reading the image names and camera parameters from a reconstruction, colmap image_undistorter_standalone loads this information from a text file (paramter --input_file. Each line in the text file specifies the filename of an image and its camera parameters. Here is an example:
day_hq/day_hq_00013.jpg SIMPLE_RADIAL_FISHEYE 1280 720 467.338 640 360 0.20964",True,{}
colmap/colmap,https://github.com/colmap/colmap,586,2019-03-03T18:26:48Z,2019-08-15T19:12:48Z,2021-01-05T10:13:11Z,MERGED,True,173,0,3,https://github.com/tsattler,added functionality to undistort images without the need for a 3D model,1,[],https://github.com/colmap/colmap/pull/586,https://github.com/tsattler,2,https://github.com/colmap/colmap/pull/586#issuecomment-490436143,"Implements functionality to undistort images without a 3D reconstruction by adding a new option to the colmap executable: colmap image_undistorter_standalone.
Rather than reading the image names and camera parameters from a reconstruction, colmap image_undistorter_standalone loads this information from a text file (paramter --input_file. Each line in the text file specifies the filename of an image and its camera parameters. Here is an example:
day_hq/day_hq_00013.jpg SIMPLE_RADIAL_FISHEYE 1280 720 467.338 640 360 0.20964",@ahojnnes Just a quick ping to see whether this is still interesting for you.,True,{}
colmap/colmap,https://github.com/colmap/colmap,586,2019-03-03T18:26:48Z,2019-08-15T19:12:48Z,2021-01-05T10:13:11Z,MERGED,True,173,0,3,https://github.com/tsattler,added functionality to undistort images without the need for a 3D model,1,[],https://github.com/colmap/colmap/pull/586,https://github.com/ahojnnes,3,https://github.com/colmap/colmap/pull/586#issuecomment-491355187,"Implements functionality to undistort images without a 3D reconstruction by adding a new option to the colmap executable: colmap image_undistorter_standalone.
Rather than reading the image names and camera parameters from a reconstruction, colmap image_undistorter_standalone loads this information from a text file (paramter --input_file. Each line in the text file specifies the filename of an image and its camera parameters. Here is an example:
day_hq/day_hq_00013.jpg SIMPLE_RADIAL_FISHEYE 1280 720 467.338 640 360 0.20964",I am still interested but was too busy to have a look at this. Will try to check it out over the next days. Sorry!,True,{}
colmap/colmap,https://github.com/colmap/colmap,586,2019-03-03T18:26:48Z,2019-08-15T19:12:48Z,2021-01-05T10:13:11Z,MERGED,True,173,0,3,https://github.com/tsattler,added functionality to undistort images without the need for a 3D model,1,[],https://github.com/colmap/colmap/pull/586,https://github.com/tsattler,4,https://github.com/colmap/colmap/pull/586#issuecomment-516380946,"Implements functionality to undistort images without a 3D reconstruction by adding a new option to the colmap executable: colmap image_undistorter_standalone.
Rather than reading the image names and camera parameters from a reconstruction, colmap image_undistorter_standalone loads this information from a text file (paramter --input_file. Each line in the text file specifies the filename of an image and its camera parameters. Here is an example:
day_hq/day_hq_00013.jpg SIMPLE_RADIAL_FISHEYE 1280 720 467.338 640 360 0.20964",@ahojnnes Just a quick ping to see whether you still want to merge this.,True,{}
colmap/colmap,https://github.com/colmap/colmap,586,2019-03-03T18:26:48Z,2019-08-15T19:12:48Z,2021-01-05T10:13:11Z,MERGED,True,173,0,3,https://github.com/tsattler,added functionality to undistort images without the need for a 3D model,1,[],https://github.com/colmap/colmap/pull/586,https://github.com/ez4lionky,5,https://github.com/colmap/colmap/pull/586#issuecomment-754368079,"Implements functionality to undistort images without a 3D reconstruction by adding a new option to the colmap executable: colmap image_undistorter_standalone.
Rather than reading the image names and camera parameters from a reconstruction, colmap image_undistorter_standalone loads this information from a text file (paramter --input_file. Each line in the text file specifies the filename of an image and its camera parameters. Here is an example:
day_hq/day_hq_00013.jpg SIMPLE_RADIAL_FISHEYE 1280 720 467.338 640 360 0.20964","Implements functionality to undistort images without a 3D reconstruction by adding a new option to the colmap executable: colmap image_undistorter_standalone.
Rather than reading the image names and camera parameters from a reconstruction, colmap image_undistorter_standalone loads this information from a text file (paramter --input_file. Each line in the text file specifies the filename of an image and its camera parameters. Here is an example:
day_hq/day_hq_00013.jpg SIMPLE_RADIAL_FISHEYE 1280 720 467.338 640 360 0.20964

@tsattler
Hi, sattler
It seems like the image undistort program only outputs undistorted images, but don't dump the undistorted camera into the disk.
Did I miss something?",True,{}
colmap/colmap,https://github.com/colmap/colmap,586,2019-03-03T18:26:48Z,2019-08-15T19:12:48Z,2021-01-05T10:13:11Z,MERGED,True,173,0,3,https://github.com/tsattler,added functionality to undistort images without the need for a 3D model,1,[],https://github.com/colmap/colmap/pull/586,https://github.com/tsattler,6,https://github.com/colmap/colmap/pull/586#issuecomment-754542282,"Implements functionality to undistort images without a 3D reconstruction by adding a new option to the colmap executable: colmap image_undistorter_standalone.
Rather than reading the image names and camera parameters from a reconstruction, colmap image_undistorter_standalone loads this information from a text file (paramter --input_file. Each line in the text file specifies the filename of an image and its camera parameters. Here is an example:
day_hq/day_hq_00013.jpg SIMPLE_RADIAL_FISHEYE 1280 720 467.338 640 360 0.20964","@ez4lionky Indeed, the program does not output the camera parameters of the undistorted images.",True,{}
colmap/colmap,https://github.com/colmap/colmap,590,2019-03-08T05:58:52Z,2019-06-14T13:22:58Z,2019-06-14T13:22:58Z,CLOSED,False,2,2,1,https://github.com/mdaiter,Update maps to unordered for faster access/emplace times,1,[],https://github.com/colmap/colmap/pull/590,https://github.com/mdaiter,1,https://github.com/colmap/colmap/pull/590,Just caught my eye: unordered_maps will let you create faster emplace and count commands (due to hashing) and avoid the unnecessary ordering that std::map includes.,Just caught my eye: unordered_maps will let you create faster emplace and count commands (due to hashing) and avoid the unnecessary ordering that std::map includes.,True,{}
colmap/colmap,https://github.com/colmap/colmap,590,2019-03-08T05:58:52Z,2019-06-14T13:22:58Z,2019-06-14T13:22:58Z,CLOSED,False,2,2,1,https://github.com/mdaiter,Update maps to unordered for faster access/emplace times,1,[],https://github.com/colmap/colmap/pull/590,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/590#issuecomment-485490662,Just caught my eye: unordered_maps will let you create faster emplace and count commands (due to hashing) and avoid the unnecessary ordering that std::map includes.,"Doesn’t seem like this should be any bottleneck here. For small sized maps (like this one), std::map is often faster. Did you profile the performance here?",True,{}
colmap/colmap,https://github.com/colmap/colmap,591,2019-03-13T16:45:24Z,2019-03-14T08:17:38Z,2019-03-14T08:17:38Z,MERGED,True,8,5,3,https://github.com/mgprt, Return squared cosine distance as residuals in GP3PEstimator. ,2,[],https://github.com/colmap/colmap/pull/591,https://github.com/mgprt,1,https://github.com/colmap/colmap/pull/591,This makes the GP3PEstimator consistent with all other estimators which return the squared distance (and RANSAC using the squared threshold for comparison).,This makes the GP3PEstimator consistent with all other estimators which return the squared distance (and RANSAC using the squared threshold for comparison).,True,{}
colmap/colmap,https://github.com/colmap/colmap,591,2019-03-13T16:45:24Z,2019-03-14T08:17:38Z,2019-03-14T08:17:38Z,MERGED,True,8,5,3,https://github.com/mgprt, Return squared cosine distance as residuals in GP3PEstimator. ,2,[],https://github.com/colmap/colmap/pull/591,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/591#issuecomment-472747613,This makes the GP3PEstimator consistent with all other estimators which return the squared distance (and RANSAC using the squared threshold for comparison).,"Excellent, thank you!",True,{}
colmap/colmap,https://github.com/colmap/colmap,601,2019-04-05T21:30:04Z,2019-04-06T09:27:05Z,2019-04-06T09:27:06Z,MERGED,True,1,0,1,https://github.com/drkoller,Fix PLY file bug inherited from old version of PoissonRecon,1,[],https://github.com/colmap/colmap/pull/601,https://github.com/drkoller,1,https://github.com/colmap/colmap/pull/601,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,601,2019-04-05T21:30:04Z,2019-04-06T09:27:05Z,2019-04-06T09:27:06Z,MERGED,True,1,0,1,https://github.com/drkoller,Fix PLY file bug inherited from old version of PoissonRecon,1,[],https://github.com/colmap/colmap/pull/601,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/601#issuecomment-480489386,,"Thanks for the fix, great!",True,{}
colmap/colmap,https://github.com/colmap/colmap,609,2019-04-19T15:32:41Z,2019-04-20T06:45:13Z,2019-04-20T06:45:13Z,MERGED,True,18,18,1,https://github.com/gerardobort,Updated documentation for patch_match_stereo CLI options,1,[],https://github.com/colmap/colmap/pull/609,https://github.com/gerardobort,1,https://github.com/colmap/colmap/pull/609,"Hi,
Just found that the FAQ documentation for patch_match_stereo was out of date since the options changed from --DenseStereo.* to --PatchMatchStereo.* (3.5-dev.2 f1ec0be).
Tis PR fixes that part of the documentation.
Thanks,","Hi,
Just found that the FAQ documentation for patch_match_stereo was out of date since the options changed from --DenseStereo.* to --PatchMatchStereo.* (3.5-dev.2 f1ec0be).
Tis PR fixes that part of the documentation.
Thanks,",True,{}
colmap/colmap,https://github.com/colmap/colmap,609,2019-04-19T15:32:41Z,2019-04-20T06:45:13Z,2019-04-20T06:45:13Z,MERGED,True,18,18,1,https://github.com/gerardobort,Updated documentation for patch_match_stereo CLI options,1,[],https://github.com/colmap/colmap/pull/609,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/609#issuecomment-485063265,"Hi,
Just found that the FAQ documentation for patch_match_stereo was out of date since the options changed from --DenseStereo.* to --PatchMatchStereo.* (3.5-dev.2 f1ec0be).
Tis PR fixes that part of the documentation.
Thanks,","Great, thanks!",True,{'HOORAY': ['https://github.com/gerardobort']}
colmap/colmap,https://github.com/colmap/colmap,620,2019-05-23T23:40:01Z,2019-05-24T07:53:52Z,2019-05-24T07:53:52Z,MERGED,True,3,1,1,https://github.com/oleg-alexandrov,CMakeLists: Do not error out if finding CGAL fails,1,[],https://github.com/colmap/colmap/pull/620,https://github.com/oleg-alexandrov,1,https://github.com/colmap/colmap/pull/620,"The following line in CMakeLists.txt
find_package(CGAL QUIET)
causes problems on my system. What worked is to put it in the conditional:
if (CGAL_ENABLED)
find_package(CGAL QUIET)
endif()
I think this makes sense. If the user does not want CGAL, why try searching for it to start with. This fixed it.
Here's the error I get.  It is nasty. CGAL itself exists, but a Qt library having CGAL does not exist.
CMake Error at /usr/lib/x86_64-linux-gnu/cmake/CGAL/CGALExports.cmake:83 (message):
The imported target ""CGAL::CGAL_Qt5"" references the file
 ""/usr/lib/x86_64-linux-gnu/libCGAL_Qt5.so.11.0.1""

but this file does not exist.  Possible reasons include:


The file was deleted, renamed, or moved to another location.


An install or uninstall procedure did not complete successfully.


The installation package was faulty and contained
""/usr/lib/x86_64-linux-gnu/cmake/CGAL/CGALExports.cmake""


but not all the files it references.
Call Stack (most recent call first):
/usr/lib/x86_64-linux-gnu/cmake/CGAL/CGALConfig.cmake:12 (include)
CMakeLists.txt:108 (find_package)
-- Configuring incomplete, errors occurred!
See also ""/home/oalexan1/projects/colmap/CMakeFiles/CMakeOutput.log"".","The following line in CMakeLists.txt
find_package(CGAL QUIET)
causes problems on my system. What worked is to put it in the conditional:
if (CGAL_ENABLED)
find_package(CGAL QUIET)
endif()
I think this makes sense. If the user does not want CGAL, why try searching for it to start with. This fixed it.
Here's the error I get.  It is nasty. CGAL itself exists, but a Qt library having CGAL does not exist.
CMake Error at /usr/lib/x86_64-linux-gnu/cmake/CGAL/CGALExports.cmake:83 (message):
The imported target ""CGAL::CGAL_Qt5"" references the file
 ""/usr/lib/x86_64-linux-gnu/libCGAL_Qt5.so.11.0.1""

but this file does not exist.  Possible reasons include:


The file was deleted, renamed, or moved to another location.


An install or uninstall procedure did not complete successfully.


The installation package was faulty and contained
""/usr/lib/x86_64-linux-gnu/cmake/CGAL/CGALExports.cmake""


but not all the files it references.
Call Stack (most recent call first):
/usr/lib/x86_64-linux-gnu/cmake/CGAL/CGALConfig.cmake:12 (include)
CMakeLists.txt:108 (find_package)
-- Configuring incomplete, errors occurred!
See also ""/home/oalexan1/projects/colmap/CMakeFiles/CMakeOutput.log"".",True,{}
colmap/colmap,https://github.com/colmap/colmap,620,2019-05-23T23:40:01Z,2019-05-24T07:53:52Z,2019-05-24T07:53:52Z,MERGED,True,3,1,1,https://github.com/oleg-alexandrov,CMakeLists: Do not error out if finding CGAL fails,1,[],https://github.com/colmap/colmap/pull/620,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/620#issuecomment-495510479,"The following line in CMakeLists.txt
find_package(CGAL QUIET)
causes problems on my system. What worked is to put it in the conditional:
if (CGAL_ENABLED)
find_package(CGAL QUIET)
endif()
I think this makes sense. If the user does not want CGAL, why try searching for it to start with. This fixed it.
Here's the error I get.  It is nasty. CGAL itself exists, but a Qt library having CGAL does not exist.
CMake Error at /usr/lib/x86_64-linux-gnu/cmake/CGAL/CGALExports.cmake:83 (message):
The imported target ""CGAL::CGAL_Qt5"" references the file
 ""/usr/lib/x86_64-linux-gnu/libCGAL_Qt5.so.11.0.1""

but this file does not exist.  Possible reasons include:


The file was deleted, renamed, or moved to another location.


An install or uninstall procedure did not complete successfully.


The installation package was faulty and contained
""/usr/lib/x86_64-linux-gnu/cmake/CGAL/CGALExports.cmake""


but not all the files it references.
Call Stack (most recent call first):
/usr/lib/x86_64-linux-gnu/cmake/CGAL/CGALConfig.cmake:12 (include)
CMakeLists.txt:108 (find_package)
-- Configuring incomplete, errors occurred!
See also ""/home/oalexan1/projects/colmap/CMakeFiles/CMakeOutput.log"".",This is a good workaround for a bug in an older version of the CGAL package that is shipped in Ubuntu. I saw this problem as well at some point in the past. Thanks and merging.,True,{}
colmap/colmap,https://github.com/colmap/colmap,630,2019-06-14T12:06:37Z,2019-06-14T13:22:44Z,2019-06-14T13:22:44Z,MERGED,True,0,1,1,https://github.com/elmirjagudin,drop unrecognised option from FAQ example,1,[],https://github.com/colmap/colmap/pull/630,https://github.com/elmirjagudin,1,https://github.com/colmap/colmap/pull/630,"Corrects FAQ example in Register/localize new images into an existing reconstruction section.
The colmap image_registrator command does not accept the --image_path argument.","Corrects FAQ example in Register/localize new images into an existing reconstruction section.
The colmap image_registrator command does not accept the --image_path argument.",True,{}
colmap/colmap,https://github.com/colmap/colmap,634,2019-06-17T11:50:12Z,2019-06-22T04:32:19Z,2019-06-22T04:32:19Z,MERGED,True,1,1,1,https://github.com/jbeich,VLFeat: unbreak build with GCC 9,1,[],https://github.com/colmap/colmap/pull/634,https://github.com/jbeich,1,https://github.com/colmap/colmap/pull/634,"Pick up vlfeat/vlfeat#200. See error log.
For master branch. I haven't tested dev yet.","Pick up vlfeat/vlfeat#200. See error log.
For master branch. I haven't tested dev yet.",True,"{'THUMBS_UP': ['https://github.com/bartoszek', 'https://github.com/ahojnnes', 'https://github.com/stolpa4']}"
colmap/colmap,https://github.com/colmap/colmap,634,2019-06-17T11:50:12Z,2019-06-22T04:32:19Z,2019-06-22T04:32:19Z,MERGED,True,1,1,1,https://github.com/jbeich,VLFeat: unbreak build with GCC 9,1,[],https://github.com/colmap/colmap/pull/634,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/634#issuecomment-504364813,"Pick up vlfeat/vlfeat#200. See error log.
For master branch. I haven't tested dev yet.",This is great but I need to merge this into the dev branch first. Can you do me a favor and make the unrelated changes disappear? Thanks!,True,{}
colmap/colmap,https://github.com/colmap/colmap,634,2019-06-17T11:50:12Z,2019-06-22T04:32:19Z,2019-06-22T04:32:19Z,MERGED,True,1,1,1,https://github.com/jbeich,VLFeat: unbreak build with GCC 9,1,[],https://github.com/colmap/colmap/pull/634,https://github.com/jbeich,3,https://github.com/colmap/colmap/pull/634#issuecomment-504379831,"Pick up vlfeat/vlfeat#200. See error log.
For master branch. I haven't tested dev yet.",Sure but you could've merged this PR to master then master into dev.,True,{}
colmap/colmap,https://github.com/colmap/colmap,643,2019-07-05T19:09:01Z,2020-08-09T17:56:18Z,2020-08-09T17:56:18Z,CLOSED,False,17,0,1,https://github.com/fishcu,[image_undistorter] Skip already undistorted images,1,[],https://github.com/colmap/colmap/pull/643,https://github.com/fishcu,1,https://github.com/colmap/colmap/pull/643,"See title.
To be consistent with other behavior in COLMAP, such as feature extraction and patch match stereo, if the output file exists, the processing should be skipped.","See title.
To be consistent with other behavior in COLMAP, such as feature extraction and patch match stereo, if the output file exists, the processing should be skipped.",True,{}
colmap/colmap,https://github.com/colmap/colmap,643,2019-07-05T19:09:01Z,2020-08-09T17:56:18Z,2020-08-09T17:56:18Z,CLOSED,False,17,0,1,https://github.com/fishcu,[image_undistorter] Skip already undistorted images,1,[],https://github.com/colmap/colmap/pull/643,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/643#issuecomment-509101530,"See title.
To be consistent with other behavior in COLMAP, such as feature extraction and patch match stereo, if the output file exists, the processing should be skipped.","I intentionally avoided this, because it has led to problems for people in the past, where they reconstruct the same scene with different parameters and use the same undistortion folder. In this case, the undistorted images do not align with the 3D model and the dense reconstruction will be terrible. Thanks for your contribution but I believe it will be better to just rewrite the undistorted images. Is this a big time saver for you? In that case, we could create a new boolean option “ignore_existing_images” and set it to false.",True,{}
colmap/colmap,https://github.com/colmap/colmap,643,2019-07-05T19:09:01Z,2020-08-09T17:56:18Z,2020-08-09T17:56:18Z,CLOSED,False,17,0,1,https://github.com/fishcu,[image_undistorter] Skip already undistorted images,1,[],https://github.com/colmap/colmap/pull/643,https://github.com/fishcu,3,https://github.com/colmap/colmap/pull/643#issuecomment-509151560,"See title.
To be consistent with other behavior in COLMAP, such as feature extraction and patch match stereo, if the output file exists, the processing should be skipped.","I see. Yes, I have found a (to be honest, niche) use case where this can save substantial amounts of time.
Could you advise me how to implement that boolean option correctly (for example, all the points where it needs to be registered or documented), or could you add that yourself?
It sounds like a good solution (-- keep it at ""true"" by default to avoid the issue you obvserved).",True,{}
colmap/colmap,https://github.com/colmap/colmap,643,2019-07-05T19:09:01Z,2020-08-09T17:56:18Z,2020-08-09T17:56:18Z,CLOSED,False,17,0,1,https://github.com/fishcu,[image_undistorter] Skip already undistorted images,1,[],https://github.com/colmap/colmap/pull/643,https://github.com/ahojnnes,4,https://github.com/colmap/colmap/pull/643#issuecomment-671082156,"See title.
To be consistent with other behavior in COLMAP, such as feature extraction and patch match stereo, if the output file exists, the processing should be skipped.",Closing this as wontfix. Thanks for your suggested contribution.,True,{}
colmap/colmap,https://github.com/colmap/colmap,657,2019-08-04T18:42:31Z,2019-08-05T19:53:05Z,2019-08-05T19:53:05Z,MERGED,True,11,0,4,https://github.com/thunders82,automatic_reconstruction : gui and command line support for mask_path,1,[],https://github.com/colmap/colmap/pull/657,https://github.com/thunders82,1,https://github.com/colmap/colmap/pull/657,"Hi @ahojnnes
Everything is in the title. It's just a cleaned up of the patch I send here : #208 (comment)
and sent as a proper pull request. Let me know if any issues
Cheers,
Geoffrey.","Hi @ahojnnes
Everything is in the title. It's just a cleaned up of the patch I send here : #208 (comment)
and sent as a proper pull request. Let me know if any issues
Cheers,
Geoffrey.",True,{}
colmap/colmap,https://github.com/colmap/colmap,657,2019-08-04T18:42:31Z,2019-08-05T19:53:05Z,2019-08-05T19:53:05Z,MERGED,True,11,0,4,https://github.com/thunders82,automatic_reconstruction : gui and command line support for mask_path,1,[],https://github.com/colmap/colmap/pull/657,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/657#issuecomment-518374968,"Hi @ahojnnes
Everything is in the title. It's just a cleaned up of the patch I send here : #208 (comment)
and sent as a proper pull request. Let me know if any issues
Cheers,
Geoffrey.","Looks great, thanks for the changes.",True,{}
colmap/colmap,https://github.com/colmap/colmap,665,2019-08-29T12:38:00Z,2019-08-30T06:48:09Z,2019-08-30T06:48:17Z,MERGED,True,10,0,1,https://github.com/elmirjagudin,check --input_path and --output_path when running bundle_adjuster command,1,[],https://github.com/colmap/colmap/pull/665,https://github.com/elmirjagudin,1,https://github.com/colmap/colmap/pull/665,"When running bundle_adjust cli command, check that specified
--input_path and --output_path directories exist.
This way we get a nice error message right at the start,
instead of getting a more cryptic error message after
potentially lengthy processing.","When running bundle_adjust cli command, check that specified
--input_path and --output_path directories exist.
This way we get a nice error message right at the start,
instead of getting a more cryptic error message after
potentially lengthy processing.",True,{}
colmap/colmap,https://github.com/colmap/colmap,665,2019-08-29T12:38:00Z,2019-08-30T06:48:09Z,2019-08-30T06:48:17Z,MERGED,True,10,0,1,https://github.com/elmirjagudin,check --input_path and --output_path when running bundle_adjuster command,1,[],https://github.com/colmap/colmap/pull/665,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/665#issuecomment-526481020,"When running bundle_adjust cli command, check that specified
--input_path and --output_path directories exist.
This way we get a nice error message right at the start,
instead of getting a more cryptic error message after
potentially lengthy processing.","Looks great, thanks!",True,{}
colmap/colmap,https://github.com/colmap/colmap,695,2019-09-26T08:27:14Z,2019-10-05T11:24:10Z,2019-10-05T11:24:18Z,MERGED,True,1,1,1,https://github.com/schedldave,signed/unsigned int color bug in matlab/read_model,1,[],https://github.com/colmap/colmap/pull/695,https://github.com/schedldave,1,https://github.com/colmap/colmap/pull/695,"Color values are converted to signed 8bit integer so the range is limited from 0 to 127 (-128 to 127, but negative colors are not used).
The correct type should be UNSIGNED 8bit integer (uint8) so the range is 0 to 255.
This code change fixes this behaviour.","Color values are converted to signed 8bit integer so the range is limited from 0 to 127 (-128 to 127, but negative colors are not used).
The correct type should be UNSIGNED 8bit integer (uint8) so the range is 0 to 255.
This code change fixes this behaviour.",True,{}
colmap/colmap,https://github.com/colmap/colmap,695,2019-09-26T08:27:14Z,2019-10-05T11:24:10Z,2019-10-05T11:24:18Z,MERGED,True,1,1,1,https://github.com/schedldave,signed/unsigned int color bug in matlab/read_model,1,[],https://github.com/colmap/colmap/pull/695,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/695#issuecomment-538641318,"Color values are converted to signed 8bit integer so the range is limited from 0 to 127 (-128 to 127, but negative colors are not used).
The correct type should be UNSIGNED 8bit integer (uint8) so the range is 0 to 255.
This code change fixes this behaviour.",Thank you for the fix!,True,{}
colmap/colmap,https://github.com/colmap/colmap,740,2019-11-20T16:03:00Z,2020-01-03T20:24:09Z,2020-01-03T20:26:20Z,MERGED,True,317,17,3,https://github.com/DaniilSNikulin,flann match,3,[],https://github.com/colmap/colmap/pull/740,https://github.com/DaniilSNikulin,1,https://github.com/colmap/colmap/pull/740,"As noted in this issue, master version of COLMAP use brute force search for pairwise feature matching for both CPU and GPU.
This PR implement ANN search for CPU version of matching.
In my tests, ANN is 6-10 times faster than brute force.
Unfortunately, I could not save dot distance function.
I tried create dot distance function for FLANN:
struct ReverseDotDistance {
  using ElementType = int;
  using ResultType = int;

  template <class Iterator1, class Iterator2>
  ResultType operator()(Iterator1 a, Iterator2 b, size_t size, ResultType /*worst_dist*/ = -1) const {
    ResultType result = ResultType();
    for (size_t i = 0; i < size; ++i) {
      result -= (*a++) * (*b++);
    }
    return result;
  }
};
However, dot distance can't be use in kdtree forest search
Dot distance still can be use in KMeans search (like in this repo), but L2 distance faster and create same result. So i decided use L2 and addinional compute dot for found neighbors.
for (Eigen::MatrixXi::Index d1_idx = 0; d1_idx < indices->rows(); ++d1_idx) {
  for (int n_idx = 0; n_idx < indices->cols(); ++n_idx) {
    const int d2_idx = indices->coeff(d1_idx, n_idx);
    distances->coeffRef(d1_idx, n_idx) = query_int.row(d1_idx).dot(dataset_int.row(d2_idx));
  }
}","As noted in this issue, master version of COLMAP use brute force search for pairwise feature matching for both CPU and GPU.
This PR implement ANN search for CPU version of matching.
In my tests, ANN is 6-10 times faster than brute force.
Unfortunately, I could not save dot distance function.
I tried create dot distance function for FLANN:
struct ReverseDotDistance {
  using ElementType = int;
  using ResultType = int;

  template <class Iterator1, class Iterator2>
  ResultType operator()(Iterator1 a, Iterator2 b, size_t size, ResultType /*worst_dist*/ = -1) const {
    ResultType result = ResultType();
    for (size_t i = 0; i < size; ++i) {
      result -= (*a++) * (*b++);
    }
    return result;
  }
};
However, dot distance can't be use in kdtree forest search
Dot distance still can be use in KMeans search (like in this repo), but L2 distance faster and create same result. So i decided use L2 and addinional compute dot for found neighbors.
for (Eigen::MatrixXi::Index d1_idx = 0; d1_idx < indices->rows(); ++d1_idx) {
  for (int n_idx = 0; n_idx < indices->cols(); ++n_idx) {
    const int d2_idx = indices->coeff(d1_idx, n_idx);
    distances->coeffRef(d1_idx, n_idx) = query_int.row(d1_idx).dot(dataset_int.row(d2_idx));
  }
}",True,{}
colmap/colmap,https://github.com/colmap/colmap,740,2019-11-20T16:03:00Z,2020-01-03T20:24:09Z,2020-01-03T20:26:20Z,MERGED,True,317,17,3,https://github.com/DaniilSNikulin,flann match,3,[],https://github.com/colmap/colmap/pull/740,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/740#issuecomment-560502921,"As noted in this issue, master version of COLMAP use brute force search for pairwise feature matching for both CPU and GPU.
This PR implement ANN search for CPU version of matching.
In my tests, ANN is 6-10 times faster than brute force.
Unfortunately, I could not save dot distance function.
I tried create dot distance function for FLANN:
struct ReverseDotDistance {
  using ElementType = int;
  using ResultType = int;

  template <class Iterator1, class Iterator2>
  ResultType operator()(Iterator1 a, Iterator2 b, size_t size, ResultType /*worst_dist*/ = -1) const {
    ResultType result = ResultType();
    for (size_t i = 0; i < size; ++i) {
      result -= (*a++) * (*b++);
    }
    return result;
  }
};
However, dot distance can't be use in kdtree forest search
Dot distance still can be use in KMeans search (like in this repo), but L2 distance faster and create same result. So i decided use L2 and addinional compute dot for found neighbors.
for (Eigen::MatrixXi::Index d1_idx = 0; d1_idx < indices->rows(); ++d1_idx) {
  for (int n_idx = 0; n_idx < indices->cols(); ++n_idx) {
    const int d2_idx = indices->coeff(d1_idx, n_idx);
    distances->coeffRef(d1_idx, n_idx) = query_int.row(d1_idx).dot(dataset_int.row(d2_idx));
  }
}","Do you have runtime comparisons for different number of features? There could be a potential further speedup when doing matching by computing the search tree only once and reusing it multiple times. In this context, it would be interesting to see the runtime of building the search tree vs. the actual search. Finally, we definitely need unit tests for this.",True,{}
colmap/colmap,https://github.com/colmap/colmap,740,2019-11-20T16:03:00Z,2020-01-03T20:24:09Z,2020-01-03T20:26:20Z,MERGED,True,317,17,3,https://github.com/DaniilSNikulin,flann match,3,[],https://github.com/colmap/colmap/pull/740,https://github.com/ahojnnes,3,https://github.com/colmap/colmap/pull/740#issuecomment-560503006,"As noted in this issue, master version of COLMAP use brute force search for pairwise feature matching for both CPU and GPU.
This PR implement ANN search for CPU version of matching.
In my tests, ANN is 6-10 times faster than brute force.
Unfortunately, I could not save dot distance function.
I tried create dot distance function for FLANN:
struct ReverseDotDistance {
  using ElementType = int;
  using ResultType = int;

  template <class Iterator1, class Iterator2>
  ResultType operator()(Iterator1 a, Iterator2 b, size_t size, ResultType /*worst_dist*/ = -1) const {
    ResultType result = ResultType();
    for (size_t i = 0; i < size; ++i) {
      result -= (*a++) * (*b++);
    }
    return result;
  }
};
However, dot distance can't be use in kdtree forest search
Dot distance still can be use in KMeans search (like in this repo), but L2 distance faster and create same result. So i decided use L2 and addinional compute dot for found neighbors.
for (Eigen::MatrixXi::Index d1_idx = 0; d1_idx < indices->rows(); ++d1_idx) {
  for (int n_idx = 0; n_idx < indices->cols(); ++n_idx) {
    const int d2_idx = indices->coeff(d1_idx, n_idx);
    distances->coeffRef(d1_idx, n_idx) = query_int.row(d1_idx).dot(dataset_int.row(d2_idx));
  }
}","Otherwise, this looks great, thanks for your contribution.",True,{}
colmap/colmap,https://github.com/colmap/colmap,740,2019-11-20T16:03:00Z,2020-01-03T20:24:09Z,2020-01-03T20:26:20Z,MERGED,True,317,17,3,https://github.com/DaniilSNikulin,flann match,3,[],https://github.com/colmap/colmap/pull/740,https://github.com/DaniilSNikulin,4,https://github.com/colmap/colmap/pull/740#issuecomment-568875522,"As noted in this issue, master version of COLMAP use brute force search for pairwise feature matching for both CPU and GPU.
This PR implement ANN search for CPU version of matching.
In my tests, ANN is 6-10 times faster than brute force.
Unfortunately, I could not save dot distance function.
I tried create dot distance function for FLANN:
struct ReverseDotDistance {
  using ElementType = int;
  using ResultType = int;

  template <class Iterator1, class Iterator2>
  ResultType operator()(Iterator1 a, Iterator2 b, size_t size, ResultType /*worst_dist*/ = -1) const {
    ResultType result = ResultType();
    for (size_t i = 0; i < size; ++i) {
      result -= (*a++) * (*b++);
    }
    return result;
  }
};
However, dot distance can't be use in kdtree forest search
Dot distance still can be use in KMeans search (like in this repo), but L2 distance faster and create same result. So i decided use L2 and addinional compute dot for found neighbors.
for (Eigen::MatrixXi::Index d1_idx = 0; d1_idx < indices->rows(); ++d1_idx) {
  for (int n_idx = 0; n_idx < indices->cols(); ++n_idx) {
    const int d2_idx = indices->coeff(d1_idx, n_idx);
    distances->coeffRef(d1_idx, n_idx) = query_int.row(d1_idx).dot(dataset_int.row(d2_idx));
  }
}","Performance testing showed: time of build index for flann is approximately 10% of query time. This correlation don't depend from number of features.



number of features
brute force time
summary flann time
build flann time
query flann time




100
0.0008
0.0082
0.0008
0.0073


200
0.0033
0.0137
0.0016
0.0121


400
0.0163
0.0269
0.0034
0.0235


800
0.0783
0.0552
0.0071
0.0480


1600
0.413
0.116
0.014
0.102


3200
5.65
0.24
0.03
0.21


6400
19.40
0.51
0.06
0.45


12800
55.6
1.2
0.1
1.1


25600
301.6
3.1
0.3
2.8



Build index only one times and memoize it could give a potential further speedup.
However, after I added memoization of flann index to FeatureMatcherCache via LRUCache, no improvements in real tasks were get.
Original flann matching:
==============================================================================
Custom feature matching
==============================================================================

Matching block [1/19] in 26.874s
Matching block [2/19] in 27.055s
Matching block [3/19] in 27.073s
Matching block [4/19] in 27.304s
Matching block [5/19] in 27.428s
Matching block [6/19] in 26.826s
Matching block [7/19] in 27.573s
Matching block [8/19] in 27.272s
Matching block [9/19] in 27.826s
Matching block [10/19] in 27.578s
Matching block [11/19] in 27.290s
Matching block [12/19] in 26.631s
Matching block [13/19] in 26.874s
Matching block [14/19] in 26.993s
Matching block [15/19] in 26.735s
Matching block [16/19] in 27.272s
Matching block [17/19] in 27.308s
Matching block [18/19] in 28.103s
Matching block [19/19] in 22.335s
Elapsed time: 8.539 [minutes]

Flann matching with memoization:
==============================================================================
Custom feature matching
==============================================================================

Matching block [1/19] in 27.616s
Matching block [2/19] in 26.995s
Matching block [3/19] in 27.186s
Matching block [4/19] in 27.508s
Matching block [5/19] in 27.273s
Matching block [6/19] in 27.455s
Matching block [7/19] in 27.234s
Matching block [8/19] in 27.138s
Matching block [9/19] in 27.721s
Matching block [10/19] in 27.569s
Matching block [11/19] in 26.939s
Matching block [12/19] in 26.871s
Matching block [13/19] in 26.907s
Matching block [14/19] in 27.057s
Matching block [15/19] in 26.899s
Matching block [16/19] in 26.750s
Matching block [17/19] in 27.036s
Matching block [18/19] in 28.284s
Matching block [19/19] in 21.933s
Elapsed time: 8.555 [minutes]

The reason for no improvements likely is my bad code,  but I have no idea what exactly slow done it.
The addition of memoization has led to major changes in the code. Cause of memoization did not give
improvements, it is not added in this PR.
Code with memoization could be found here.",True,{}
colmap/colmap,https://github.com/colmap/colmap,740,2019-11-20T16:03:00Z,2020-01-03T20:24:09Z,2020-01-03T20:26:20Z,MERGED,True,317,17,3,https://github.com/DaniilSNikulin,flann match,3,[],https://github.com/colmap/colmap/pull/740,https://github.com/ahojnnes,5,https://github.com/colmap/colmap/pull/740#issuecomment-570688450,"As noted in this issue, master version of COLMAP use brute force search for pairwise feature matching for both CPU and GPU.
This PR implement ANN search for CPU version of matching.
In my tests, ANN is 6-10 times faster than brute force.
Unfortunately, I could not save dot distance function.
I tried create dot distance function for FLANN:
struct ReverseDotDistance {
  using ElementType = int;
  using ResultType = int;

  template <class Iterator1, class Iterator2>
  ResultType operator()(Iterator1 a, Iterator2 b, size_t size, ResultType /*worst_dist*/ = -1) const {
    ResultType result = ResultType();
    for (size_t i = 0; i < size; ++i) {
      result -= (*a++) * (*b++);
    }
    return result;
  }
};
However, dot distance can't be use in kdtree forest search
Dot distance still can be use in KMeans search (like in this repo), but L2 distance faster and create same result. So i decided use L2 and addinional compute dot for found neighbors.
for (Eigen::MatrixXi::Index d1_idx = 0; d1_idx < indices->rows(); ++d1_idx) {
  for (int n_idx = 0; n_idx < indices->cols(); ++n_idx) {
    const int d2_idx = indices->coeff(d1_idx, n_idx);
    distances->coeffRef(d1_idx, n_idx) = query_int.row(d1_idx).dot(dataset_int.row(d2_idx));
  }
}","This is great, I made a few small improvements and merged your PR into the dev branch. Thanks very much for the contribution and for the timings. Since the memoization only brings small runtime improvements, I will go with your suggested changes as is.",True,{}
colmap/colmap,https://github.com/colmap/colmap,743,2019-11-27T23:15:24Z,2019-12-01T21:56:30Z,2019-12-01T21:56:30Z,MERGED,True,14,2,1,https://github.com/drkoller,Fix bug in GpuMat::FillWithScalar() implementation,1,[],https://github.com/colmap/colmap/pull/743,https://github.com/drkoller,1,https://github.com/colmap/colmap/pull/743,"In the COLMAP MVS code, the current implementation of GpuMat::FillWithScalar() does not properly handle GpuMat objects containing multi-byte values. So, this usage of the method:

  
    
      colmap/src/mvs/patch_match_cuda.cu
    
    
        Lines 1633 to 1635
      in
      f3d7aae
    
  
  
    

        
          
           prev_sel_prob_map_.reset(new GpuMat<float>(ref_width_, ref_height_, 
        

        
          
                                                      problem_.src_image_idxs.size())); 
        

        
          
           prev_sel_prob_map_->FillWithScalar(0.5f); 
        
    
  


does not work as intended, since the GpuMat<float> 4-byte matrix values cannot be set by simply calling cudaMemset(), which only sets single byte values. Additionally, the method does not properly take the pitch of the GpuMat into account.
This pull request fixes these bugs in GpuMat::FillWithScalar() by calling a kernel to set the matrix values rather than trying to use cudaMemset().","In the COLMAP MVS code, the current implementation of GpuMat::FillWithScalar() does not properly handle GpuMat objects containing multi-byte values. So, this usage of the method:

  
    
      colmap/src/mvs/patch_match_cuda.cu
    
    
        Lines 1633 to 1635
      in
      f3d7aae
    
  
  
    

        
          
           prev_sel_prob_map_.reset(new GpuMat<float>(ref_width_, ref_height_, 
        

        
          
                                                      problem_.src_image_idxs.size())); 
        

        
          
           prev_sel_prob_map_->FillWithScalar(0.5f); 
        
    
  


does not work as intended, since the GpuMat<float> 4-byte matrix values cannot be set by simply calling cudaMemset(), which only sets single byte values. Additionally, the method does not properly take the pitch of the GpuMat into account.
This pull request fixes these bugs in GpuMat::FillWithScalar() by calling a kernel to set the matrix values rather than trying to use cudaMemset().",True,{}
colmap/colmap,https://github.com/colmap/colmap,743,2019-11-27T23:15:24Z,2019-12-01T21:56:30Z,2019-12-01T21:56:30Z,MERGED,True,14,2,1,https://github.com/drkoller,Fix bug in GpuMat::FillWithScalar() implementation,1,[],https://github.com/colmap/colmap/pull/743,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/743#issuecomment-560164495,"In the COLMAP MVS code, the current implementation of GpuMat::FillWithScalar() does not properly handle GpuMat objects containing multi-byte values. So, this usage of the method:

  
    
      colmap/src/mvs/patch_match_cuda.cu
    
    
        Lines 1633 to 1635
      in
      f3d7aae
    
  
  
    

        
          
           prev_sel_prob_map_.reset(new GpuMat<float>(ref_width_, ref_height_, 
        

        
          
                                                      problem_.src_image_idxs.size())); 
        

        
          
           prev_sel_prob_map_->FillWithScalar(0.5f); 
        
    
  


does not work as intended, since the GpuMat<float> 4-byte matrix values cannot be set by simply calling cudaMemset(), which only sets single byte values. Additionally, the method does not properly take the pitch of the GpuMat into account.
This pull request fixes these bugs in GpuMat::FillWithScalar() by calling a kernel to set the matrix values rather than trying to use cudaMemset().","Indeed, this is a bug. Thanks for catching this!",True,{}
colmap/colmap,https://github.com/colmap/colmap,747,2019-11-30T02:33:44Z,2019-12-28T21:27:04Z,2019-12-28T21:27:04Z,CLOSED,False,28,18,4,https://github.com/oleg-alexandrov,Update confusing text,3,[],https://github.com/colmap/colmap/pull/747,https://github.com/oleg-alexandrov,1,https://github.com/colmap/colmap/pull/747,"It is confusing to state that colmap needs a GPU, therefore it can export to the format of other packages.","It is confusing to state that colmap needs a GPU, therefore it can export to the format of other packages.",True,{}
colmap/colmap,https://github.com/colmap/colmap,747,2019-11-30T02:33:44Z,2019-12-28T21:27:04Z,2019-12-28T21:27:04Z,CLOSED,False,28,18,4,https://github.com/oleg-alexandrov,Update confusing text,3,[],https://github.com/colmap/colmap/pull/747,https://github.com/oleg-alexandrov,2,https://github.com/colmap/colmap/pull/747#issuecomment-560011599,"It is confusing to state that colmap needs a GPU, therefore it can export to the format of other packages.",I added another minor clarification.,True,{}
colmap/colmap,https://github.com/colmap/colmap,747,2019-11-30T02:33:44Z,2019-12-28T21:27:04Z,2019-12-28T21:27:04Z,CLOSED,False,28,18,4,https://github.com/oleg-alexandrov,Update confusing text,3,[],https://github.com/colmap/colmap/pull/747,https://github.com/ahojnnes,3,https://github.com/colmap/colmap/pull/747#issuecomment-560165116,"It is confusing to state that colmap needs a GPU, therefore it can export to the format of other packages.",Thanks.,True,{}
colmap/colmap,https://github.com/colmap/colmap,747,2019-11-30T02:33:44Z,2019-12-28T21:27:04Z,2019-12-28T21:27:04Z,CLOSED,False,28,18,4,https://github.com/oleg-alexandrov,Update confusing text,3,[],https://github.com/colmap/colmap/pull/747,https://github.com/ahojnnes,4,https://github.com/colmap/colmap/pull/747#issuecomment-560502341,"It is confusing to state that colmap needs a GPU, therefore it can export to the format of other packages.","I actually don't fully understand how the description of this PR relates to the actual changes in the text. Here, you talk about GPU but I don't see any text changes related to that?",True,{}
colmap/colmap,https://github.com/colmap/colmap,747,2019-11-30T02:33:44Z,2019-12-28T21:27:04Z,2019-12-28T21:27:04Z,CLOSED,False,28,18,4,https://github.com/oleg-alexandrov,Update confusing text,3,[],https://github.com/colmap/colmap/pull/747,https://github.com/oleg-alexandrov,5,https://github.com/colmap/colmap/pull/747#issuecomment-560507127,"It is confusing to state that colmap needs a GPU, therefore it can export to the format of other packages.","Sorry. That is because of my second commit which I piled up upon the first. Here is the first commit:
6a7a145
Here I noted that the GPU functionality is not connected to the ability to export to other tools.
In the second commit:
5756102
I added something about pinhole vs simple pinhole.
I should have made two pull requests, normally, but they were small so I put them both together.
Do let me know if something is still confusing.",True,{}
colmap/colmap,https://github.com/colmap/colmap,747,2019-11-30T02:33:44Z,2019-12-28T21:27:04Z,2019-12-28T21:27:04Z,CLOSED,False,28,18,4,https://github.com/oleg-alexandrov,Update confusing text,3,[],https://github.com/colmap/colmap/pull/747,https://github.com/oleg-alexandrov,6,https://github.com/colmap/colmap/pull/747#issuecomment-569452398,"It is confusing to state that colmap needs a GPU, therefore it can export to the format of other packages.","I broke this into two more manageable pull requests that can be reviewed separately:
#777
#776
So closing this.",True,{}
colmap/colmap,https://github.com/colmap/colmap,751,2019-12-04T16:44:30Z,2019-12-17T09:08:32Z,2019-12-17T09:08:37Z,MERGED,True,5,0,1,https://github.com/oleg-alexandrov,Clarify about image id being the same as in the database,3,[],https://github.com/colmap/colmap/pull/751,https://github.com/oleg-alexandrov,1,https://github.com/colmap/colmap/pull/751,"This section starts by suggesting the user should create a text file with the cameras, and then run feature detection and matching, then use this text file to get the user cameras. The reality is more complicated. The text file should have image ids that agree with the database created during feature detection and matching. This text is clarifying that.","This section starts by suggesting the user should create a text file with the cameras, and then run feature detection and matching, then use this text file to get the user cameras. The reality is more complicated. The text file should have image ids that agree with the database created during feature detection and matching. This text is clarifying that.",True,{}
colmap/colmap,https://github.com/colmap/colmap,751,2019-12-04T16:44:30Z,2019-12-17T09:08:32Z,2019-12-17T09:08:37Z,MERGED,True,5,0,1,https://github.com/oleg-alexandrov,Clarify about image id being the same as in the database,3,[],https://github.com/colmap/colmap/pull/751,https://github.com/oleg-alexandrov,2,https://github.com/colmap/colmap/pull/751#issuecomment-563323971,"This section starts by suggesting the user should create a text file with the cameras, and then run feature detection and matching, then use this text file to get the user cameras. The reality is more complicated. The text file should have image ids that agree with the database created during feature detection and matching. This text is clarifying that.",Thanks. I fixed the typo.,True,{}
colmap/colmap,https://github.com/colmap/colmap,751,2019-12-04T16:44:30Z,2019-12-17T09:08:32Z,2019-12-17T09:08:37Z,MERGED,True,5,0,1,https://github.com/oleg-alexandrov,Clarify about image id being the same as in the database,3,[],https://github.com/colmap/colmap/pull/751,https://github.com/ahojnnes,3,https://github.com/colmap/colmap/pull/751#issuecomment-566450931,"This section starts by suggesting the user should create a text file with the cameras, and then run feature detection and matching, then use this text file to get the user cameras. The reality is more complicated. The text file should have image ids that agree with the database created during feature detection and matching. This text is clarifying that.",Thank you!,True,{}
colmap/colmap,https://github.com/colmap/colmap,753,2019-12-05T11:55:09Z,2019-12-09T14:43:28Z,2019-12-09T14:43:38Z,MERGED,True,200,7,2,https://github.com/ClementPinard,Add write_model functions for python scripts,2,[],https://github.com/colmap/colmap/pull/753,https://github.com/ClementPinard,1,https://github.com/colmap/colmap/pull/753,"This commit adds functions to write models using python, be it binary of textual
Tests have been added too
Both have been renamed for their new functionality","This commit adds functions to write models using python, be it binary of textual
Tests have been added too
Both have been renamed for their new functionality",True,{}
colmap/colmap,https://github.com/colmap/colmap,753,2019-12-05T11:55:09Z,2019-12-09T14:43:28Z,2019-12-09T14:43:38Z,MERGED,True,200,7,2,https://github.com/ClementPinard,Add write_model functions for python scripts,2,[],https://github.com/colmap/colmap/pull/753,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/753#issuecomment-563150310,"This commit adds functions to write models using python, be it binary of textual
Tests have been added too
Both have been renamed for their new functionality","Looks great, left one minor comment. Thanks!",True,{}
colmap/colmap,https://github.com/colmap/colmap,753,2019-12-05T11:55:09Z,2019-12-09T14:43:28Z,2019-12-09T14:43:38Z,MERGED,True,200,7,2,https://github.com/ClementPinard,Add write_model functions for python scripts,2,[],https://github.com/colmap/colmap/pull/753,https://github.com/ClementPinard,3,https://github.com/colmap/colmap/pull/753#issuecomment-563239584,"This commit adds functions to write models using python, be it binary of textual
Tests have been added too
Both have been renamed for their new functionality","Hi thanks for you comment !
I updated my code with several improvements in addition to your suggestion :

Unifying notations
not using the dictionnary key to get the id, but the object .id attribute, so that the function caller can have any key-dict system they want

Clément",True,{}
colmap/colmap,https://github.com/colmap/colmap,753,2019-12-05T11:55:09Z,2019-12-09T14:43:28Z,2019-12-09T14:43:38Z,MERGED,True,200,7,2,https://github.com/ClementPinard,Add write_model functions for python scripts,2,[],https://github.com/colmap/colmap/pull/753,https://github.com/ahojnnes,4,https://github.com/colmap/colmap/pull/753#issuecomment-563269983,"This commit adds functions to write models using python, be it binary of textual
Tests have been added too
Both have been renamed for their new functionality","Looks great, thanks for the contribution!",True,{}
colmap/colmap,https://github.com/colmap/colmap,755,2019-12-05T23:37:23Z,2019-12-08T21:06:42Z,2019-12-11T07:27:49Z,MERGED,True,6,7,2,https://github.com/drkoller,Fix bug in GpuMat::Rotate() implementation,2,[],https://github.com/colmap/colmap/pull/755,https://github.com/drkoller,1,https://github.com/colmap/colmap/pull/755,"In the COLMAP MVS code, the current implementation of GpuMat::Rotate() does not properly handle GpuMat objects for which the row pitch (in bytes) is not a multiple of the matrix data type size. So, this usage of the method:

  
    
      colmap/src/mvs/patch_match_cuda.cu
    
    
        Lines 1672 to 1678
      in
      06d546b
    
  
  
    

        
          
           // Rotate random map. 
        

        
          
           { 
        

        
          
             std::unique_ptr<GpuMatPRNG> rotated_rand_state_map( 
        

        
          
                 new GpuMatPRNG(width, height)); 
        

        
          
             rand_state_map_->Rotate(rotated_rand_state_map.get()); 
        

        
          
             rand_state_map_.swap(rotated_rand_state_map); 
        

        
          
           } 
        
    
  


does not work as intended, since the GpuMatPRNG matrix value data type (curandState) is 48 bytes long, which does not divide evenly into the pitch value returned by the cudaMallocPitch() memory allocation for many matrix sizes.
This pull request fixes this bug in GpuMat::Rotate(). Similar bugs may exist in other GpuMat methods (such as Transpose(), FlipHorizontal()), but they do not affect COLMAP behavior, and I haven't addressed them.","In the COLMAP MVS code, the current implementation of GpuMat::Rotate() does not properly handle GpuMat objects for which the row pitch (in bytes) is not a multiple of the matrix data type size. So, this usage of the method:

  
    
      colmap/src/mvs/patch_match_cuda.cu
    
    
        Lines 1672 to 1678
      in
      06d546b
    
  
  
    

        
          
           // Rotate random map. 
        

        
          
           { 
        

        
          
             std::unique_ptr<GpuMatPRNG> rotated_rand_state_map( 
        

        
          
                 new GpuMatPRNG(width, height)); 
        

        
          
             rand_state_map_->Rotate(rotated_rand_state_map.get()); 
        

        
          
             rand_state_map_.swap(rotated_rand_state_map); 
        

        
          
           } 
        
    
  


does not work as intended, since the GpuMatPRNG matrix value data type (curandState) is 48 bytes long, which does not divide evenly into the pitch value returned by the cudaMallocPitch() memory allocation for many matrix sizes.
This pull request fixes this bug in GpuMat::Rotate(). Similar bugs may exist in other GpuMat methods (such as Transpose(), FlipHorizontal()), but they do not affect COLMAP behavior, and I haven't addressed them.",True,{}
colmap/colmap,https://github.com/colmap/colmap,755,2019-12-05T23:37:23Z,2019-12-08T21:06:42Z,2019-12-11T07:27:49Z,MERGED,True,6,7,2,https://github.com/drkoller,Fix bug in GpuMat::Rotate() implementation,2,[],https://github.com/colmap/colmap/pull/755,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/755#issuecomment-562550145,"In the COLMAP MVS code, the current implementation of GpuMat::Rotate() does not properly handle GpuMat objects for which the row pitch (in bytes) is not a multiple of the matrix data type size. So, this usage of the method:

  
    
      colmap/src/mvs/patch_match_cuda.cu
    
    
        Lines 1672 to 1678
      in
      06d546b
    
  
  
    

        
          
           // Rotate random map. 
        

        
          
           { 
        

        
          
             std::unique_ptr<GpuMatPRNG> rotated_rand_state_map( 
        

        
          
                 new GpuMatPRNG(width, height)); 
        

        
          
             rand_state_map_->Rotate(rotated_rand_state_map.get()); 
        

        
          
             rand_state_map_.swap(rotated_rand_state_map); 
        

        
          
           } 
        
    
  


does not work as intended, since the GpuMatPRNG matrix value data type (curandState) is 48 bytes long, which does not divide evenly into the pitch value returned by the cudaMallocPitch() memory allocation for many matrix sizes.
This pull request fixes this bug in GpuMat::Rotate(). Similar bugs may exist in other GpuMat methods (such as Transpose(), FlipHorizontal()), but they do not affect COLMAP behavior, and I haven't addressed them.","Thanks very much for this fix. Out of curiosity, does it make any difference in the computed depth maps?",True,{}
colmap/colmap,https://github.com/colmap/colmap,755,2019-12-05T23:37:23Z,2019-12-08T21:06:42Z,2019-12-11T07:27:49Z,MERGED,True,6,7,2,https://github.com/drkoller,Fix bug in GpuMat::Rotate() implementation,2,[],https://github.com/colmap/colmap/pull/755,https://github.com/ahojnnes,3,https://github.com/colmap/colmap/pull/755#issuecomment-563149259,"In the COLMAP MVS code, the current implementation of GpuMat::Rotate() does not properly handle GpuMat objects for which the row pitch (in bytes) is not a multiple of the matrix data type size. So, this usage of the method:

  
    
      colmap/src/mvs/patch_match_cuda.cu
    
    
        Lines 1672 to 1678
      in
      06d546b
    
  
  
    

        
          
           // Rotate random map. 
        

        
          
           { 
        

        
          
             std::unique_ptr<GpuMatPRNG> rotated_rand_state_map( 
        

        
          
                 new GpuMatPRNG(width, height)); 
        

        
          
             rand_state_map_->Rotate(rotated_rand_state_map.get()); 
        

        
          
             rand_state_map_.swap(rotated_rand_state_map); 
        

        
          
           } 
        
    
  


does not work as intended, since the GpuMatPRNG matrix value data type (curandState) is 48 bytes long, which does not divide evenly into the pitch value returned by the cudaMallocPitch() memory allocation for many matrix sizes.
This pull request fixes this bug in GpuMat::Rotate(). Similar bugs may exist in other GpuMat methods (such as Transpose(), FlipHorizontal()), but they do not affect COLMAP behavior, and I haven't addressed them.",@drkoller I applied the same fix for the transpose/flip functions. Thanks again.,True,{}
colmap/colmap,https://github.com/colmap/colmap,755,2019-12-05T23:37:23Z,2019-12-08T21:06:42Z,2019-12-11T07:27:49Z,MERGED,True,6,7,2,https://github.com/drkoller,Fix bug in GpuMat::Rotate() implementation,2,[],https://github.com/colmap/colmap/pull/755,https://github.com/drkoller,4,https://github.com/colmap/colmap/pull/755#issuecomment-563488566,"In the COLMAP MVS code, the current implementation of GpuMat::Rotate() does not properly handle GpuMat objects for which the row pitch (in bytes) is not a multiple of the matrix data type size. So, this usage of the method:

  
    
      colmap/src/mvs/patch_match_cuda.cu
    
    
        Lines 1672 to 1678
      in
      06d546b
    
  
  
    

        
          
           // Rotate random map. 
        

        
          
           { 
        

        
          
             std::unique_ptr<GpuMatPRNG> rotated_rand_state_map( 
        

        
          
                 new GpuMatPRNG(width, height)); 
        

        
          
             rand_state_map_->Rotate(rotated_rand_state_map.get()); 
        

        
          
             rand_state_map_.swap(rotated_rand_state_map); 
        

        
          
           } 
        
    
  


does not work as intended, since the GpuMatPRNG matrix value data type (curandState) is 48 bytes long, which does not divide evenly into the pitch value returned by the cudaMallocPitch() memory allocation for many matrix sizes.
This pull request fixes this bug in GpuMat::Rotate(). Similar bugs may exist in other GpuMat methods (such as Transpose(), FlipHorizontal()), but they do not affect COLMAP behavior, and I haven't addressed them.","Thanks very much for this fix. Out of curiosity, does it make any difference in the computed depth maps?

Yes, the depth maps generated with the bug fix are slightly different, although they don't appear to necessarily be ""better"" to the naked eye. With the buggy version of GpuMat::Rotate(), the rand_state_map was getting getting slightly corrupted during rotation, due to copying of uninitialized memory and misaligned memory accesses. But since rand_state_map just contains state info for the PRNG, the effect of the bug is just that the stream of generated random numbers used in patch_match_stereo had somewhat less randomness than expected from the usual cuRAND algorithm.
Here's a comparison of photometric depth map images as computed before and after the bug fix, using the first image from your ETH3D ""living_room"" dataset as reference image, at 1000x667 resolution. Before bug fix:

After bug fix:

You can observe some minor variations due to the different random values, but no big deal!",True,{}
colmap/colmap,https://github.com/colmap/colmap,755,2019-12-05T23:37:23Z,2019-12-08T21:06:42Z,2019-12-11T07:27:49Z,MERGED,True,6,7,2,https://github.com/drkoller,Fix bug in GpuMat::Rotate() implementation,2,[],https://github.com/colmap/colmap/pull/755,https://github.com/ahojnnes,5,https://github.com/colmap/colmap/pull/755#issuecomment-564415208,"In the COLMAP MVS code, the current implementation of GpuMat::Rotate() does not properly handle GpuMat objects for which the row pitch (in bytes) is not a multiple of the matrix data type size. So, this usage of the method:

  
    
      colmap/src/mvs/patch_match_cuda.cu
    
    
        Lines 1672 to 1678
      in
      06d546b
    
  
  
    

        
          
           // Rotate random map. 
        

        
          
           { 
        

        
          
             std::unique_ptr<GpuMatPRNG> rotated_rand_state_map( 
        

        
          
                 new GpuMatPRNG(width, height)); 
        

        
          
             rand_state_map_->Rotate(rotated_rand_state_map.get()); 
        

        
          
             rand_state_map_.swap(rotated_rand_state_map); 
        

        
          
           } 
        
    
  


does not work as intended, since the GpuMatPRNG matrix value data type (curandState) is 48 bytes long, which does not divide evenly into the pitch value returned by the cudaMallocPitch() memory allocation for many matrix sizes.
This pull request fixes this bug in GpuMat::Rotate(). Similar bugs may exist in other GpuMat methods (such as Transpose(), FlipHorizontal()), but they do not affect COLMAP behavior, and I haven't addressed them.","Good to know, thank you again!",True,{}
colmap/colmap,https://github.com/colmap/colmap,759,2019-12-11T03:36:40Z,2019-12-13T19:06:39Z,2019-12-13T19:06:39Z,MERGED,True,126,0,7,https://github.com/tjdahlke,Add docker functionality,13,[],https://github.com/colmap/colmap/pull/759,https://github.com/tjdahlke,1,https://github.com/colmap/colmap/pull/759,"I had trouble installing COLMAP on my local machine, so I used Docker to make a container with COLMAP built/installed on it, and simplify the use of the binaries via the command line. A Dockerfile has been added so that users can build the container from scratch, and scripts with a README.md have also been added for ease of use by others.
I've tested COLMAP in this container successfully. The host machine GPUs are ported to the docker container, so the user can make use of full GPU functionality with COLMAP using this container.
Further, this makes the build environment standardized and reproducible, and allows the work in this repo to be accessible to a wider range of users.
I also made a dockerHub organization page to host the 'official' docker image that the Dockerfile builds. That way, a user does not have to build the docker image from scratch and can quickly get up and running with a stable build. However, the user can always modify the Dockerfile themselves and build an alternative image to run COLMAP on if desired. Happy to share access to the dockerHub colmap organization page that I made, or defer to another dockerHub organization page if one has already been made.","I had trouble installing COLMAP on my local machine, so I used Docker to make a container with COLMAP built/installed on it, and simplify the use of the binaries via the command line. A Dockerfile has been added so that users can build the container from scratch, and scripts with a README.md have also been added for ease of use by others.
I've tested COLMAP in this container successfully. The host machine GPUs are ported to the docker container, so the user can make use of full GPU functionality with COLMAP using this container.
Further, this makes the build environment standardized and reproducible, and allows the work in this repo to be accessible to a wider range of users.
I also made a dockerHub organization page to host the 'official' docker image that the Dockerfile builds. That way, a user does not have to build the docker image from scratch and can quickly get up and running with a stable build. However, the user can always modify the Dockerfile themselves and build an alternative image to run COLMAP on if desired. Happy to share access to the dockerHub colmap organization page that I made, or defer to another dockerHub organization page if one has already been made.",True,{}
colmap/colmap,https://github.com/colmap/colmap,759,2019-12-11T03:36:40Z,2019-12-13T19:06:39Z,2019-12-13T19:06:39Z,MERGED,True,126,0,7,https://github.com/tjdahlke,Add docker functionality,13,[],https://github.com/colmap/colmap/pull/759,https://github.com/tjdahlke,2,https://github.com/colmap/colmap/pull/759#issuecomment-564706151,"I had trouble installing COLMAP on my local machine, so I used Docker to make a container with COLMAP built/installed on it, and simplify the use of the binaries via the command line. A Dockerfile has been added so that users can build the container from scratch, and scripts with a README.md have also been added for ease of use by others.
I've tested COLMAP in this container successfully. The host machine GPUs are ported to the docker container, so the user can make use of full GPU functionality with COLMAP using this container.
Further, this makes the build environment standardized and reproducible, and allows the work in this repo to be accessible to a wider range of users.
I also made a dockerHub organization page to host the 'official' docker image that the Dockerfile builds. That way, a user does not have to build the docker image from scratch and can quickly get up and running with a stable build. However, the user can always modify the Dockerfile themselves and build an alternative image to run COLMAP on if desired. Happy to share access to the dockerHub colmap organization page that I made, or defer to another dockerHub organization page if one has already been made.",@ahojnnes; made the changes you suggested and re-tested successfully with the new docker container that results from those changes. Let me know if you have any more feedback!,True,{}
colmap/colmap,https://github.com/colmap/colmap,760,2019-12-11T11:49:38Z,2019-12-12T06:31:40Z,2019-12-12T06:32:01Z,MERGED,True,1,0,1,https://github.com/D-Alex,fix: add missing target library for OpenMP,1,[],https://github.com/colmap/colmap/pull/760,https://github.com/D-Alex,1,https://github.com/colmap/colmap/pull/760,This fixes a linking error observed on Mac OS X High Sierra (brew),This fixes a linking error observed on Mac OS X High Sierra (brew),True,{}
colmap/colmap,https://github.com/colmap/colmap,760,2019-12-11T11:49:38Z,2019-12-12T06:31:40Z,2019-12-12T06:32:01Z,MERGED,True,1,0,1,https://github.com/D-Alex,fix: add missing target library for OpenMP,1,[],https://github.com/colmap/colmap/pull/760,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/760#issuecomment-564870288,This fixes a linking error observed on Mac OS X High Sierra (brew),Thanks!,True,{}
colmap/colmap,https://github.com/colmap/colmap,776,2019-12-28T21:20:43Z,2020-01-07T11:39:11Z,2020-01-07T11:39:11Z,MERGED,True,5,6,1,https://github.com/oleg-alexandrov,Update confusing text,1,[],https://github.com/colmap/colmap/pull/776,https://github.com/oleg-alexandrov,1,https://github.com/colmap/colmap/pull/776,"This pull request is carved out of #747 which I will close, because it had too many commits and it was not clear what I meant to change.
The point of this pull request is to update some confusing text. The doc was talking about exporting colmap data, both above and below. Hence the text that colmap needs a GPU does not belong there.","This pull request is carved out of #747 which I will close, because it had too many commits and it was not clear what I meant to change.
The point of this pull request is to update some confusing text. The doc was talking about exporting colmap data, both above and below. Hence the text that colmap needs a GPU does not belong there.",True,{}
colmap/colmap,https://github.com/colmap/colmap,777,2019-12-28T21:25:47Z,2020-01-03T20:37:05Z,2020-01-03T20:37:13Z,MERGED,True,3,3,1,https://github.com/oleg-alexandrov,Clarify pinhole vs simple pinhole,1,[],https://github.com/colmap/colmap/pull/777,https://github.com/oleg-alexandrov,1,https://github.com/colmap/colmap/pull/777,"I think it is useful to clarify a bit how these two differ. I know camera_models.h explains it, but it looks easier to just spell it out. It also addresses the question in #121.","I think it is useful to clarify a bit how these two differ. I know camera_models.h explains it, but it looks easier to just spell it out. It also addresses the question in #121.",True,{}
colmap/colmap,https://github.com/colmap/colmap,777,2019-12-28T21:25:47Z,2020-01-03T20:37:05Z,2020-01-03T20:37:13Z,MERGED,True,3,3,1,https://github.com/oleg-alexandrov,Clarify pinhole vs simple pinhole,1,[],https://github.com/colmap/colmap/pull/777,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/777#issuecomment-570691138,"I think it is useful to clarify a bit how these two differ. I know camera_models.h explains it, but it looks easier to just spell it out. It also addresses the question in #121.",Thanks!,True,{}
colmap/colmap,https://github.com/colmap/colmap,783,2020-01-15T04:13:41Z,2020-01-25T20:43:35Z,2020-01-25T20:43:45Z,MERGED,True,47,7,1,https://github.com/mihaimorariu,Configure the parameters of read_dense.py,5,[],https://github.com/colmap/colmap/pull/783,https://github.com/mihaimorariu,1,https://github.com/colmap/colmap/pull/783,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,783,2020-01-15T04:13:41Z,2020-01-25T20:43:35Z,2020-01-25T20:43:45Z,MERGED,True,47,7,1,https://github.com/mihaimorariu,Configure the parameters of read_dense.py,5,[],https://github.com/colmap/colmap/pull/783,https://github.com/mihaimorariu,2,https://github.com/colmap/colmap/pull/783#issuecomment-577960395,,Thank you for your feedback!,True,{}
colmap/colmap,https://github.com/colmap/colmap,783,2020-01-15T04:13:41Z,2020-01-25T20:43:35Z,2020-01-25T20:43:45Z,MERGED,True,47,7,1,https://github.com/mihaimorariu,Configure the parameters of read_dense.py,5,[],https://github.com/colmap/colmap/pull/783,https://github.com/ahojnnes,3,https://github.com/colmap/colmap/pull/783#issuecomment-578441477,,"Thanks, looks great!",True,{}
colmap/colmap,https://github.com/colmap/colmap,791,2020-01-29T05:50:21Z,,2022-01-26T12:22:15Z,OPEN,False,0,0,442,https://github.com/wzel,Make permission bits consistent,1,[],https://github.com/colmap/colmap/pull/791,https://github.com/wzel,1,https://github.com/colmap/colmap/pull/791,"*.sh, *.py, and *.bat get 755.
Anything else gets 644.","*.sh, *.py, and *.bat get 755.
Anything else gets 644.",True,{}
colmap/colmap,https://github.com/colmap/colmap,792,2020-01-29T06:00:36Z,2021-05-29T11:18:39Z,2021-05-29T11:18:39Z,CLOSED,False,1,2,1,https://github.com/wzel,Remove dead youtube link,1,[],https://github.com/colmap/colmap/pull/792,https://github.com/wzel,1,https://github.com/colmap/colmap/pull/792,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,792,2020-01-29T06:00:36Z,2021-05-29T11:18:39Z,2021-05-29T11:18:39Z,CLOSED,False,1,2,1,https://github.com/wzel,Remove dead youtube link,1,[],https://github.com/colmap/colmap/pull/792,https://github.com/attilaolah,2,https://github.com/colmap/colmap/pull/792#issuecomment-651843806,,"While you're here, you could also remove the three dead YouTube links from https://colmap.github.io/datasets.html. Only one of them seems to be working.",True,{}
colmap/colmap,https://github.com/colmap/colmap,792,2020-01-29T06:00:36Z,2021-05-29T11:18:39Z,2021-05-29T11:18:39Z,CLOSED,False,1,2,1,https://github.com/wzel,Remove dead youtube link,1,[],https://github.com/colmap/colmap/pull/792,https://github.com/ahojnnes,3,https://github.com/colmap/colmap/pull/792#issuecomment-671082045,,I am working on a new tutorial video and also updated the dataset youtube links. Thanks.,True,{}
colmap/colmap,https://github.com/colmap/colmap,792,2020-01-29T06:00:36Z,2021-05-29T11:18:39Z,2021-05-29T11:18:39Z,CLOSED,False,1,2,1,https://github.com/wzel,Remove dead youtube link,1,[],https://github.com/colmap/colmap/pull/792,https://github.com/wzel,4,https://github.com/colmap/colmap/pull/792#issuecomment-673990037,,"May I close this and remove from my to-do list, then?",True,{}
colmap/colmap,https://github.com/colmap/colmap,792,2020-01-29T06:00:36Z,2021-05-29T11:18:39Z,2021-05-29T11:18:39Z,CLOSED,False,1,2,1,https://github.com/wzel,Remove dead youtube link,1,[],https://github.com/colmap/colmap/pull/792,https://github.com/ahojnnes,5,https://github.com/colmap/colmap/pull/792#issuecomment-850816377,,"This has been fixed in another PR, thanks.",True,{}
colmap/colmap,https://github.com/colmap/colmap,799,2020-02-11T10:15:26Z,2020-07-27T15:51:31Z,2020-07-27T15:51:32Z,MERGED,True,39,3,3,https://github.com/boitumeloruf,Allow to save fused point cloud in colmap format when using command line,3,[],https://github.com/colmap/colmap/pull/799,https://github.com/boitumeloruf,1,https://github.com/colmap/colmap/pull/799,"Adjusted src/base/reconstruction.cc to import point cloud from std::vector
Adjusted src/exe/colmap.cc to allow saving in colmap format when calling stereo_fusion from command line

See Issue #738","Adjusted src/base/reconstruction.cc to import point cloud from std::vector
Adjusted src/exe/colmap.cc to allow saving in colmap format when calling stereo_fusion from command line

See Issue #738",True,{}
colmap/colmap,https://github.com/colmap/colmap,814,2020-02-27T18:51:22Z,2020-02-28T10:59:14Z,2020-02-28T10:59:14Z,MERGED,True,2,2,1,https://github.com/KhaledSharif,Fix build.py build_freeimage function,1,[],https://github.com/colmap/colmap/pull/814,https://github.com/KhaledSharif,1,https://github.com/colmap/colmap/pull/814,"Paths when building freeimage are incorrect, they have been fixed in this pull request","Paths when building freeimage are incorrect, they have been fixed in this pull request",True,{}
colmap/colmap,https://github.com/colmap/colmap,817,2020-03-02T17:40:05Z,2020-03-07T06:38:17Z,2020-03-07T06:38:17Z,MERGED,True,3,0,1,https://github.com/SBCV,Fixed txt parsing error caused by incorrect LC_NUMERIC value,2,[],https://github.com/colmap/colmap/pull/817,https://github.com/SBCV,1,https://github.com/colmap/colmap/pull/817,"This PR resolves #766 .
Currently, the imported results are potentially incorrect, since std::stold etc. depend on the value of LC_NUMERIC (see stof() ).
Further, I observed that the value of LC_NUMERIC within colmap depends on how the corresponding code has been executed (command line vs gui). Concretely, std::setlocale(LC_NUMERIC, NULL) returned C using the command line (e.g. colmap bundler_adjuster) and de_DE.UTF-8 using the gui (i.e. colmap gui). I guess that QT changes this value somewhere.
Therefore, this PR adjusts the value of LC_NUMMERIC at a global gui level. (All functions loaded by the gui are affected and redundancy is avoided).
If you feel that the value should be changed somewhere else just let me know
Bests
Sebastian","This PR resolves #766 .
Currently, the imported results are potentially incorrect, since std::stold etc. depend on the value of LC_NUMERIC (see stof() ).
Further, I observed that the value of LC_NUMERIC within colmap depends on how the corresponding code has been executed (command line vs gui). Concretely, std::setlocale(LC_NUMERIC, NULL) returned C using the command line (e.g. colmap bundler_adjuster) and de_DE.UTF-8 using the gui (i.e. colmap gui). I guess that QT changes this value somewhere.
Therefore, this PR adjusts the value of LC_NUMMERIC at a global gui level. (All functions loaded by the gui are affected and redundancy is avoided).
If you feel that the value should be changed somewhere else just let me know
Bests
Sebastian",True,{}
colmap/colmap,https://github.com/colmap/colmap,817,2020-03-02T17:40:05Z,2020-03-07T06:38:17Z,2020-03-07T06:38:17Z,MERGED,True,3,0,1,https://github.com/SBCV,Fixed txt parsing error caused by incorrect LC_NUMERIC value,2,[],https://github.com/colmap/colmap/pull/817,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/817#issuecomment-596053623,"This PR resolves #766 .
Currently, the imported results are potentially incorrect, since std::stold etc. depend on the value of LC_NUMERIC (see stof() ).
Further, I observed that the value of LC_NUMERIC within colmap depends on how the corresponding code has been executed (command line vs gui). Concretely, std::setlocale(LC_NUMERIC, NULL) returned C using the command line (e.g. colmap bundler_adjuster) and de_DE.UTF-8 using the gui (i.e. colmap gui). I guess that QT changes this value somewhere.
Therefore, this PR adjusts the value of LC_NUMMERIC at a global gui level. (All functions loaded by the gui are affected and redundancy is avoided).
If you feel that the value should be changed somewhere else just let me know
Bests
Sebastian","Great, thanks!",True,{}
colmap/colmap,https://github.com/colmap/colmap,819,2020-03-03T12:29:06Z,2020-03-07T06:40:11Z,2020-03-07T07:47:36Z,MERGED,True,14,1,2,https://github.com/SBCV,Fixed unrecognized option random_seed,1,[],https://github.com/colmap/colmap/pull/819,https://github.com/SBCV,1,https://github.com/colmap/colmap/pull/819,This PR resolves  #818,This PR resolves  #818,True,{}
colmap/colmap,https://github.com/colmap/colmap,819,2020-03-03T12:29:06Z,2020-03-07T06:40:11Z,2020-03-07T07:47:36Z,MERGED,True,14,1,2,https://github.com/SBCV,Fixed unrecognized option random_seed,1,[],https://github.com/colmap/colmap/pull/819,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/819#issuecomment-596053741,This PR resolves  #818,Thanks!,True,{}
colmap/colmap,https://github.com/colmap/colmap,819,2020-03-03T12:29:06Z,2020-03-07T06:40:11Z,2020-03-07T07:47:36Z,MERGED,True,14,1,2,https://github.com/SBCV,Fixed unrecognized option random_seed,1,[],https://github.com/colmap/colmap/pull/819,https://github.com/SBCV,3,https://github.com/colmap/colmap/pull/819#issuecomment-596058492,This PR resolves  #818,You're welcome,True,{}
colmap/colmap,https://github.com/colmap/colmap,821,2020-03-05T13:59:17Z,2020-06-24T09:31:00Z,2020-06-24T09:31:14Z,MERGED,True,59,54,2,https://github.com/ClementPinard,Handle existing camera,3,[],https://github.com/colmap/colmap/pull/821,https://github.com/ClementPinard,1,https://github.com/colmap/colmap/pull/821,"Was using python database script to make a db file with already calibrated cameras, and a bunch of pictures associated to them.
The feature extractor works great but it tries to create a new camera for images that are already in the database. The result is the database gets new cameras in the db file, with no image linked to them.
This PR makes sure that it does not happen.
Also, I could see that the actual default value of prior_tvec (which should probably be called prior_gps or something, since it gets converted after) is nan and not 0, so I changed the database python script accordingly to avoid errors in spatial matcher.
Lastly, genuine question, is there a plan to use qvec prior in the future ? It' possible to get a rough odometry estimation with several IMU enabled camera such as drone videos or late generations of GoPros. If you have some pointers for papers using prior position and orientation estimation for photogrammetry other than for spatial matching, i'd be happy to read them !
Thanks for your help !
Clément","Was using python database script to make a db file with already calibrated cameras, and a bunch of pictures associated to them.
The feature extractor works great but it tries to create a new camera for images that are already in the database. The result is the database gets new cameras in the db file, with no image linked to them.
This PR makes sure that it does not happen.
Also, I could see that the actual default value of prior_tvec (which should probably be called prior_gps or something, since it gets converted after) is nan and not 0, so I changed the database python script accordingly to avoid errors in spatial matcher.
Lastly, genuine question, is there a plan to use qvec prior in the future ? It' possible to get a rough odometry estimation with several IMU enabled camera such as drone videos or late generations of GoPros. If you have some pointers for papers using prior position and orientation estimation for photogrammetry other than for spatial matching, i'd be happy to read them !
Thanks for your help !
Clément",True,{}
colmap/colmap,https://github.com/colmap/colmap,821,2020-03-05T13:59:17Z,2020-06-24T09:31:00Z,2020-06-24T09:31:14Z,MERGED,True,59,54,2,https://github.com/ClementPinard,Handle existing camera,3,[],https://github.com/colmap/colmap/pull/821,https://github.com/ClementPinard,2,https://github.com/colmap/colmap/pull/821#issuecomment-645577713,"Was using python database script to make a db file with already calibrated cameras, and a bunch of pictures associated to them.
The feature extractor works great but it tries to create a new camera for images that are already in the database. The result is the database gets new cameras in the db file, with no image linked to them.
This PR makes sure that it does not happen.
Also, I could see that the actual default value of prior_tvec (which should probably be called prior_gps or something, since it gets converted after) is nan and not 0, so I changed the database python script accordingly to avoid errors in spatial matcher.
Lastly, genuine question, is there a plan to use qvec prior in the future ? It' possible to get a rough odometry estimation with several IMU enabled camera such as drone videos or late generations of GoPros. If you have some pointers for papers using prior position and orientation estimation for photogrammetry other than for spatial matching, i'd be happy to read them !
Thanks for your help !
Clément","Hi, is this PR considered ? I actually need this modif in my own project (otherwise, tons of unnecessary cameras are created). When I'll share my project, I'll point the README to my personal branch, but I'd rather point to the master in order to keep the other developments up to date :)
thanks !",True,{}
colmap/colmap,https://github.com/colmap/colmap,821,2020-03-05T13:59:17Z,2020-06-24T09:31:00Z,2020-06-24T09:31:14Z,MERGED,True,59,54,2,https://github.com/ClementPinard,Handle existing camera,3,[],https://github.com/colmap/colmap/pull/821,https://github.com/ahojnnes,3,https://github.com/colmap/colmap/pull/821#issuecomment-648709216,"Was using python database script to make a db file with already calibrated cameras, and a bunch of pictures associated to them.
The feature extractor works great but it tries to create a new camera for images that are already in the database. The result is the database gets new cameras in the db file, with no image linked to them.
This PR makes sure that it does not happen.
Also, I could see that the actual default value of prior_tvec (which should probably be called prior_gps or something, since it gets converted after) is nan and not 0, so I changed the database python script accordingly to avoid errors in spatial matcher.
Lastly, genuine question, is there a plan to use qvec prior in the future ? It' possible to get a rough odometry estimation with several IMU enabled camera such as drone videos or late generations of GoPros. If you have some pointers for papers using prior position and orientation estimation for photogrammetry other than for spatial matching, i'd be happy to read them !
Thanks for your help !
Clément","Looks good to me, thanks for the improvement! Sorry for the slow response.",True,{'THUMBS_UP': ['https://github.com/ClementPinard']}
colmap/colmap,https://github.com/colmap/colmap,853,2020-04-24T17:57:17Z,2020-04-24T20:24:10Z,2020-04-24T20:24:10Z,MERGED,True,1,1,1,https://github.com/jbeich,Unbreak CGAL_ENABLED with CGAL 5.0,1,[],https://github.com/colmap/colmap/pull/853,https://github.com/jbeich,1,https://github.com/colmap/colmap/pull/853,Found downstream. See error log.,Found downstream. See error log.,True,{}
colmap/colmap,https://github.com/colmap/colmap,868,2020-05-08T18:07:58Z,2020-05-09T17:38:51Z,2020-05-09T17:38:51Z,MERGED,True,3,0,1,https://github.com/DaniilSNikulin,force check and sort image_list,1,[],https://github.com/colmap/colmap/pull/868,https://github.com/DaniilSNikulin,1,https://github.com/colmap/colmap/pull/868,"In documentation not required what image_list, which contains in image_list_path must be sorted. However, in realization this is expected and need for single_camera_per_folder mode.","In documentation not required what image_list, which contains in image_list_path must be sorted. However, in realization this is expected and need for single_camera_per_folder mode.",True,{}
colmap/colmap,https://github.com/colmap/colmap,868,2020-05-08T18:07:58Z,2020-05-09T17:38:51Z,2020-05-09T17:38:51Z,MERGED,True,3,0,1,https://github.com/DaniilSNikulin,force check and sort image_list,1,[],https://github.com/colmap/colmap/pull/868,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/868#issuecomment-626210887,"In documentation not required what image_list, which contains in image_list_path must be sorted. However, in realization this is expected and need for single_camera_per_folder mode.",Thanks for the fix.,True,{}
colmap/colmap,https://github.com/colmap/colmap,869,2020-05-09T11:58:23Z,2020-05-09T17:42:48Z,2020-05-09T17:42:48Z,CLOSED,False,903,89,22,https://github.com/zpillio,Increased sparse solver threshold,51,[],https://github.com/colmap/colmap/pull/869,https://github.com/zpillio,1,https://github.com/colmap/colmap/pull/869,"Found that BA convergence sloves down when it whiches to ceres::ITERATIVE_SCHUR solver type. (You can recognise it from the ceres log by checking ls_iter column. It contains when 1 for non iterative method is used, but goes up to maximum 100 for iterative method.)
ceres::ITERATIVE_SCHUR is kept, because for large problems that's faster, but the value of kMaxNumImagesDirectSparseSolver is increased from 1000 to 10000.","Found that BA convergence sloves down when it whiches to ceres::ITERATIVE_SCHUR solver type. (You can recognise it from the ceres log by checking ls_iter column. It contains when 1 for non iterative method is used, but goes up to maximum 100 for iterative method.)
ceres::ITERATIVE_SCHUR is kept, because for large problems that's faster, but the value of kMaxNumImagesDirectSparseSolver is increased from 1000 to 10000.",True,{}
colmap/colmap,https://github.com/colmap/colmap,869,2020-05-09T11:58:23Z,2020-05-09T17:42:48Z,2020-05-09T17:42:48Z,CLOSED,False,903,89,22,https://github.com/zpillio,Increased sparse solver threshold,51,[],https://github.com/colmap/colmap/pull/869,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/869#issuecomment-626210810,"Found that BA convergence sloves down when it whiches to ceres::ITERATIVE_SCHUR solver type. (You can recognise it from the ceres log by checking ls_iter column. It contains when 1 for non iterative method is used, but goes up to maximum 100 for iterative method.)
ceres::ITERATIVE_SCHUR is kept, because for large problems that's faster, but the value of kMaxNumImagesDirectSparseSolver is increased from 1000 to 10000.","This PR contains many more changes than just changing the Ceres thresholds. Also, these thresholds very much depend on the sparsity pattern of the problem. I did quite some evaluations on these trade-offs and would like to keep the current defaults unless you can show the opposite on a really large set of datasets.",True,{}
colmap/colmap,https://github.com/colmap/colmap,869,2020-05-09T11:58:23Z,2020-05-09T17:42:48Z,2020-05-09T17:42:48Z,CLOSED,False,903,89,22,https://github.com/zpillio,Increased sparse solver threshold,51,[],https://github.com/colmap/colmap/pull/869,https://github.com/zpillio,3,https://github.com/colmap/colmap/pull/869#issuecomment-626211390,"Found that BA convergence sloves down when it whiches to ceres::ITERATIVE_SCHUR solver type. (You can recognise it from the ceres log by checking ls_iter column. It contains when 1 for non iterative method is used, but goes up to maximum 100 for iterative method.)
ceres::ITERATIVE_SCHUR is kept, because for large problems that's faster, but the value of kMaxNumImagesDirectSparseSolver is increased from 1000 to 10000.",Sorry that was a mistake. I created a wrong poll request.,True,{}
colmap/colmap,https://github.com/colmap/colmap,879,2020-05-20T04:18:55Z,2020-06-05T11:16:24Z,2020-06-05T11:16:24Z,CLOSED,False,2,2,1,https://github.com/hiakru,Correct Complete and Merge print log int CompleteAndMergeTracks,1,[],https://github.com/colmap/colmap/pull/879,https://github.com/hiakru,1,https://github.com/colmap/colmap/pull/879,create an issue #878,create an issue #878,True,{}
colmap/colmap,https://github.com/colmap/colmap,879,2020-05-20T04:18:55Z,2020-06-05T11:16:24Z,2020-06-05T11:16:24Z,CLOSED,False,2,2,1,https://github.com/hiakru,Correct Complete and Merge print log int CompleteAndMergeTracks,1,[],https://github.com/colmap/colmap/pull/879,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/879#issuecomment-639419018,create an issue #878,"Sorry, I noticed too late that you opened a PR with this fix. I separately fixed this in the master branch already. Thanks very much for your fix in any case!",True,{}
colmap/colmap,https://github.com/colmap/colmap,882,2020-05-23T09:17:07Z,2020-06-24T09:43:29Z,2020-06-24T09:43:29Z,CLOSED,False,1,0,1,https://github.com/atcw,Geometry.h add missing <cstdio> include,1,[],https://github.com/colmap/colmap/pull/882,https://github.com/atcw,1,https://github.com/colmap/colmap/pull/882,"Does not compile otherwise because ""FILE does not name a type"" error on compilation in PoissonRec/Geometry.h","Does not compile otherwise because ""FILE does not name a type"" error on compilation in PoissonRec/Geometry.h",True,{}
colmap/colmap,https://github.com/colmap/colmap,882,2020-05-23T09:17:07Z,2020-06-24T09:43:29Z,2020-06-24T09:43:29Z,CLOSED,False,1,0,1,https://github.com/atcw,Geometry.h add missing <cstdio> include,1,[],https://github.com/colmap/colmap/pull/882,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/882#issuecomment-648715419,"Does not compile otherwise because ""FILE does not name a type"" error on compilation in PoissonRec/Geometry.h","Thanks for the fix, already resolved through another PR.",True,{}
colmap/colmap,https://github.com/colmap/colmap,887,2020-05-30T15:22:20Z,2020-06-24T09:37:41Z,2020-06-24T09:37:41Z,MERGED,True,36,3,5,https://github.com/S-o-T,Custom matching speedup,2,[],https://github.com/colmap/colmap/pull/887,https://github.com/S-o-T,1,https://github.com/colmap/colmap/pull/887,"Default value for ImagePairsMatchingOptions.block_size should be the same as the number of image pairs to be matched based on default value of ExhaustiveMatchingOptions.block_size (block_size * (block_size - 1) / 2). Low value of this option decrease potential utilization of hardware resources. Also, utilization can be increased by filtering out non unique image pairs.","Default value for ImagePairsMatchingOptions.block_size should be the same as the number of image pairs to be matched based on default value of ExhaustiveMatchingOptions.block_size (block_size * (block_size - 1) / 2). Low value of this option decrease potential utilization of hardware resources. Also, utilization can be increased by filtering out non unique image pairs.",True,{}
colmap/colmap,https://github.com/colmap/colmap,887,2020-05-30T15:22:20Z,2020-06-24T09:37:41Z,2020-06-24T09:37:41Z,MERGED,True,36,3,5,https://github.com/S-o-T,Custom matching speedup,2,[],https://github.com/colmap/colmap/pull/887,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/887#issuecomment-648707778,"Default value for ImagePairsMatchingOptions.block_size should be the same as the number of image pairs to be matched based on default value of ExhaustiveMatchingOptions.block_size (block_size * (block_size - 1) / 2). Low value of this option decrease potential utilization of hardware resources. Also, utilization can be increased by filtering out non unique image pairs.","Thanks, looks good. I added a minor suggestion for improvement.",True,{}
colmap/colmap,https://github.com/colmap/colmap,888,2020-06-01T20:23:07Z,2020-06-24T09:23:29Z,2020-06-24T09:23:35Z,MERGED,True,1,0,1,https://github.com/Fytch,add missing include <stdio.h> to lib/PoissonRecon/Geometry.h,1,[],https://github.com/colmap/colmap/pull/888,https://github.com/Fytch,1,https://github.com/colmap/colmap/pull/888,"Would not compile otherwise with GCC 10.1.0:
In file included from /tmp/tmp.ij35ejNwXQ/colmap/lib/PoissonRecon/Geometry.cpp:28:
/tmp/tmp.ij35ejNwXQ/colmap/lib/PoissonRecon/Geometry.h:344:2: error: ‘FILE’ does not name a type
  344 |  FILE* _fp;
      |  ^~~~
In file included from /tmp/tmp.ij35ejNwXQ/colmap/lib/PoissonRecon/Geometry.cpp:28:
/tmp/tmp.ij35ejNwXQ/colmap/lib/PoissonRecon/Geometry.h:36:1: note: ‘FILE’ is defined in header ‘<cstdio>’; did you forget to ‘#include <cstdio>’?
   35 | #include ""Hash.h""
  +++ |+#include <cstdio>
   36 | 

Also mentioned in #886.","Would not compile otherwise with GCC 10.1.0:
In file included from /tmp/tmp.ij35ejNwXQ/colmap/lib/PoissonRecon/Geometry.cpp:28:
/tmp/tmp.ij35ejNwXQ/colmap/lib/PoissonRecon/Geometry.h:344:2: error: ‘FILE’ does not name a type
  344 |  FILE* _fp;
      |  ^~~~
In file included from /tmp/tmp.ij35ejNwXQ/colmap/lib/PoissonRecon/Geometry.cpp:28:
/tmp/tmp.ij35ejNwXQ/colmap/lib/PoissonRecon/Geometry.h:36:1: note: ‘FILE’ is defined in header ‘<cstdio>’; did you forget to ‘#include <cstdio>’?
   35 | #include ""Hash.h""
  +++ |+#include <cstdio>
   36 | 

Also mentioned in #886.",True,{}
colmap/colmap,https://github.com/colmap/colmap,888,2020-06-01T20:23:07Z,2020-06-24T09:23:29Z,2020-06-24T09:23:35Z,MERGED,True,1,0,1,https://github.com/Fytch,add missing include <stdio.h> to lib/PoissonRecon/Geometry.h,1,[],https://github.com/colmap/colmap/pull/888,https://github.com/Fytch,2,https://github.com/colmap/colmap/pull/888#issuecomment-637105139,"Would not compile otherwise with GCC 10.1.0:
In file included from /tmp/tmp.ij35ejNwXQ/colmap/lib/PoissonRecon/Geometry.cpp:28:
/tmp/tmp.ij35ejNwXQ/colmap/lib/PoissonRecon/Geometry.h:344:2: error: ‘FILE’ does not name a type
  344 |  FILE* _fp;
      |  ^~~~
In file included from /tmp/tmp.ij35ejNwXQ/colmap/lib/PoissonRecon/Geometry.cpp:28:
/tmp/tmp.ij35ejNwXQ/colmap/lib/PoissonRecon/Geometry.h:36:1: note: ‘FILE’ is defined in header ‘<cstdio>’; did you forget to ‘#include <cstdio>’?
   35 | #include ""Hash.h""
  +++ |+#include <cstdio>
   36 | 

Also mentioned in #886.","There's also pull request #882 but that one proposes to include <cstdio>, the C++ variant of the header. As FILE is used without the std:: namespace qualifier (which would be necessary for the C++ variants of the C headers) and as the other C headers in the same source file are being included in their C variant, I propose to include the C variant here, too.",True,{}
colmap/colmap,https://github.com/colmap/colmap,888,2020-06-01T20:23:07Z,2020-06-24T09:23:29Z,2020-06-24T09:23:35Z,MERGED,True,1,0,1,https://github.com/Fytch,add missing include <stdio.h> to lib/PoissonRecon/Geometry.h,1,[],https://github.com/colmap/colmap/pull/888,https://github.com/ahojnnes,3,https://github.com/colmap/colmap/pull/888#issuecomment-648705207,"Would not compile otherwise with GCC 10.1.0:
In file included from /tmp/tmp.ij35ejNwXQ/colmap/lib/PoissonRecon/Geometry.cpp:28:
/tmp/tmp.ij35ejNwXQ/colmap/lib/PoissonRecon/Geometry.h:344:2: error: ‘FILE’ does not name a type
  344 |  FILE* _fp;
      |  ^~~~
In file included from /tmp/tmp.ij35ejNwXQ/colmap/lib/PoissonRecon/Geometry.cpp:28:
/tmp/tmp.ij35ejNwXQ/colmap/lib/PoissonRecon/Geometry.h:36:1: note: ‘FILE’ is defined in header ‘<cstdio>’; did you forget to ‘#include <cstdio>’?
   35 | #include ""Hash.h""
  +++ |+#include <cstdio>
   36 | 

Also mentioned in #886.",Thanks for the fix!,True,{}
colmap/colmap,https://github.com/colmap/colmap,889,2020-06-01T20:38:33Z,2020-06-24T09:33:22Z,2020-06-24T09:33:22Z,MERGED,True,3,3,1,https://github.com/Fytch,Catch std::invalid_argument const& instead of std::exception in misc.cc.,2,[],https://github.com/colmap/colmap/pull/889,https://github.com/Fytch,1,https://github.com/colmap/colmap/pull/889,"Firstly, catching a polymorphic type like std::exception by value causes
warnings. Secondly, we don't want to accidentally catch std::bad_alloc,
we only want to catch the errors potentially generated by std::stoi, both
of which derive from std::invalid_argument:
https://en.cppreference.com/w/cpp/string/basic_string/stol#Exceptions","Firstly, catching a polymorphic type like std::exception by value causes
warnings. Secondly, we don't want to accidentally catch std::bad_alloc,
we only want to catch the errors potentially generated by std::stoi, both
of which derive from std::invalid_argument:
https://en.cppreference.com/w/cpp/string/basic_string/stol#Exceptions",True,{}
colmap/colmap,https://github.com/colmap/colmap,889,2020-06-01T20:38:33Z,2020-06-24T09:33:22Z,2020-06-24T09:33:22Z,MERGED,True,3,3,1,https://github.com/Fytch,Catch std::invalid_argument const& instead of std::exception in misc.cc.,2,[],https://github.com/colmap/colmap/pull/889,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/889#issuecomment-648702305,"Firstly, catching a polymorphic type like std::exception by value causes
warnings. Secondly, we don't want to accidentally catch std::bad_alloc,
we only want to catch the errors potentially generated by std::stoi, both
of which derive from std::invalid_argument:
https://en.cppreference.com/w/cpp/string/basic_string/stol#Exceptions","Thanks for the fix, happy to merge after the cosmetic issue is addressed.",True,{}
colmap/colmap,https://github.com/colmap/colmap,889,2020-06-01T20:38:33Z,2020-06-24T09:33:22Z,2020-06-24T09:33:22Z,MERGED,True,3,3,1,https://github.com/Fytch,Catch std::invalid_argument const& instead of std::exception in misc.cc.,2,[],https://github.com/colmap/colmap/pull/889,https://github.com/ahojnnes,3,https://github.com/colmap/colmap/pull/889#issuecomment-648710238,"Firstly, catching a polymorphic type like std::exception by value causes
warnings. Secondly, we don't want to accidentally catch std::bad_alloc,
we only want to catch the errors potentially generated by std::stoi, both
of which derive from std::invalid_argument:
https://en.cppreference.com/w/cpp/string/basic_string/stol#Exceptions",Applying the change myself. Thanks!,True,{}
colmap/colmap,https://github.com/colmap/colmap,892,2020-06-08T06:45:09Z,2020-06-09T03:20:19Z,2020-06-10T08:46:49Z,CLOSED,False,5,5,1,https://github.com/hiakru,update colmap command script in image undistortion,2,[],https://github.com/colmap/colmap/pull/892,https://github.com/hiakru,1,https://github.com/colmap/colmap/pull/892,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,892,2020-06-08T06:45:09Z,2020-06-09T03:20:19Z,2020-06-10T08:46:49Z,CLOSED,False,5,5,1,https://github.com/hiakru,update colmap command script in image undistortion,2,[],https://github.com/colmap/colmap/pull/892,https://github.com/hiakru,2,https://github.com/colmap/colmap/pull/892#issuecomment-640402974,,"@ahojnnes  Found the invalid colmap scripts created by image undistortaion, could you help review? thanks~",True,{}
colmap/colmap,https://github.com/colmap/colmap,892,2020-06-08T06:45:09Z,2020-06-09T03:20:19Z,2020-06-10T08:46:49Z,CLOSED,False,5,5,1,https://github.com/hiakru,update colmap command script in image undistortion,2,[],https://github.com/colmap/colmap/pull/892,https://github.com/ahojnnes,3,https://github.com/colmap/colmap/pull/892#issuecomment-641849780,,"If you reopen the PR, I am happy to merge. Thanks!",True,{}
colmap/colmap,https://github.com/colmap/colmap,893,2020-06-09T03:23:34Z,2020-06-10T08:47:23Z,2020-06-10T08:47:30Z,MERGED,True,5,5,1,https://github.com/hiakru,update colmap command script in image undistortion,1,[],https://github.com/colmap/colmap/pull/893,https://github.com/hiakru,1,https://github.com/colmap/colmap/pull/893,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,893,2020-06-09T03:23:34Z,2020-06-10T08:47:23Z,2020-06-10T08:47:30Z,MERGED,True,5,5,1,https://github.com/hiakru,update colmap command script in image undistortion,1,[],https://github.com/colmap/colmap/pull/893,https://github.com/hiakru,2,https://github.com/colmap/colmap/pull/893#issuecomment-641004981,,"@ahojnnes  Found the invalid colmap scripts created by image undistortaion, could you help review? thanks~",True,{}
colmap/colmap,https://github.com/colmap/colmap,893,2020-06-09T03:23:34Z,2020-06-10T08:47:23Z,2020-06-10T08:47:30Z,MERGED,True,5,5,1,https://github.com/hiakru,update colmap command script in image undistortion,1,[],https://github.com/colmap/colmap/pull/893,https://github.com/ahojnnes,3,https://github.com/colmap/colmap/pull/893#issuecomment-641850190,,Thanks for the fix!,True,{}
colmap/colmap,https://github.com/colmap/colmap,894,2020-06-10T09:26:31Z,2020-06-10T17:28:26Z,2020-06-10T17:28:26Z,MERGED,True,2,0,1,https://github.com/hiakru,Make local_ba_min_tri_angle configurable in mapper,1,[],https://github.com/colmap/colmap/pull/894,https://github.com/hiakru,1,https://github.com/colmap/colmap/pull/894,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,897,2020-06-12T07:35:21Z,2020-06-16T14:16:01Z,2020-06-16T14:16:01Z,CLOSED,False,41,13,1,https://github.com/hiakru,Filter observations with negative depth,1,[],https://github.com/colmap/colmap/pull/897,https://github.com/hiakru,1,https://github.com/colmap/colmap/pull/897,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,897,2020-06-12T07:35:21Z,2020-06-16T14:16:01Z,2020-06-16T14:16:01Z,CLOSED,False,41,13,1,https://github.com/hiakru,Filter observations with negative depth,1,[],https://github.com/colmap/colmap/pull/897,https://github.com/hiakru,2,https://github.com/colmap/colmap/pull/897#issuecomment-644794232,,"Oooooh, my bad",True,{}
colmap/colmap,https://github.com/colmap/colmap,899,2020-06-13T20:28:43Z,2020-06-16T14:08:59Z,2020-06-16T14:08:59Z,MERGED,True,2,2,1,https://github.com/simonlynen,parallel compile,1,[],https://github.com/colmap/colmap/pull/899,https://github.com/simonlynen,1,https://github.com/colmap/colmap/pull/899,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,900,2020-06-13T20:32:47Z,2020-06-16T14:08:47Z,2020-06-16T14:08:47Z,MERGED,True,3,3,1,https://github.com/simonlynen,Catch polymorphic type std::exception by c-ref,1,[],https://github.com/colmap/colmap/pull/900,https://github.com/simonlynen,1,https://github.com/colmap/colmap/pull/900,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,900,2020-06-13T20:32:47Z,2020-06-16T14:08:47Z,2020-06-16T14:08:47Z,MERGED,True,3,3,1,https://github.com/simonlynen,Catch polymorphic type std::exception by c-ref,1,[],https://github.com/colmap/colmap/pull/900,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/900#issuecomment-644789868,,Thanks!,True,{}
colmap/colmap,https://github.com/colmap/colmap,902,2020-06-14T06:58:56Z,2020-06-14T07:06:14Z,2020-06-14T07:06:14Z,CLOSED,False,1,0,1,https://github.com/baudm,Fix PoissonRecon build under GCC 10,1,[],https://github.com/colmap/colmap/pull/902,https://github.com/baudm,1,https://github.com/colmap/colmap/pull/902,"In file included from /home/user/colmap/lib/PoissonRecon/Geometry.cpp:28:
/home/user/colmap/lib/PoissonRecon/Geometry.h:344:2: error: ‘FILE’ does not name a type
  344 |  FILE* _fp;
      |  ^~~~
In file included from /home/user/colmap/lib/PoissonRecon/Geometry.cpp:28:
/home/user/colmap/lib/PoissonRecon/Geometry.h:36:1: note: ‘FILE’ is defined in header ‘<cstdio>’; did you forget to ‘#include <cstdio>’?
   35 | #include ""Hash.h""
  +++ |+#include <cstdio>
   36 |","In file included from /home/user/colmap/lib/PoissonRecon/Geometry.cpp:28:
/home/user/colmap/lib/PoissonRecon/Geometry.h:344:2: error: ‘FILE’ does not name a type
  344 |  FILE* _fp;
      |  ^~~~
In file included from /home/user/colmap/lib/PoissonRecon/Geometry.cpp:28:
/home/user/colmap/lib/PoissonRecon/Geometry.h:36:1: note: ‘FILE’ is defined in header ‘<cstdio>’; did you forget to ‘#include <cstdio>’?
   35 | #include ""Hash.h""
  +++ |+#include <cstdio>
   36 |",True,{}
colmap/colmap,https://github.com/colmap/colmap,902,2020-06-14T06:58:56Z,2020-06-14T07:06:14Z,2020-06-14T07:06:14Z,CLOSED,False,1,0,1,https://github.com/baudm,Fix PoissonRecon build under GCC 10,1,[],https://github.com/colmap/colmap/pull/902,https://github.com/baudm,2,https://github.com/colmap/colmap/pull/902#issuecomment-643728333,"In file included from /home/user/colmap/lib/PoissonRecon/Geometry.cpp:28:
/home/user/colmap/lib/PoissonRecon/Geometry.h:344:2: error: ‘FILE’ does not name a type
  344 |  FILE* _fp;
      |  ^~~~
In file included from /home/user/colmap/lib/PoissonRecon/Geometry.cpp:28:
/home/user/colmap/lib/PoissonRecon/Geometry.h:36:1: note: ‘FILE’ is defined in header ‘<cstdio>’; did you forget to ‘#include <cstdio>’?
   35 | #include ""Hash.h""
  +++ |+#include <cstdio>
   36 |",My bad for not checking the list of open pull requests. This is a duplicate of  #888 and #882.,True,{}
colmap/colmap,https://github.com/colmap/colmap,904,2020-06-15T03:12:56Z,2020-06-16T14:08:20Z,2020-06-16T14:08:20Z,MERGED,True,2,1,1,https://github.com/hiakru,Enable AddLogOptions in option_manager,1,[],https://github.com/colmap/colmap/pull/904,https://github.com/hiakru,1,https://github.com/colmap/colmap/pull/904,#903,#903,True,{}
colmap/colmap,https://github.com/colmap/colmap,907,2020-06-17T05:32:56Z,2020-06-24T09:15:54Z,2020-06-24T09:15:54Z,CLOSED,False,1,0,1,https://github.com/hiakru,Retriangulate after AdjustGlobalBundle,1,[],https://github.com/colmap/colmap/pull/907,https://github.com/hiakru,1,https://github.com/colmap/colmap/pull/907,"#898
I think it's reasonable that images could generate new point3D, as the pose of images changed after global bundle.","#898
I think it's reasonable that images could generate new point3D, as the pose of images changed after global bundle.",True,{}
colmap/colmap,https://github.com/colmap/colmap,907,2020-06-17T05:32:56Z,2020-06-24T09:15:54Z,2020-06-24T09:15:54Z,CLOSED,False,1,0,1,https://github.com/hiakru,Retriangulate after AdjustGlobalBundle,1,[],https://github.com/colmap/colmap/pull/907,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/907#issuecomment-648701295,"#898
I think it's reasonable that images could generate new point3D, as the pose of images changed after global bundle.","Retriangulation has very relaxed triangulation thresholds. “Retriangulation” with tight thresholds is already covered by the CompleteAndMerge() function. Thanks for the idea, but I don’t think this is a good idea.",True,{}
colmap/colmap,https://github.com/colmap/colmap,921,2020-06-30T14:48:31Z,2020-07-02T19:18:43Z,2020-07-17T21:47:29Z,MERGED,True,1,1,1,https://github.com/attilaolah,Fix a reStructuredText issue,1,[],https://github.com/colmap/colmap/pull/921,https://github.com/attilaolah,1,https://github.com/colmap/colmap/pull/921,The missing space seems to prevent reStructuredText from properly rendering the word images.txt with code font.,The missing space seems to prevent reStructuredText from properly rendering the word images.txt with code font.,True,{}
colmap/colmap,https://github.com/colmap/colmap,932,2020-07-26T12:48:52Z,2020-08-08T08:45:45Z,2020-08-08T08:45:46Z,CLOSED,False,225,3,4,https://github.com/pablospe,Show a COLMAP reconstruction with Open3D (python script),3,[],https://github.com/colmap/colmap/pull/932,https://github.com/pablospe,1,https://github.com/colmap/colmap/pull/932,"For running the example:
python run_example.py --input_model <colmap_reconstruction_path>/sparse

For non-blocking visualization with Open3D this kind of the logic in run_example.py is needed:
import colmap

model = colmap.Model()
model.read_sparse(args.input_model, ext=args.input_format)

# display
model.create_window()
model.show_points()
model.show_cameras()
model.render()

(This PR is a draft for the moment)
I would recommend to include the content of read_write_model.py inside colmap.py and remove the test_read_write_model.py. A better name for run_example.py. And add proper documentation.
Ideally, it would be nice to have everything in this class:
colmap.database
colmap.export_to_*()
colmap.read_dense()
...","For running the example:
python run_example.py --input_model <colmap_reconstruction_path>/sparse

For non-blocking visualization with Open3D this kind of the logic in run_example.py is needed:
import colmap

model = colmap.Model()
model.read_sparse(args.input_model, ext=args.input_format)

# display
model.create_window()
model.show_points()
model.show_cameras()
model.render()

(This PR is a draft for the moment)
I would recommend to include the content of read_write_model.py inside colmap.py and remove the test_read_write_model.py. A better name for run_example.py. And add proper documentation.
Ideally, it would be nice to have everything in this class:
colmap.database
colmap.export_to_*()
colmap.read_dense()
...",True,{}
colmap/colmap,https://github.com/colmap/colmap,932,2020-07-26T12:48:52Z,2020-08-08T08:45:45Z,2020-08-08T08:45:46Z,CLOSED,False,225,3,4,https://github.com/pablospe,Show a COLMAP reconstruction with Open3D (python script),3,[],https://github.com/colmap/colmap/pull/932,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/932#issuecomment-670846235,"For running the example:
python run_example.py --input_model <colmap_reconstruction_path>/sparse

For non-blocking visualization with Open3D this kind of the logic in run_example.py is needed:
import colmap

model = colmap.Model()
model.read_sparse(args.input_model, ext=args.input_format)

# display
model.create_window()
model.show_points()
model.show_cameras()
model.render()

(This PR is a draft for the moment)
I would recommend to include the content of read_write_model.py inside colmap.py and remove the test_read_write_model.py. A better name for run_example.py. And add proper documentation.
Ideally, it would be nice to have everything in this class:
colmap.database
colmap.export_to_*()
colmap.read_dense()
...","Thanks Pablo. I played a little with the script and there were some issues with the visualization/construction of the camera geometries. I fixed those and also restructured the code a little by moving your code to a visualize_model.py script. I merged those changes through a separate PR. It's in the dev branch already, so will close this PR here. Thanks!",True,{}
colmap/colmap,https://github.com/colmap/colmap,936,2020-07-28T16:02:47Z,2020-07-28T18:09:19Z,2020-07-28T18:11:33Z,MERGED,True,2,2,1,https://github.com/Pascal-So,Fix typos in image.h,1,[],https://github.com/colmap/colmap/pull/936,https://github.com/Pascal-So,1,https://github.com/colmap/colmap/pull/936,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,936,2020-07-28T16:02:47Z,2020-07-28T18:09:19Z,2020-07-28T18:11:33Z,MERGED,True,2,2,1,https://github.com/Pascal-So,Fix typos in image.h,1,[],https://github.com/colmap/colmap/pull/936,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/936#issuecomment-665193203,,Thanks!,True,{}
colmap/colmap,https://github.com/colmap/colmap,943,2020-08-04T15:21:43Z,2020-08-05T05:03:05Z,2020-08-05T05:03:05Z,MERGED,True,46,1,2,https://github.com/vlarsson,Fix for EPnP estimator,1,[],https://github.com/colmap/colmap/pull/943,https://github.com/vlarsson,1,https://github.com/colmap/colmap/pull/943,"I was doing some benchmarking with absolute pose solvers and found that COLMAP's implementation of EPnP was returning garbage in roughly 25% of cases. After comparing with the OpenGV implementation I found the problem. I have not done any extensive testing after the fix, but I think it should work better now.","I was doing some benchmarking with absolute pose solvers and found that COLMAP's implementation of EPnP was returning garbage in roughly 25% of cases. After comparing with the OpenGV implementation I found the problem. I have not done any extensive testing after the fix, but I think it should work better now.",True,{}
colmap/colmap,https://github.com/colmap/colmap,943,2020-08-04T15:21:43Z,2020-08-05T05:03:05Z,2020-08-05T05:03:05Z,MERGED,True,46,1,2,https://github.com/vlarsson,Fix for EPnP estimator,1,[],https://github.com/colmap/colmap/pull/943,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/943#issuecomment-668981397,"I was doing some benchmarking with absolute pose solvers and found that COLMAP's implementation of EPnP was returning garbage in roughly 25% of cases. After comparing with the OpenGV implementation I found the problem. I have not done any extensive testing after the fix, but I think it should work better now.","Thanks, looks good!",True,{}
colmap/colmap,https://github.com/colmap/colmap,948,2020-08-08T08:32:12Z,2020-08-08T08:42:21Z,2020-08-08T08:42:25Z,MERGED,True,298,26,5,https://github.com/ahojnnes,Visualize models using Python in Open3D,5,[],https://github.com/colmap/colmap/pull/948,https://github.com/ahojnnes,1,https://github.com/colmap/colmap/pull/948,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,949,2020-08-11T01:42:10Z,2020-09-20T06:28:46Z,2020-09-22T17:30:49Z,MERGED,True,73,118,1,https://github.com/Pascal-So,BuildImageModel: use std::vector instead of numbered arguments,3,[],https://github.com/colmap/colmap/pull/949,https://github.com/Pascal-So,1,https://github.com/colmap/colmap/pull/949,I needed to make this change anyway in my fork and it looks quite upstreamable so I might as well send you this PR. I hope that this is useful and that I'm not missing some obvious reason why the previous version was implemented like that.,I needed to make this change anyway in my fork and it looks quite upstreamable so I might as well send you this PR. I hope that this is useful and that I'm not missing some obvious reason why the previous version was implemented like that.,True,{}
colmap/colmap,https://github.com/colmap/colmap,949,2020-08-11T01:42:10Z,2020-09-20T06:28:46Z,2020-09-22T17:30:49Z,MERGED,True,73,118,1,https://github.com/Pascal-So,BuildImageModel: use std::vector instead of numbered arguments,3,[],https://github.com/colmap/colmap/pull/949,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/949#issuecomment-672828833,I needed to make this change anyway in my fork and it looks quite upstreamable so I might as well send you this PR. I hope that this is useful and that I'm not missing some obvious reason why the previous version was implemented like that.,"Thanks, looks like a nice simplification. I added a small suggestion.",True,{}
colmap/colmap,https://github.com/colmap/colmap,949,2020-08-11T01:42:10Z,2020-09-20T06:28:46Z,2020-09-22T17:30:49Z,MERGED,True,73,118,1,https://github.com/Pascal-So,BuildImageModel: use std::vector instead of numbered arguments,3,[],https://github.com/colmap/colmap/pull/949,https://github.com/Pascal-So,3,https://github.com/colmap/colmap/pull/949#issuecomment-672896779,I needed to make this change anyway in my fork and it looks quite upstreamable so I might as well send you this PR. I hope that this is useful and that I'm not missing some obvious reason why the previous version was implemented like that.,"Oh right of course, thank you for catching this!
Looking at this again now, I think that I'll probably change BuildImageModel to just accept two output iterators and pass a nop output iterator for the line data if selection_mode is active. That way we never have to copy anything around at all. This will have to be after my exam later this week though.",True,{}
colmap/colmap,https://github.com/colmap/colmap,949,2020-08-11T01:42:10Z,2020-09-20T06:28:46Z,2020-09-22T17:30:49Z,MERGED,True,73,118,1,https://github.com/Pascal-So,BuildImageModel: use std::vector instead of numbered arguments,3,[],https://github.com/colmap/colmap/pull/949,https://github.com/Pascal-So,4,https://github.com/colmap/colmap/pull/949#issuecomment-674589407,I needed to make this change anyway in my fork and it looks quite upstreamable so I might as well send you this PR. I hope that this is useful and that I'm not missing some obvious reason why the previous version was implemented like that.,"This version now seems like the simpler option to me to avoid a copy than doing anything with back_inserter.
My usecase is that I'm displaying more information per image using additional lines, but I hope the change makes sense for you even in the standard setting.",True,{}
colmap/colmap,https://github.com/colmap/colmap,949,2020-08-11T01:42:10Z,2020-09-20T06:28:46Z,2020-09-22T17:30:49Z,MERGED,True,73,118,1,https://github.com/Pascal-So,BuildImageModel: use std::vector instead of numbered arguments,3,[],https://github.com/colmap/colmap/pull/949,https://github.com/ahojnnes,5,https://github.com/colmap/colmap/pull/949#issuecomment-695751398,I needed to make this change anyway in my fork and it looks quite upstreamable so I might as well send you this PR. I hope that this is useful and that I'm not missing some obvious reason why the previous version was implemented like that.,"Great, thanks very much and sorry for the delay in getting this merged.",True,{}
colmap/colmap,https://github.com/colmap/colmap,953,2020-08-13T22:51:59Z,2020-08-14T21:37:49Z,2020-08-14T21:37:49Z,MERGED,True,1,1,1,https://github.com/ignacio-rocco,Update tutorial.rst,1,[],https://github.com/colmap/colmap/pull/953,https://github.com/ignacio-rocco,1,https://github.com/colmap/colmap/pull/953,fixed small typo: lather -> later,fixed small typo: lather -> later,True,{}
colmap/colmap,https://github.com/colmap/colmap,957,2020-08-19T18:49:23Z,2020-09-20T06:27:34Z,2020-09-20T06:27:45Z,MERGED,True,94,0,2,https://github.com/SBCV,Python script for writing depth/normal arrays,1,[],https://github.com/colmap/colmap/pull/957,https://github.com/SBCV,1,https://github.com/colmap/colmap/pull/957,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,957,2020-08-19T18:49:23Z,2020-09-20T06:27:34Z,2020-09-20T06:27:45Z,MERGED,True,94,0,2,https://github.com/SBCV,Python script for writing depth/normal arrays,1,[],https://github.com/colmap/colmap/pull/957,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/957#issuecomment-695751285,,Thanks very much.,True,{}
colmap/colmap,https://github.com/colmap/colmap,972,2020-09-08T07:26:35Z,,2022-01-26T12:22:15Z,OPEN,False,89,7,5,https://github.com/boitumeloruf,COLMAP-Model-Aligner: Write SimilarityTransform to file,7,[],https://github.com/colmap/colmap/pull/972,https://github.com/boitumeloruf,1,https://github.com/colmap/colmap/pull/972,When using the model_aligner the computed SimilarityTransform which is used to transform the model is additionally exported to a .txt file. This allows to use the unaligned reconstruction for further processing (i.e. OpenMVS) and perform the perform the alignment transformation on the final result.,When using the model_aligner the computed SimilarityTransform which is used to transform the model is additionally exported to a .txt file. This allows to use the unaligned reconstruction for further processing (i.e. OpenMVS) and perform the perform the alignment transformation on the final result.,True,{}
colmap/colmap,https://github.com/colmap/colmap,982,2020-09-17T09:20:19Z,2020-09-17T11:11:30Z,2020-09-17T11:11:30Z,MERGED,True,25,17,2,https://github.com/mihaidusmanu,8 point algorithm internal contraint fix,2,[],https://github.com/colmap/colmap/pull/982,https://github.com/mihaidusmanu,1,https://github.com/colmap/colmap/pull/982,De-normalize before enforcing the internal constraints and update the test accordingly. Fixes #861,De-normalize before enforcing the internal constraints and update the test accordingly. Fixes #861,True,{}
colmap/colmap,https://github.com/colmap/colmap,984,2020-09-18T16:31:43Z,2020-09-21T19:33:47Z,2020-09-21T19:33:47Z,MERGED,True,179,0,2,https://github.com/SBCV,script for modifying fused results,1,[],https://github.com/colmap/colmap/pull/984,https://github.com/SBCV,1,https://github.com/colmap/colmap/pull/984,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,984,2020-09-18T16:31:43Z,2020-09-21T19:33:47Z,2020-09-21T19:33:47Z,MERGED,True,179,0,2,https://github.com/SBCV,script for modifying fused results,1,[],https://github.com/colmap/colmap/pull/984,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/984#issuecomment-695751128,,"Looks great, thanks. Left some minor comments for you.",True,{}
colmap/colmap,https://github.com/colmap/colmap,984,2020-09-18T16:31:43Z,2020-09-21T19:33:47Z,2020-09-21T19:33:47Z,MERGED,True,179,0,2,https://github.com/SBCV,script for modifying fused results,1,[],https://github.com/colmap/colmap/pull/984,https://github.com/SBCV,3,https://github.com/colmap/colmap/pull/984#issuecomment-695769785,,"Changed the PR according to your comments and updated the PR accordingly. I guess the two ""unused"" comments referred both to ""import struct""?",True,{}
colmap/colmap,https://github.com/colmap/colmap,984,2020-09-18T16:31:43Z,2020-09-21T19:33:47Z,2020-09-21T19:33:47Z,MERGED,True,179,0,2,https://github.com/SBCV,script for modifying fused results,1,[],https://github.com/colmap/colmap/pull/984,https://github.com/ahojnnes,4,https://github.com/colmap/colmap/pull/984#issuecomment-695776080,,Pandas seems like a heavy dependency just for enabling structured numpy arrays. The same should be possible with numpy out of the box?,True,{}
colmap/colmap,https://github.com/colmap/colmap,984,2020-09-18T16:31:43Z,2020-09-21T19:33:47Z,2020-09-21T19:33:47Z,MERGED,True,179,0,2,https://github.com/SBCV,script for modifying fused results,1,[],https://github.com/colmap/colmap/pull/984,https://github.com/SBCV,5,https://github.com/colmap/colmap/pull/984#issuecomment-695987238,,"I leveraged the pandas package here, because it is internally used by the pyntcloud package (and will be automatically installed with pip install pyntcloud).
I've also considered other libraries than pyntcloud.
For example, in the past I've used plyfile, which has no other dependencies. However, the interface of plyfile is really convoluted and a lot of custom code is required for writing points from and to plyfiles. See this this file for example. In addition, I've read that pyntcloud is three times faster.
I also considered Open3D for reading/writing ply files. However, Open3D does not support to configure the types in the generated output file (32 bit float vs 64 bit float). Thus, with Open3D it is not possible to compare the results, i.e.
    assert filecmp.cmp(path_to_fused_ply_input, path_to_fused_ply_output)
    assert filecmp.cmp(path_to_fused_ply_vis_input, path_to_fused_ply_vis_output)

Thus, I think that the pyntcloud package is a valid choice - and therefore the usage of pandas not too bad. What do you think?",True,{}
colmap/colmap,https://github.com/colmap/colmap,984,2020-09-18T16:31:43Z,2020-09-21T19:33:47Z,2020-09-21T19:33:47Z,MERGED,True,179,0,2,https://github.com/SBCV,script for modifying fused results,1,[],https://github.com/colmap/colmap/pull/984,https://github.com/ahojnnes,6,https://github.com/colmap/colmap/pull/984#issuecomment-696326310,,"Thanks for the explanations, makes sense to me. Merging and thanks for the contribution.",True,{'THUMBS_UP': ['https://github.com/SBCV']}
colmap/colmap,https://github.com/colmap/colmap,985,2020-09-19T21:25:28Z,2020-09-21T05:43:13Z,2020-09-21T05:43:13Z,MERGED,True,63,8,3,https://github.com/whuaegeanse,Fix bugs of sift feature matching,4,[],https://github.com/colmap/colmap/pull/985,https://github.com/whuaegeanse,1,https://github.com/colmap/colmap/pull/985,"Fix bug in sift feature matching, when features cannot be extracted from images lacking texture.


Fix bug in sift feature matching, when the number of feature points extracted from an image lacking texture is less than 2.","Fix bug in sift feature matching, when features cannot be extracted from images lacking texture.


Fix bug in sift feature matching, when the number of feature points extracted from an image lacking texture is less than 2.",True,{}
colmap/colmap,https://github.com/colmap/colmap,985,2020-09-19T21:25:28Z,2020-09-21T05:43:13Z,2020-09-21T05:43:13Z,MERGED,True,63,8,3,https://github.com/whuaegeanse,Fix bugs of sift feature matching,4,[],https://github.com/colmap/colmap/pull/985,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/985#issuecomment-695750822,"Fix bug in sift feature matching, when features cannot be extracted from images lacking texture.


Fix bug in sift feature matching, when the number of feature points extracted from an image lacking texture is less than 2.","Thanks, looks good to me. I left some minor comments that could be addressed before merging.",True,{}
colmap/colmap,https://github.com/colmap/colmap,985,2020-09-19T21:25:28Z,2020-09-21T05:43:13Z,2020-09-21T05:43:13Z,MERGED,True,63,8,3,https://github.com/whuaegeanse,Fix bugs of sift feature matching,4,[],https://github.com/colmap/colmap/pull/985,https://github.com/whuaegeanse,3,https://github.com/colmap/colmap/pull/985#issuecomment-695772534,"Fix bug in sift feature matching, when features cannot be extracted from images lacking texture.


Fix bug in sift feature matching, when the number of feature points extracted from an image lacking texture is less than 2.","Thanks, looks good to me. I left some minor comments that could be addressed before merging.

Following your suggestion, I made a new commit.",True,{}
colmap/colmap,https://github.com/colmap/colmap,985,2020-09-19T21:25:28Z,2020-09-21T05:43:13Z,2020-09-21T05:43:13Z,MERGED,True,63,8,3,https://github.com/whuaegeanse,Fix bugs of sift feature matching,4,[],https://github.com/colmap/colmap/pull/985,https://github.com/ahojnnes,4,https://github.com/colmap/colmap/pull/985#issuecomment-695775876,"Fix bug in sift feature matching, when features cannot be extracted from images lacking texture.


Fix bug in sift feature matching, when the number of feature points extracted from an image lacking texture is less than 2.","Thanks, one more comment: it would be good to use an LRU cache similar to keypoints_/descriptors_cache_ for the new Exists methods to avoid disk access to the database.",True,{}
colmap/colmap,https://github.com/colmap/colmap,985,2020-09-19T21:25:28Z,2020-09-21T05:43:13Z,2020-09-21T05:43:13Z,MERGED,True,63,8,3,https://github.com/whuaegeanse,Fix bugs of sift feature matching,4,[],https://github.com/colmap/colmap/pull/985,https://github.com/whuaegeanse,5,https://github.com/colmap/colmap/pull/985#issuecomment-695807567,"Fix bug in sift feature matching, when features cannot be extracted from images lacking texture.


Fix bug in sift feature matching, when the number of feature points extracted from an image lacking texture is less than 2.","Thanks, one more comment: it would be good to use an LRU cache similar to keypoints_/descriptors_cache_ for the new Exists methods to avoid disk access to the database.

Good idea. I have learnt a lot from you. Thank you for providing such a great open source SfM engine.",True,{}
colmap/colmap,https://github.com/colmap/colmap,985,2020-09-19T21:25:28Z,2020-09-21T05:43:13Z,2020-09-21T05:43:13Z,MERGED,True,63,8,3,https://github.com/whuaegeanse,Fix bugs of sift feature matching,4,[],https://github.com/colmap/colmap/pull/985,https://github.com/ahojnnes,6,https://github.com/colmap/colmap/pull/985#issuecomment-695911178,"Fix bug in sift feature matching, when features cannot be extracted from images lacking texture.


Fix bug in sift feature matching, when the number of feature points extracted from an image lacking texture is less than 2.","Thanks, this looks great.",True,{}
colmap/colmap,https://github.com/colmap/colmap,989,2020-09-25T13:43:15Z,2020-10-30T20:02:29Z,2020-10-30T20:02:30Z,MERGED,True,3,0,1,https://github.com/srinivas32,Update .travis.yml,1,[],https://github.com/colmap/colmap/pull/989,https://github.com/srinivas32,1,https://github.com/colmap/colmap/pull/989,ppc64le arch added on yaml file.,ppc64le arch added on yaml file.,True,{}
colmap/colmap,https://github.com/colmap/colmap,989,2020-09-25T13:43:15Z,2020-10-30T20:02:29Z,2020-10-30T20:02:30Z,MERGED,True,3,0,1,https://github.com/srinivas32,Update .travis.yml,1,[],https://github.com/colmap/colmap/pull/989,https://github.com/srinivas32,2,https://github.com/colmap/colmap/pull/989#issuecomment-707027985,ppc64le arch added on yaml file.,Added power support for the travis.yml file with ppc64le. This is part of the Ubuntu distribution for ppc64le. This helps us simplify testing later when distributions are re-building and re-releasing. For more info tag @gerrith3.,True,{}
colmap/colmap,https://github.com/colmap/colmap,989,2020-09-25T13:43:15Z,2020-10-30T20:02:29Z,2020-10-30T20:02:30Z,MERGED,True,3,0,1,https://github.com/srinivas32,Update .travis.yml,1,[],https://github.com/colmap/colmap/pull/989,https://github.com/srinivas32,3,https://github.com/colmap/colmap/pull/989#issuecomment-718963933,ppc64le arch added on yaml file.,"Added power support for the travis.yml file with ppc64le. This is part of the Ubuntu distribution for ppc64le. This helps us simplify testing later when distributions are re-building and re-releasing. For more info tag @gerrith3.
build has passed  successfully with out any issues.please close this issue.",True,{}
colmap/colmap,https://github.com/colmap/colmap,997,2020-10-03T22:05:49Z,2020-10-11T10:58:32Z,2020-10-11T10:58:38Z,MERGED,True,4,4,1,https://github.com/Pascal-So,fix camera model query,1,[],https://github.com/colmap/colmap/pull/997,https://github.com/Pascal-So,1,https://github.com/colmap/colmap/pull/997,The return value of StringReplace was not being used and therefore the query was done with the name still containing spaces and dashes.,The return value of StringReplace was not being used and therefore the query was done with the name still containing spaces and dashes.,True,{}
colmap/colmap,https://github.com/colmap/colmap,997,2020-10-03T22:05:49Z,2020-10-11T10:58:32Z,2020-10-11T10:58:38Z,MERGED,True,4,4,1,https://github.com/Pascal-So,fix camera model query,1,[],https://github.com/colmap/colmap/pull/997,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/997#issuecomment-706686746,The return value of StringReplace was not being used and therefore the query was done with the name still containing spaces and dashes.,Thanks for the fix.,True,{}
colmap/colmap,https://github.com/colmap/colmap,1007,2020-10-13T16:43:40Z,2020-10-14T21:21:55Z,2020-10-14T21:22:02Z,MERGED,True,1,1,1,https://github.com/sniklaus,fixed small bug in visualize_model.py,1,[],https://github.com/colmap/colmap/pull/1007,https://github.com/sniklaus,1,https://github.com/colmap/colmap/pull/1007,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,1007,2020-10-13T16:43:40Z,2020-10-14T21:21:55Z,2020-10-14T21:22:02Z,MERGED,True,1,1,1,https://github.com/sniklaus,fixed small bug in visualize_model.py,1,[],https://github.com/colmap/colmap/pull/1007,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/1007#issuecomment-708667212,,Thanks!,True,{}
colmap/colmap,https://github.com/colmap/colmap,1015,2020-10-18T04:57:08Z,,2022-01-26T12:22:15Z,OPEN,False,6,1,1,https://github.com/lijgame,Fix link error when clang9 is used,5,[],https://github.com/colmap/colmap/pull/1015,https://github.com/lijgame,1,https://github.com/colmap/colmap/pull/1015,"Fix issue #1014
It's bug in LLVM: https://bugzilla.redhat.com/show_bug.cgi?id=1803203","Fix issue #1014
It's bug in LLVM: https://bugzilla.redhat.com/show_bug.cgi?id=1803203",True,{}
colmap/colmap,https://github.com/colmap/colmap,1038,2020-11-02T08:51:00Z,2021-02-14T07:57:26Z,2021-02-14T07:57:27Z,MERGED,True,3,4,1,https://github.com/DaniilSNikulin,"search src images for patch_match from all set, not only referenced subset",1,[],https://github.com/colmap/colmap/pull/1038,https://github.com/DaniilSNikulin,1,https://github.com/colmap/colmap/pull/1038,fixes #1034,fixes #1034,True,{}
colmap/colmap,https://github.com/colmap/colmap,1038,2020-11-02T08:51:00Z,2021-02-14T07:57:26Z,2021-02-14T07:57:27Z,MERGED,True,3,4,1,https://github.com/DaniilSNikulin,"search src images for patch_match from all set, not only referenced subset",1,[],https://github.com/colmap/colmap/pull/1038,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/1038#issuecomment-778742445,fixes #1034,Thanks and sorry for delay in reviewing these changes.,True,{}
colmap/colmap,https://github.com/colmap/colmap,1039,2020-11-03T18:17:18Z,2020-11-12T09:32:20Z,2020-11-12T09:32:25Z,MERGED,True,2,2,1,https://github.com/UncleGene,Remove deprecated qt foreach,2,[],https://github.com/colmap/colmap/pull/1039,https://github.com/UncleGene,1,https://github.com/colmap/colmap/pull/1039,"QT foreach is on deprecation path (https://codereview.qt-project.org/c/qt/qtbase/+/147363) and already may not be available in qt depending on build configuration.
Change to C++11+ range for should be forward-compatible, and as far as I can see C++11 is the current minimum version","QT foreach is on deprecation path (https://codereview.qt-project.org/c/qt/qtbase/+/147363) and already may not be available in qt depending on build configuration.
Change to C++11+ range for should be forward-compatible, and as far as I can see C++11 is the current minimum version",True,{}
colmap/colmap,https://github.com/colmap/colmap,1039,2020-11-03T18:17:18Z,2020-11-12T09:32:20Z,2020-11-12T09:32:25Z,MERGED,True,2,2,1,https://github.com/UncleGene,Remove deprecated qt foreach,2,[],https://github.com/colmap/colmap/pull/1039,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/1039#issuecomment-725959397,"QT foreach is on deprecation path (https://codereview.qt-project.org/c/qt/qtbase/+/147363) and already may not be available in qt depending on build configuration.
Change to C++11+ range for should be forward-compatible, and as far as I can see C++11 is the current minimum version",Thanks!,True,{}
colmap/colmap,https://github.com/colmap/colmap,1040,2020-11-04T22:21:14Z,2020-11-05T08:31:20Z,2020-11-05T16:16:13Z,MERGED,True,54,0,2,https://github.com/daithimaco,Ensure DecomposeHomographyMatrix() always returns rotations,1,[],https://github.com/colmap/colmap/pull/1040,https://github.com/daithimaco,1,https://github.com/colmap/colmap/pull/1040,"DecomposeHomographyMatrix() sometimes returns reflection matrices instead of rotations.
This results in invalid quaternions in two view geometry estimation:

  
    
      colmap/src/estimators/two_view_geometry.cc
    
    
         Line 209
      in
      91795d0
    
  
  
    

        
          
           qvec = RotationMatrixToQuaternion(R); 
        
    
  


Adding a fix here which just involves making sure the homography matrix has positive determinant before applying the formulas from the paper.
Also added a unit test, and confirmed it fails about half the time without this change.","DecomposeHomographyMatrix() sometimes returns reflection matrices instead of rotations.
This results in invalid quaternions in two view geometry estimation:

  
    
      colmap/src/estimators/two_view_geometry.cc
    
    
         Line 209
      in
      91795d0
    
  
  
    

        
          
           qvec = RotationMatrixToQuaternion(R); 
        
    
  


Adding a fix here which just involves making sure the homography matrix has positive determinant before applying the formulas from the paper.
Also added a unit test, and confirmed it fails about half the time without this change.",True,{}
colmap/colmap,https://github.com/colmap/colmap,1040,2020-11-04T22:21:14Z,2020-11-05T08:31:20Z,2020-11-05T16:16:13Z,MERGED,True,54,0,2,https://github.com/daithimaco,Ensure DecomposeHomographyMatrix() always returns rotations,1,[],https://github.com/colmap/colmap/pull/1040,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/1040#issuecomment-722225867,"DecomposeHomographyMatrix() sometimes returns reflection matrices instead of rotations.
This results in invalid quaternions in two view geometry estimation:

  
    
      colmap/src/estimators/two_view_geometry.cc
    
    
         Line 209
      in
      91795d0
    
  
  
    

        
          
           qvec = RotationMatrixToQuaternion(R); 
        
    
  


Adding a fix here which just involves making sure the homography matrix has positive determinant before applying the formulas from the paper.
Also added a unit test, and confirmed it fails about half the time without this change.","Great, thank you!",True,{}
colmap/colmap,https://github.com/colmap/colmap,1058,2020-11-19T12:45:04Z,,2022-01-26T12:22:15Z,OPEN,False,14,0,4,https://github.com/Dawars,Add image_list_path option to mapper gui,3,[],https://github.com/colmap/colmap/pull/1058,https://github.com/Dawars,1,https://github.com/colmap/colmap/pull/1058,"I added gui option to the mapper to support image_list_path.
I like monitoring the reconstruction in real time and sometimes I have to use a subset of the matched images.
I thought this might be useful for others, otherwise please close","I added gui option to the mapper to support image_list_path.
I like monitoring the reconstruction in real time and sometimes I have to use a subset of the matched images.
I thought this might be useful for others, otherwise please close",True,{}
colmap/colmap,https://github.com/colmap/colmap,1058,2020-11-19T12:45:04Z,,2022-01-26T12:22:15Z,OPEN,False,14,0,4,https://github.com/Dawars,Add image_list_path option to mapper gui,3,[],https://github.com/colmap/colmap/pull/1058,https://github.com/Dawars,2,https://github.com/colmap/colmap/pull/1058#issuecomment-785767377,"I added gui option to the mapper to support image_list_path.
I like monitoring the reconstruction in real time and sometimes I have to use a subset of the matched images.
I thought this might be useful for others, otherwise please close","The list doesn't get refreshed when the reconstruction is paused and then resumed but neither do the other parameters so I think this is the expected behavior.
Maybe it would be interesting in the future to create a file browser window to select the images.",True,{}
colmap/colmap,https://github.com/colmap/colmap,1079,2020-12-18T00:13:06Z,2020-12-18T09:25:07Z,2020-12-18T09:25:07Z,MERGED,True,15,15,3,https://github.com/drkoller,Fix AMD/Windows GUI visualization bug,1,[],https://github.com/colmap/colmap/pull/1079,https://github.com/drkoller,1,https://github.com/colmap/colmap/pull/1079,"Throughout the lifetime of the COLMAP software, users on the Windows platform with AMD display drivers have reported problems visualizing 3D geometry in the main display window of the COLMAP GUI. See for example:

#218 Reconstruction on AMD cards yields wrong results
#865 Sparse reconstruction show is not normal when I use amd r5 3500u
Discussion thread on COLMAP Google Groups

The source of these problems is an OpenGL programming bug resulting in mismatched vertex attribute indices (locations) between the shader code and the calling code. For example, this current COLMAP code:

  
    
      colmap/src/ui/line_painter.cc
    
    
        Lines 84 to 92
      in
      0aea04c
    
  
  
    

        
          
           // in_position 
        

        
          
           shader_program_.enableAttributeArray(0); 
        

        
          
           shader_program_.setAttributeBuffer(0, GL_FLOAT, 0, 3, 
        

        
          
                                              sizeof(PointPainter::Data)); 
        

        
          
            
        

        
          
           // in_color 
        

        
          
           shader_program_.enableAttributeArray(1); 
        

        
          
           shader_program_.setAttributeBuffer(1, GL_FLOAT, 3 * sizeof(GLfloat), 4, 
        

        
          
                                              sizeof(PointPainter::Data)); 
        
    
  


sets the vertex position attribute to correspond to location 0, and the vertex color attribute to location 1. However, these attribute locations are not specified in the GLSL shaders, and so different OpenGL implementations are free to assign different mappings for these vertex attributes. While Nvidia drivers seem to use choose locations 0 and 1 for the vertex position and color attributes, respectively, AMD drivers on Windows seem to be using the opposite configuration (location 0 for color, location 1 for position) when the COLMAP shaders are compiled. So, the vertex data is misinterpreted by the shaders on AMD cards.
There are several different ways in OpenGL to harmonize the vertex attribute locations with the shaders (glGetAttribLocation() queries, glBindAttribLocation() binding, GL_ARB_explicit_attrib_location in the shader code, etc.). In this PR, I've fixed the bug by using similar QOpenGLShaderProgram methods to those already in use by COLMAP, but calling them with the corresponding attribute names from the shader programs, rather than the hard-coded indices of 0 and 1. With this change, the vertex attributes are properly matched, and 3D geometry is rendered as expected on both NVidia and AMD systems.","Throughout the lifetime of the COLMAP software, users on the Windows platform with AMD display drivers have reported problems visualizing 3D geometry in the main display window of the COLMAP GUI. See for example:

#218 Reconstruction on AMD cards yields wrong results
#865 Sparse reconstruction show is not normal when I use amd r5 3500u
Discussion thread on COLMAP Google Groups

The source of these problems is an OpenGL programming bug resulting in mismatched vertex attribute indices (locations) between the shader code and the calling code. For example, this current COLMAP code:

  
    
      colmap/src/ui/line_painter.cc
    
    
        Lines 84 to 92
      in
      0aea04c
    
  
  
    

        
          
           // in_position 
        

        
          
           shader_program_.enableAttributeArray(0); 
        

        
          
           shader_program_.setAttributeBuffer(0, GL_FLOAT, 0, 3, 
        

        
          
                                              sizeof(PointPainter::Data)); 
        

        
          
            
        

        
          
           // in_color 
        

        
          
           shader_program_.enableAttributeArray(1); 
        

        
          
           shader_program_.setAttributeBuffer(1, GL_FLOAT, 3 * sizeof(GLfloat), 4, 
        

        
          
                                              sizeof(PointPainter::Data)); 
        
    
  


sets the vertex position attribute to correspond to location 0, and the vertex color attribute to location 1. However, these attribute locations are not specified in the GLSL shaders, and so different OpenGL implementations are free to assign different mappings for these vertex attributes. While Nvidia drivers seem to use choose locations 0 and 1 for the vertex position and color attributes, respectively, AMD drivers on Windows seem to be using the opposite configuration (location 0 for color, location 1 for position) when the COLMAP shaders are compiled. So, the vertex data is misinterpreted by the shaders on AMD cards.
There are several different ways in OpenGL to harmonize the vertex attribute locations with the shaders (glGetAttribLocation() queries, glBindAttribLocation() binding, GL_ARB_explicit_attrib_location in the shader code, etc.). In this PR, I've fixed the bug by using similar QOpenGLShaderProgram methods to those already in use by COLMAP, but calling them with the corresponding attribute names from the shader programs, rather than the hard-coded indices of 0 and 1. With this change, the vertex attributes are properly matched, and 3D geometry is rendered as expected on both NVidia and AMD systems.",True,{}
colmap/colmap,https://github.com/colmap/colmap,1079,2020-12-18T00:13:06Z,2020-12-18T09:25:07Z,2020-12-18T09:25:07Z,MERGED,True,15,15,3,https://github.com/drkoller,Fix AMD/Windows GUI visualization bug,1,[],https://github.com/colmap/colmap/pull/1079,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/1079#issuecomment-747968730,"Throughout the lifetime of the COLMAP software, users on the Windows platform with AMD display drivers have reported problems visualizing 3D geometry in the main display window of the COLMAP GUI. See for example:

#218 Reconstruction on AMD cards yields wrong results
#865 Sparse reconstruction show is not normal when I use amd r5 3500u
Discussion thread on COLMAP Google Groups

The source of these problems is an OpenGL programming bug resulting in mismatched vertex attribute indices (locations) between the shader code and the calling code. For example, this current COLMAP code:

  
    
      colmap/src/ui/line_painter.cc
    
    
        Lines 84 to 92
      in
      0aea04c
    
  
  
    

        
          
           // in_position 
        

        
          
           shader_program_.enableAttributeArray(0); 
        

        
          
           shader_program_.setAttributeBuffer(0, GL_FLOAT, 0, 3, 
        

        
          
                                              sizeof(PointPainter::Data)); 
        

        
          
            
        

        
          
           // in_color 
        

        
          
           shader_program_.enableAttributeArray(1); 
        

        
          
           shader_program_.setAttributeBuffer(1, GL_FLOAT, 3 * sizeof(GLfloat), 4, 
        

        
          
                                              sizeof(PointPainter::Data)); 
        
    
  


sets the vertex position attribute to correspond to location 0, and the vertex color attribute to location 1. However, these attribute locations are not specified in the GLSL shaders, and so different OpenGL implementations are free to assign different mappings for these vertex attributes. While Nvidia drivers seem to use choose locations 0 and 1 for the vertex position and color attributes, respectively, AMD drivers on Windows seem to be using the opposite configuration (location 0 for color, location 1 for position) when the COLMAP shaders are compiled. So, the vertex data is misinterpreted by the shaders on AMD cards.
There are several different ways in OpenGL to harmonize the vertex attribute locations with the shaders (glGetAttribLocation() queries, glBindAttribLocation() binding, GL_ARB_explicit_attrib_location in the shader code, etc.). In this PR, I've fixed the bug by using similar QOpenGLShaderProgram methods to those already in use by COLMAP, but calling them with the corresponding attribute names from the shader programs, rather than the hard-coded indices of 0 and 1. With this change, the vertex attributes are properly matched, and 3D geometry is rendered as expected on both NVidia and AMD systems.","Fantastic, thanks very much for tracking down this issue!",True,{}
colmap/colmap,https://github.com/colmap/colmap,1084,2020-12-30T16:32:56Z,2020-12-30T17:07:08Z,2020-12-30T17:07:16Z,MERGED,True,1,0,1,https://github.com/ClementPinard,include colmap_cuda in COLMAP_LIBRARIES when compiled with cuda,1,[],https://github.com/colmap/colmap/pull/1084,https://github.com/ClementPinard,1,https://github.com/colmap/colmap/pull/1084,"fixes #1065
As discussed there, the example given in https://colmap.github.io/install.html#library does not work if colmap was compiled with cuda support because it doesnt link against the cuda_colmap library, even if the cuda functions are not used.
This PR tries tries to fix the problem by adding colmap_cuda to the COLMAP_LIBRARIES variable so that the end user does not have to worry about it.","fixes #1065
As discussed there, the example given in https://colmap.github.io/install.html#library does not work if colmap was compiled with cuda support because it doesnt link against the cuda_colmap library, even if the cuda functions are not used.
This PR tries tries to fix the problem by adding colmap_cuda to the COLMAP_LIBRARIES variable so that the end user does not have to worry about it.",True,{}
colmap/colmap,https://github.com/colmap/colmap,1084,2020-12-30T16:32:56Z,2020-12-30T17:07:08Z,2020-12-30T17:07:16Z,MERGED,True,1,0,1,https://github.com/ClementPinard,include colmap_cuda in COLMAP_LIBRARIES when compiled with cuda,1,[],https://github.com/colmap/colmap/pull/1084,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/1084#issuecomment-752692624,"fixes #1065
As discussed there, the example given in https://colmap.github.io/install.html#library does not work if colmap was compiled with cuda support because it doesnt link against the cuda_colmap library, even if the cuda functions are not used.
This PR tries tries to fix the problem by adding colmap_cuda to the COLMAP_LIBRARIES variable so that the end user does not have to worry about it.",Thanks!,True,{}
colmap/colmap,https://github.com/colmap/colmap,1103,2021-02-02T00:37:51Z,2021-02-12T19:45:43Z,2021-02-12T19:45:43Z,MERGED,True,56,7,3,https://github.com/Ahmed-Salama,Store relative poses in two_view_geometry table,1,[],https://github.com/colmap/colmap/pull/1103,https://github.com/Ahmed-Salama,1,https://github.com/colmap/colmap/pull/1103,"Small change to persist two view geometry relative pose (qvec and tvec) in the corresponding two_view_geometries table.
COLMAP's database has a two_view_geometries table which serializes instances of the TwoViewGeometry class, but it doesn't store the relative pose, which adds the burden of having to re-compute after reading from the database.
Also extended base/database_test to test the read and write.","Small change to persist two view geometry relative pose (qvec and tvec) in the corresponding two_view_geometries table.
COLMAP's database has a two_view_geometries table which serializes instances of the TwoViewGeometry class, but it doesn't store the relative pose, which adds the burden of having to re-compute after reading from the database.
Also extended base/database_test to test the read and write.",True,{}
colmap/colmap,https://github.com/colmap/colmap,1103,2021-02-02T00:37:51Z,2021-02-12T19:45:43Z,2021-02-12T19:45:43Z,MERGED,True,56,7,3,https://github.com/Ahmed-Salama,Store relative poses in two_view_geometry table,1,[],https://github.com/colmap/colmap/pull/1103,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/1103#issuecomment-778413669,"Small change to persist two view geometry relative pose (qvec and tvec) in the corresponding two_view_geometries table.
COLMAP's database has a two_view_geometries table which serializes instances of the TwoViewGeometry class, but it doesn't store the relative pose, which adds the burden of having to re-compute after reading from the database.
Also extended base/database_test to test the read and write.",Looks perfect. Nice feature addition. Thanks!,True,{}
colmap/colmap,https://github.com/colmap/colmap,1114,2021-02-11T05:03:57Z,2021-02-22T22:42:32Z,2021-02-22T22:42:55Z,CLOSED,False,815,164,32,https://github.com/anmatako,Integration of PatchmatchNet into colmap by implementing the evaluation in LibTorch ,13,[],https://github.com/colmap/colmap/pull/1114,https://github.com/anmatako,1,https://github.com/colmap/colmap/pull/1114,"Example of PatchmatchNet integration with COLMAP using LibTorch.

Added PatchMatchNet implementation as alternative to standard patch-match
New functionality controlled by the new --method learned option in patch_match_stereo
Additional options were added in PatchMatchOptions to load a checkpoint and a parameter dictionary
Created inheritance structure for PatchMatch (base class) and PatchMatchCuda and PatchMatchNet (derived) to facilitate the choice of processing method
All PatchmatchNet torch-related files are under to colmap_cuda library due to their CUDA dependency","Example of PatchmatchNet integration with COLMAP using LibTorch.

Added PatchMatchNet implementation as alternative to standard patch-match
New functionality controlled by the new --method learned option in patch_match_stereo
Additional options were added in PatchMatchOptions to load a checkpoint and a parameter dictionary
Created inheritance structure for PatchMatch (base class) and PatchMatchCuda and PatchMatchNet (derived) to facilitate the choice of processing method
All PatchmatchNet torch-related files are under to colmap_cuda library due to their CUDA dependency",True,{}
colmap/colmap,https://github.com/colmap/colmap,1114,2021-02-11T05:03:57Z,2021-02-22T22:42:32Z,2021-02-22T22:42:55Z,CLOSED,False,815,164,32,https://github.com/anmatako,Integration of PatchmatchNet into colmap by implementing the evaluation in LibTorch ,13,[],https://github.com/colmap/colmap/pull/1114,https://github.com/anmatako,2,https://github.com/colmap/colmap/pull/1114#issuecomment-783729415,"Example of PatchmatchNet integration with COLMAP using LibTorch.

Added PatchMatchNet implementation as alternative to standard patch-match
New functionality controlled by the new --method learned option in patch_match_stereo
Additional options were added in PatchMatchOptions to load a checkpoint and a parameter dictionary
Created inheritance structure for PatchMatch (base class) and PatchMatchCuda and PatchMatchNet (derived) to facilitate the choice of processing method
All PatchmatchNet torch-related files are under to colmap_cuda library due to their CUDA dependency",Abandon this in favor of newer PR that should be able to get merged in public repo,True,{}
colmap/colmap,https://github.com/colmap/colmap,1115,2021-02-11T23:37:49Z,2021-02-12T19:38:32Z,2021-02-23T04:26:34Z,MERGED,True,6,2,1,https://github.com/anmatako,Fix runtime crash when sparsesuite is missing from ceres,1,[],https://github.com/colmap/colmap/pull/1115,https://github.com/anmatako,1,https://github.com/colmap/colmap/pull/1115,"The Ceres built-in variable sparse_linear_algebra_library_type  is set correctly during build, so checking the existence of sparse support before using the SPARSE_SCHUR method avoids a runtime crash in bundle adjustment","The Ceres built-in variable sparse_linear_algebra_library_type  is set correctly during build, so checking the existence of sparse support before using the SPARSE_SCHUR method avoids a runtime crash in bundle adjustment",True,{}
colmap/colmap,https://github.com/colmap/colmap,1115,2021-02-11T23:37:49Z,2021-02-12T19:38:32Z,2021-02-23T04:26:34Z,MERGED,True,6,2,1,https://github.com/anmatako,Fix runtime crash when sparsesuite is missing from ceres,1,[],https://github.com/colmap/colmap/pull/1115,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/1115#issuecomment-778409726,"The Ceres built-in variable sparse_linear_algebra_library_type  is set correctly during build, so checking the existence of sparse support before using the SPARSE_SCHUR method avoids a runtime crash in bundle adjustment","LGTM, thank you!",True,{}
colmap/colmap,https://github.com/colmap/colmap,1118,2021-02-14T10:45:25Z,2021-02-26T12:57:04Z,2021-02-26T12:57:08Z,CLOSED,False,5,20,1,https://github.com/ahojnnes,Upgrade to Ubuntu 1804 in Travis CI,2,[],https://github.com/colmap/colmap/pull/1118,https://github.com/ahojnnes,1,https://github.com/colmap/colmap/pull/1118,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,1119,2021-02-14T11:10:18Z,2021-02-22T04:31:56Z,2021-02-26T12:56:38Z,MERGED,True,139,153,4,https://github.com/ahojnnes,Replace Travis CI with Azure Pipelines for Linux/Mac builds,46,[],https://github.com/colmap/colmap/pull/1119,https://github.com/ahojnnes,1,https://github.com/colmap/colmap/pull/1119,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,1121,2021-02-15T10:39:21Z,,2022-01-26T12:22:15Z,OPEN,False,3,12,1,https://github.com/tdegraaff,Fixed the collection of arguments in colmap.bat,2,[],https://github.com/colmap/colmap/pull/1121,https://github.com/tdegraaff,1,https://github.com/colmap/colmap/pull/1121,"The previous use of the shift-operator in colmap.bat lead to splitting """"-encapsulated comma-separated values (e.g. ""1,2,3"") into individual arguments. Therefore, parameters like --ImageReader.camera_params could not be used on Windows (see screenshot).

This pull request replaces the previous mechanism that uses the shift-operator by simply using the %* operator. This way, using --ImageReader.camera_params on Windows works flawlessly.","The previous use of the shift-operator in colmap.bat lead to splitting """"-encapsulated comma-separated values (e.g. ""1,2,3"") into individual arguments. Therefore, parameters like --ImageReader.camera_params could not be used on Windows (see screenshot).

This pull request replaces the previous mechanism that uses the shift-operator by simply using the %* operator. This way, using --ImageReader.camera_params on Windows works flawlessly.",True,{}
colmap/colmap,https://github.com/colmap/colmap,1126,2021-02-18T22:10:16Z,2021-02-27T12:21:23Z,2021-02-27T12:21:23Z,MERGED,True,21,21,7,https://github.com/UncleGene,Update print statements for Python 3 compatibility,1,[],https://github.com/colmap/colmap/pull/1126,https://github.com/UncleGene,1,https://github.com/colmap/colmap/pull/1126,Python 3 would not accept print statements without braces,Python 3 would not accept print statements without braces,True,{}
colmap/colmap,https://github.com/colmap/colmap,1129,2021-02-22T23:13:03Z,,2022-01-26T12:22:15Z,OPEN,False,809,152,29,https://github.com/anmatako,Add PatchMatchNet module for MVS and calculation of normals from depth,20,[],https://github.com/colmap/colmap/pull/1129,https://github.com/anmatako,1,https://github.com/colmap/colmap/pull/1129,"This work mainly integrated PatchMatchNet functionality in colamp using a TorchScript pre-trained module. Additionally it introduces functionality to calculate normal maps from depth maps since PatchMatchNet evaluation does not create normal maps as part of its process. More details about the changes:

Colmap can compile with Torch support to enable PatchMatchNet. For this the pre-compiled LitTorch library needs to be downloaded from here https://pytorch.org/ on the desired configuration for GPU or CPU-only and the archive extracted under <colmap-root>/lib/ thus creating a libtorch subfolder. Then CMake should be able to find the dependency and set the correct compilation flags.
PatchMatchNet can now be enabled from patch_match_stereo by setting the mvs_module_path option to a valid TorchScript module. One such module is included as part of this PR in <colmap-root>\mvs-modules\patchmatchnet-module.pt

The TorchScript interface is fairly generic using the following input structure: (images: List[Tensor], intrisics: Tensor, extrinsics: Tensor, depth_params: Tensor) with the output being a tuple of (depth: Tensor, confidence: Tensor). Thus any module that subscribes to that input/output format for forward evaluation can be used instead.


Functionality of standard patch-match remains unchanged. There is now an inheritance structure used to select between standard and PMNet processing
Normal maps are now not required for stereo fusion. If missing they will be calculated from the depth maps themselves. This is needed to accommodate PMNet processing that does not produce normal maps as part of the estimation work.

Note that use of calculated normal maps can be forced even for standard patch-match processing through the use of a new stereo fusion option --StereoFusion.calculate_normals.


Confidence maps can now be used for stereo fusion and they are optional. If missing a confidence of 1 is assumed everywhere. This is also added to make use of the confidence maps that are created as part of PMNet estimation.
New method for finding related images for fusion based on triangulation scoring is introduced and can be enabled with the option --StereoFusion.use_triangulation_scoring. This is included for parity with PatchMatchNet that has this method for finding related images instead of the colmap default. (useful for comparing results between colmap and Python)","This work mainly integrated PatchMatchNet functionality in colamp using a TorchScript pre-trained module. Additionally it introduces functionality to calculate normal maps from depth maps since PatchMatchNet evaluation does not create normal maps as part of its process. More details about the changes:

Colmap can compile with Torch support to enable PatchMatchNet. For this the pre-compiled LitTorch library needs to be downloaded from here https://pytorch.org/ on the desired configuration for GPU or CPU-only and the archive extracted under <colmap-root>/lib/ thus creating a libtorch subfolder. Then CMake should be able to find the dependency and set the correct compilation flags.
PatchMatchNet can now be enabled from patch_match_stereo by setting the mvs_module_path option to a valid TorchScript module. One such module is included as part of this PR in <colmap-root>\mvs-modules\patchmatchnet-module.pt

The TorchScript interface is fairly generic using the following input structure: (images: List[Tensor], intrisics: Tensor, extrinsics: Tensor, depth_params: Tensor) with the output being a tuple of (depth: Tensor, confidence: Tensor). Thus any module that subscribes to that input/output format for forward evaluation can be used instead.


Functionality of standard patch-match remains unchanged. There is now an inheritance structure used to select between standard and PMNet processing
Normal maps are now not required for stereo fusion. If missing they will be calculated from the depth maps themselves. This is needed to accommodate PMNet processing that does not produce normal maps as part of the estimation work.

Note that use of calculated normal maps can be forced even for standard patch-match processing through the use of a new stereo fusion option --StereoFusion.calculate_normals.


Confidence maps can now be used for stereo fusion and they are optional. If missing a confidence of 1 is assumed everywhere. This is also added to make use of the confidence maps that are created as part of PMNet estimation.
New method for finding related images for fusion based on triangulation scoring is introduced and can be enabled with the option --StereoFusion.use_triangulation_scoring. This is included for parity with PatchMatchNet that has this method for finding related images instead of the colmap default. (useful for comparing results between colmap and Python)",True,{'THUMBS_UP': ['https://github.com/Dawars']}
colmap/colmap,https://github.com/colmap/colmap,1129,2021-02-22T23:13:03Z,,2022-01-26T12:22:15Z,OPEN,False,809,152,29,https://github.com/anmatako,Add PatchMatchNet module for MVS and calculation of normals from depth,20,[],https://github.com/colmap/colmap/pull/1129,https://github.com/Dawars,2,https://github.com/colmap/colmap/pull/1129#issuecomment-787470988,"This work mainly integrated PatchMatchNet functionality in colamp using a TorchScript pre-trained module. Additionally it introduces functionality to calculate normal maps from depth maps since PatchMatchNet evaluation does not create normal maps as part of its process. More details about the changes:

Colmap can compile with Torch support to enable PatchMatchNet. For this the pre-compiled LitTorch library needs to be downloaded from here https://pytorch.org/ on the desired configuration for GPU or CPU-only and the archive extracted under <colmap-root>/lib/ thus creating a libtorch subfolder. Then CMake should be able to find the dependency and set the correct compilation flags.
PatchMatchNet can now be enabled from patch_match_stereo by setting the mvs_module_path option to a valid TorchScript module. One such module is included as part of this PR in <colmap-root>\mvs-modules\patchmatchnet-module.pt

The TorchScript interface is fairly generic using the following input structure: (images: List[Tensor], intrisics: Tensor, extrinsics: Tensor, depth_params: Tensor) with the output being a tuple of (depth: Tensor, confidence: Tensor). Thus any module that subscribes to that input/output format for forward evaluation can be used instead.


Functionality of standard patch-match remains unchanged. There is now an inheritance structure used to select between standard and PMNet processing
Normal maps are now not required for stereo fusion. If missing they will be calculated from the depth maps themselves. This is needed to accommodate PMNet processing that does not produce normal maps as part of the estimation work.

Note that use of calculated normal maps can be forced even for standard patch-match processing through the use of a new stereo fusion option --StereoFusion.calculate_normals.


Confidence maps can now be used for stereo fusion and they are optional. If missing a confidence of 1 is assumed everywhere. This is also added to make use of the confidence maps that are created as part of PMNet estimation.
New method for finding related images for fusion based on triangulation scoring is introduced and can be enabled with the option --StereoFusion.use_triangulation_scoring. This is included for parity with PatchMatchNet that has this method for finding related images instead of the colmap default. (useful for comparing results between colmap and Python)","I've been trying to compile this but I get the following error:
-- Caffe2: CUDA detected: 11.2
-- Caffe2: CUDA nvcc is: /usr/local/cuda/bin/nvcc
-- Caffe2: CUDA toolkit directory: /usr/local/cuda
-- Caffe2: Header version is: 11.2
-- Found cuDNN: v8.1.0  (include: /usr/include, library: /usr/lib/x86_64-linux-gnu/libcudnn.so)
-- Autodetected CUDA architecture(s):  6.1
-- Added CUDA NVCC flags for: -gencode;arch=compute_61,code=sm_61
-- Build type specified as Release
-- Enabling SIMD support
-- Enabling OpenMP support
-- Disabling interprocedural optimization
-- Autodetected CUDA architecture(s):  6.1
-- Enabling CUDA support (version: 11.2, archs: sm_61)
-- Enabling LibTorch support
-- Enabling OpenGL support
-- Disabling profiling support
-- Enabling CGAL support
-- Configuring done
CMake Error in src/CMakeLists.txt:
  Imported target ""torch"" includes non-existent path

    ""MKL_INCLUDE_DIR-NOTFOUND""

  in its INTERFACE_INCLUDE_DIRECTORIES.  Possible reasons include:

  * The path was deleted, renamed, or moved to another location.

  * An install or uninstall procedure did not complete successfully.

  * The installation package was faulty and references files it does not
  provide.



Which libtorch/cuda version are you using?
I've tried Cuda 11.2, cuDNN: v8.1.0, MKL 2020.04 and libtorch 1.7.1 on a 1080Ti. Same for Cuda 10.2 cuDNN: v7.",True,{}
colmap/colmap,https://github.com/colmap/colmap,1129,2021-02-22T23:13:03Z,,2022-01-26T12:22:15Z,OPEN,False,809,152,29,https://github.com/anmatako,Add PatchMatchNet module for MVS and calculation of normals from depth,20,[],https://github.com/colmap/colmap/pull/1129,https://github.com/anmatako,3,https://github.com/colmap/colmap/pull/1129#issuecomment-787500325,"This work mainly integrated PatchMatchNet functionality in colamp using a TorchScript pre-trained module. Additionally it introduces functionality to calculate normal maps from depth maps since PatchMatchNet evaluation does not create normal maps as part of its process. More details about the changes:

Colmap can compile with Torch support to enable PatchMatchNet. For this the pre-compiled LitTorch library needs to be downloaded from here https://pytorch.org/ on the desired configuration for GPU or CPU-only and the archive extracted under <colmap-root>/lib/ thus creating a libtorch subfolder. Then CMake should be able to find the dependency and set the correct compilation flags.
PatchMatchNet can now be enabled from patch_match_stereo by setting the mvs_module_path option to a valid TorchScript module. One such module is included as part of this PR in <colmap-root>\mvs-modules\patchmatchnet-module.pt

The TorchScript interface is fairly generic using the following input structure: (images: List[Tensor], intrisics: Tensor, extrinsics: Tensor, depth_params: Tensor) with the output being a tuple of (depth: Tensor, confidence: Tensor). Thus any module that subscribes to that input/output format for forward evaluation can be used instead.


Functionality of standard patch-match remains unchanged. There is now an inheritance structure used to select between standard and PMNet processing
Normal maps are now not required for stereo fusion. If missing they will be calculated from the depth maps themselves. This is needed to accommodate PMNet processing that does not produce normal maps as part of the estimation work.

Note that use of calculated normal maps can be forced even for standard patch-match processing through the use of a new stereo fusion option --StereoFusion.calculate_normals.


Confidence maps can now be used for stereo fusion and they are optional. If missing a confidence of 1 is assumed everywhere. This is also added to make use of the confidence maps that are created as part of PMNet estimation.
New method for finding related images for fusion based on triangulation scoring is introduced and can be enabled with the option --StereoFusion.use_triangulation_scoring. This is included for parity with PatchMatchNet that has this method for finding related images instead of the colmap default. (useful for comparing results between colmap and Python)","I've been trying to compile this but I get the following error:
-- Caffe2: CUDA detected: 11.2
-- Caffe2: CUDA nvcc is: /usr/local/cuda/bin/nvcc
-- Caffe2: CUDA toolkit directory: /usr/local/cuda
-- Caffe2: Header version is: 11.2
-- Found cuDNN: v8.1.0  (include: /usr/include, library: /usr/lib/x86_64-linux-gnu/libcudnn.so)
-- Autodetected CUDA architecture(s):  6.1
-- Added CUDA NVCC flags for: -gencode;arch=compute_61,code=sm_61
-- Build type specified as Release
-- Enabling SIMD support
-- Enabling OpenMP support
-- Disabling interprocedural optimization
-- Autodetected CUDA architecture(s):  6.1
-- Enabling CUDA support (version: 11.2, archs: sm_61)
-- Enabling LibTorch support
-- Enabling OpenGL support
-- Disabling profiling support
-- Enabling CGAL support
-- Configuring done
CMake Error in src/CMakeLists.txt:
  Imported target ""torch"" includes non-existent path

    ""MKL_INCLUDE_DIR-NOTFOUND""

  in its INTERFACE_INCLUDE_DIRECTORIES.  Possible reasons include:

  * The path was deleted, renamed, or moved to another location.

  * An install or uninstall procedure did not complete successfully.

  * The installation package was faulty and references files it does not
  provide.

Which libtorch/cuda version are you using?
I've tried Cuda 11.2, cuDNN: v8.1.0, MKL 2020.04 and libtorch 1.7.1 on a 1080Ti. Same for Cuda 10.2 cuDNN: v7.

@Dawars It seems that LibTorch requires MKL as a dependency even though it already contains the headers and binaries in the LibTorch package itself. See if installing MKL on your system would resolve your issue.
On my end I made some modifications in the CMake configurations of LibTorch itself to make things work. I'll see if I can make changes in colmap CMake instead and have things work with vanilla LibTorch.
For reference here's a diff between my modified LibTorch and the vanilla one (LibTorch 1.7.1 for CUDA 10.1 with CUDNN 7.6.0)
diff --git ""a/c:\\Users\\anmatako\\Downloads\\libtorch/include/ATen/Parallel.h"" ""b/lib\\libtorch/include/ATen/Parallel.h""
index 9e2f9be..cc652f2 100644
--- ""a/c:\\Users\\anmatako\\Downloads\\libtorch/include/ATen/Parallel.h""
+++ ""b/lib\\libtorch/include/ATen/Parallel.h""
@@ -38,7 +38,7 @@ namespace internal {

 // Initialise num_threads lazily at first parallel call
 inline CAFFE2_API void lazy_init_num_threads() {
-  thread_local bool init = false;
+  static thread_local bool init = false;
   if (C10_UNLIKELY(!init)) {
     at::init_num_threads();
     init = true;
diff --git ""a/c:\\Users\\anmatako\\Downloads\\libtorch/include/c10/util/StringUtil.h"" ""b/lib\\libtorch/include/c10/util/StringUtil.h""
index d2744f1..79da0ae 100644
--- ""a/c:\\Users\\anmatako\\Downloads\\libtorch/include/c10/util/StringUtil.h""
+++ ""b/lib\\libtorch/include/c10/util/StringUtil.h""
@@ -74,7 +74,7 @@ struct _str_wrapper<const char*> final {
 template<>
 struct _str_wrapper<> final {
   static const std::string& call() {
-    thread_local const std::string empty_string_literal;
+    static thread_local const std::string empty_string_literal;
     return empty_string_literal;
   }
 };
diff --git ""a/c:\\Users\\anmatako\\Downloads\\libtorch/share/cmake/Caffe2/public/cuda.cmake"" ""b/lib\\libtorch/share/cmake/Caffe2/public/cuda.cmake""
index 8b60915..041e19b 100644
--- ""a/c:\\Users\\anmatako\\Downloads\\libtorch/share/cmake/Caffe2/public/cuda.cmake""
+++ ""b/lib\\libtorch/share/cmake/Caffe2/public/cuda.cmake""
@@ -480,7 +480,7 @@ endforeach()
 # Set C++14 support
 set(CUDA_PROPAGATE_HOST_FLAGS_BLACKLIST ""-Werror"")
 if(MSVC)
-  list(APPEND CUDA_NVCC_FLAGS ""--Werror"" ""cross-execution-space-call"")
+  # list(APPEND CUDA_NVCC_FLAGS ""--Werror"" ""cross-execution-space-call"")
   list(APPEND CUDA_NVCC_FLAGS ""--no-host-device-move-forward"")
 else()
   list(APPEND CUDA_NVCC_FLAGS ""-std=c++14"")
diff --git ""a/c:\\Users\\anmatako\\Downloads\\libtorch/share/cmake/Caffe2/public/mkl.cmake"" ""b/lib\\libtorch/share/cmake/Caffe2/public/mkl.cmake""
index 9515a4a..c68074b 100644
--- ""a/c:\\Users\\anmatako\\Downloads\\libtorch/share/cmake/Caffe2/public/mkl.cmake""
+++ ""b/lib\\libtorch/share/cmake/Caffe2/public/mkl.cmake""
@@ -1,4 +1,4 @@
-find_package(MKL QUIET)
+set(MKL_INCLUDE_DIR ${CMAKE_TORCHLIB_PATH}/include)

 if(NOT TARGET caffe2::mkl)
   add_library(caffe2::mkl INTERFACE IMPORTED)",True,{}
colmap/colmap,https://github.com/colmap/colmap,1129,2021-02-22T23:13:03Z,,2022-01-26T12:22:15Z,OPEN,False,809,152,29,https://github.com/anmatako,Add PatchMatchNet module for MVS and calculation of normals from depth,20,[],https://github.com/colmap/colmap/pull/1129,https://github.com/anmatako,4,https://github.com/colmap/colmap/pull/1129#issuecomment-788195517,"This work mainly integrated PatchMatchNet functionality in colamp using a TorchScript pre-trained module. Additionally it introduces functionality to calculate normal maps from depth maps since PatchMatchNet evaluation does not create normal maps as part of its process. More details about the changes:

Colmap can compile with Torch support to enable PatchMatchNet. For this the pre-compiled LitTorch library needs to be downloaded from here https://pytorch.org/ on the desired configuration for GPU or CPU-only and the archive extracted under <colmap-root>/lib/ thus creating a libtorch subfolder. Then CMake should be able to find the dependency and set the correct compilation flags.
PatchMatchNet can now be enabled from patch_match_stereo by setting the mvs_module_path option to a valid TorchScript module. One such module is included as part of this PR in <colmap-root>\mvs-modules\patchmatchnet-module.pt

The TorchScript interface is fairly generic using the following input structure: (images: List[Tensor], intrisics: Tensor, extrinsics: Tensor, depth_params: Tensor) with the output being a tuple of (depth: Tensor, confidence: Tensor). Thus any module that subscribes to that input/output format for forward evaluation can be used instead.


Functionality of standard patch-match remains unchanged. There is now an inheritance structure used to select between standard and PMNet processing
Normal maps are now not required for stereo fusion. If missing they will be calculated from the depth maps themselves. This is needed to accommodate PMNet processing that does not produce normal maps as part of the estimation work.

Note that use of calculated normal maps can be forced even for standard patch-match processing through the use of a new stereo fusion option --StereoFusion.calculate_normals.


Confidence maps can now be used for stereo fusion and they are optional. If missing a confidence of 1 is assumed everywhere. This is also added to make use of the confidence maps that are created as part of PMNet estimation.
New method for finding related images for fusion based on triangulation scoring is introduced and can be enabled with the option --StereoFusion.use_triangulation_scoring. This is included for parity with PatchMatchNet that has this method for finding related images instead of the colmap default. (useful for comparing results between colmap and Python)","@Dawars @ahojnnes I update colmap's cmake to set the MKL flags without needing the full dependency for LibTorch to build. Also, I removed an NVCC flag set by LibTorch that was causing issues with Eigen/Core.
However I'm not sure what to do with this part of the diff:
diff --git ""a/c:\\Users\\anmatako\\Downloads\\libtorch/include/ATen/Parallel.h"" ""b/lib\\libtorch/include/ATen/Parallel.h""
index 9e2f9be..cc652f2 100644
--- ""a/c:\\Users\\anmatako\\Downloads\\libtorch/include/ATen/Parallel.h""
+++ ""b/lib\\libtorch/include/ATen/Parallel.h""
@@ -38,7 +38,7 @@ namespace internal {

 // Initialise num_threads lazily at first parallel call
 inline CAFFE2_API void lazy_init_num_threads() {
-  thread_local bool init = false;
+  static thread_local bool init = false;
   if (C10_UNLIKELY(!init)) {
     at::init_num_threads();
     init = true;
diff --git ""a/c:\\Users\\anmatako\\Downloads\\libtorch/include/c10/util/StringUtil.h"" ""b/lib\\libtorch/include/c10/util/StringUtil.h""
index d2744f1..79da0ae 100644
--- ""a/c:\\Users\\anmatako\\Downloads\\libtorch/include/c10/util/StringUtil.h""
+++ ""b/lib\\libtorch/include/c10/util/StringUtil.h""
@@ -74,7 +74,7 @@ struct _str_wrapper<const char*> final {
 template<>
 struct _str_wrapper<> final {
   static const std::string& call() {
-    thread_local const std::string empty_string_literal;
+    static thread_local const std::string empty_string_literal;
     return empty_string_literal;
   }
 };

I'm not sure if the issue with thread_local having to be static is specific to MSVC (windows) or if it happens on other platforms as well, since I have no good way to test this cross-platform.",True,{}
colmap/colmap,https://github.com/colmap/colmap,1129,2021-02-22T23:13:03Z,,2022-01-26T12:22:15Z,OPEN,False,809,152,29,https://github.com/anmatako,Add PatchMatchNet module for MVS and calculation of normals from depth,20,[],https://github.com/colmap/colmap/pull/1129,https://github.com/Dawars,5,https://github.com/colmap/colmap/pull/1129#issuecomment-788198564,"This work mainly integrated PatchMatchNet functionality in colamp using a TorchScript pre-trained module. Additionally it introduces functionality to calculate normal maps from depth maps since PatchMatchNet evaluation does not create normal maps as part of its process. More details about the changes:

Colmap can compile with Torch support to enable PatchMatchNet. For this the pre-compiled LitTorch library needs to be downloaded from here https://pytorch.org/ on the desired configuration for GPU or CPU-only and the archive extracted under <colmap-root>/lib/ thus creating a libtorch subfolder. Then CMake should be able to find the dependency and set the correct compilation flags.
PatchMatchNet can now be enabled from patch_match_stereo by setting the mvs_module_path option to a valid TorchScript module. One such module is included as part of this PR in <colmap-root>\mvs-modules\patchmatchnet-module.pt

The TorchScript interface is fairly generic using the following input structure: (images: List[Tensor], intrisics: Tensor, extrinsics: Tensor, depth_params: Tensor) with the output being a tuple of (depth: Tensor, confidence: Tensor). Thus any module that subscribes to that input/output format for forward evaluation can be used instead.


Functionality of standard patch-match remains unchanged. There is now an inheritance structure used to select between standard and PMNet processing
Normal maps are now not required for stereo fusion. If missing they will be calculated from the depth maps themselves. This is needed to accommodate PMNet processing that does not produce normal maps as part of the estimation work.

Note that use of calculated normal maps can be forced even for standard patch-match processing through the use of a new stereo fusion option --StereoFusion.calculate_normals.


Confidence maps can now be used for stereo fusion and they are optional. If missing a confidence of 1 is assumed everywhere. This is also added to make use of the confidence maps that are created as part of PMNet estimation.
New method for finding related images for fusion based on triangulation scoring is introduced and can be enabled with the option --StereoFusion.use_triangulation_scoring. This is included for parity with PatchMatchNet that has this method for finding related images instead of the colmap default. (useful for comparing results between colmap and Python)","I'll try it out on Ubuntu and let you know. One problem for me was that
cmake found the mkl.cmake from cgal which was installed on my machine,
maybe we need to supply a custom version with colmap.
…
On 2021. Mar 1., Mon at 20:07, Antonios Matakos ***@***.***> wrote:
 @Dawars <https://github.com/Dawars> @ahojnnes
 <https://github.com/ahojnnes> I update colmap's cmake to set the MKL
 flags without needed the full dependency and also removed an NVCC flag set
 by LibTorch that was causing issues with Eigen/Core so now it should build
 without MKL being present.

 However I'm not sure what to do with this part of the diff:

 diff --git ""a/c:\\Users\\anmatako\\Downloads\\libtorch/include/ATen/Parallel.h"" ""b/lib\\libtorch/include/ATen/Parallel.h""
 index 9e2f9be..cc652f2 100644
 --- ""a/c:\\Users\\anmatako\\Downloads\\libtorch/include/ATen/Parallel.h""
 +++ ""b/lib\\libtorch/include/ATen/Parallel.h""
 @@ -38,7 +38,7 @@ namespace internal {

  // Initialise num_threads lazily at first parallel call
  inline CAFFE2_API void lazy_init_num_threads() {
 -  thread_local bool init = false;
 +  static thread_local bool init = false;
    if (C10_UNLIKELY(!init)) {
      at::init_num_threads();
      init = true;
 diff --git ""a/c:\\Users\\anmatako\\Downloads\\libtorch/include/c10/util/StringUtil.h"" ""b/lib\\libtorch/include/c10/util/StringUtil.h""
 index d2744f1..79da0ae 100644
 --- ""a/c:\\Users\\anmatako\\Downloads\\libtorch/include/c10/util/StringUtil.h""
 +++ ""b/lib\\libtorch/include/c10/util/StringUtil.h""
 @@ -74,7 +74,7 @@ struct _str_wrapper<const char*> final {
  template<>
  struct _str_wrapper<> final {
    static const std::string& call() {
 -    thread_local const std::string empty_string_literal;
 +    static thread_local const std::string empty_string_literal;
      return empty_string_literal;
    }
  };

 I'm not sure if the issue with thread_local having to be static is
 specific to MSVC (windows) or if it happens on other platforms as well,
 since I have no good way to test this cross-platform.

 —
 You are receiving this because you were mentioned.
 Reply to this email directly, view it on GitHub
 <#1129 (comment)>, or
 unsubscribe
 <https://github.com/notifications/unsubscribe-auth/AAI35ZCP6JH4HYRP37YFET3TBPQYJANCNFSM4YBNICEQ>
 .",True,{}
colmap/colmap,https://github.com/colmap/colmap,1129,2021-02-22T23:13:03Z,,2022-01-26T12:22:15Z,OPEN,False,809,152,29,https://github.com/anmatako,Add PatchMatchNet module for MVS and calculation of normals from depth,20,[],https://github.com/colmap/colmap/pull/1129,https://github.com/Dawars,6,https://github.com/colmap/colmap/pull/1129#issuecomment-788244176,"This work mainly integrated PatchMatchNet functionality in colamp using a TorchScript pre-trained module. Additionally it introduces functionality to calculate normal maps from depth maps since PatchMatchNet evaluation does not create normal maps as part of its process. More details about the changes:

Colmap can compile with Torch support to enable PatchMatchNet. For this the pre-compiled LitTorch library needs to be downloaded from here https://pytorch.org/ on the desired configuration for GPU or CPU-only and the archive extracted under <colmap-root>/lib/ thus creating a libtorch subfolder. Then CMake should be able to find the dependency and set the correct compilation flags.
PatchMatchNet can now be enabled from patch_match_stereo by setting the mvs_module_path option to a valid TorchScript module. One such module is included as part of this PR in <colmap-root>\mvs-modules\patchmatchnet-module.pt

The TorchScript interface is fairly generic using the following input structure: (images: List[Tensor], intrisics: Tensor, extrinsics: Tensor, depth_params: Tensor) with the output being a tuple of (depth: Tensor, confidence: Tensor). Thus any module that subscribes to that input/output format for forward evaluation can be used instead.


Functionality of standard patch-match remains unchanged. There is now an inheritance structure used to select between standard and PMNet processing
Normal maps are now not required for stereo fusion. If missing they will be calculated from the depth maps themselves. This is needed to accommodate PMNet processing that does not produce normal maps as part of the estimation work.

Note that use of calculated normal maps can be forced even for standard patch-match processing through the use of a new stereo fusion option --StereoFusion.calculate_normals.


Confidence maps can now be used for stereo fusion and they are optional. If missing a confidence of 1 is assumed everywhere. This is also added to make use of the confidence maps that are created as part of PMNet estimation.
New method for finding related images for fusion based on triangulation scoring is introduced and can be enabled with the option --StereoFusion.use_triangulation_scoring. This is included for parity with PatchMatchNet that has this method for finding related images instead of the colmap default. (useful for comparing results between colmap and Python)","Now it compiles and runs fine, no additional cmake config needed for mkl.
However the model file seems to be corrupted. I get the following error at: torch::jit::load(options_.mvs_module_path, kDevIn);
cache_size: 20
write_consistency_graph: 0
mvs_module_path: /home/dawars/projects/colmap_torch/mvs-modules/patchmatchnet-module.pt
allow_missing_files: 0
First definition of patch-match module for thread index: 0
Signal: SIGSEGV (signal SIGSEGV: invalid address (fault address: 0x0))

Process finished with exit code 9

I checked it Python and Netron as well:
Error loading Python module. Unknown expression '=' in 'patchmatchnet-module3.pt'.
Python 3.7.9 (default, Aug 31 2020, 12:42:55) 
Type 'copyright', 'credits' or 'license' for more information
IPython 7.18.1 -- An enhanced Interactive Python. Type '?' for help.
PyDev console: using IPython 7.18.1
Python 3.7.9 (default, Aug 31 2020, 12:42:55) 
[GCC 7.3.0] on linux
import torch
with open('/home/dawars/projects/colmap_torch/mvs-modules/patchmatchnet-module.pt') as f:
    model = torch.load(f)
    
Traceback (most recent call last):
  File ""/home/dawars/miniconda3/envs/historic/lib/python3.7/site-packages/IPython/core/interactiveshell.py"", line 3417, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-3-f97813dbac00>"", line 2, in <module>
    model = torch.load(f)
  File ""/home/dawars/miniconda3/envs/historic/lib/python3.7/site-packages/torch/serialization.py"", line 572, in load
    if _is_zipfile(opened_file):
  File ""/home/dawars/miniconda3/envs/historic/lib/python3.7/site-packages/torch/serialization.py"", line 56, in _is_zipfile
    byte = f.read(1)
  File ""/home/dawars/miniconda3/envs/historic/lib/python3.7/codecs.py"", line 322, in decode
    (result, consumed) = self._buffer_decode(data, self.errors, final)
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xa2 in position 72: invalid start byte
with open('/home/dawars/projects/colmap_torch/mvs-modules/patchmatchnet-module3.pt') as f:
    model = torch.load(f)
    
Traceback (most recent call last):
  File ""/home/dawars/miniconda3/envs/historic/lib/python3.7/site-packages/IPython/core/interactiveshell.py"", line 3417, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-4-a6ef56580e99>"", line 2, in <module>
    model = torch.load(f)
  File ""/home/dawars/miniconda3/envs/historic/lib/python3.7/site-packages/torch/serialization.py"", line 572, in load
    if _is_zipfile(opened_file):
  File ""/home/dawars/miniconda3/envs/historic/lib/python3.7/site-packages/torch/serialization.py"", line 56, in _is_zipfile
    byte = f.read(1)
  File ""/home/dawars/miniconda3/envs/historic/lib/python3.7/codecs.py"", line 322, in decode
    (result, consumed) = self._buffer_decode(data, self.errors, final)
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xa2 in position 72: invalid start byte",True,{}
colmap/colmap,https://github.com/colmap/colmap,1129,2021-02-22T23:13:03Z,,2022-01-26T12:22:15Z,OPEN,False,809,152,29,https://github.com/anmatako,Add PatchMatchNet module for MVS and calculation of normals from depth,20,[],https://github.com/colmap/colmap/pull/1129,https://github.com/anmatako,7,https://github.com/colmap/colmap/pull/1129#issuecomment-788322591,"This work mainly integrated PatchMatchNet functionality in colamp using a TorchScript pre-trained module. Additionally it introduces functionality to calculate normal maps from depth maps since PatchMatchNet evaluation does not create normal maps as part of its process. More details about the changes:

Colmap can compile with Torch support to enable PatchMatchNet. For this the pre-compiled LitTorch library needs to be downloaded from here https://pytorch.org/ on the desired configuration for GPU or CPU-only and the archive extracted under <colmap-root>/lib/ thus creating a libtorch subfolder. Then CMake should be able to find the dependency and set the correct compilation flags.
PatchMatchNet can now be enabled from patch_match_stereo by setting the mvs_module_path option to a valid TorchScript module. One such module is included as part of this PR in <colmap-root>\mvs-modules\patchmatchnet-module.pt

The TorchScript interface is fairly generic using the following input structure: (images: List[Tensor], intrisics: Tensor, extrinsics: Tensor, depth_params: Tensor) with the output being a tuple of (depth: Tensor, confidence: Tensor). Thus any module that subscribes to that input/output format for forward evaluation can be used instead.


Functionality of standard patch-match remains unchanged. There is now an inheritance structure used to select between standard and PMNet processing
Normal maps are now not required for stereo fusion. If missing they will be calculated from the depth maps themselves. This is needed to accommodate PMNet processing that does not produce normal maps as part of the estimation work.

Note that use of calculated normal maps can be forced even for standard patch-match processing through the use of a new stereo fusion option --StereoFusion.calculate_normals.


Confidence maps can now be used for stereo fusion and they are optional. If missing a confidence of 1 is assumed everywhere. This is also added to make use of the confidence maps that are created as part of PMNet estimation.
New method for finding related images for fusion based on triangulation scoring is introduced and can be enabled with the option --StereoFusion.use_triangulation_scoring. This is included for parity with PatchMatchNet that has this method for finding related images instead of the colmap default. (useful for comparing results between colmap and Python)","I can load the module just fine in C++ and Python 3.8.5 on Windows using torch.jit.load; even torch.load works as well with a warning like this:
...Python\Python38\site-packages\torch\serialization.py:589: UserWarning: 'torch.load' received a zip file that looks like a TorchScript archive dispatching to 'torch.jit.load' (call 'torch.jit.load' directly to silence this warning)
  warnings.warn(""'torch.load' received a zip file that looks like a TorchScript archive""

Wondering if there's some issue with committing the binary as part of the repo or an issue with Python version. See if it will run with a different python version. Also I can send you the module file directly so we can see if it's an issue caused when the file gets commited.

Now it compiles and runs fine, no additional cmake config needed for mkl.
However the model file seems to be corrupted. I get the following error at: torch::jit::load(options_.mvs_module_path, kDevIn);
cache_size: 20
write_consistency_graph: 0
mvs_module_path: /home/dawars/projects/colmap_torch/mvs-modules/patchmatchnet-module.pt
allow_missing_files: 0
First definition of patch-match module for thread index: 0
Signal: SIGSEGV (signal SIGSEGV: invalid address (fault address: 0x0))

Process finished with exit code 9

I checked it Python and Netron as well:
Error loading Python module. Unknown expression '=' in 'patchmatchnet-module3.pt'.
Python 3.7.9 (default, Aug 31 2020, 12:42:55) 
Type 'copyright', 'credits' or 'license' for more information
IPython 7.18.1 -- An enhanced Interactive Python. Type '?' for help.
PyDev console: using IPython 7.18.1
Python 3.7.9 (default, Aug 31 2020, 12:42:55) 
[GCC 7.3.0] on linux
import torch
with open('/home/dawars/projects/colmap_torch/mvs-modules/patchmatchnet-module.pt') as f:
    model = torch.load(f)
    
Traceback (most recent call last):
  File ""/home/dawars/miniconda3/envs/historic/lib/python3.7/site-packages/IPython/core/interactiveshell.py"", line 3417, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-3-f97813dbac00>"", line 2, in <module>
    model = torch.load(f)
  File ""/home/dawars/miniconda3/envs/historic/lib/python3.7/site-packages/torch/serialization.py"", line 572, in load
    if _is_zipfile(opened_file):
  File ""/home/dawars/miniconda3/envs/historic/lib/python3.7/site-packages/torch/serialization.py"", line 56, in _is_zipfile
    byte = f.read(1)
  File ""/home/dawars/miniconda3/envs/historic/lib/python3.7/codecs.py"", line 322, in decode
    (result, consumed) = self._buffer_decode(data, self.errors, final)
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xa2 in position 72: invalid start byte
with open('/home/dawars/projects/colmap_torch/mvs-modules/patchmatchnet-module3.pt') as f:
    model = torch.load(f)
    
Traceback (most recent call last):
  File ""/home/dawars/miniconda3/envs/historic/lib/python3.7/site-packages/IPython/core/interactiveshell.py"", line 3417, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-4-a6ef56580e99>"", line 2, in <module>
    model = torch.load(f)
  File ""/home/dawars/miniconda3/envs/historic/lib/python3.7/site-packages/torch/serialization.py"", line 572, in load
    if _is_zipfile(opened_file):
  File ""/home/dawars/miniconda3/envs/historic/lib/python3.7/site-packages/torch/serialization.py"", line 56, in _is_zipfile
    byte = f.read(1)
  File ""/home/dawars/miniconda3/envs/historic/lib/python3.7/codecs.py"", line 322, in decode
    (result, consumed) = self._buffer_decode(data, self.errors, final)
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xa2 in position 72: invalid start byte",True,{}
colmap/colmap,https://github.com/colmap/colmap,1129,2021-02-22T23:13:03Z,,2022-01-26T12:22:15Z,OPEN,False,809,152,29,https://github.com/anmatako,Add PatchMatchNet module for MVS and calculation of normals from depth,20,[],https://github.com/colmap/colmap/pull/1129,https://github.com/anmatako,8,https://github.com/colmap/colmap/pull/1129#issuecomment-788349017,"This work mainly integrated PatchMatchNet functionality in colamp using a TorchScript pre-trained module. Additionally it introduces functionality to calculate normal maps from depth maps since PatchMatchNet evaluation does not create normal maps as part of its process. More details about the changes:

Colmap can compile with Torch support to enable PatchMatchNet. For this the pre-compiled LitTorch library needs to be downloaded from here https://pytorch.org/ on the desired configuration for GPU or CPU-only and the archive extracted under <colmap-root>/lib/ thus creating a libtorch subfolder. Then CMake should be able to find the dependency and set the correct compilation flags.
PatchMatchNet can now be enabled from patch_match_stereo by setting the mvs_module_path option to a valid TorchScript module. One such module is included as part of this PR in <colmap-root>\mvs-modules\patchmatchnet-module.pt

The TorchScript interface is fairly generic using the following input structure: (images: List[Tensor], intrisics: Tensor, extrinsics: Tensor, depth_params: Tensor) with the output being a tuple of (depth: Tensor, confidence: Tensor). Thus any module that subscribes to that input/output format for forward evaluation can be used instead.


Functionality of standard patch-match remains unchanged. There is now an inheritance structure used to select between standard and PMNet processing
Normal maps are now not required for stereo fusion. If missing they will be calculated from the depth maps themselves. This is needed to accommodate PMNet processing that does not produce normal maps as part of the estimation work.

Note that use of calculated normal maps can be forced even for standard patch-match processing through the use of a new stereo fusion option --StereoFusion.calculate_normals.


Confidence maps can now be used for stereo fusion and they are optional. If missing a confidence of 1 is assumed everywhere. This is also added to make use of the confidence maps that are created as part of PMNet estimation.
New method for finding related images for fusion based on triangulation scoring is introduced and can be enabled with the option --StereoFusion.use_triangulation_scoring. This is included for parity with PatchMatchNet that has this method for finding related images instead of the colmap default. (useful for comparing results between colmap and Python)","@Dawars one more thing you can try in case it's an issue with encodings between windows and Linux would be to pull PatchMatchNet from the tip of my branch here https://github.com/anmatako/PatchmatchNet
Then uncomment these 3 lines here: https://github.com/anmatako/PatchmatchNet/blob/e21992b1c2d028536403632eb1bf4bfb1aa8f176/eval.py#L97-L99
and you can run from within the root folder of PatchmatchNet as follows:
python eval.py --output_folder <your output folder> --checkpoint_path checkpoints/patchmatchnet-params.pt --input_type params --output_type depth

This will create a new TorchScript module named patchmatchnet-module.pt in your specified output folder. If you can load that module then it must be some conversion issue between OSes.",True,{}
colmap/colmap,https://github.com/colmap/colmap,1129,2021-02-22T23:13:03Z,,2022-01-26T12:22:15Z,OPEN,False,809,152,29,https://github.com/anmatako,Add PatchMatchNet module for MVS and calculation of normals from depth,20,[],https://github.com/colmap/colmap/pull/1129,https://github.com/Dawars,9,https://github.com/colmap/colmap/pull/1129#issuecomment-789176876,"This work mainly integrated PatchMatchNet functionality in colamp using a TorchScript pre-trained module. Additionally it introduces functionality to calculate normal maps from depth maps since PatchMatchNet evaluation does not create normal maps as part of its process. More details about the changes:

Colmap can compile with Torch support to enable PatchMatchNet. For this the pre-compiled LitTorch library needs to be downloaded from here https://pytorch.org/ on the desired configuration for GPU or CPU-only and the archive extracted under <colmap-root>/lib/ thus creating a libtorch subfolder. Then CMake should be able to find the dependency and set the correct compilation flags.
PatchMatchNet can now be enabled from patch_match_stereo by setting the mvs_module_path option to a valid TorchScript module. One such module is included as part of this PR in <colmap-root>\mvs-modules\patchmatchnet-module.pt

The TorchScript interface is fairly generic using the following input structure: (images: List[Tensor], intrisics: Tensor, extrinsics: Tensor, depth_params: Tensor) with the output being a tuple of (depth: Tensor, confidence: Tensor). Thus any module that subscribes to that input/output format for forward evaluation can be used instead.


Functionality of standard patch-match remains unchanged. There is now an inheritance structure used to select between standard and PMNet processing
Normal maps are now not required for stereo fusion. If missing they will be calculated from the depth maps themselves. This is needed to accommodate PMNet processing that does not produce normal maps as part of the estimation work.

Note that use of calculated normal maps can be forced even for standard patch-match processing through the use of a new stereo fusion option --StereoFusion.calculate_normals.


Confidence maps can now be used for stereo fusion and they are optional. If missing a confidence of 1 is assumed everywhere. This is also added to make use of the confidence maps that are created as part of PMNet estimation.
New method for finding related images for fusion based on triangulation scoring is introduced and can be enabled with the option --StereoFusion.use_triangulation_scoring. This is included for parity with PatchMatchNet that has this method for finding related images instead of the colmap default. (useful for comparing results between colmap and Python)","With PyTorch 1.7.1 I can read the model file properly.
I think the problem is that libtorch tries to open the file as a text file, not binary, that was one of my problems with Python.
I tried explicitly setting the file mode via:
std::ifstream model_file(options_.mvs_module_path, std::ios::in | std::ios::binary);

    model_[thread_index_] = torch::jit::load(model_file, kDevIn);
but I still get the same result.
Probably I'll have to compile a debug version of libtorch for linux to get more info. I have little experience with it but I'll try.
Here is the stack trace:
First definition of patch-match module for thread index: 0
Signal: SIGSEGV (signal SIGSEGV: invalid address (fault address: 0x0))
*** Aborted at 1614714901 (unix time) try ""date -d @1614714901"" if you are using GNU date ***
PC: @     0x7f2b751ee986 std::__detail::_Executor<>::_M_dfs()
*** SIGSEGV (@0x3e8000044a0) received by PID 17575 (TID 0x7f2b22fc4700) from PID 17568; stack trace: ***
    @     0x7f2b84b3a631 (unknown)
    @     0x7f2b8305f3c0 (unknown)
    @     0x7f2b751ee986 std::__detail::_Executor<>::_M_dfs()
    @     0x7f2b751eeb53 std::__detail::_Executor<>::_M_dfs()
    @     0x7f2b751eec6c std::__detail::_Executor<>::_M_dfs()
    @     0x7f2b751ef412 std::__detail::__regex_algo_impl<>()
    @     0x7f2b319995fe c10::Device::Device()
    @     0x7f2b7544963d torch::jit::Unpickler::readInstruction()
    @     0x7f2b7544b540 torch::jit::Unpickler::run()
    @     0x7f2b7544baf1 torch::jit::Unpickler::parse_ivalue()
    @     0x7f2b753ef9c2 torch::jit::readArchiveAndTensors()
    @     0x7f2b753efcdd torch::jit::(anonymous namespace)::ScriptModuleDeserializer::readArchive()
    @     0x7f2b753f2605 torch::jit::(anonymous namespace)::ScriptModuleDeserializer::deserialize()
    @     0x7f2b753f2bd9 torch::jit::load()
    @     0x7f2b753f5455 torch::jit::load()
    @     0x55620f2f4c46 colmap::mvs::PatchMatchNet::InitModule()
    @     0x55620f2f43d6 colmap::mvs::PatchMatchNet::PatchMatchNet()
    @     0x55620ec7c9b0 colmap::mvs::PatchMatchController::ProcessProblem()
    @     0x55620ec8fb63 std::__invoke_impl<>()
    @     0x55620ec8fa50 std::__invoke<>()
    @     0x55620ec8f851 _ZNSt5_BindIFMN6colmap3mvs20PatchMatchControllerEFvRKNS1_17PatchMatchOptionsEmEPS2_S3_mEE6__callIvJEJLm0ELm1ELm2EEEET_OSt5tupleIJDpT0_EESt12_Index_tupleIJXspT1_EEE
    @     0x55620ec8f367 std::_Bind<>::operator()<>()
    @     0x55620ec8efdd std::__invoke_impl<>()
    @     0x55620ec8ed55 std::__invoke<>()
    @     0x55620ec8ea7d _ZZNSt13__future_base11_Task_stateISt5_BindIFMN6colmap3mvs20PatchMatchControllerEFvRKNS3_17PatchMatchOptionsEmEPS4_S5_mEESaIiEFvvEE6_M_runEvENKUlvE_clEv
    @     0x55620ec8f436 _ZNKSt13__future_base12_Task_setterISt10unique_ptrINS_7_ResultIvEENS_12_Result_base8_DeleterEEZNS_11_Task_stateISt5_BindIFMN6colmap3mvs20PatchMatchControllerEFvRKNSA_17PatchMatchOptionsEmEPSB_SC_mEESaIiEFvvEE6_M_runEvEUlvE_vEclEv
    @     0x55620ec8f08c _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateISt5_BindIFMN6colmap3mvs20PatchMatchControllerEFvRKNSD_17PatchMatchOptionsEmEPSE_SF_mEESaIiEFvvEE6_M_runEvEUlvE_vEEE9_M_invokeERKSt9_Any_data
    @     0x55620eacd258 std::function<>::operator()()
    @     0x55620eacc75e std::__future_base::_State_baseV2::_M_do_set()
    @     0x55620ead4019 std::__invoke_impl<>()
    @     0x55620ead1136 std::__invoke<>()
    @     0x55620eacce3e _ZZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJPS1_S9_SA_EEvRSt9once_flagOT_DpOT0_ENKUlvE_clEv
Signal: SIGSEGV (unknown crash reason)

Process finished with exit code 11

This is the error I got with PyTorch 1.6 might be related:
with open('/home/dawars/projects/colmap_torch/mvs-modules/patchmatchnet-module_windows.pt', 'br') as f:
    model = torch.jit.load(f)
Traceback (most recent call last):
  File ""/home/dawars/miniconda3/envs/historic/lib/python3.7/site-packages/IPython/core/interactiveshell.py"", line 3417, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-4-d6e3587a7e88>"", line 2, in <module>
    model = torch.jit.load(f)
  File ""/home/dawars/miniconda3/envs/historic/lib/python3.7/site-packages/torch/jit/__init__.py"", line 277, in load
    cpp_module = torch._C.import_ir_module_from_buffer(cu, f.read(), map_location, _extra_files)
RuntimeError: 
Arguments for call are not valid.
The following variants are available:
  
  aten::upsample_nearest1d.out(Tensor self, int[1] output_size, float? scales=None, *, Tensor(a!) out) -> (Tensor(a!)):
  Expected a value of type 'List[int]' for argument 'output_size' but instead found type 'Optional[List[int]]'.
  
  aten::upsample_nearest1d(Tensor self, int[1] output_size, float? scales=None) -> (Tensor):
  Expected a value of type 'List[int]' for argument 'output_size' but instead found type 'Optional[List[int]]'.
The original call is:
  File ""C:\Users\anmatako\AppData\Roaming\Python\Python38\site-packages\torch\nn\functional.py"", line 3130
    if input.dim() == 3 and mode == 'nearest':
        return torch._C._nn.upsample_nearest1d(input, output_size, scale_factors)
               ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    if input.dim() == 4 and mode == 'nearest':
        return torch._C._nn.upsample_nearest2d(input, output_size, scale_factors)
Serialized   File ""code/__torch__/torch/nn/functional/___torch_mangle_46.py"", line 155
    _49 = False
  if _49:
    _51 = torch.upsample_nearest1d(input, output_size3, scale_factors6)
          ~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    _50 = _51
  else:
'interpolate' is being compiled since it was called from 'FeatureNet.forward'
Serialized   File ""code/__torch__/models/net.py"", line 139
  def forward(self: __torch__.models.net.FeatureNet,
    x: Tensor) -> List[Tensor]:
    _35 = __torch__.torch.nn.functional.___torch_mangle_46.interpolate
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    _36 = torch.empty([1], dtype=None, layout=None, device=None, pin_memory=None, memory_format=None)
    _37 = torch.empty([1], dtype=None, layout=None, device=None, pin_memory=None, memory_format=None)",True,{}
colmap/colmap,https://github.com/colmap/colmap,1129,2021-02-22T23:13:03Z,,2022-01-26T12:22:15Z,OPEN,False,809,152,29,https://github.com/anmatako,Add PatchMatchNet module for MVS and calculation of normals from depth,20,[],https://github.com/colmap/colmap/pull/1129,https://github.com/anmatako,10,https://github.com/colmap/colmap/pull/1129#issuecomment-789186784,"This work mainly integrated PatchMatchNet functionality in colamp using a TorchScript pre-trained module. Additionally it introduces functionality to calculate normal maps from depth maps since PatchMatchNet evaluation does not create normal maps as part of its process. More details about the changes:

Colmap can compile with Torch support to enable PatchMatchNet. For this the pre-compiled LitTorch library needs to be downloaded from here https://pytorch.org/ on the desired configuration for GPU or CPU-only and the archive extracted under <colmap-root>/lib/ thus creating a libtorch subfolder. Then CMake should be able to find the dependency and set the correct compilation flags.
PatchMatchNet can now be enabled from patch_match_stereo by setting the mvs_module_path option to a valid TorchScript module. One such module is included as part of this PR in <colmap-root>\mvs-modules\patchmatchnet-module.pt

The TorchScript interface is fairly generic using the following input structure: (images: List[Tensor], intrisics: Tensor, extrinsics: Tensor, depth_params: Tensor) with the output being a tuple of (depth: Tensor, confidence: Tensor). Thus any module that subscribes to that input/output format for forward evaluation can be used instead.


Functionality of standard patch-match remains unchanged. There is now an inheritance structure used to select between standard and PMNet processing
Normal maps are now not required for stereo fusion. If missing they will be calculated from the depth maps themselves. This is needed to accommodate PMNet processing that does not produce normal maps as part of the estimation work.

Note that use of calculated normal maps can be forced even for standard patch-match processing through the use of a new stereo fusion option --StereoFusion.calculate_normals.


Confidence maps can now be used for stereo fusion and they are optional. If missing a confidence of 1 is assumed everywhere. This is also added to make use of the confidence maps that are created as part of PMNet estimation.
New method for finding related images for fusion based on triangulation scoring is introduced and can be enabled with the option --StereoFusion.use_triangulation_scoring. This is included for parity with PatchMatchNet that has this method for finding related images instead of the colmap default. (useful for comparing results between colmap and Python)","Being able to load the module with Pytorch 1.7.1 at least means that the module does not seem to be corrupted. The Pytorch 1.6 issue you see looks like a simple incompatibility with older versions.
As for the error you get when you try to load with LibTorch, I'm quite confused as well, as it should not need any special configs in fstream and should load without issues. Can you try with LibTorch 1.7.1 for CUDA 10.1 and cudnn 7.6.0? That's the same package I'm using and I was wondering if there's something in these dependencies that makes the loading incompatible when doing it from colmap.

With PyTorch 1.7.1 I can read the model file properly.
I think the problem is that libtorch tries to open the file as a text file, not binary, that was one of my problems with Python.
I tried explicitly setting the file mode via:
std::ifstream model_file(options_.mvs_module_path, std::ios::in | std::ios::binary);

    model_[thread_index_] = torch::jit::load(model_file, kDevIn);
but I still get the same result.
Probably I'll have to compile a debug version of libtorch for linux to get more info. I have little experience with it but I'll try.
Here is the stack trace:
First definition of patch-match module for thread index: 0
Signal: SIGSEGV (signal SIGSEGV: invalid address (fault address: 0x0))
*** Aborted at 1614714901 (unix time) try ""date -d @1614714901"" if you are using GNU date ***
PC: @     0x7f2b751ee986 std::__detail::_Executor<>::_M_dfs()
*** SIGSEGV (@0x3e8000044a0) received by PID 17575 (TID 0x7f2b22fc4700) from PID 17568; stack trace: ***
    @     0x7f2b84b3a631 (unknown)
    @     0x7f2b8305f3c0 (unknown)
    @     0x7f2b751ee986 std::__detail::_Executor<>::_M_dfs()
    @     0x7f2b751eeb53 std::__detail::_Executor<>::_M_dfs()
    @     0x7f2b751eec6c std::__detail::_Executor<>::_M_dfs()
    @     0x7f2b751ef412 std::__detail::__regex_algo_impl<>()
    @     0x7f2b319995fe c10::Device::Device()
    @     0x7f2b7544963d torch::jit::Unpickler::readInstruction()
    @     0x7f2b7544b540 torch::jit::Unpickler::run()
    @     0x7f2b7544baf1 torch::jit::Unpickler::parse_ivalue()
    @     0x7f2b753ef9c2 torch::jit::readArchiveAndTensors()
    @     0x7f2b753efcdd torch::jit::(anonymous namespace)::ScriptModuleDeserializer::readArchive()
    @     0x7f2b753f2605 torch::jit::(anonymous namespace)::ScriptModuleDeserializer::deserialize()
    @     0x7f2b753f2bd9 torch::jit::load()
    @     0x7f2b753f5455 torch::jit::load()
    @     0x55620f2f4c46 colmap::mvs::PatchMatchNet::InitModule()
    @     0x55620f2f43d6 colmap::mvs::PatchMatchNet::PatchMatchNet()
    @     0x55620ec7c9b0 colmap::mvs::PatchMatchController::ProcessProblem()
    @     0x55620ec8fb63 std::__invoke_impl<>()
    @     0x55620ec8fa50 std::__invoke<>()
    @     0x55620ec8f851 _ZNSt5_BindIFMN6colmap3mvs20PatchMatchControllerEFvRKNS1_17PatchMatchOptionsEmEPS2_S3_mEE6__callIvJEJLm0ELm1ELm2EEEET_OSt5tupleIJDpT0_EESt12_Index_tupleIJXspT1_EEE
    @     0x55620ec8f367 std::_Bind<>::operator()<>()
    @     0x55620ec8efdd std::__invoke_impl<>()
    @     0x55620ec8ed55 std::__invoke<>()
    @     0x55620ec8ea7d _ZZNSt13__future_base11_Task_stateISt5_BindIFMN6colmap3mvs20PatchMatchControllerEFvRKNS3_17PatchMatchOptionsEmEPS4_S5_mEESaIiEFvvEE6_M_runEvENKUlvE_clEv
    @     0x55620ec8f436 _ZNKSt13__future_base12_Task_setterISt10unique_ptrINS_7_ResultIvEENS_12_Result_base8_DeleterEEZNS_11_Task_stateISt5_BindIFMN6colmap3mvs20PatchMatchControllerEFvRKNSA_17PatchMatchOptionsEmEPSB_SC_mEESaIiEFvvEE6_M_runEvEUlvE_vEclEv
    @     0x55620ec8f08c _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateISt5_BindIFMN6colmap3mvs20PatchMatchControllerEFvRKNSD_17PatchMatchOptionsEmEPSE_SF_mEESaIiEFvvEE6_M_runEvEUlvE_vEEE9_M_invokeERKSt9_Any_data
    @     0x55620eacd258 std::function<>::operator()()
    @     0x55620eacc75e std::__future_base::_State_baseV2::_M_do_set()
    @     0x55620ead4019 std::__invoke_impl<>()
    @     0x55620ead1136 std::__invoke<>()
    @     0x55620eacce3e _ZZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJPS1_S9_SA_EEvRSt9once_flagOT_DpOT0_ENKUlvE_clEv
Signal: SIGSEGV (unknown crash reason)

Process finished with exit code 11

This is the error I got with PyTorch 1.6 might be related:
with open('/home/dawars/projects/colmap_torch/mvs-modules/patchmatchnet-module_windows.pt', 'br') as f:
    model = torch.jit.load(f)
Traceback (most recent call last):
  File ""/home/dawars/miniconda3/envs/historic/lib/python3.7/site-packages/IPython/core/interactiveshell.py"", line 3417, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-4-d6e3587a7e88>"", line 2, in <module>
    model = torch.jit.load(f)
  File ""/home/dawars/miniconda3/envs/historic/lib/python3.7/site-packages/torch/jit/__init__.py"", line 277, in load
    cpp_module = torch._C.import_ir_module_from_buffer(cu, f.read(), map_location, _extra_files)
RuntimeError: 
Arguments for call are not valid.
The following variants are available:
  
  aten::upsample_nearest1d.out(Tensor self, int[1] output_size, float? scales=None, *, Tensor(a!) out) -> (Tensor(a!)):
  Expected a value of type 'List[int]' for argument 'output_size' but instead found type 'Optional[List[int]]'.
  
  aten::upsample_nearest1d(Tensor self, int[1] output_size, float? scales=None) -> (Tensor):
  Expected a value of type 'List[int]' for argument 'output_size' but instead found type 'Optional[List[int]]'.
The original call is:
  File ""C:\Users\anmatako\AppData\Roaming\Python\Python38\site-packages\torch\nn\functional.py"", line 3130
    if input.dim() == 3 and mode == 'nearest':
        return torch._C._nn.upsample_nearest1d(input, output_size, scale_factors)
               ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    if input.dim() == 4 and mode == 'nearest':
        return torch._C._nn.upsample_nearest2d(input, output_size, scale_factors)
Serialized   File ""code/__torch__/torch/nn/functional/___torch_mangle_46.py"", line 155
    _49 = False
  if _49:
    _51 = torch.upsample_nearest1d(input, output_size3, scale_factors6)
          ~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    _50 = _51
  else:
'interpolate' is being compiled since it was called from 'FeatureNet.forward'
Serialized   File ""code/__torch__/models/net.py"", line 139
  def forward(self: __torch__.models.net.FeatureNet,
    x: Tensor) -> List[Tensor]:
    _35 = __torch__.torch.nn.functional.___torch_mangle_46.interpolate
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    _36 = torch.empty([1], dtype=None, layout=None, device=None, pin_memory=None, memory_format=None)
    _37 = torch.empty([1], dtype=None, layout=None, device=None, pin_memory=None, memory_format=None)",True,{}
colmap/colmap,https://github.com/colmap/colmap,1129,2021-02-22T23:13:03Z,,2022-01-26T12:22:15Z,OPEN,False,809,152,29,https://github.com/anmatako,Add PatchMatchNet module for MVS and calculation of normals from depth,20,[],https://github.com/colmap/colmap/pull/1129,https://github.com/Dawars,11,https://github.com/colmap/colmap/pull/1129#issuecomment-791048604,"This work mainly integrated PatchMatchNet functionality in colamp using a TorchScript pre-trained module. Additionally it introduces functionality to calculate normal maps from depth maps since PatchMatchNet evaluation does not create normal maps as part of its process. More details about the changes:

Colmap can compile with Torch support to enable PatchMatchNet. For this the pre-compiled LitTorch library needs to be downloaded from here https://pytorch.org/ on the desired configuration for GPU or CPU-only and the archive extracted under <colmap-root>/lib/ thus creating a libtorch subfolder. Then CMake should be able to find the dependency and set the correct compilation flags.
PatchMatchNet can now be enabled from patch_match_stereo by setting the mvs_module_path option to a valid TorchScript module. One such module is included as part of this PR in <colmap-root>\mvs-modules\patchmatchnet-module.pt

The TorchScript interface is fairly generic using the following input structure: (images: List[Tensor], intrisics: Tensor, extrinsics: Tensor, depth_params: Tensor) with the output being a tuple of (depth: Tensor, confidence: Tensor). Thus any module that subscribes to that input/output format for forward evaluation can be used instead.


Functionality of standard patch-match remains unchanged. There is now an inheritance structure used to select between standard and PMNet processing
Normal maps are now not required for stereo fusion. If missing they will be calculated from the depth maps themselves. This is needed to accommodate PMNet processing that does not produce normal maps as part of the estimation work.

Note that use of calculated normal maps can be forced even for standard patch-match processing through the use of a new stereo fusion option --StereoFusion.calculate_normals.


Confidence maps can now be used for stereo fusion and they are optional. If missing a confidence of 1 is assumed everywhere. This is also added to make use of the confidence maps that are created as part of PMNet estimation.
New method for finding related images for fusion based on triangulation scoring is introduced and can be enabled with the option --StereoFusion.use_triangulation_scoring. This is included for parity with PatchMatchNet that has this method for finding related images instead of the colmap default. (useful for comparing results between colmap and Python)","I compiled the debug version and it works, which is not very useful. Now
I'm compiling in release mode.

I tried setting up Cuda 10.1 but on Ubuntu cublas is missing for this
version, therefore I used 11.0.
Not sure what to do from here. Also Pytorch 1.8 has just been released.
…
On 2021. Mar 2., Tue at 21:20, Antonios Matakos ***@***.***> wrote:
 Being able to load the module with Pytorch 1.7.1 at least means that the
 module does not seem to be corrupted. The Pytorch 1.6 issue you see looks
 like a simple incompatibility with older versions.

 As for the error you get when you try to load with LibTorch, I'm quite
 confused as well, as it should not need any special configs in fstream and
 should load without issues. Can you try with LibTorch 1.7.1 for CUDA 10.1
 and cudnn 7.6.0? That's the same package I'm using and I was wondering if
 there's something in these dependencies that makes the loading incompatible
 when doing it from colmap.

 With PyTorch 1.7.1 I can read the model file properly.
 I think the problem is that libtorch tries to open the file as a text
 file, not binary, that was one of my problems with Python.

 I tried explicitly setting the file mode via:

 std::ifstream model_file(options_.mvs_module_path, std::ios::in | std::ios::binary);

     model_[thread_index_] = torch::jit::load(model_file, kDevIn);

 but I still get the same result.

 Probably I'll have to compile a debug version of libtorch for linux to get
 more info. I have little experience with it but I'll try.

 Here is the stack trace:

 First definition of patch-match module for thread index: 0
 Signal: SIGSEGV (signal SIGSEGV: invalid address (fault address: 0x0))
 *** Aborted at 1614714901 (unix time) try ""date -d @1614714901"" if you are using GNU date ***
 PC: @     0x7f2b751ee986 std::__detail::_Executor<>::_M_dfs()
 *** SIGSEGV ***@***.***) received by PID 17575 (TID 0x7f2b22fc4700) from PID 17568; stack trace: ***
     @     0x7f2b84b3a631 (unknown)
     @     0x7f2b8305f3c0 (unknown)
     @     0x7f2b751ee986 std::__detail::_Executor<>::_M_dfs()
     @     0x7f2b751eeb53 std::__detail::_Executor<>::_M_dfs()
     @     0x7f2b751eec6c std::__detail::_Executor<>::_M_dfs()
     @     0x7f2b751ef412 std::__detail::__regex_algo_impl<>()
     @     0x7f2b319995fe c10::Device::Device()
     @     0x7f2b7544963d torch::jit::Unpickler::readInstruction()
     @     0x7f2b7544b540 torch::jit::Unpickler::run()
     @     0x7f2b7544baf1 torch::jit::Unpickler::parse_ivalue()
     @     0x7f2b753ef9c2 torch::jit::readArchiveAndTensors()
     @     0x7f2b753efcdd torch::jit::(anonymous namespace)::ScriptModuleDeserializer::readArchive()
     @     0x7f2b753f2605 torch::jit::(anonymous namespace)::ScriptModuleDeserializer::deserialize()
     @     0x7f2b753f2bd9 torch::jit::load()
     @     0x7f2b753f5455 torch::jit::load()
     @     0x55620f2f4c46 colmap::mvs::PatchMatchNet::InitModule()
     @     0x55620f2f43d6 colmap::mvs::PatchMatchNet::PatchMatchNet()
     @     0x55620ec7c9b0 colmap::mvs::PatchMatchController::ProcessProblem()
     @     0x55620ec8fb63 std::__invoke_impl<>()
     @     0x55620ec8fa50 std::__invoke<>()
     @     0x55620ec8f851 _ZNSt5_BindIFMN6colmap3mvs20PatchMatchControllerEFvRKNS1_17PatchMatchOptionsEmEPS2_S3_mEE6__callIvJEJLm0ELm1ELm2EEEET_OSt5tupleIJDpT0_EESt12_Index_tupleIJXspT1_EEE
     @     0x55620ec8f367 std::_Bind<>::operator()<>()
     @     0x55620ec8efdd std::__invoke_impl<>()
     @     0x55620ec8ed55 std::__invoke<>()
     @     0x55620ec8ea7d _ZZNSt13__future_base11_Task_stateISt5_BindIFMN6colmap3mvs20PatchMatchControllerEFvRKNS3_17PatchMatchOptionsEmEPS4_S5_mEESaIiEFvvEE6_M_runEvENKUlvE_clEv
     @     0x55620ec8f436 _ZNKSt13__future_base12_Task_setterISt10unique_ptrINS_7_ResultIvEENS_12_Result_base8_DeleterEEZNS_11_Task_stateISt5_BindIFMN6colmap3mvs20PatchMatchControllerEFvRKNSA_17PatchMatchOptionsEmEPSB_SC_mEESaIiEFvvEE6_M_runEvEUlvE_vEclEv
     @     0x55620ec8f08c _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateISt5_BindIFMN6colmap3mvs20PatchMatchControllerEFvRKNSD_17PatchMatchOptionsEmEPSE_SF_mEESaIiEFvvEE6_M_runEvEUlvE_vEEE9_M_invokeERKSt9_Any_data
     @     0x55620eacd258 std::function<>::operator()()
     @     0x55620eacc75e std::__future_base::_State_baseV2::_M_do_set()
     @     0x55620ead4019 std::__invoke_impl<>()
     @     0x55620ead1136 std::__invoke<>()
     @     0x55620eacce3e _ZZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJPS1_S9_SA_EEvRSt9once_flagOT_DpOT0_ENKUlvE_clEv
 Signal: SIGSEGV (unknown crash reason)

 Process finished with exit code 11

 This is the error I got with PyTorch 1.6 might be related:

 with open('/home/dawars/projects/colmap_torch/mvs-modules/patchmatchnet-module_windows.pt', 'br') as f:
     model = torch.jit.load(f)
 Traceback (most recent call last):
   File ""/home/dawars/miniconda3/envs/historic/lib/python3.7/site-packages/IPython/core/interactiveshell.py"", line 3417, in run_code
     exec(code_obj, self.user_global_ns, self.user_ns)
   File ""<ipython-input-4-d6e3587a7e88>"", line 2, in <module>
     model = torch.jit.load(f)
   File ""/home/dawars/miniconda3/envs/historic/lib/python3.7/site-packages/torch/jit/__init__.py"", line 277, in load
     cpp_module = torch._C.import_ir_module_from_buffer(cu, f.read(), map_location, _extra_files)
 RuntimeError:
 Arguments for call are not valid.
 The following variants are available:

   aten::upsample_nearest1d.out(Tensor self, int[1] output_size, float? scales=None, *, Tensor(a!) out) -> (Tensor(a!)):
   Expected a value of type 'List[int]' for argument 'output_size' but instead found type 'Optional[List[int]]'.

   aten::upsample_nearest1d(Tensor self, int[1] output_size, float? scales=None) -> (Tensor):
   Expected a value of type 'List[int]' for argument 'output_size' but instead found type 'Optional[List[int]]'.
 The original call is:
   File ""C:\Users\anmatako\AppData\Roaming\Python\Python38\site-packages\torch\nn\functional.py"", line 3130
     if input.dim() == 3 and mode == 'nearest':
         return torch._C._nn.upsample_nearest1d(input, output_size, scale_factors)
                ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
     if input.dim() == 4 and mode == 'nearest':
         return torch._C._nn.upsample_nearest2d(input, output_size, scale_factors)
 Serialized   File ""code/__torch__/torch/nn/functional/___torch_mangle_46.py"", line 155
     _49 = False
   if _49:
     _51 = torch.upsample_nearest1d(input, output_size3, scale_factors6)
           ~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
     _50 = _51
   else:
 'interpolate' is being compiled since it was called from 'FeatureNet.forward'
 Serialized   File ""code/__torch__/models/net.py"", line 139
   def forward(self: __torch__.models.net.FeatureNet,
     x: Tensor) -> List[Tensor]:
     _35 = __torch__.torch.nn.functional.___torch_mangle_46.interpolate
     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
     _36 = torch.empty([1], dtype=None, layout=None, device=None, pin_memory=None, memory_format=None)
     _37 = torch.empty([1], dtype=None, layout=None, device=None, pin_memory=None, memory_format=None)

 —
 You are receiving this because you were mentioned.
 Reply to this email directly, view it on GitHub
 <#1129 (comment)>, or
 unsubscribe
 <https://github.com/notifications/unsubscribe-auth/AAI35ZCJAMSZSBXYTXHTDHDTBVCAHANCNFSM4YBNICEQ>
 .",True,{}
colmap/colmap,https://github.com/colmap/colmap,1131,2021-02-23T20:27:23Z,2021-02-24T09:13:24Z,2021-02-24T18:01:09Z,MERGED,True,60,23,1,https://github.com/anmatako,Allow ReadPly to handle double precision files,2,[],https://github.com/colmap/colmap/pull/1131,https://github.com/anmatako,1,https://github.com/colmap/colmap/pull/1131,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,1132,2021-02-23T20:31:09Z,2021-02-24T09:16:03Z,2021-11-17T03:39:30Z,MERGED,True,26,31,2,https://github.com/anmatako,Update GPSTransform calculations to improve accuracy,1,[],https://github.com/colmap/colmap/pull/1132,https://github.com/anmatako,1,https://github.com/colmap/colmap/pull/1132,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,1133,2021-02-23T20:34:55Z,2021-02-24T09:16:50Z,2021-02-24T18:00:18Z,MERGED,True,21,13,2,https://github.com/anmatako,Add scale template flag in SimilarityTransform3::Estimate,1,[],https://github.com/colmap/colmap/pull/1133,https://github.com/anmatako,1,https://github.com/colmap/colmap/pull/1133,This new functionality can be leveraged when aligning reconstruction if we would rather not estimate a scale factor.,This new functionality can be leveraged when aligning reconstruction if we would rather not estimate a scale factor.,True,{}
colmap/colmap,https://github.com/colmap/colmap,1134,2021-02-23T20:37:10Z,2021-02-24T09:18:35Z,2021-02-24T17:59:51Z,MERGED,True,20,0,2,https://github.com/anmatako,Add CopyFile utility that can copy or hard/soft-link files,1,[],https://github.com/colmap/colmap/pull/1134,https://github.com/anmatako,1,https://github.com/colmap/colmap/pull/1134,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,1134,2021-02-23T20:37:10Z,2021-02-24T09:18:35Z,2021-02-24T17:59:51Z,MERGED,True,20,0,2,https://github.com/anmatako,Add CopyFile utility that can copy or hard/soft-link files,1,[],https://github.com/colmap/colmap/pull/1134,https://github.com/anmatako,2,https://github.com/colmap/colmap/pull/1134#issuecomment-784494886,,This will be leveraged in subsequent PRs to skip undistortion of already undistorted images.,True,{}
colmap/colmap,https://github.com/colmap/colmap,1135,2021-02-23T21:02:06Z,,2022-01-26T12:22:15Z,OPEN,False,78,0,3,https://github.com/anmatako,Update camera intrinsics with new camera_updater command,11,[],https://github.com/colmap/colmap/pull/1135,https://github.com/anmatako,1,https://github.com/colmap/colmap/pull/1135,"This is a limited command to update the intrinsics for SIMPLE_RADIAL cameras (focal length, principal point x, and principal point y). The input is a CSV file with 4 entries per line: <camera_id>, <focal length>, <PP x>, <PP y>. It also sets the prior_focal_length field to true.","This is a limited command to update the intrinsics for SIMPLE_RADIAL cameras (focal length, principal point x, and principal point y). The input is a CSV file with 4 entries per line: <camera_id>, <focal length>, <PP x>, <PP y>. It also sets the prior_focal_length field to true.",True,{}
colmap/colmap,https://github.com/colmap/colmap,1135,2021-02-23T21:02:06Z,,2022-01-26T12:22:15Z,OPEN,False,78,0,3,https://github.com/anmatako,Update camera intrinsics with new camera_updater command,11,[],https://github.com/colmap/colmap/pull/1135,https://github.com/anmatako,2,https://github.com/colmap/colmap/pull/1135#issuecomment-798922152,"This is a limited command to update the intrinsics for SIMPLE_RADIAL cameras (focal length, principal point x, and principal point y). The input is a CSV file with 4 entries per line: <camera_id>, <focal length>, <PP x>, <PP y>. It also sets the prior_focal_length field to true.",Updated the functionality to now handle all camera models,True,{}
colmap/colmap,https://github.com/colmap/colmap,1136,2021-02-23T21:09:08Z,2021-03-03T17:38:57Z,2021-03-03T17:58:01Z,MERGED,True,132,0,4,https://github.com/anmatako,Allow cleanup of SQLite tables using new database_cleaner command,3,[],https://github.com/colmap/colmap/pull/1136,https://github.com/anmatako,1,https://github.com/colmap/colmap/pull/1136,Added functionality to clear SQLite tables and also call VACUUM on Database::Close to reduce the DB file size after cleanup.,Added functionality to clear SQLite tables and also call VACUUM on Database::Close to reduce the DB file size after cleanup.,True,{}
colmap/colmap,https://github.com/colmap/colmap,1137,2021-02-23T21:19:42Z,2021-02-24T09:45:05Z,2021-02-24T17:59:17Z,MERGED,True,11,1,1,https://github.com/anmatako,Change ReconstructionMaanger to write larger recons first,1,[],https://github.com/colmap/colmap/pull/1137,https://github.com/anmatako,1,https://github.com/colmap/colmap/pull/1137,"ReconstructionManager::Write now uses the NumPoints3D as proxy for a reconstruction's size and writes the output in descending order based on size. This allows larger reconstructions to be written first which is a useful behavior since sparse models may end up with a large main recon and more much smaller ones, and with this change we ensure that if we only look at the first recon it will be the ""main"" one.","ReconstructionManager::Write now uses the NumPoints3D as proxy for a reconstruction's size and writes the output in descending order based on size. This allows larger reconstructions to be written first which is a useful behavior since sparse models may end up with a large main recon and more much smaller ones, and with this change we ensure that if we only look at the first recon it will be the ""main"" one.",True,{}
colmap/colmap,https://github.com/colmap/colmap,1138,2021-02-23T21:46:44Z,,2022-01-26T12:22:15Z,OPEN,False,151,24,1,https://github.com/anmatako,Extend model_merger functionality to allow merging of multiple models,11,[],https://github.com/colmap/colmap/pull/1138,https://github.com/anmatako,1,https://github.com/colmap/colmap/pull/1138,model_merger now has a new option input_path and when given it will look in all subfolders for valid reconstructions and try to merge them into a single model doing pair-wise merging starting from the larger reconstructions first. The existing functionality of two model merge using intput_path1 and input_path2 remains unchanged.,model_merger now has a new option input_path and when given it will look in all subfolders for valid reconstructions and try to merge them into a single model doing pair-wise merging starting from the larger reconstructions first. The existing functionality of two model merge using intput_path1 and input_path2 remains unchanged.,True,{'THUMBS_UP': ['https://github.com/willard-yuan']}
colmap/colmap,https://github.com/colmap/colmap,1139,2021-02-23T21:56:12Z,2021-02-24T09:22:00Z,2021-02-24T17:58:35Z,MERGED,True,22,2,4,https://github.com/anmatako,Expose BA options in IncrementalMapper,1,[],https://github.com/colmap/colmap/pull/1139,https://github.com/anmatako,1,https://github.com/colmap/colmap/pull/1139,Incremental mapper now exposes the function tolerance option for local and global BA. This allows for control over the BA convergence by explicitly setting this option when using mapper or hierarchical_mapper,Incremental mapper now exposes the function tolerance option for local and global BA. This allows for control over the BA convergence by explicitly setting this option when using mapper or hierarchical_mapper,True,{}
colmap/colmap,https://github.com/colmap/colmap,1140,2021-02-23T22:39:48Z,2021-03-03T17:42:34Z,2021-03-03T17:57:55Z,MERGED,True,221,25,4,https://github.com/anmatako,Extend SceneClustering to support non-hierarchical (flat) clusters,3,[],https://github.com/colmap/colmap/pull/1140,https://github.com/anmatako,1,https://github.com/colmap/colmap/pull/1140,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,1140,2021-02-23T22:39:48Z,2021-03-03T17:42:34Z,2021-03-03T17:57:55Z,MERGED,True,221,25,4,https://github.com/anmatako,Extend SceneClustering to support non-hierarchical (flat) clusters,3,[],https://github.com/colmap/colmap/pull/1140,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/1140#issuecomment-784936566,,Would be great to add some unit tests to scene_clustering_test.cc to make sure this new functionality works as expected.,True,{}
colmap/colmap,https://github.com/colmap/colmap,1140,2021-02-23T22:39:48Z,2021-03-03T17:42:34Z,2021-03-03T17:57:55Z,MERGED,True,221,25,4,https://github.com/anmatako,Extend SceneClustering to support non-hierarchical (flat) clusters,3,[],https://github.com/colmap/colmap/pull/1140,https://github.com/anmatako,3,https://github.com/colmap/colmap/pull/1140#issuecomment-788182982,,"Would be great to add some unit tests to scene_clustering_test.cc to make sure this new functionality works as expected.

Unit tests added for flat clustering with and without overlaps.",True,{}
colmap/colmap,https://github.com/colmap/colmap,1140,2021-02-23T22:39:48Z,2021-03-03T17:42:34Z,2021-03-03T17:57:55Z,MERGED,True,221,25,4,https://github.com/anmatako,Extend SceneClustering to support non-hierarchical (flat) clusters,3,[],https://github.com/colmap/colmap/pull/1140,https://github.com/anmatako,4,https://github.com/colmap/colmap/pull/1140#issuecomment-788326374,,"Tests will have to be revised. It appears that the graph cut is not fully deterministic in the order it assigns labels to clusters; the cluster sizes and the IDs in each cluster are as expected but the order may differ, e.g. cluster 0 on Windows may be cluster 1 in Ubuntu. Not sure why this is not being an issue with the unit tests for hierarchical clustering. New tests pass on Windows and Mac but fail in Ubuntu.",True,{}
colmap/colmap,https://github.com/colmap/colmap,1140,2021-02-23T22:39:48Z,2021-03-03T17:42:34Z,2021-03-03T17:57:55Z,MERGED,True,221,25,4,https://github.com/anmatako,Extend SceneClustering to support non-hierarchical (flat) clusters,3,[],https://github.com/colmap/colmap/pull/1140,https://github.com/anmatako,5,https://github.com/colmap/colmap/pull/1140#issuecomment-788581847,,Made the new flat clustering deterministic sorting by descending cluster size and using min image ID as tie breaker. Now the test should be consistent on all environments.,True,{}
colmap/colmap,https://github.com/colmap/colmap,1141,2021-02-23T22:43:39Z,2021-02-24T09:26:40Z,2021-02-24T17:57:48Z,MERGED,True,8,6,2,https://github.com/anmatako,Allow configurable paths for mvs::Model,1,[],https://github.com/colmap/colmap/pull/1141,https://github.com/anmatako,1,https://github.com/colmap/colmap/pull/1141,Instead of using hard-coded values for the sparse and images folders of the model we allow these to be passed as parameters; the default values are compatible with existing functionality.,Instead of using hard-coded values for the sparse and images folders of the model we allow these to be passed as parameters; the default values are compatible with existing functionality.,True,{}
colmap/colmap,https://github.com/colmap/colmap,1142,2021-02-23T23:14:41Z,2021-02-27T12:20:31Z,2021-02-27T21:15:01Z,MERGED,True,52,9,4,https://github.com/anmatako,Allow custom config and missing dependencies for patch-match,1,[],https://github.com/colmap/colmap/pull/1142,https://github.com/anmatako,1,https://github.com/colmap/colmap/pull/1142,patch_match_stereo can now use a custom config using the --config_path option instead of just relying on the default patch-match.cfg from the workspace. Also a new option for patch-match is introduced (--PatchMatchStereo.allow_missing_files) to allow the process to ignore missing source images or depth/normal maps and simply exclude that image index from the patch-match problem without error.,patch_match_stereo can now use a custom config using the --config_path option instead of just relying on the default patch-match.cfg from the workspace. Also a new option for patch-match is introduced (--PatchMatchStereo.allow_missing_files) to allow the process to ignore missing source images or depth/normal maps and simply exclude that image index from the patch-match problem without error.,True,{}
colmap/colmap,https://github.com/colmap/colmap,1143,2021-02-23T23:59:45Z,,2022-01-26T12:22:15Z,OPEN,False,146,0,5,https://github.com/anmatako,Add auto_matcher command for feature matching,12,[],https://github.com/colmap/colmap/pull/1143,https://github.com/anmatako,1,https://github.com/colmap/colmap/pull/1143,"auto_matcher is a convenience feature matching command that chooses the best feature matching method based on the given option. The choices in order are:

ImagePairsFeatureMatcher: if the --ImagePairsMatching.match_list_path is set to a valid image pairs file that includes all images in the DB
SpatialFeatureMatcher: if the image pairs file is not given or is malformed in any way and the DB contains GPS priors for the images
ExhaustiveFeatureMatcher: This is a fallback that should always work if neither of the two earlier choices are usable. It is also used when the max matching distance of the spatial matcher is larger than the max distance of images in the DB; this happens because in such a case the spatial matcher devolves to exhausting matching anyway, and leveraging the batches of the exhaustive matcher speeds things up a bit","auto_matcher is a convenience feature matching command that chooses the best feature matching method based on the given option. The choices in order are:

ImagePairsFeatureMatcher: if the --ImagePairsMatching.match_list_path is set to a valid image pairs file that includes all images in the DB
SpatialFeatureMatcher: if the image pairs file is not given or is malformed in any way and the DB contains GPS priors for the images
ExhaustiveFeatureMatcher: This is a fallback that should always work if neither of the two earlier choices are usable. It is also used when the max matching distance of the spatial matcher is larger than the max distance of images in the DB; this happens because in such a case the spatial matcher devolves to exhausting matching anyway, and leveraging the batches of the exhaustive matcher speeds things up a bit",True,{}
colmap/colmap,https://github.com/colmap/colmap,1144,2021-02-24T00:34:20Z,2021-02-27T11:54:59Z,2021-03-06T05:30:14Z,MERGED,True,65,15,3,https://github.com/anmatako,Add fixed extrinsics in rig config,4,[],https://github.com/colmap/colmap/pull/1144,https://github.com/anmatako,1,https://github.com/colmap/colmap/pull/1144,"The rig config can now support fields for relative extrinsics and use these values instead of estimating relative poses from the reconstruction. To use the new behavior the rig config must contain the new ""location"" and ""orientation"" properties and the flag estimate_rig_relative_poses must be false (--estimate_rig_relative_poses 0) when calling rig_bundle_adjuster","The rig config can now support fields for relative extrinsics and use these values instead of estimating relative poses from the reconstruction. To use the new behavior the rig config must contain the new ""location"" and ""orientation"" properties and the flag estimate_rig_relative_poses must be false (--estimate_rig_relative_poses 0) when calling rig_bundle_adjuster",True,{}
colmap/colmap,https://github.com/colmap/colmap,1145,2021-02-24T01:33:03Z,2021-03-07T11:05:40Z,2021-03-07T16:55:14Z,CLOSED,False,148,0,1,https://github.com/anmatako,Add utility to compare poses between two sparse models,5,[],https://github.com/colmap/colmap/pull/1145,https://github.com/anmatako,1,https://github.com/colmap/colmap/pull/1145,"model_comparator takes two sparse models as input and after aligning them it calculates some simple statistics on difference in pose parameters (translation, rotation, projection center) between them.","model_comparator takes two sparse models as input and after aligning them it calculates some simple statistics on difference in pose parameters (translation, rotation, projection center) between them.",True,{'THUMBS_UP': ['https://github.com/kondela']}
colmap/colmap,https://github.com/colmap/colmap,1145,2021-02-24T01:33:03Z,2021-03-07T11:05:40Z,2021-03-07T16:55:14Z,CLOSED,False,148,0,1,https://github.com/anmatako,Add utility to compare poses between two sparse models,5,[],https://github.com/colmap/colmap/pull/1145,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/1145#issuecomment-791265464,"model_comparator takes two sparse models as input and after aligning them it calculates some simple statistics on difference in pose parameters (translation, rotation, projection center) between them.","It could be useful to not just print percentiles but provide optional output CLI parameters to specify paths to text files where we write all rotation, translation errors. It would allow for easy visualization outside of COLMAP in Python, etc. Thanks.",True,{}
colmap/colmap,https://github.com/colmap/colmap,1145,2021-02-24T01:33:03Z,2021-03-07T11:05:40Z,2021-03-07T16:55:14Z,CLOSED,False,148,0,1,https://github.com/anmatako,Add utility to compare poses between two sparse models,5,[],https://github.com/colmap/colmap/pull/1145,https://github.com/anmatako,3,https://github.com/colmap/colmap/pull/1145#issuecomment-791669486,"model_comparator takes two sparse models as input and after aligning them it calculates some simple statistics on difference in pose parameters (translation, rotation, projection center) between them.","It could be useful to not just print percentiles but provide optional output CLI parameters to specify paths to text files where we write all rotation, translation errors. It would allow for easy visualization outside of COLMAP in Python, etc. Thanks.

Recommended changes were added in the new update",True,{}
colmap/colmap,https://github.com/colmap/colmap,1145,2021-02-24T01:33:03Z,2021-03-07T11:05:40Z,2021-03-07T16:55:14Z,CLOSED,False,148,0,1,https://github.com/anmatako,Add utility to compare poses between two sparse models,5,[],https://github.com/colmap/colmap/pull/1145,https://github.com/ahojnnes,4,https://github.com/colmap/colmap/pull/1145#issuecomment-792258687,"model_comparator takes two sparse models as input and after aligning them it calculates some simple statistics on difference in pose parameters (translation, rotation, projection center) between them.","I made some cosmetic changes, which I thought were easier, if I directly do them instead of going through review comments. Closing this PR. Thanks!",True,{}
colmap/colmap,https://github.com/colmap/colmap,1146,2021-02-24T04:10:52Z,2021-03-09T21:50:24Z,2021-03-09T21:55:59Z,MERGED,True,162,8,6,https://github.com/anmatako,ImageReder new option and bug fix in GPS priors,15,[],https://github.com/colmap/colmap/pull/1146,https://github.com/anmatako,1,https://github.com/colmap/colmap/pull/1146,"Default behavior of ImageReader is now changed and it will attempt to reuse the same camera model if the model exif tag and image size remains the same. The old default of one camera per image can now be used through the explicit option --ImageReader.single_camera_per_image 1. Convenience input --camera_mode was added in feature_extractor to set the correct flags for ImageReader.
Fixed bug when reading GPS coordinates from EXIF tag where the Lat/Lon reference tag (N or S, and E or W) was being ignored resulting in incorrect GPS coordinates for locations outside the NE quadrant; coordinates were always positive instead of negative Lat for south hemisphere and negative Lon for West hemisphere.","Default behavior of ImageReader is now changed and it will attempt to reuse the same camera model if the model exif tag and image size remains the same. The old default of one camera per image can now be used through the explicit option --ImageReader.single_camera_per_image 1. Convenience input --camera_mode was added in feature_extractor to set the correct flags for ImageReader.
Fixed bug when reading GPS coordinates from EXIF tag where the Lat/Lon reference tag (N or S, and E or W) was being ignored resulting in incorrect GPS coordinates for locations outside the NE quadrant; coordinates were always positive instead of negative Lat for south hemisphere and negative Lon for West hemisphere.",True,{}
colmap/colmap,https://github.com/colmap/colmap,1147,2021-02-24T05:02:48Z,2021-03-04T07:51:39Z,2021-03-04T20:30:26Z,MERGED,True,257,22,3,https://github.com/anmatako,Support more formats in model_converter,9,[],https://github.com/colmap/colmap/pull/1147,https://github.com/anmatako,1,https://github.com/colmap/colmap/pull/1147,"model_converter changes:

Added support for 2 new formats (CAM and Recon3D)
New option remove_image_prefix allows de-registering of images before conversion
New option skip_distortion can be used to export the model without the distortion parameters (set to 0)","model_converter changes:

Added support for 2 new formats (CAM and Recon3D)
New option remove_image_prefix allows de-registering of images before conversion
New option skip_distortion can be used to export the model without the distortion parameters (set to 0)",True,{'HEART': ['https://github.com/Eberty']}
colmap/colmap,https://github.com/colmap/colmap,1148,2021-02-24T06:02:25Z,2021-03-09T22:41:34Z,2021-03-10T22:25:39Z,MERGED,True,370,171,7,https://github.com/anmatako,Parallelize stereo fusion; needs pre-loading of entire workspace,18,[],https://github.com/colmap/colmap/pull/1148,https://github.com/anmatako,1,https://github.com/colmap/colmap/pull/1148,"Stereo fusion can now be done in parallel as long as the entire workspace gets pre-loaded. A new NoCacheWorkspace class can do that when initializing fusion. Parallel execution is the new default so to use the existing functionality with cache and sequential fusion stereo_fusion must be used with --StereoFusion.use_cache 1.
Also added options to:

Use image masks that excludes pixels from the depth maps. Work similarly to masks in ImageReaderOptions
Restrict the fused point cloud within a specified bounding box described from its two 3D corner points. The bounding box is in plan text format with space separated numeric values for the corner points, e.g. `     .","Stereo fusion can now be done in parallel as long as the entire workspace gets pre-loaded. A new NoCacheWorkspace class can do that when initializing fusion. Parallel execution is the new default so to use the existing functionality with cache and sequential fusion stereo_fusion must be used with --StereoFusion.use_cache 1.
Also added options to:

Use image masks that excludes pixels from the depth maps. Work similarly to masks in ImageReaderOptions
Restrict the fused point cloud within a specified bounding box described from its two 3D corner points. The bounding box is in plan text format with space separated numeric values for the corner points, e.g. `     .",True,{}
colmap/colmap,https://github.com/colmap/colmap,1148,2021-02-24T06:02:25Z,2021-03-09T22:41:34Z,2021-03-10T22:25:39Z,MERGED,True,370,171,7,https://github.com/anmatako,Parallelize stereo fusion; needs pre-loading of entire workspace,18,[],https://github.com/colmap/colmap/pull/1148,https://github.com/anmatako,2,https://github.com/colmap/colmap/pull/1148#issuecomment-784806701,"Stereo fusion can now be done in parallel as long as the entire workspace gets pre-loaded. A new NoCacheWorkspace class can do that when initializing fusion. Parallel execution is the new default so to use the existing functionality with cache and sequential fusion stereo_fusion must be used with --StereoFusion.use_cache 1.
Also added options to:

Use image masks that excludes pixels from the depth maps. Work similarly to masks in ImageReaderOptions
Restrict the fused point cloud within a specified bounding box described from its two 3D corner points. The bounding box is in plan text format with space separated numeric values for the corner points, e.g. `     .",This will not build for now since it has dependencies on #1129. I will fix any residual build issues once that PR gets merged.,True,{}
colmap/colmap,https://github.com/colmap/colmap,1148,2021-02-24T06:02:25Z,2021-03-09T22:41:34Z,2021-03-10T22:25:39Z,MERGED,True,370,171,7,https://github.com/anmatako,Parallelize stereo fusion; needs pre-loading of entire workspace,18,[],https://github.com/colmap/colmap/pull/1148,https://github.com/anmatako,3,https://github.com/colmap/colmap/pull/1148#issuecomment-792321811,"Stereo fusion can now be done in parallel as long as the entire workspace gets pre-loaded. A new NoCacheWorkspace class can do that when initializing fusion. Parallel execution is the new default so to use the existing functionality with cache and sequential fusion stereo_fusion must be used with --StereoFusion.use_cache 1.
Also added options to:

Use image masks that excludes pixels from the depth maps. Work similarly to masks in ImageReaderOptions
Restrict the fused point cloud within a specified bounding box described from its two 3D corner points. The bounding box is in plan text format with space separated numeric values for the corner points, e.g. `     .","Replaced OpenMP with ThreadPool for both fusion and workspace. Also removed all the members from Fusion that were only really used internally in the Fuse function. Now there's much less of the ugliness with the thread_id indexing. Performance took a minor hit, but overall it's not significant.",True,{}
colmap/colmap,https://github.com/colmap/colmap,1148,2021-02-24T06:02:25Z,2021-03-09T22:41:34Z,2021-03-10T22:25:39Z,MERGED,True,370,171,7,https://github.com/anmatako,Parallelize stereo fusion; needs pre-loading of entire workspace,18,[],https://github.com/colmap/colmap/pull/1148,https://github.com/ahojnnes,4,https://github.com/colmap/colmap/pull/1148#issuecomment-792335947,"Stereo fusion can now be done in parallel as long as the entire workspace gets pre-loaded. A new NoCacheWorkspace class can do that when initializing fusion. Parallel execution is the new default so to use the existing functionality with cache and sequential fusion stereo_fusion must be used with --StereoFusion.use_cache 1.
Also added options to:

Use image masks that excludes pixels from the depth maps. Work similarly to masks in ImageReaderOptions
Restrict the fused point cloud within a specified bounding box described from its two 3D corner points. The bounding box is in plan text format with space separated numeric values for the corner points, e.g. `     .","@anmatako You will have to merge with master. note that I modularized exe/colmap.cc into individual source files, since it grew way beyond what we should put into a single source file.",True,{}
colmap/colmap,https://github.com/colmap/colmap,1148,2021-02-24T06:02:25Z,2021-03-09T22:41:34Z,2021-03-10T22:25:39Z,MERGED,True,370,171,7,https://github.com/anmatako,Parallelize stereo fusion; needs pre-loading of entire workspace,18,[],https://github.com/colmap/colmap/pull/1148,https://github.com/anmatako,5,https://github.com/colmap/colmap/pull/1148#issuecomment-792337531,"Stereo fusion can now be done in parallel as long as the entire workspace gets pre-loaded. A new NoCacheWorkspace class can do that when initializing fusion. Parallel execution is the new default so to use the existing functionality with cache and sequential fusion stereo_fusion must be used with --StereoFusion.use_cache 1.
Also added options to:

Use image masks that excludes pixels from the depth maps. Work similarly to masks in ImageReaderOptions
Restrict the fused point cloud within a specified bounding box described from its two 3D corner points. The bounding box is in plan text format with space separated numeric values for the corner points, e.g. `     .","@anmatako You will have to merge with master. note that I modularized exe/colmap.cc into individual source files, since it grew way beyond what we should put into a single source file.

yes now that we are getting closer with these changes I'll do a merge from master and also resolve some other issues with confidence maps and calculated normals that were introduced from the PatchMatchNet PR.
I'll do a good cleanup and make sure this builds standalone.",True,{}
colmap/colmap,https://github.com/colmap/colmap,1148,2021-02-24T06:02:25Z,2021-03-09T22:41:34Z,2021-03-10T22:25:39Z,MERGED,True,370,171,7,https://github.com/anmatako,Parallelize stereo fusion; needs pre-loading of entire workspace,18,[],https://github.com/colmap/colmap/pull/1148,https://github.com/ahojnnes,6,https://github.com/colmap/colmap/pull/1148#issuecomment-794516135,"Stereo fusion can now be done in parallel as long as the entire workspace gets pre-loaded. A new NoCacheWorkspace class can do that when initializing fusion. Parallel execution is the new default so to use the existing functionality with cache and sequential fusion stereo_fusion must be used with --StereoFusion.use_cache 1.
Also added options to:

Use image masks that excludes pixels from the depth maps. Work similarly to masks in ImageReaderOptions
Restrict the fused point cloud within a specified bounding box described from its two 3D corner points. The bounding box is in plan text format with space separated numeric values for the corner points, e.g. `     .","@anmatako Thanks, the PR looks great now. I trust you checked correctness that these changes lead to equivalent (+- small changes) fusion results as before? I left two minor comments, then I am happy to merge. Thanks!",True,{}
colmap/colmap,https://github.com/colmap/colmap,1148,2021-02-24T06:02:25Z,2021-03-09T22:41:34Z,2021-03-10T22:25:39Z,MERGED,True,370,171,7,https://github.com/anmatako,Parallelize stereo fusion; needs pre-loading of entire workspace,18,[],https://github.com/colmap/colmap/pull/1148,https://github.com/anmatako,7,https://github.com/colmap/colmap/pull/1148#issuecomment-794520457,"Stereo fusion can now be done in parallel as long as the entire workspace gets pre-loaded. A new NoCacheWorkspace class can do that when initializing fusion. Parallel execution is the new default so to use the existing functionality with cache and sequential fusion stereo_fusion must be used with --StereoFusion.use_cache 1.
Also added options to:

Use image masks that excludes pixels from the depth maps. Work similarly to masks in ImageReaderOptions
Restrict the fused point cloud within a specified bounding box described from its two 3D corner points. The bounding box is in plan text format with space separated numeric values for the corner points, e.g. `     .","@anmatako Thanks, the PR looks great now. I trust you checked correctness that these changes lead to equivalent (+- small changes) fusion results as before? I left two minor comments, then I am happy to merge. Thanks!

Thanks! I've tested quite a lot in our pipelines and the differences are really minor compared to single threaded fusion; less than 0.1% in the number fused points and visually nothing stood out as an obvious outlier.",True,{}
colmap/colmap,https://github.com/colmap/colmap,1148,2021-02-24T06:02:25Z,2021-03-09T22:41:34Z,2021-03-10T22:25:39Z,MERGED,True,370,171,7,https://github.com/anmatako,Parallelize stereo fusion; needs pre-loading of entire workspace,18,[],https://github.com/colmap/colmap/pull/1148,https://github.com/ahojnnes,8,https://github.com/colmap/colmap/pull/1148#issuecomment-794554411,"Stereo fusion can now be done in parallel as long as the entire workspace gets pre-loaded. A new NoCacheWorkspace class can do that when initializing fusion. Parallel execution is the new default so to use the existing functionality with cache and sequential fusion stereo_fusion must be used with --StereoFusion.use_cache 1.
Also added options to:

Use image masks that excludes pixels from the depth maps. Work similarly to masks in ImageReaderOptions
Restrict the fused point cloud within a specified bounding box described from its two 3D corner points. The bounding box is in plan text format with space separated numeric values for the corner points, e.g. `     .",Thanks very much. This is a great improvement!,True,{}
colmap/colmap,https://github.com/colmap/colmap,1150,2021-02-24T10:06:51Z,2021-02-26T09:54:39Z,2021-02-26T09:54:45Z,MERGED,True,67,15,4,https://github.com/ahojnnes,Setup Azure pipelines for Windows build,15,[],https://github.com/colmap/colmap/pull/1150,https://github.com/ahojnnes,1,https://github.com/colmap/colmap/pull/1150,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,1155,2021-02-27T12:35:04Z,,2022-01-26T12:22:15Z,OPEN,False,8,1,1,https://github.com/ahojnnes,Release binaries to Github from Azure pipelines,1,[],https://github.com/colmap/colmap/pull/1155,https://github.com/ahojnnes,1,https://github.com/colmap/colmap/pull/1155,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,1156,2021-02-27T12:54:57Z,,2022-01-26T12:22:15Z,OPEN,False,18,2,2,https://github.com/ahojnnes,Enable CUDA build under Windows in Azure pipelines,4,[],https://github.com/colmap/colmap/pull/1156,https://github.com/ahojnnes,1,https://github.com/colmap/colmap/pull/1156,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,1157,2021-03-04T15:11:25Z,2021-03-04T15:55:25Z,2021-03-04T15:55:28Z,MERGED,True,1,0,1,https://github.com/ahojnnes,Fix Mac 10.15 build due to changed Qt5 path,1,[],https://github.com/colmap/colmap/pull/1157,https://github.com/ahojnnes,1,https://github.com/colmap/colmap/pull/1157,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,1158,2021-03-06T05:34:34Z,2021-03-06T11:08:41Z,2021-03-07T16:55:52Z,MERGED,True,2,2,1,https://github.com/anmatako,Fix bug in ReadCameraRigConfig when reading extrinsics,2,[],https://github.com/colmap/colmap/pull/1158,https://github.com/anmatako,1,https://github.com/colmap/colmap/pull/1158,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,1159,2021-03-07T10:56:12Z,2021-03-07T11:27:37Z,2021-03-07T11:27:37Z,MERGED,True,147,2,1,https://github.com/ahojnnes,Add utility to compare poses between two sparse models,7,[],https://github.com/colmap/colmap/pull/1159,https://github.com/ahojnnes,1,https://github.com/colmap/colmap/pull/1159,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,1160,2021-03-07T13:03:24Z,2021-03-07T18:57:06Z,2021-03-07T18:57:06Z,MERGED,True,3021,2332,20,https://github.com/ahojnnes,Modularize executable main functions into separate sources,1,[],https://github.com/colmap/colmap/pull/1160,https://github.com/ahojnnes,1,https://github.com/colmap/colmap/pull/1160,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,1162,2021-03-08T12:52:55Z,2021-03-08T13:15:39Z,2021-03-08T13:15:39Z,MERGED,True,9,9,6,https://github.com/ahojnnes,Fix unnecessary copies in for range loops,1,[],https://github.com/colmap/colmap/pull/1162,https://github.com/ahojnnes,1,https://github.com/colmap/colmap/pull/1162,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,1163,2021-03-08T16:04:18Z,2021-03-08T17:03:32Z,2021-03-08T17:03:33Z,MERGED,True,167,123,36,https://github.com/ahojnnes,Add script to clang-format all source code,3,[],https://github.com/colmap/colmap/pull/1163,https://github.com/ahojnnes,1,https://github.com/colmap/colmap/pull/1163,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,1164,2021-03-08T16:43:33Z,2021-03-09T09:21:51Z,2021-03-10T22:26:12Z,MERGED,True,9,3,1,https://github.com/anmatako,Add back new options and formats for model_converter,3,[],https://github.com/colmap/colmap/pull/1164,https://github.com/anmatako,1,https://github.com/colmap/colmap/pull/1164,Seems that between commits 78b6ae7 and e68974c the new options and formats for model_converter were missed.,Seems that between commits 78b6ae7 and e68974c the new options and formats for model_converter were missed.,True,{}
colmap/colmap,https://github.com/colmap/colmap,1165,2021-03-08T23:53:45Z,2021-03-12T09:24:41Z,2021-03-12T14:50:38Z,MERGED,True,140,34,14,https://github.com/anmatako,Add new CMake option to disable GUI,16,[],https://github.com/colmap/colmap/pull/1165,https://github.com/anmatako,1,https://github.com/colmap/colmap/pull/1165,The dependencies to Qt and the GUI build are now conditional on the new GUI_ENABLED option.,The dependencies to Qt and the GUI build are now conditional on the new GUI_ENABLED option.,True,{}
colmap/colmap,https://github.com/colmap/colmap,1165,2021-03-08T23:53:45Z,2021-03-12T09:24:41Z,2021-03-12T14:50:38Z,MERGED,True,140,34,14,https://github.com/anmatako,Add new CMake option to disable GUI,16,[],https://github.com/colmap/colmap/pull/1165,https://github.com/anmatako,2,https://github.com/colmap/colmap/pull/1165#issuecomment-793363190,The dependencies to Qt and the GUI build are now conditional on the new GUI_ENABLED option.,"@ahojnnes Seems to me that with the current colmap setup, OpenGL and Qt are intertwined so when disabling the GUI and skipping Qt we cannot really use OpenGL as well. Is this understanding accurate?
I can see a case of problematic behavior with my changes when we build without GUI support and without CUDA as well. This is the case where kUseOpenGL becomes true and the underlying Qt classes are stubbed out so things would fail.
What would be the best way to handle that? It seems to only affect feature extraction and matching that can use GPU either from CUDA or OpenGL. My idea would be to simply check the use_gpu option and ensure it's always false when both GUI_ENABLED and CUDA_ENABLED are undefined. This would force Sift to use cpu for extraction and matching which would not cause any kind of failure.",True,{}
colmap/colmap,https://github.com/colmap/colmap,1165,2021-03-08T23:53:45Z,2021-03-12T09:24:41Z,2021-03-12T14:50:38Z,MERGED,True,140,34,14,https://github.com/anmatako,Add new CMake option to disable GUI,16,[],https://github.com/colmap/colmap/pull/1165,https://github.com/whuaegeanse,3,https://github.com/colmap/colmap/pull/1165#issuecomment-794003970,The dependencies to Qt and the GUI build are now conditional on the new GUI_ENABLED option.,"@anmatako
At least two Qt related codes need to be changed. The first is the code related to SiftGPU. The second place is the code related to IncrementalMapperOptions.",True,{}
colmap/colmap,https://github.com/colmap/colmap,1165,2021-03-08T23:53:45Z,2021-03-12T09:24:41Z,2021-03-12T14:50:38Z,MERGED,True,140,34,14,https://github.com/anmatako,Add new CMake option to disable GUI,16,[],https://github.com/colmap/colmap/pull/1165,https://github.com/anmatako,4,https://github.com/colmap/colmap/pull/1165#issuecomment-794181224,The dependencies to Qt and the GUI build are now conditional on the new GUI_ENABLED option.,"@anmatako
At least two Qt related codes need to be changed. The first is the code related to SiftGPU. The second place is the code related to IncrementalMapperOptions.

@whuaegeanse The mapper options you linked are forward declarations and when the GUI is disabled the ""ui"" folder is excluded form the sources so they are never actually used. So, I don't think there's a need to add any special handling for them.
However, I do plan to make some additional changes to better handle the feature matching and extraction when both GUI and CUDA are disabled.",True,{}
colmap/colmap,https://github.com/colmap/colmap,1165,2021-03-08T23:53:45Z,2021-03-12T09:24:41Z,2021-03-12T14:50:38Z,MERGED,True,140,34,14,https://github.com/anmatako,Add new CMake option to disable GUI,16,[],https://github.com/colmap/colmap/pull/1165,https://github.com/anmatako,5,https://github.com/colmap/colmap/pull/1165#issuecomment-794275122,The dependencies to Qt and the GUI build are now conditional on the new GUI_ENABLED option.,Latest update now handles the case of both CUDA and OpenGL missing when attempting to use Sift GPU. In this case there is an error and EXIT_FAILURE with a message to disable the use_gpu option.,True,{}
colmap/colmap,https://github.com/colmap/colmap,1165,2021-03-08T23:53:45Z,2021-03-12T09:24:41Z,2021-03-12T14:50:38Z,MERGED,True,140,34,14,https://github.com/anmatako,Add new CMake option to disable GUI,16,[],https://github.com/colmap/colmap/pull/1165,https://github.com/whuaegeanse,6,https://github.com/colmap/colmap/pull/1165#issuecomment-794720579,The dependencies to Qt and the GUI build are now conditional on the new GUI_ENABLED option.,"@anmatako @ahojnnes Consider using SIFTGPU's original opengl-related code, which has nothing to do with Qt. In this way, we can use opengl to accelerate feature extraction and feature matching without relying on Qt.I have done relevant experiments and the results are very good, and I am happy to submit relevant code for SIFTGPU that does not rely on Qt.",True,{}
colmap/colmap,https://github.com/colmap/colmap,1165,2021-03-08T23:53:45Z,2021-03-12T09:24:41Z,2021-03-12T14:50:38Z,MERGED,True,140,34,14,https://github.com/anmatako,Add new CMake option to disable GUI,16,[],https://github.com/colmap/colmap/pull/1165,https://github.com/anmatako,7,https://github.com/colmap/colmap/pull/1165#issuecomment-794844330,The dependencies to Qt and the GUI build are now conditional on the new GUI_ENABLED option.,"@anmatako @ahojnnes Consider using SIFTGPU's original opengl-related code, which has nothing to do with Qt. In this way, we can use opengl to accelerate feature extraction and feature matching without relying on Qt.I have done relevant experiments and the results are very good, and I am happy to submit relevant code for SIFTGPU that does not rely on Qt.

@whuaegeanse I don't think the problem in this case is the implementation of Sift GPU that colmap is using. If I understand correctly, colmap uses the default implementation you are linking and it does indeed depend on OpenGL and builds with it. The problem as I see it is with colmap's use of OpenGL that only happens through Qt and thus is tied to the GUI. So, when I'm disabling the GUI I am also (as a side-effect) removing the ability to use OpenGL as well.
There should be a way to decouple OpenGL from Qt in colmap, but such a change goes beyond the scope of this PR. My intent here is much simpler and along the lines of:
""I don't want the colmap GUI and I accept that this also means that OpenGL will be unavailable as well"".
Of course the behavior of disabling the GUI needs to be properly documented, so I'm open to suggestions as to where would be the best place to add such a note.
@ahojnnes please correct me if my understanding of this issue is incorrect.",True,{}
colmap/colmap,https://github.com/colmap/colmap,1165,2021-03-08T23:53:45Z,2021-03-12T09:24:41Z,2021-03-12T14:50:38Z,MERGED,True,140,34,14,https://github.com/anmatako,Add new CMake option to disable GUI,16,[],https://github.com/colmap/colmap/pull/1165,https://github.com/whuaegeanse,8,https://github.com/colmap/colmap/pull/1165#issuecomment-794989778,The dependencies to Qt and the GUI build are now conditional on the new GUI_ENABLED option.,"@anmatako You are right, after disabling Qt, feature extraction and feature matching that rely on opengl will not be available.
But disabling Qt should not affect the use of feature extraction and feature matching, because the original version of SIFTGPU has nothing to do with related interface libraries such as Qt. Therefore, we should provide an OpenGLContextManager that does not rely on Qt.",True,{}
colmap/colmap,https://github.com/colmap/colmap,1165,2021-03-08T23:53:45Z,2021-03-12T09:24:41Z,2021-03-12T14:50:38Z,MERGED,True,140,34,14,https://github.com/anmatako,Add new CMake option to disable GUI,16,[],https://github.com/colmap/colmap/pull/1165,https://github.com/anmatako,9,https://github.com/colmap/colmap/pull/1165#issuecomment-795698027,The dependencies to Qt and the GUI build are now conditional on the new GUI_ENABLED option.,"@whuaegeanse I agree with you that it should be possible to implement a context manager that does not rely on Qt, but that should be a separate issue and PR.",True,{'THUMBS_UP': ['https://github.com/ahojnnes']}
colmap/colmap,https://github.com/colmap/colmap,1166,2021-03-09T15:36:34Z,,2022-01-26T12:22:15Z,OPEN,False,91,1,5,https://github.com/DaniilSNikulin,Issue 1033 prior intrinsic for multiple cameras,3,[],https://github.com/colmap/colmap/pull/1166,https://github.com/DaniilSNikulin,1,https://github.com/colmap/colmap/pull/1166,"fixes #1033
Extended functionality by allowing users to specify a prior intrinsics for multiple cameras.
Also extended documentation for new functionality.
API was changed, but saved backward compatibility.
Code was hand tested,  but unit tests are not exists. I don't now how create tests for CLI module.","fixes #1033
Extended functionality by allowing users to specify a prior intrinsics for multiple cameras.
Also extended documentation for new functionality.
API was changed, but saved backward compatibility.
Code was hand tested,  but unit tests are not exists. I don't now how create tests for CLI module.",True,{'THUMBS_UP': ['https://github.com/ishipachev']}
colmap/colmap,https://github.com/colmap/colmap,1167,2021-03-09T20:07:40Z,,2022-01-26T12:22:15Z,OPEN,False,457,275,3,https://github.com/anmatako,Add new auto_mapper command,11,[],https://github.com/colmap/colmap/pull/1167,https://github.com/anmatako,1,https://github.com/colmap/colmap/pull/1167,"The new auto_mapper command is a convenience command that combines mapper, triangulator, and bundle adjuster as needed based on the provided options. It can do the following:

Standard mapper with optional point triangulator and rig BA if a rig config path is provided
Hierarchical mapper followed by point triangulator and rig or standard BA
Read existing reconstruction followed by point triangulator and rig or standard BA

Also, added new option skip_color_extraction in both auto_mapper and point_triangulator that avoids the call to Reconstruction::ExtractColorsForAllImages after triangulation since that's a pretty slow part of the process (single-threaded only) and is not necessary when we don't care about colors of the sparse point clouds","The new auto_mapper command is a convenience command that combines mapper, triangulator, and bundle adjuster as needed based on the provided options. It can do the following:

Standard mapper with optional point triangulator and rig BA if a rig config path is provided
Hierarchical mapper followed by point triangulator and rig or standard BA
Read existing reconstruction followed by point triangulator and rig or standard BA

Also, added new option skip_color_extraction in both auto_mapper and point_triangulator that avoids the call to Reconstruction::ExtractColorsForAllImages after triangulation since that's a pretty slow part of the process (single-threaded only) and is not necessary when we don't care about colors of the sparse point clouds",True,{}
colmap/colmap,https://github.com/colmap/colmap,1167,2021-03-09T20:07:40Z,,2022-01-26T12:22:15Z,OPEN,False,457,275,3,https://github.com/anmatako,Add new auto_mapper command,11,[],https://github.com/colmap/colmap/pull/1167,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/1167#issuecomment-794541828,"The new auto_mapper command is a convenience command that combines mapper, triangulator, and bundle adjuster as needed based on the provided options. It can do the following:

Standard mapper with optional point triangulator and rig BA if a rig config path is provided
Hierarchical mapper followed by point triangulator and rig or standard BA
Read existing reconstruction followed by point triangulator and rig or standard BA

Also, added new option skip_color_extraction in both auto_mapper and point_triangulator that avoids the call to Reconstruction::ExtractColorsForAllImages after triangulation since that's a pretty slow part of the process (single-threaded only) and is not necessary when we don't care about colors of the sparse point clouds","I like the skip_color_extraction but I am not 100% sure about the logic in the auto_mapper command to be honest. I don't want to encourage people to rely too much on the hierarchical_mapper, which will not work too well when the input consists of internet images, etc.",True,{}
colmap/colmap,https://github.com/colmap/colmap,1167,2021-03-09T20:07:40Z,,2022-01-26T12:22:15Z,OPEN,False,457,275,3,https://github.com/anmatako,Add new auto_mapper command,11,[],https://github.com/colmap/colmap/pull/1167,https://github.com/anmatako,3,https://github.com/colmap/colmap/pull/1167#issuecomment-794711257,"The new auto_mapper command is a convenience command that combines mapper, triangulator, and bundle adjuster as needed based on the provided options. It can do the following:

Standard mapper with optional point triangulator and rig BA if a rig config path is provided
Hierarchical mapper followed by point triangulator and rig or standard BA
Read existing reconstruction followed by point triangulator and rig or standard BA

Also, added new option skip_color_extraction in both auto_mapper and point_triangulator that avoids the call to Reconstruction::ExtractColorsForAllImages after triangulation since that's a pretty slow part of the process (single-threaded only) and is not necessary when we don't care about colors of the sparse point clouds","I like the skip_color_extraction but I am not 100% sure about the logic in the auto_mapper command to be honest. I don't want to encourage people to rely too much on the hierarchical_mapper, which will not work too well when the input consists of internet images, etc.

I can see the concern about relying too much on auto_mapper. Has worked well enough for me so far since our datasets are more cohesive, but that may not generalize well enough to be broadly used.
I can leave the refactoring and the new skip_color_extraction for point triangulator and remove the auto_mapper command from this PR. Another alternative would be to make the default hierarchical mapper threshold really high (for the auto_mapper command only) to prevent accidental usage, such that auto_mapper would default to mapper unless options are explicitly set to enable the hierarchical_mapper.
Either approach is fine by me.",True,{}
colmap/colmap,https://github.com/colmap/colmap,1168,2021-03-09T20:23:16Z,2021-03-10T22:56:49Z,2021-03-10T23:01:39Z,MERGED,True,162,48,6,https://github.com/anmatako,Add new functionality in image_undistorter,9,[],https://github.com/colmap/colmap/pull/1168,https://github.com/anmatako,1,https://github.com/colmap/colmap/pull/1168,"Extending the functionality of image_undistorter to support the following:

We can now set the number of related images in the MVS workspace for patch-match through the new num_related_images option instead of always using the default of 20.
We can optionally provide a text files with the image names we want included in the MVS problem through the new input_images option instead of always using all the registered images from the sparse model.
We can avoid undistortion and replace it with a simple copy or linking of images when the images are already undistorted and we are not resizing them. The choice of copy or linking is controlled by the new copy_policy option.
The undistorter now checks the status of each image undistortion task and only writes out the setup for the images that were successfully undistorted.","Extending the functionality of image_undistorter to support the following:

We can now set the number of related images in the MVS workspace for patch-match through the new num_related_images option instead of always using the default of 20.
We can optionally provide a text files with the image names we want included in the MVS problem through the new input_images option instead of always using all the registered images from the sparse model.
We can avoid undistortion and replace it with a simple copy or linking of images when the images are already undistorted and we are not resizing them. The choice of copy or linking is controlled by the new copy_policy option.
The undistorter now checks the status of each image undistortion task and only writes out the setup for the images that were successfully undistorted.",True,{}
colmap/colmap,https://github.com/colmap/colmap,1169,2021-03-09T20:42:15Z,2021-03-10T22:21:11Z,2021-03-10T22:23:51Z,MERGED,True,295,144,3,https://github.com/anmatako,Refactoring and new functionality in Reconstruction class,11,[],https://github.com/colmap/colmap/pull/1169,https://github.com/anmatako,1,https://github.com/colmap/colmap/pull/1169,"New functionality:

ComputeBoundsAndCentroid: Computes the bounding box (two corner points) of the reconstruction and the 3D point centroid based on the min and max percentiles. Similarly to how Normalize works.
ComputeCentroid: Computes the centroid based on the min and max percentiles.
ComputeBoundingBox: Computes the bounding box as two corner points based on the min and max percentiles.
Crop: Crops the reconstruction based on the given bounding box. It does not modify the current reconstruction; the cropped result is an output by reference instead. The output reconstruction only includes the 3D points within the bounding box. It includes all images and cameras of the original reconstruction, but only the images that see 3D points inside the bounding box are registered.

Modified functionality:

Normalize: Works same as before but now leverages the new ComputeBoundsAndCentroid function.
Align and AlignRobust: These are now templated on a bool flag that determines whether or not the scale is estimated when estimating the similarity transform. Also they can export the transform used in alignment since it's now provided as input by reference.","New functionality:

ComputeBoundsAndCentroid: Computes the bounding box (two corner points) of the reconstruction and the 3D point centroid based on the min and max percentiles. Similarly to how Normalize works.
ComputeCentroid: Computes the centroid based on the min and max percentiles.
ComputeBoundingBox: Computes the bounding box as two corner points based on the min and max percentiles.
Crop: Crops the reconstruction based on the given bounding box. It does not modify the current reconstruction; the cropped result is an output by reference instead. The output reconstruction only includes the 3D points within the bounding box. It includes all images and cameras of the original reconstruction, but only the images that see 3D points inside the bounding box are registered.

Modified functionality:

Normalize: Works same as before but now leverages the new ComputeBoundsAndCentroid function.
Align and AlignRobust: These are now templated on a bool flag that determines whether or not the scale is estimated when estimating the similarity transform. Also they can export the transform used in alignment since it's now provided as input by reference.",True,{}
colmap/colmap,https://github.com/colmap/colmap,1169,2021-03-09T20:42:15Z,2021-03-10T22:21:11Z,2021-03-10T22:23:51Z,MERGED,True,295,144,3,https://github.com/anmatako,Refactoring and new functionality in Reconstruction class,11,[],https://github.com/colmap/colmap/pull/1169,https://github.com/anmatako,2,https://github.com/colmap/colmap/pull/1169#issuecomment-794428339,"New functionality:

ComputeBoundsAndCentroid: Computes the bounding box (two corner points) of the reconstruction and the 3D point centroid based on the min and max percentiles. Similarly to how Normalize works.
ComputeCentroid: Computes the centroid based on the min and max percentiles.
ComputeBoundingBox: Computes the bounding box as two corner points based on the min and max percentiles.
Crop: Crops the reconstruction based on the given bounding box. It does not modify the current reconstruction; the cropped result is an output by reference instead. The output reconstruction only includes the 3D points within the bounding box. It includes all images and cameras of the original reconstruction, but only the images that see 3D points inside the bounding box are registered.

Modified functionality:

Normalize: Works same as before but now leverages the new ComputeBoundsAndCentroid function.
Align and AlignRobust: These are now templated on a bool flag that determines whether or not the scale is estimated when estimating the similarity transform. Also they can export the transform used in alignment since it's now provided as input by reference.",This new functionality is leveraged in additional model manipulation commands that will be part of subsequent PR.,True,{}
colmap/colmap,https://github.com/colmap/colmap,1169,2021-03-09T20:42:15Z,2021-03-10T22:21:11Z,2021-03-10T22:23:51Z,MERGED,True,295,144,3,https://github.com/anmatako,Refactoring and new functionality in Reconstruction class,11,[],https://github.com/colmap/colmap/pull/1169,https://github.com/anmatako,3,https://github.com/colmap/colmap/pull/1169#issuecomment-794633906,"New functionality:

ComputeBoundsAndCentroid: Computes the bounding box (two corner points) of the reconstruction and the 3D point centroid based on the min and max percentiles. Similarly to how Normalize works.
ComputeCentroid: Computes the centroid based on the min and max percentiles.
ComputeBoundingBox: Computes the bounding box as two corner points based on the min and max percentiles.
Crop: Crops the reconstruction based on the given bounding box. It does not modify the current reconstruction; the cropped result is an output by reference instead. The output reconstruction only includes the 3D points within the bounding box. It includes all images and cameras of the original reconstruction, but only the images that see 3D points inside the bounding box are registered.

Modified functionality:

Normalize: Works same as before but now leverages the new ComputeBoundsAndCentroid function.
Align and AlignRobust: These are now templated on a bool flag that determines whether or not the scale is estimated when estimating the similarity transform. Also they can export the transform used in alignment since it's now provided as input by reference.",I'll add some unit tests for the new functionality in the next update and it should be good then.,True,{}
colmap/colmap,https://github.com/colmap/colmap,1170,2021-03-10T02:07:49Z,2021-03-12T14:25:43Z,2021-03-12T14:25:45Z,MERGED,True,7,25,3,https://github.com/whuaegeanse,Fix the memory leak caused by not releasing the memory of the PRNG at the end of the thread,18,[],https://github.com/colmap/colmap/pull/1170,https://github.com/whuaegeanse,1,https://github.com/colmap/colmap/pull/1170,Fix the memory leak caused by not releasing the memory of the PRNG at the end of the thread as mentioned by #1161.,Fix the memory leak caused by not releasing the memory of the PRNG at the end of the thread as mentioned by #1161.,True,{}
colmap/colmap,https://github.com/colmap/colmap,1170,2021-03-10T02:07:49Z,2021-03-12T14:25:43Z,2021-03-12T14:25:45Z,MERGED,True,7,25,3,https://github.com/whuaegeanse,Fix the memory leak caused by not releasing the memory of the PRNG at the end of the thread,18,[],https://github.com/colmap/colmap/pull/1170,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/1170#issuecomment-796197599,Fix the memory leak caused by not releasing the memory of the PRNG at the end of the thread as mentioned by #1161.,Thank you for this fix. I think there is a way to avoid the compiler errors. Please have a look at: whuaegeanse#1. Let's see what the CI build does but we can safely drop support for older versions of GCC and other compilers at this point. Several years have passed since I originally wrote this code.,True,{'THUMBS_UP': ['https://github.com/whuaegeanse']}
colmap/colmap,https://github.com/colmap/colmap,1170,2021-03-10T02:07:49Z,2021-03-12T14:25:43Z,2021-03-12T14:25:45Z,MERGED,True,7,25,3,https://github.com/whuaegeanse,Fix the memory leak caused by not releasing the memory of the PRNG at the end of the thread,18,[],https://github.com/colmap/colmap/pull/1170,https://github.com/whuaegeanse,3,https://github.com/colmap/colmap/pull/1170#issuecomment-796435440,Fix the memory leak caused by not releasing the memory of the PRNG at the end of the thread as mentioned by #1161.,"@ahojnnes  There seems to be no problem. But I have another question, does the extern variable PRNG need to be initialized to nullptr? There seems to be an implicit conversion and copy construction. Is there a certain overhead?",True,{}
colmap/colmap,https://github.com/colmap/colmap,1170,2021-03-10T02:07:49Z,2021-03-12T14:25:43Z,2021-03-12T14:25:45Z,MERGED,True,7,25,3,https://github.com/whuaegeanse,Fix the memory leak caused by not releasing the memory of the PRNG at the end of the thread,18,[],https://github.com/colmap/colmap/pull/1170,https://github.com/ahojnnes,4,https://github.com/colmap/colmap/pull/1170#issuecomment-796697930,Fix the memory leak caused by not releasing the memory of the PRNG at the end of the thread as mentioned by #1161.,"No, indeed, there is no need to initialize to the nullptr. We can drop it. Thanks.",True,{}
colmap/colmap,https://github.com/colmap/colmap,1176,2021-03-12T15:39:05Z,2021-03-13T11:20:05Z,2021-03-13T15:38:17Z,MERGED,True,0,1,1,https://github.com/anmatako,Fix fusion segfault bug,5,[],https://github.com/colmap/colmap/pull/1176,https://github.com/anmatako,1,https://github.com/colmap/colmap/pull/1176,Merge was incorrect and resulting in re-initialization of workspace with empty components. Removed the offending code and tested both parallel and single-thread fusion.,Merge was incorrect and resulting in re-initialization of workspace with empty components. Removed the offending code and tested both parallel and single-thread fusion.,True,{}
colmap/colmap,https://github.com/colmap/colmap,1177,2021-03-14T20:52:40Z,2021-03-30T08:48:14Z,2021-03-30T14:55:27Z,MERGED,True,302,30,6,https://github.com/anmatako,Update model_aligner functionality,12,[],https://github.com/colmap/colmap/pull/1177,https://github.com/anmatako,1,https://github.com/colmap/colmap/pull/1177,"model_aligner has been extended with the following additional functionality:

Can use either an image list (existing method) or the location priors from the database (new functionality) for alignment. Using the new database_path option will use the database instead of an image list
Can optionally skip the scale estimation during alignment. This is controlled by the new estimate_scale flag.
Can optionally export the alignment transform in a text file as a 4x4 row-major matrix. This is enabled by providing a valid path for the output transform file through the new transform_path option.
Can perform 5 types of alignment: ""plane"", ""ecef"", ""enu"", ""enu-unscaled"", and ""custom"".

The different alignment types work as:

custom: This is the same as the existing method where the image locations are used as-is for alignment
plane: This does not use any reference images. It simply aligns the model to the principal plane of the 3D points (estimated with SVD), such that the x-y plane aligns with the principal plane
ecef: This mode assumes that the image locations (from file or database) are provided as GPS Lat/Lon/Alt coordinates (WGS84) and then converts them to the ECEF coordinate systems and aligns the model. This results in a model with global orientation expressed in physical units (meters).
enu: This mode also assumes that the image locations are provided as GPS coordinates. It aligns the model with the true ENU ground plane at the model's 3D points centroid, such that x points East, y points North, and z points Up. The model scale is in physical units (meters).
enu-unscaled: Does the same alignment as the ""enu"" mode with the only difference that the model's original scale is preserved. This is useful for model display or to avoid numerical instabilities for large extent models.","model_aligner has been extended with the following additional functionality:

Can use either an image list (existing method) or the location priors from the database (new functionality) for alignment. Using the new database_path option will use the database instead of an image list
Can optionally skip the scale estimation during alignment. This is controlled by the new estimate_scale flag.
Can optionally export the alignment transform in a text file as a 4x4 row-major matrix. This is enabled by providing a valid path for the output transform file through the new transform_path option.
Can perform 5 types of alignment: ""plane"", ""ecef"", ""enu"", ""enu-unscaled"", and ""custom"".

The different alignment types work as:

custom: This is the same as the existing method where the image locations are used as-is for alignment
plane: This does not use any reference images. It simply aligns the model to the principal plane of the 3D points (estimated with SVD), such that the x-y plane aligns with the principal plane
ecef: This mode assumes that the image locations (from file or database) are provided as GPS Lat/Lon/Alt coordinates (WGS84) and then converts them to the ECEF coordinate systems and aligns the model. This results in a model with global orientation expressed in physical units (meters).
enu: This mode also assumes that the image locations are provided as GPS coordinates. It aligns the model with the true ENU ground plane at the model's 3D points centroid, such that x points East, y points North, and z points Up. The model scale is in physical units (meters).
enu-unscaled: Does the same alignment as the ""enu"" mode with the only difference that the model's original scale is preserved. This is useful for model display or to avoid numerical instabilities for large extent models.",True,{}
colmap/colmap,https://github.com/colmap/colmap,1177,2021-03-14T20:52:40Z,2021-03-30T08:48:14Z,2021-03-30T14:55:27Z,MERGED,True,302,30,6,https://github.com/anmatako,Update model_aligner functionality,12,[],https://github.com/colmap/colmap/pull/1177,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/1177#issuecomment-810023454,"model_aligner has been extended with the following additional functionality:

Can use either an image list (existing method) or the location priors from the database (new functionality) for alignment. Using the new database_path option will use the database instead of an image list
Can optionally skip the scale estimation during alignment. This is controlled by the new estimate_scale flag.
Can optionally export the alignment transform in a text file as a 4x4 row-major matrix. This is enabled by providing a valid path for the output transform file through the new transform_path option.
Can perform 5 types of alignment: ""plane"", ""ecef"", ""enu"", ""enu-unscaled"", and ""custom"".

The different alignment types work as:

custom: This is the same as the existing method where the image locations are used as-is for alignment
plane: This does not use any reference images. It simply aligns the model to the principal plane of the 3D points (estimated with SVD), such that the x-y plane aligns with the principal plane
ecef: This mode assumes that the image locations (from file or database) are provided as GPS Lat/Lon/Alt coordinates (WGS84) and then converts them to the ECEF coordinate systems and aligns the model. This results in a model with global orientation expressed in physical units (meters).
enu: This mode also assumes that the image locations are provided as GPS coordinates. It aligns the model with the true ENU ground plane at the model's 3D points centroid, such that x points East, y points North, and z points Up. The model scale is in physical units (meters).
enu-unscaled: Does the same alignment as the ""enu"" mode with the only difference that the model's original scale is preserved. This is useful for model display or to avoid numerical instabilities for large extent models.","Thanks Antonios for the fixes, LGTM.",True,{}
colmap/colmap,https://github.com/colmap/colmap,1178,2021-03-14T21:02:20Z,2021-04-08T16:01:39Z,2021-04-08T16:05:57Z,MERGED,True,50,0,3,https://github.com/anmatako,Add new model_transformer command,15,[],https://github.com/colmap/colmap/pull/1178,https://github.com/anmatako,1,https://github.com/colmap/colmap/pull/1178,The new command reads a sparse or dense model and a similarity transform from file and then writes the transformed model in the same format.,The new command reads a sparse or dense model and a similarity transform from file and then writes the transformed model in the same format.,True,{}
colmap/colmap,https://github.com/colmap/colmap,1178,2021-03-14T21:02:20Z,2021-04-08T16:01:39Z,2021-04-08T16:05:57Z,MERGED,True,50,0,3,https://github.com/anmatako,Add new model_transformer command,15,[],https://github.com/colmap/colmap/pull/1178,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/1178#issuecomment-813010818,The new command reads a sparse or dense model and a similarity transform from file and then writes the transformed model in the same format.,This will need a merge with master. Thanks.,True,{}
colmap/colmap,https://github.com/colmap/colmap,1179,2021-03-14T22:34:21Z,2021-04-04T10:38:07Z,2021-04-04T15:45:02Z,MERGED,True,379,5,8,https://github.com/anmatako,Add new model_cropper and model_splitter commands,13,[],https://github.com/colmap/colmap/pull/1179,https://github.com/anmatako,1,https://github.com/colmap/colmap/pull/1179,"model_cropping: Reads model from input_path, crops using the values provided in boundary and writes cropped model in output_path. It can support GPS coordinates (WGS84 lat/lon/alt) in the boundary descriptor if the model transform to ECEF is provided in the gps_transform_path option. The boundary option should be in one of two formats:

x1,y1,z1,x2,y2,z2: 6 boundary coordinates defining the corner points of the bounding box. Either in model coordinates or GPS coordinates if the gps_transform_path is provided.
p0,p1: 2 percentiles (min, max) of the 3D points extent, similarly to how percentiles are used in Reconstruction::Normalize

model_splitter: Reads model from input_path, splits the model in parts according to the split_type and split_params options, and writes the model parts as sub-folders in output_path. The valid options for splitting are:

split_type=""parts"", split_params=""n1,n2,n3"": Splits the model in n1*n2*n3 equal parts, each with extent ex/n1, ey/n2, yz/n3.
split_type=""extent"", split_params=""ex,ey,ez"": Splits the model in equal parts such that the extent of each part does not exceed (ex, ey, ez) in the (x, y, z) axes respectively, e.g. for a model with extent (11, 12, 4) using split_params=""5,5,5"" will lead in a split of 9 parts, each with extent of (3.3333, 4, 4). The extent can be expressed in physical units (meters) if the gps_transform_path is provided.
split_type=""tiles"", split_params=""<path to tiles_text_file>"": Splits the model according to the entries in tiles_text_file; this file contains entries (one per line) of the form: TILE_KEY X1 Y1 Z1 X2 Y2 Z2, where TILE_KEY is used as a name for the subfolder where the output is stored and the 6 coordinates that follow specify the bounding box for cropping. The coordinates can be in model units or GPS coordinates if gps_transform_path is provided.

Additional options can be used to:

Reject models from the output based on number of registered images (min_reg_images), the number of 3D points (min_num_points) and the proportion of output area covered by the model (min_area_ratio).
Create overlap between the output parts (overlap_ratio) expressed as a percentage of the extent.","model_cropping: Reads model from input_path, crops using the values provided in boundary and writes cropped model in output_path. It can support GPS coordinates (WGS84 lat/lon/alt) in the boundary descriptor if the model transform to ECEF is provided in the gps_transform_path option. The boundary option should be in one of two formats:

x1,y1,z1,x2,y2,z2: 6 boundary coordinates defining the corner points of the bounding box. Either in model coordinates or GPS coordinates if the gps_transform_path is provided.
p0,p1: 2 percentiles (min, max) of the 3D points extent, similarly to how percentiles are used in Reconstruction::Normalize

model_splitter: Reads model from input_path, splits the model in parts according to the split_type and split_params options, and writes the model parts as sub-folders in output_path. The valid options for splitting are:

split_type=""parts"", split_params=""n1,n2,n3"": Splits the model in n1*n2*n3 equal parts, each with extent ex/n1, ey/n2, yz/n3.
split_type=""extent"", split_params=""ex,ey,ez"": Splits the model in equal parts such that the extent of each part does not exceed (ex, ey, ez) in the (x, y, z) axes respectively, e.g. for a model with extent (11, 12, 4) using split_params=""5,5,5"" will lead in a split of 9 parts, each with extent of (3.3333, 4, 4). The extent can be expressed in physical units (meters) if the gps_transform_path is provided.
split_type=""tiles"", split_params=""<path to tiles_text_file>"": Splits the model according to the entries in tiles_text_file; this file contains entries (one per line) of the form: TILE_KEY X1 Y1 Z1 X2 Y2 Z2, where TILE_KEY is used as a name for the subfolder where the output is stored and the 6 coordinates that follow specify the bounding box for cropping. The coordinates can be in model units or GPS coordinates if gps_transform_path is provided.

Additional options can be used to:

Reject models from the output based on number of registered images (min_reg_images), the number of 3D points (min_num_points) and the proportion of output area covered by the model (min_area_ratio).
Create overlap between the output parts (overlap_ratio) expressed as a percentage of the extent.",True,{}
colmap/colmap,https://github.com/colmap/colmap,1179,2021-03-14T22:34:21Z,2021-04-04T10:38:07Z,2021-04-04T15:45:02Z,MERGED,True,379,5,8,https://github.com/anmatako,Add new model_cropper and model_splitter commands,13,[],https://github.com/colmap/colmap/pull/1179,https://github.com/anmatako,2,https://github.com/colmap/colmap/pull/1179#issuecomment-802151003,"model_cropping: Reads model from input_path, crops using the values provided in boundary and writes cropped model in output_path. It can support GPS coordinates (WGS84 lat/lon/alt) in the boundary descriptor if the model transform to ECEF is provided in the gps_transform_path option. The boundary option should be in one of two formats:

x1,y1,z1,x2,y2,z2: 6 boundary coordinates defining the corner points of the bounding box. Either in model coordinates or GPS coordinates if the gps_transform_path is provided.
p0,p1: 2 percentiles (min, max) of the 3D points extent, similarly to how percentiles are used in Reconstruction::Normalize

model_splitter: Reads model from input_path, splits the model in parts according to the split_type and split_params options, and writes the model parts as sub-folders in output_path. The valid options for splitting are:

split_type=""parts"", split_params=""n1,n2,n3"": Splits the model in n1*n2*n3 equal parts, each with extent ex/n1, ey/n2, yz/n3.
split_type=""extent"", split_params=""ex,ey,ez"": Splits the model in equal parts such that the extent of each part does not exceed (ex, ey, ez) in the (x, y, z) axes respectively, e.g. for a model with extent (11, 12, 4) using split_params=""5,5,5"" will lead in a split of 9 parts, each with extent of (3.3333, 4, 4). The extent can be expressed in physical units (meters) if the gps_transform_path is provided.
split_type=""tiles"", split_params=""<path to tiles_text_file>"": Splits the model according to the entries in tiles_text_file; this file contains entries (one per line) of the form: TILE_KEY X1 Y1 Z1 X2 Y2 Z2, where TILE_KEY is used as a name for the subfolder where the output is stored and the 6 coordinates that follow specify the bounding box for cropping. The coordinates can be in model units or GPS coordinates if gps_transform_path is provided.

Additional options can be used to:

Reject models from the output based on number of registered images (min_reg_images), the number of 3D points (min_num_points) and the proportion of output area covered by the model (min_area_ratio).
Create overlap between the output parts (overlap_ratio) expressed as a percentage of the extent.","It will be good to document new commands here as all: https://colmap.github.io/cli.html#commands.

Yes I'll make sure to add them there for better reference. Also where is a good place to add example usage for the new commands and the ones I'm extending?",True,{}
colmap/colmap,https://github.com/colmap/colmap,1182,2021-03-18T20:32:35Z,2021-03-19T06:40:00Z,2021-03-19T15:35:44Z,MERGED,True,18,18,1,https://github.com/anmatako,Update SiftGPU to use floorf for floats,1,[],https://github.com/colmap/colmap/pull/1182,https://github.com/anmatako,1,https://github.com/colmap/colmap/pull/1182,"With the latest MSVC update the build breaks on Windows with this error:
error: calling a __host__ function(""__floorf"") from a __global__ function(...) is not allowed
This happens due to the use of floor reverting to a host function for float arguments, whereas the correct usage of floorf is calling a device function.","With the latest MSVC update the build breaks on Windows with this error:
error: calling a __host__ function(""__floorf"") from a __global__ function(...) is not allowed
This happens due to the use of floor reverting to a host function for float arguments, whereas the correct usage of floorf is calling a device function.",True,{}
colmap/colmap,https://github.com/colmap/colmap,1187,2021-03-24T18:23:58Z,2021-03-27T15:54:23Z,2021-03-27T15:54:23Z,MERGED,True,39,20,1,https://github.com/drkoller,"Improvements to NVM, Cam, Recon3D, and Bundler exporters",3,[],https://github.com/colmap/colmap/pull/1187,https://github.com/drkoller,1,https://github.com/colmap/colmap/pull/1187,"This PR improves the code for some of the model_converter export formats:

Fix bugs introduced in PR #1147 affecting the export of Cam and Recon3D formats
Add support for non-square pixels to the Cam format exporter
Consistently support pinhole camera models for NVM, Cam, Recon3D, and Bundler exporters","This PR improves the code for some of the model_converter export formats:

Fix bugs introduced in PR #1147 affecting the export of Cam and Recon3D formats
Add support for non-square pixels to the Cam format exporter
Consistently support pinhole camera models for NVM, Cam, Recon3D, and Bundler exporters",True,{}
colmap/colmap,https://github.com/colmap/colmap,1191,2021-03-26T06:30:47Z,2021-03-26T20:57:02Z,2021-03-26T20:57:03Z,MERGED,True,1,1,1,https://github.com/iuk,fix typo in extraction.cc,1,[],https://github.com/colmap/colmap/pull/1191,https://github.com/iuk,1,https://github.com/colmap/colmap/pull/1191,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,1193,2021-03-31T16:52:45Z,2021-04-01T02:20:47Z,2021-04-01T02:20:47Z,CLOSED,False,4,2,1,https://github.com/whuaegeanse,Fix the problem that the build.py script cannot download the eigen library,21,[],https://github.com/colmap/colmap/pull/1193,https://github.com/whuaegeanse,1,https://github.com/colmap/colmap/pull/1193,"urllib.request.urlretrieve cannot download eigen from gitlab as mentioned in  #973 .
This pull request solves this problem by using the requests library, but you need to install a third-party library requests in python 3 .
Before run build.py script, install requests by pip($ python -m pip install requests).
Installing Requests","urllib.request.urlretrieve cannot download eigen from gitlab as mentioned in  #973 .
This pull request solves this problem by using the requests library, but you need to install a third-party library requests in python 3 .
Before run build.py script, install requests by pip($ python -m pip install requests).
Installing Requests",True,{}
colmap/colmap,https://github.com/colmap/colmap,1194,2021-04-01T02:24:44Z,2021-04-10T11:48:16Z,2021-04-10T15:56:22Z,MERGED,True,4,2,1,https://github.com/whuaegeanse,Fix error of using urllib to download eigen from gitlab,2,[],https://github.com/colmap/colmap/pull/1194,https://github.com/whuaegeanse,1,https://github.com/colmap/colmap/pull/1194,"urllib.request.urlretrieve cannot download eigen from gitlab as mentioned in #973 .
This pull request solves this problem by using the requests library, but you need to install a third-party library requests in python 3 .
Before run build.py script, install requests by pip($ python -m pip install requests).
Installing Requests","urllib.request.urlretrieve cannot download eigen from gitlab as mentioned in #973 .
This pull request solves this problem by using the requests library, but you need to install a third-party library requests in python 3 .
Before run build.py script, install requests by pip($ python -m pip install requests).
Installing Requests",True,{}
colmap/colmap,https://github.com/colmap/colmap,1196,2021-04-05T22:21:16Z,2021-04-08T12:23:00Z,2021-04-08T12:23:00Z,MERGED,True,11,3,1,https://github.com/drkoller,Fix radial distortion in Cam format exporter,2,[],https://github.com/colmap/colmap/pull/1196,https://github.com/drkoller,1,https://github.com/colmap/colmap/pull/1196,"The radial distortion parameters exported by the *.cam file format exporter are currently not computed properly. This PR fixes the Reconstruction::ExportCam() exporter so that the radial distortion parameters in *.cam files will accurately reflect the same distortion as in COLMAP.
If both of the two exported radial distortion parameters in a *.cam file are non-zero, then they are used in a distortion model very similar to the COLMAP and Bundler distortion models. However, if only the second parameter is non-zero, then a different camera model (similar to VisualSFM) is assumed for *.cam files.","The radial distortion parameters exported by the *.cam file format exporter are currently not computed properly. This PR fixes the Reconstruction::ExportCam() exporter so that the radial distortion parameters in *.cam files will accurately reflect the same distortion as in COLMAP.
If both of the two exported radial distortion parameters in a *.cam file are non-zero, then they are used in a distortion model very similar to the COLMAP and Bundler distortion models. However, if only the second parameter is non-zero, then a different camera model (similar to VisualSFM) is assumed for *.cam files.",True,{}
colmap/colmap,https://github.com/colmap/colmap,1199,2021-04-07T01:07:46Z,2021-04-08T11:54:28Z,2021-04-08T11:54:28Z,MERGED,True,1,1,1,https://github.com/iuk,use type point2D_t instead of image_t,1,[],https://github.com/colmap/colmap/pull/1199,https://github.com/iuk,1,https://github.com/colmap/colmap/pull/1199,More reasonable use point2D_t instead of image_t,More reasonable use point2D_t instead of image_t,True,{}
colmap/colmap,https://github.com/colmap/colmap,1204,2021-04-13T20:40:31Z,,2021-04-13T20:40:31Z,OPEN,False,1,1,1,https://github.com/branonm,Update patch_match.h,1,[],https://github.com/colmap/colmap/pull/1204,https://github.com/branonm,1,https://github.com/colmap/colmap/pull/1204,Change private methods and variables to protected to allow access from derived classes.,Change private methods and variables to protected to allow access from derived classes.,True,{}
colmap/colmap,https://github.com/colmap/colmap,1217,2021-05-04T09:38:16Z,2021-05-08T07:30:48Z,2021-05-08T07:30:48Z,MERGED,True,14,15,1,https://github.com/mihaidusmanu,Multi-line string fix in Python model script,3,[],https://github.com/colmap/colmap/pull/1217,https://github.com/mihaidusmanu,1,https://github.com/colmap/colmap/pull/1217,"In the current version, the read_write_model.py script only writes the first line of each multi-line string (tested on Python 3.6+). This PR is a simple fix by using + \ to avoid the string breaks between lines.","In the current version, the read_write_model.py script only writes the first line of each multi-line string (tested on Python 3.6+). This PR is a simple fix by using + \ to avoid the string breaks between lines.",True,{}
colmap/colmap,https://github.com/colmap/colmap,1230,2021-06-07T14:34:35Z,2021-06-12T19:29:32Z,2021-06-12T19:29:32Z,CLOSED,False,0,0,0,https://github.com/oldshuren,Add RefineAbsolutePoseWithCovariance to return covariances,0,[],https://github.com/colmap/colmap/pull/1230,https://github.com/oldshuren,1,https://github.com/colmap/colmap/pull/1230,When using colmap to localize an image. It is good to know the confidence of good is the localization.  RefineAbsolutePoseWithCovariance is same as  RefineAbsolutePose but return the covariances from ceres solver.,When using colmap to localize an image. It is good to know the confidence of good is the localization.  RefineAbsolutePoseWithCovariance is same as  RefineAbsolutePose but return the covariances from ceres solver.,True,{}
colmap/colmap,https://github.com/colmap/colmap,1234,2021-06-12T20:02:10Z,,2022-01-26T12:22:15Z,OPEN,False,31,2,2,https://github.com/oldshuren,Modify RefineAbsolutePose to return covariance,1,[],https://github.com/colmap/colmap/pull/1234,https://github.com/oldshuren,1,https://github.com/colmap/colmap/pull/1234,Covariances are important for determining the confidence of localization of the query images from colmap models. So it is very useful to return the covariance values.,Covariances are important for determining the confidence of localization of the query images from colmap models. So it is very useful to return the covariance values.,True,{}
colmap/colmap,https://github.com/colmap/colmap,1236,2021-06-15T16:42:03Z,2021-06-17T07:28:24Z,2021-06-17T07:28:24Z,MERGED,True,2,0,1,https://github.com/Matstah,added visibility_sigma to CLI input options for delaunay_mesher.,2,[],https://github.com/colmap/colmap/pull/1236,https://github.com/Matstah,1,https://github.com/colmap/colmap/pull/1236,The visibility_sigma variable seemed to have been forgotten for the cli.,The visibility_sigma variable seemed to have been forgotten for the cli.,True,{}
colmap/colmap,https://github.com/colmap/colmap,1236,2021-06-15T16:42:03Z,2021-06-17T07:28:24Z,2021-06-17T07:28:24Z,MERGED,True,2,0,1,https://github.com/Matstah,added visibility_sigma to CLI input options for delaunay_mesher.,2,[],https://github.com/colmap/colmap/pull/1236,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/1236#issuecomment-863001168,The visibility_sigma variable seemed to have been forgotten for the cli.,Thanks,True,{}
colmap/colmap,https://github.com/colmap/colmap,1240,2021-06-21T07:28:14Z,2021-06-22T21:00:14Z,2021-06-22T21:00:20Z,MERGED,True,1,1,1,https://github.com/tsattler,Backwards compatibility of model_aligner,1,[],https://github.com/colmap/colmap/pull/1240,https://github.com/tsattler,1,https://github.com/colmap/colmap/pull/1240,"In previous versions of Colmap, the model_aligner would align a 3D model to a set of camera poses. In this version, not setting the alignment_type option defaults to aligning the model with the dominant plane, which is not the behavior users would expect given previous versions (see #1239 ). I suggest to keep backwards compatibility by keeping the original behavior as the default.","In previous versions of Colmap, the model_aligner would align a 3D model to a set of camera poses. In this version, not setting the alignment_type option defaults to aligning the model with the dominant plane, which is not the behavior users would expect given previous versions (see #1239 ). I suggest to keep backwards compatibility by keeping the original behavior as the default.",True,{}
colmap/colmap,https://github.com/colmap/colmap,1240,2021-06-21T07:28:14Z,2021-06-22T21:00:14Z,2021-06-22T21:00:20Z,MERGED,True,1,1,1,https://github.com/tsattler,Backwards compatibility of model_aligner,1,[],https://github.com/colmap/colmap/pull/1240,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/1240#issuecomment-866329864,"In previous versions of Colmap, the model_aligner would align a 3D model to a set of camera poses. In this version, not setting the alignment_type option defaults to aligning the model with the dominant plane, which is not the behavior users would expect given previous versions (see #1239 ). I suggest to keep backwards compatibility by keeping the original behavior as the default.",Thanks!,True,{}
colmap/colmap,https://github.com/colmap/colmap,1257,2021-07-12T17:04:25Z,2021-08-24T15:28:33Z,2021-08-24T15:34:21Z,MERGED,True,31,11,3,https://github.com/Skydes,Compute reprojection error in generalized absolute solver,7,[],https://github.com/colmap/colmap/pull/1257,https://github.com/Skydes,1,https://github.com/colmap/colmap/pull/1257,"Currently the generalized absolute pose solver computes the squared cosine similarity:

  
    
      colmap/src/estimators/generalized_absolute_pose.cc
    
    
        Lines 319 to 321
      in
      cf4a39c
    
  
  
    

        
          
           const double cosine_dist = 
        

        
          
               1 - inv_pcx_norm * inv_x_norm * (pcx_0 * x_0 + pcx_1 * x_1 + pcx_2); 
        

        
          
           (*residuals)[i] = cosine_dist * cosine_dist; 
        
    
  


This is not consistent with the single-camera solver, which uses the squared reprojection error, and makes it tricky to tune the RANSAC inlier threshold. This PR allows the GP3P solver to optionally instead compute the reprojection error.
Catch: in-class initialization of non-static data members requires C++>=11, but afaik COLMAP already assumed C++11.
@mihaidusmanu @ahojnnes @mgprt","Currently the generalized absolute pose solver computes the squared cosine similarity:

  
    
      colmap/src/estimators/generalized_absolute_pose.cc
    
    
        Lines 319 to 321
      in
      cf4a39c
    
  
  
    

        
          
           const double cosine_dist = 
        

        
          
               1 - inv_pcx_norm * inv_x_norm * (pcx_0 * x_0 + pcx_1 * x_1 + pcx_2); 
        

        
          
           (*residuals)[i] = cosine_dist * cosine_dist; 
        
    
  


This is not consistent with the single-camera solver, which uses the squared reprojection error, and makes it tricky to tune the RANSAC inlier threshold. This PR allows the GP3P solver to optionally instead compute the reprojection error.
Catch: in-class initialization of non-static data members requires C++>=11, but afaik COLMAP already assumed C++11.
@mihaidusmanu @ahojnnes @mgprt",True,{}
colmap/colmap,https://github.com/colmap/colmap,1257,2021-07-12T17:04:25Z,2021-08-24T15:28:33Z,2021-08-24T15:34:21Z,MERGED,True,31,11,3,https://github.com/Skydes,Compute reprojection error in generalized absolute solver,7,[],https://github.com/colmap/colmap/pull/1257,https://github.com/mgprt,2,https://github.com/colmap/colmap/pull/1257#issuecomment-880519093,"Currently the generalized absolute pose solver computes the squared cosine similarity:

  
    
      colmap/src/estimators/generalized_absolute_pose.cc
    
    
        Lines 319 to 321
      in
      cf4a39c
    
  
  
    

        
          
           const double cosine_dist = 
        

        
          
               1 - inv_pcx_norm * inv_x_norm * (pcx_0 * x_0 + pcx_1 * x_1 + pcx_2); 
        

        
          
           (*residuals)[i] = cosine_dist * cosine_dist; 
        
    
  


This is not consistent with the single-camera solver, which uses the squared reprojection error, and makes it tricky to tune the RANSAC inlier threshold. This PR allows the GP3P solver to optionally instead compute the reprojection error.
Catch: in-class initialization of non-static data members requires C++>=11, but afaik COLMAP already assumed C++11.
@mihaidusmanu @ahojnnes @mgprt","Non-static data member initialization was apparently added in GCC 4.7 (https://gcc.gnu.org/projects/cxx-status.html#cxx11) and COLMAP requires at least 4.9 on Linux.
Not sure about MSVC.",True,{}
colmap/colmap,https://github.com/colmap/colmap,1257,2021-07-12T17:04:25Z,2021-08-24T15:28:33Z,2021-08-24T15:34:21Z,MERGED,True,31,11,3,https://github.com/Skydes,Compute reprojection error in generalized absolute solver,7,[],https://github.com/colmap/colmap/pull/1257,https://github.com/ahojnnes,3,https://github.com/colmap/colmap/pull/1257#issuecomment-893256564,"Currently the generalized absolute pose solver computes the squared cosine similarity:

  
    
      colmap/src/estimators/generalized_absolute_pose.cc
    
    
        Lines 319 to 321
      in
      cf4a39c
    
  
  
    

        
          
           const double cosine_dist = 
        

        
          
               1 - inv_pcx_norm * inv_x_norm * (pcx_0 * x_0 + pcx_1 * x_1 + pcx_2); 
        

        
          
           (*residuals)[i] = cosine_dist * cosine_dist; 
        
    
  


This is not consistent with the single-camera solver, which uses the squared reprojection error, and makes it tricky to tune the RANSAC inlier threshold. This PR allows the GP3P solver to optionally instead compute the reprojection error.
Catch: in-class initialization of non-static data members requires C++>=11, but afaik COLMAP already assumed C++11.
@mihaidusmanu @ahojnnes @mgprt",Thanks Paul. Have not had time to look into this until now. One problem with this approach arises when the intrinsics of the different cameras in the rig are different. Then the single reprojection threshold in normalized coordinates will correspond to different pixel values in the different cameras. It might be worth noting that in a comment somewhere.,True,{}
colmap/colmap,https://github.com/colmap/colmap,1257,2021-07-12T17:04:25Z,2021-08-24T15:28:33Z,2021-08-24T15:34:21Z,MERGED,True,31,11,3,https://github.com/Skydes,Compute reprojection error in generalized absolute solver,7,[],https://github.com/colmap/colmap/pull/1257,https://github.com/Skydes,4,https://github.com/colmap/colmap/pull/1257#issuecomment-894799403,"Currently the generalized absolute pose solver computes the squared cosine similarity:

  
    
      colmap/src/estimators/generalized_absolute_pose.cc
    
    
        Lines 319 to 321
      in
      cf4a39c
    
  
  
    

        
          
           const double cosine_dist = 
        

        
          
               1 - inv_pcx_norm * inv_x_norm * (pcx_0 * x_0 + pcx_1 * x_1 + pcx_2); 
        

        
          
           (*residuals)[i] = cosine_dist * cosine_dist; 
        
    
  


This is not consistent with the single-camera solver, which uses the squared reprojection error, and makes it tricky to tune the RANSAC inlier threshold. This PR allows the GP3P solver to optionally instead compute the reprojection error.
Catch: in-class initialization of non-static data members requires C++>=11, but afaik COLMAP already assumed C++11.
@mihaidusmanu @ahojnnes @mgprt",Thanks @ahojnnes for the comment. This is indeed a problem and I don't see an easy way to get around this. I thus added a warning to the docstring. I usually compute the normalized threshold using the average of the focal lengths over all cameras in the rig.,True,{}
colmap/colmap,https://github.com/colmap/colmap,1275,2021-08-17T13:03:57Z,2021-08-24T19:00:42Z,2021-08-24T19:00:43Z,MERGED,True,20,11,1,https://github.com/snavely,Modifying scripts/python/flickr_downloader.py to create files with correct extensions,3,[],https://github.com/colmap/colmap/pull/1275,https://github.com/snavely,1,https://github.com/colmap/colmap/pull/1275,"Prior to this change, all downloaded files will be saved with a .jpg extension, regardless of the actual file type or extension of the file. This change retains the extension of the file.","Prior to this change, all downloaded files will be saved with a .jpg extension, regardless of the actual file type or extension of the file. This change retains the extension of the file.",True,{}
colmap/colmap,https://github.com/colmap/colmap,1275,2021-08-17T13:03:57Z,2021-08-24T19:00:42Z,2021-08-24T19:00:43Z,MERGED,True,20,11,1,https://github.com/snavely,Modifying scripts/python/flickr_downloader.py to create files with correct extensions,3,[],https://github.com/colmap/colmap/pull/1275,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/1275#issuecomment-904896339,"Prior to this change, all downloaded files will be saved with a .jpg extension, regardless of the actual file type or extension of the file. This change retains the extension of the file.",Thanks Noah!,True,{}
colmap/colmap,https://github.com/colmap/colmap,1276,2021-08-18T10:24:29Z,2021-08-24T12:27:36Z,2021-08-24T12:27:36Z,MERGED,True,1,1,1,https://github.com/hiakru,[update undistortion] update dumped commands,1,[],https://github.com/colmap/colmap/pull/1276,https://github.com/hiakru,1,https://github.com/colmap/colmap/pull/1276,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,1281,2021-08-25T03:16:07Z,2021-09-03T07:23:45Z,2021-09-03T10:40:34Z,MERGED,True,21,1,2,https://github.com/MasahiroOgawa,revise Dockerfile and readme.,2,[],https://github.com/colmap/colmap/pull/1281,https://github.com/MasahiroOgawa,1,https://github.com/colmap/colmap/pull/1281,"Current docker/build.sh failed because git needs tzdata, and tzdata asked to select geographic area, but it accidentally stops.
So I fixed it.","Current docker/build.sh failed because git needs tzdata, and tzdata asked to select geographic area, but it accidentally stops.
So I fixed it.",True,{}
colmap/colmap,https://github.com/colmap/colmap,1293,2021-09-10T22:18:02Z,,2022-01-26T12:22:15Z,OPEN,False,263,144,1,https://github.com/johnwlambert,Add type hints and docstrings to python IO file,2,[],https://github.com/colmap/colmap/pull/1293,https://github.com/johnwlambert,1,https://github.com/colmap/colmap/pull/1293,"Currently the read_write_model.py file is not very clear because the input and return types are not explained thoroughly. This PR updates the documentation for scripts/python/read_write_model.py .

Reformatted docstrings to be consistent and in the google format (https://google.github.io/styleguide/pyguide.html#383-functions-and-methods)
Added type hints to improve readability.
Reformatted code in the python black style for consistency.","Currently the read_write_model.py file is not very clear because the input and return types are not explained thoroughly. This PR updates the documentation for scripts/python/read_write_model.py .

Reformatted docstrings to be consistent and in the google format (https://google.github.io/styleguide/pyguide.html#383-functions-and-methods)
Added type hints to improve readability.
Reformatted code in the python black style for consistency.",True,{}
colmap/colmap,https://github.com/colmap/colmap,1317,2021-10-25T21:01:00Z,2021-10-27T06:20:37Z,2021-11-09T19:57:35Z,MERGED,True,22,20,4,https://github.com/ahojnnes,Fix compiler warnings reported by GCC,2,[],https://github.com/colmap/colmap/pull/1317,https://github.com/ahojnnes,1,https://github.com/colmap/colmap/pull/1317,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,1318,2021-10-25T21:03:45Z,2021-10-27T11:01:46Z,2021-10-27T11:01:46Z,MERGED,True,1,1,1,https://github.com/ahojnnes,Auto-rotate JPEG images based on EXIF orientation,3,[],https://github.com/colmap/colmap/pull/1318,https://github.com/ahojnnes,1,https://github.com/colmap/colmap/pull/1318,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,1319,2021-10-26T19:00:25Z,2021-10-26T21:44:56Z,2021-10-26T21:44:56Z,MERGED,True,1,1,1,https://github.com/ahojnnes,Update to latest vcpkg version,1,[],https://github.com/colmap/colmap/pull/1319,https://github.com/ahojnnes,1,https://github.com/colmap/colmap/pull/1319,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,1329,2021-11-09T19:56:47Z,2021-11-18T20:13:17Z,2021-11-18T20:13:17Z,MERGED,True,1,0,1,https://github.com/ahojnnes,Add missing include in case CUDA/GUI is not available,3,[],https://github.com/colmap/colmap/pull/1329,https://github.com/ahojnnes,1,https://github.com/colmap/colmap/pull/1329,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,1330,2021-11-12T16:51:17Z,2021-11-14T14:38:46Z,2021-11-14T14:38:46Z,CLOSED,False,15,27,3,https://github.com/mihaidusmanu,Exposed descriptor normalization to command line.,1,[],https://github.com/colmap/colmap/pull/1330,https://github.com/mihaidusmanu,1,https://github.com/colmap/colmap/pull/1330,"This allows the user to choose between RootSIFT and SIFT descriptors directly from the command line without requiring to recompile from sources. This is useful for benchmarking purposes, but reduces the ease of adding new normalizations in the future. Not sure how to keep both, but I am open to suggestions :).","This allows the user to choose between RootSIFT and SIFT descriptors directly from the command line without requiring to recompile from sources. This is useful for benchmarking purposes, but reduces the ease of adding new normalizations in the future. Not sure how to keep both, but I am open to suggestions :).",True,{}
colmap/colmap,https://github.com/colmap/colmap,1331,2021-11-13T07:49:41Z,2021-11-13T11:13:46Z,2021-11-13T11:13:47Z,MERGED,True,1,1,1,https://github.com/ahojnnes,Upgrade vcpkg to fix CI build issues,1,[],https://github.com/colmap/colmap/pull/1331,https://github.com/ahojnnes,1,https://github.com/colmap/colmap/pull/1331,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,1332,2021-11-15T09:12:44Z,2021-11-15T18:28:10Z,2021-11-15T18:28:32Z,MERGED,True,16,0,1,https://github.com/mihaidusmanu,Added descriptor normalization argument to feature_extractor.,1,[],https://github.com/colmap/colmap/pull/1332,https://github.com/mihaidusmanu,1,https://github.com/colmap/colmap/pull/1332,Allows users to select between L1_ROOT and L2 at runtime in the feature_extractor (for benchmarking purposes). Default stays RootSIFT as it usually performs better.,Allows users to select between L1_ROOT and L2 at runtime in the feature_extractor (for benchmarking purposes). Default stays RootSIFT as it usually performs better.,True,{}
colmap/colmap,https://github.com/colmap/colmap,1332,2021-11-15T09:12:44Z,2021-11-15T18:28:10Z,2021-11-15T18:28:32Z,MERGED,True,16,0,1,https://github.com/mihaidusmanu,Added descriptor normalization argument to feature_extractor.,1,[],https://github.com/colmap/colmap/pull/1332,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/1332#issuecomment-969195991,Allows users to select between L1_ROOT and L2 at runtime in the feature_extractor (for benchmarking purposes). Default stays RootSIFT as it usually performs better.,Thanks Mihai!,True,{}
colmap/colmap,https://github.com/colmap/colmap,1333,2021-11-16T15:39:26Z,2021-11-18T21:20:11Z,2021-11-18T21:20:11Z,MERGED,True,13,11,2,https://github.com/Freeverc,Fix wrong WGS84 model and test cases in GPSTransform,3,[],https://github.com/colmap/colmap/pull/1333,https://github.com/Freeverc,1,https://github.com/colmap/colmap/pull/1333,Fix wrong WGS84 model and test cases in GPSTransform,Fix wrong WGS84 model and test cases in GPSTransform,True,{}
colmap/colmap,https://github.com/colmap/colmap,1334,2021-11-17T21:34:47Z,2021-11-18T19:28:44Z,2021-11-18T19:28:44Z,MERGED,True,1,1,1,https://github.com/chpatrick,Add CUDA_SAFE_CALL to cudaGetDeviceCount.,2,[],https://github.com/colmap/colmap/pull/1334,https://github.com/chpatrick,1,https://github.com/colmap/colmap/pull/1334,Otherwise if there's an error GetNumCudaDevices returns uninitialized memory.,Otherwise if there's an error GetNumCudaDevices returns uninitialized memory.,True,{}
colmap/colmap,https://github.com/colmap/colmap,1335,2021-11-18T10:22:37Z,2021-11-18T14:25:57Z,2021-11-18T14:26:00Z,CLOSED,False,1,1,1,https://github.com/whuaegeanse,Fix memory leak in the function of StringAppendV,25,[],https://github.com/colmap/colmap/pull/1335,https://github.com/whuaegeanse,1,https://github.com/colmap/colmap/pull/1335,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,1337,2021-11-18T14:27:04Z,2021-11-18T18:58:05Z,2021-11-23T17:54:46Z,MERGED,True,1,1,1,https://github.com/whuaegeanse,Fix memory leak in the function of StringAppendV,1,[],https://github.com/colmap/colmap/pull/1337,https://github.com/whuaegeanse,1,https://github.com/colmap/colmap/pull/1337,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,1360,2021-12-28T19:49:04Z,2021-12-29T11:37:59Z,2021-12-29T11:37:59Z,MERGED,True,2,2,1,https://github.com/rmbrualla,Fixes bug in sprt.cc: num_inliers was not set.,1,[],https://github.com/colmap/colmap/pull/1360,https://github.com/rmbrualla,1,https://github.com/colmap/colmap/pull/1360,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,1360,2021-12-28T19:49:04Z,2021-12-29T11:37:59Z,2021-12-29T11:37:59Z,MERGED,True,2,2,1,https://github.com/rmbrualla,Fixes bug in sprt.cc: num_inliers was not set.,1,[],https://github.com/colmap/colmap/pull/1360,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/1360#issuecomment-1002552960,,Thanks Ricardo!,True,{}
colmap/colmap,https://github.com/colmap/colmap,1361,2021-12-29T13:25:08Z,2021-12-29T16:10:22Z,2021-12-29T16:10:22Z,MERGED,True,4,0,1,https://github.com/rmbrualla,Prevent a divide by zero corner case.,1,[],https://github.com/colmap/colmap/pull/1361,https://github.com/rmbrualla,1,https://github.com/colmap/colmap/pull/1361,"This was observed to lead to a SIGILL error. It could be due to num_inliers being zero, or that inlier_ration ^ kMinNumSamples being so small, that it flushes to zero.","This was observed to lead to a SIGILL error. It could be due to num_inliers being zero, or that inlier_ration ^ kMinNumSamples being so small, that it flushes to zero.",True,{}
colmap/colmap,https://github.com/colmap/colmap,1361,2021-12-29T13:25:08Z,2021-12-29T16:10:22Z,2021-12-29T16:10:22Z,MERGED,True,4,0,1,https://github.com/rmbrualla,Prevent a divide by zero corner case.,1,[],https://github.com/colmap/colmap/pull/1361,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/1361#issuecomment-1002609248,"This was observed to lead to a SIGILL error. It could be due to num_inliers being zero, or that inlier_ration ^ kMinNumSamples being so small, that it flushes to zero.",Thanks again.,True,{}
colmap/colmap,https://github.com/colmap/colmap,1362,2021-12-29T22:19:11Z,2021-12-30T17:15:15Z,2021-12-30T17:15:15Z,MERGED,True,1,0,1,https://github.com/rmbrualla,Adds missing header.,1,[],https://github.com/colmap/colmap/pull/1362,https://github.com/rmbrualla,1,https://github.com/colmap/colmap/pull/1362,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,1363,2021-12-31T16:54:36Z,2022-01-03T08:04:52Z,2022-05-17T02:39:42Z,MERGED,True,4,0,1,https://github.com/whuaegeanse,Keep precision in the process of storing in text.,5,[],https://github.com/colmap/colmap/pull/1363,https://github.com/whuaegeanse,1,https://github.com/colmap/colmap/pull/1363,"When writing variables to std::ostringstream, we will loose precision of double variables if output manipulators were not applied.","When writing variables to std::ostringstream, we will loose precision of double variables if output manipulators were not applied.",True,{}
colmap/colmap,https://github.com/colmap/colmap,1363,2021-12-31T16:54:36Z,2022-01-03T08:04:52Z,2022-05-17T02:39:42Z,MERGED,True,4,0,1,https://github.com/whuaegeanse,Keep precision in the process of storing in text.,5,[],https://github.com/colmap/colmap/pull/1363,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/1363#issuecomment-1003694817,"When writing variables to std::ostringstream, we will loose precision of double variables if output manipulators were not applied.","Thanks for the fix. However, I don’t think we need the std::fixed and can save us some bytes on disk. Also, I suggest to use the full 17 digits precision for the 2D points to ensure identical results to the binary format. Thanks!",True,{}
colmap/colmap,https://github.com/colmap/colmap,1363,2021-12-31T16:54:36Z,2022-01-03T08:04:52Z,2022-05-17T02:39:42Z,MERGED,True,4,0,1,https://github.com/whuaegeanse,Keep precision in the process of storing in text.,5,[],https://github.com/colmap/colmap/pull/1363,https://github.com/ahojnnes,3,https://github.com/colmap/colmap/pull/1363#issuecomment-1003923128,"When writing variables to std::ostringstream, we will loose precision of double variables if output manipulators were not applied.",Thanks!,True,{}
colmap/colmap,https://github.com/colmap/colmap,1365,2022-01-02T10:21:42Z,2022-01-02T10:43:33Z,2022-01-02T10:43:33Z,MERGED,True,15,10,1,https://github.com/Skydes,Require Qt in COLMAPConfig only if GUI is enabled,1,[],https://github.com/colmap/colmap/pull/1365,https://github.com/Skydes,1,https://github.com/colmap/colmap/pull/1365,PR #1165 introduced the CMake option GUI_ENABLED to disable to GUI but did not disable the Qt requirement in the exported COLMAPConfig.cmake file.,PR #1165 introduced the CMake option GUI_ENABLED to disable to GUI but did not disable the Qt requirement in the exported COLMAPConfig.cmake file.,True,{}
colmap/colmap,https://github.com/colmap/colmap,1365,2022-01-02T10:21:42Z,2022-01-02T10:43:33Z,2022-01-02T10:43:33Z,MERGED,True,15,10,1,https://github.com/Skydes,Require Qt in COLMAPConfig only if GUI is enabled,1,[],https://github.com/colmap/colmap/pull/1365,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/1365#issuecomment-1003694941,PR #1165 introduced the CMake option GUI_ENABLED to disable to GUI but did not disable the Qt requirement in the exported COLMAPConfig.cmake file.,"Great, thanks Paul!",True,{}
colmap/colmap,https://github.com/colmap/colmap,1366,2022-01-03T23:01:35Z,2022-01-04T09:35:26Z,2022-01-04T09:35:26Z,MERGED,True,72,38,4,https://github.com/Skydes,Expose exe internals,2,[],https://github.com/colmap/colmap/pull/1366,https://github.com/Skydes,1,https://github.com/colmap/colmap/pull/1366,"In pycolmap we now bind some of the exe functions like RunPointTriangulator. See pycolmap/pipeline.cc. We therefore need COLMAP to expose some exe code that is currently hidden in anonymous namespace or argc-argv functions. Most of this code is likely useful for others and worthy to be publicly exposed, but src/exe is probably not the right place for it.
Any advice on where these bits should be moved?
@ahojnnes @mihaidusmanu @Phil26AT","In pycolmap we now bind some of the exe functions like RunPointTriangulator. See pycolmap/pipeline.cc. We therefore need COLMAP to expose some exe code that is currently hidden in anonymous namespace or argc-argv functions. Most of this code is likely useful for others and worthy to be publicly exposed, but src/exe is probably not the right place for it.
Any advice on where these bits should be moved?
@ahojnnes @mihaidusmanu @Phil26AT",True,{}
colmap/colmap,https://github.com/colmap/colmap,1366,2022-01-03T23:01:35Z,2022-01-04T09:35:26Z,2022-01-04T09:35:26Z,MERGED,True,72,38,4,https://github.com/Skydes,Expose exe internals,2,[],https://github.com/colmap/colmap/pull/1366,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/1366#issuecomment-1004654281,"In pycolmap we now bind some of the exe functions like RunPointTriangulator. See pycolmap/pipeline.cc. We therefore need COLMAP to expose some exe code that is currently hidden in anonymous namespace or argc-argv functions. Most of this code is likely useful for others and worthy to be publicly exposed, but src/exe is probably not the right place for it.
Any advice on where these bits should be moved?
@ahojnnes @mihaidusmanu @Phil26AT",I am fine with the proposed changes. Thanks!,True,{}
colmap/colmap,https://github.com/colmap/colmap,1368,2022-01-04T11:01:06Z,2022-01-04T18:29:22Z,2022-01-04T18:29:22Z,MERGED,True,5,0,1,https://github.com/Skydes, Expose exe internals - fix,2,[],https://github.com/colmap/colmap/pull/1368,https://github.com/Skydes,1,https://github.com/colmap/colmap/pull/1368,PR #1366 exposed some functions in src/exe but I forgot to include these files in the exported library.,PR #1366 exposed some functions in src/exe but I forgot to include these files in the exported library.,True,{}
colmap/colmap,https://github.com/colmap/colmap,1369,2022-01-04T11:22:15Z,2022-01-04T16:03:18Z,2022-01-04T16:03:19Z,MERGED,True,10,4,1,https://github.com/ferreram,Fix inliers matches extraction in EstimateUncalibrated function.,2,[],https://github.com/colmap/colmap/pull/1369,https://github.com/ferreram,1,https://github.com/colmap/colmap/pull/1369,"Currently, the inliers found with the fundamental matrix are always the one used in EstimateUncalibrated(), even if the homography is selected as a better fit.  This commit fixes this behavior.","Currently, the inliers found with the fundamental matrix are always the one used in EstimateUncalibrated(), even if the homography is selected as a better fit.  This commit fixes this behavior.",True,{}
colmap/colmap,https://github.com/colmap/colmap,1369,2022-01-04T11:22:15Z,2022-01-04T16:03:18Z,2022-01-04T16:03:19Z,MERGED,True,10,4,1,https://github.com/ferreram,Fix inliers matches extraction in EstimateUncalibrated function.,2,[],https://github.com/colmap/colmap/pull/1369,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/1369#issuecomment-1004934691,"Currently, the inliers found with the fundamental matrix are always the one used in EstimateUncalibrated(), even if the homography is selected as a better fit.  This commit fixes this behavior.",Thanks for the fix !,True,{}
colmap/colmap,https://github.com/colmap/colmap,1371,2022-01-07T08:36:29Z,2022-01-23T16:17:47Z,2022-01-23T16:17:48Z,MERGED,True,352,48,4,https://github.com/ferreram,Update ModelAligner to handle GPS and custom coords. and more,11,[],https://github.com/colmap/colmap/pull/1371,https://github.com/ferreram,1,https://github.com/colmap/colmap/pull/1371,"Adds GPS conversions to and from ENU coords. (GPS -> ENU, ECEF -> ENU, ENU -> GPS, ENU -> ECEF).

Update of ModelAligner function:

Now handles either GPS or custom coordinates as reference coordinates for alignment.
Alignment to pure ENU frame offered as an option.
Aligning reconstruction to ref coords. origin offered as an option.
Fix the alignment to plane case if no ref or database provided.
Documentation added for the function.","Adds GPS conversions to and from ENU coords. (GPS -> ENU, ECEF -> ENU, ENU -> GPS, ENU -> ECEF).

Update of ModelAligner function:

Now handles either GPS or custom coordinates as reference coordinates for alignment.
Alignment to pure ENU frame offered as an option.
Aligning reconstruction to ref coords. origin offered as an option.
Fix the alignment to plane case if no ref or database provided.
Documentation added for the function.",True,{}
colmap/colmap,https://github.com/colmap/colmap,1382,2022-01-19T20:29:46Z,2022-01-20T13:31:01Z,2022-01-20T13:31:02Z,MERGED,True,18,16,7,https://github.com/ahojnnes,Fix warnings for latest compiler/libraries,5,[],https://github.com/colmap/colmap/pull/1382,https://github.com/ahojnnes,1,https://github.com/colmap/colmap/pull/1382,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,1383,2022-01-19T20:33:05Z,2022-01-20T00:06:01Z,2022-01-20T00:06:02Z,MERGED,True,0,4,1,https://github.com/ahojnnes,Remove deprecated Mac OSX 10.14 image in ADO pipeline,1,[],https://github.com/colmap/colmap/pull/1383,https://github.com/ahojnnes,1,https://github.com/colmap/colmap/pull/1383,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,1384,2022-01-19T20:35:02Z,2022-01-20T05:49:27Z,2022-01-20T05:49:27Z,MERGED,True,4,0,1,https://github.com/ahojnnes,Add Mac OSX 11 ADO pipeline job,3,[],https://github.com/colmap/colmap/pull/1384,https://github.com/ahojnnes,1,https://github.com/colmap/colmap/pull/1384,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,1387,2022-01-20T18:19:37Z,2022-01-20T19:22:31Z,2022-01-20T19:22:32Z,MERGED,True,9,4,4,https://github.com/ahojnnes,Fix clang compiler warnings,2,[],https://github.com/colmap/colmap/pull/1387,https://github.com/ahojnnes,1,https://github.com/colmap/colmap/pull/1387,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,1390,2022-01-22T11:34:32Z,2022-01-22T13:05:20Z,2022-01-22T13:05:20Z,MERGED,True,85,35,12,https://github.com/ahojnnes,Add Address Sanitizer options and fix reported issues,4,[],https://github.com/colmap/colmap/pull/1390,https://github.com/ahojnnes,1,https://github.com/colmap/colmap/pull/1390,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,1391,2022-01-22T13:07:14Z,2022-01-22T13:44:35Z,2022-01-22T13:44:36Z,MERGED,True,3,3,2,https://github.com/ahojnnes,User/joschonb/asan cleanup,6,[],https://github.com/colmap/colmap/pull/1391,https://github.com/ahojnnes,1,https://github.com/colmap/colmap/pull/1391,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,1392,2022-01-22T15:28:49Z,2022-01-22T22:52:49Z,2022-01-22T22:52:50Z,MERGED,True,12,4,2,https://github.com/ahojnnes,Add ADO pipeline for Visual Studio 2022,2,[],https://github.com/colmap/colmap/pull/1392,https://github.com/ahojnnes,1,https://github.com/colmap/colmap/pull/1392,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,1393,2022-01-22T19:18:01Z,,2022-01-26T12:22:15Z,OPEN,False,41,8,7,https://github.com/ahojnnes,Install Windows runtime dependencies and release in ADO pipeline,13,[],https://github.com/colmap/colmap/pull/1393,https://github.com/ahojnnes,1,https://github.com/colmap/colmap/pull/1393,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,1395,2022-01-23T10:49:44Z,2022-01-23T11:14:00Z,2022-01-23T11:14:00Z,MERGED,True,14,0,1,https://github.com/ahojnnes,Add ccache option,1,[],https://github.com/colmap/colmap/pull/1395,https://github.com/ahojnnes,1,https://github.com/colmap/colmap/pull/1395,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,1397,2022-01-23T13:25:17Z,,2022-02-26T07:05:14Z,OPEN,False,154,11,6,https://github.com/ahojnnes,Add e2e tests for CI pipeline,11,[],https://github.com/colmap/colmap/pull/1397,https://github.com/ahojnnes,1,https://github.com/colmap/colmap/pull/1397,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,1401,2022-01-25T20:42:17Z,2022-01-25T21:59:15Z,2022-01-25T21:59:15Z,MERGED,True,9,7,1,https://github.com/ahojnnes,Fix camera size change under Windows,1,[],https://github.com/colmap/colmap/pull/1401,https://github.com/ahojnnes,1,https://github.com/colmap/colmap/pull/1401,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,1402,2022-01-26T09:28:08Z,2022-01-26T09:53:27Z,2022-01-26T10:32:06Z,MERGED,True,97,2,2,https://github.com/ahojnnes,Release of COLMAP version 3.7,1,[],https://github.com/colmap/colmap/pull/1402,https://github.com/ahojnnes,1,https://github.com/colmap/colmap/pull/1402,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,1403,2022-01-26T10:34:49Z,2022-01-26T12:28:27Z,2022-01-26T12:28:27Z,CLOSED,False,8263,3670,172,https://github.com/ahojnnes,Upgrade to COLMAP version 3.7,123,[],https://github.com/colmap/colmap/pull/1403,https://github.com/ahojnnes,1,https://github.com/colmap/colmap/pull/1403,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,1404,2022-01-26T10:37:35Z,2022-01-26T13:05:56Z,2022-01-26T13:05:56Z,MERGED,True,2,2,1,https://github.com/ahojnnes,Increase version number to 3.8,1,[],https://github.com/colmap/colmap/pull/1404,https://github.com/ahojnnes,1,https://github.com/colmap/colmap/pull/1404,New dev version is 3.8.,New dev version is 3.8.,True,{}
colmap/colmap,https://github.com/colmap/colmap,1405,2022-01-26T10:50:11Z,2022-01-26T13:32:32Z,2022-01-26T14:10:37Z,CLOSED,False,102,16,4,https://github.com/ferreram,Back to not taking EXIF orientation into account,5,[],https://github.com/colmap/colmap/pull/1405,https://github.com/ferreram,1,https://github.com/colmap/colmap/pull/1405,Reverting back to the original implementation which did not use the EXIF orientation flag into account when reading images.,Reverting back to the original implementation which did not use the EXIF orientation flag into account when reading images.,True,{}
colmap/colmap,https://github.com/colmap/colmap,1405,2022-01-26T10:50:11Z,2022-01-26T13:32:32Z,2022-01-26T14:10:37Z,CLOSED,False,102,16,4,https://github.com/ferreram,Back to not taking EXIF orientation into account,5,[],https://github.com/colmap/colmap/pull/1405,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/1405#issuecomment-1022153175,Reverting back to the original implementation which did not use the EXIF orientation flag into account when reading images.,Seems like something went wrong with the merge?,True,{}
colmap/colmap,https://github.com/colmap/colmap,1405,2022-01-26T10:50:11Z,2022-01-26T13:32:32Z,2022-01-26T14:10:37Z,CLOSED,False,102,16,4,https://github.com/ferreram,Back to not taking EXIF orientation into account,5,[],https://github.com/colmap/colmap/pull/1405,https://github.com/ahojnnes,3,https://github.com/colmap/colmap/pull/1405#issuecomment-1022200802,Reverting back to the original implementation which did not use the EXIF orientation flag into account when reading images.,"Thanks for the commit. Need this to be merged today, so cherry-picked your changes here: #1406",True,{}
colmap/colmap,https://github.com/colmap/colmap,1405,2022-01-26T10:50:11Z,2022-01-26T13:32:32Z,2022-01-26T14:10:37Z,CLOSED,False,102,16,4,https://github.com/ferreram,Back to not taking EXIF orientation into account,5,[],https://github.com/colmap/colmap/pull/1405,https://github.com/ferreram,4,https://github.com/colmap/colmap/pull/1405#issuecomment-1022232828,Reverting back to the original implementation which did not use the EXIF orientation flag into account when reading images.,Absolutely fine with me 👍,True,{}
colmap/colmap,https://github.com/colmap/colmap,1406,2022-01-26T13:31:29Z,2022-01-26T13:58:42Z,2022-01-26T13:58:43Z,MERGED,True,4,4,2,https://github.com/ahojnnes,Reverting back to the original implementation which did not use the E…,3,[],https://github.com/colmap/colmap/pull/1406,https://github.com/ahojnnes,1,https://github.com/colmap/colmap/pull/1406,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,1408,2022-01-27T10:00:33Z,2022-01-27T13:01:36Z,2022-01-27T13:01:36Z,MERGED,True,76,3,6,https://github.com/ferreram,Adding user-specified option for reconstructing purely planar scene. …,3,[],https://github.com/colmap/colmap/pull/1408,https://github.com/ferreram,1,https://github.com/colmap/colmap/pull/1408,"… If option is set, estimation of homography-based two-view geometry for matching will be forced.
In my tests, this option significantly improves the quality of the matching step when reconstructing planar scenes.
Feel free to merge it or not as it might be a bit specific.","… If option is set, estimation of homography-based two-view geometry for matching will be forced.
In my tests, this option significantly improves the quality of the matching step when reconstructing planar scenes.
Feel free to merge it or not as it might be a bit specific.",True,{}
colmap/colmap,https://github.com/colmap/colmap,1408,2022-01-27T10:00:33Z,2022-01-27T13:01:36Z,2022-01-27T13:01:36Z,MERGED,True,76,3,6,https://github.com/ferreram,Adding user-specified option for reconstructing purely planar scene. …,3,[],https://github.com/colmap/colmap/pull/1408,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/1408#issuecomment-1023157735,"… If option is set, estimation of homography-based two-view geometry for matching will be forced.
In my tests, this option significantly improves the quality of the matching step when reconstructing planar scenes.
Feel free to merge it or not as it might be a bit specific.","Thanks, looks good to me.",True,{}
colmap/colmap,https://github.com/colmap/colmap,1409,2022-01-27T10:06:30Z,,2022-03-11T07:09:12Z,OPEN,False,1321,50,27,https://github.com/ferreram,Sfm-GPS BA,10,[],https://github.com/colmap/colmap/pull/1409,https://github.com/ferreram,1,https://github.com/colmap/colmap/pull/1409,"Hey @ahojnnes ,
I have been working on directly adding prior motions (e.g. from GPS) into the Bundle Adjustment steps of Colmap.
It allows to use the priors on cameras' position directly in the incremental reconstruction as well as in pure BA.
This not ready to be merged yet but I wanted to know if you would feel like adding this option to Colmap and if so, I'd be glad to get your opinion on it.","Hey @ahojnnes ,
I have been working on directly adding prior motions (e.g. from GPS) into the Bundle Adjustment steps of Colmap.
It allows to use the priors on cameras' position directly in the incremental reconstruction as well as in pure BA.
This not ready to be merged yet but I wanted to know if you would feel like adding this option to Colmap and if so, I'd be glad to get your opinion on it.",True,"{'THUMBS_UP': ['https://github.com/michaelschleiss', 'https://github.com/csunking', 'https://github.com/EwertzJN', 'https://github.com/kevinhangoat', 'https://github.com/tpwrules', 'https://github.com/KBentley57']}"
colmap/colmap,https://github.com/colmap/colmap,1409,2022-01-27T10:06:30Z,,2022-03-11T07:09:12Z,OPEN,False,1321,50,27,https://github.com/ferreram,Sfm-GPS BA,10,[],https://github.com/colmap/colmap/pull/1409,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/1409#issuecomment-1023168537,"Hey @ahojnnes ,
I have been working on directly adding prior motions (e.g. from GPS) into the Bundle Adjustment steps of Colmap.
It allows to use the priors on cameras' position directly in the incremental reconstruction as well as in pure BA.
This not ready to be merged yet but I wanted to know if you would feel like adding this option to Colmap and if so, I'd be glad to get your opinion on it.","I will have a more detailed look, but this would be a quite useful feature. Do you have some test data to share that could be used to validate that this works?",True,{}
colmap/colmap,https://github.com/colmap/colmap,1409,2022-01-27T10:06:30Z,,2022-03-11T07:09:12Z,OPEN,False,1321,50,27,https://github.com/ferreram,Sfm-GPS BA,10,[],https://github.com/colmap/colmap/pull/1409,https://github.com/ferreram,3,https://github.com/colmap/colmap/pull/1409#issuecomment-1023399525,"Hey @ahojnnes ,
I have been working on directly adding prior motions (e.g. from GPS) into the Bundle Adjustment steps of Colmap.
It allows to use the priors on cameras' position directly in the incremental reconstruction as well as in pure BA.
This not ready to be merged yet but I wanted to know if you would feel like adding this option to Colmap and if so, I'd be glad to get your opinion on it.","Yes I can provide some test data for you to validate everything.  Is it OK if I email them to you (the data are not confidential but they should not be publicly disclosed)?  Also, my data are a bit specific because they have been acquired with underwater robots.  I have validated the fusion of GPS info in the SfM with these underwater collected data but it could be worth testing it on different data as well.",True,{}
colmap/colmap,https://github.com/colmap/colmap,1409,2022-01-27T10:06:30Z,,2022-03-11T07:09:12Z,OPEN,False,1321,50,27,https://github.com/ferreram,Sfm-GPS BA,10,[],https://github.com/colmap/colmap/pull/1409,https://github.com/EwertzJN,4,https://github.com/colmap/colmap/pull/1409#issuecomment-1055244135,"Hey @ahojnnes ,
I have been working on directly adding prior motions (e.g. from GPS) into the Bundle Adjustment steps of Colmap.
It allows to use the priors on cameras' position directly in the incremental reconstruction as well as in pure BA.
This not ready to be merged yet but I wanted to know if you would feel like adding this option to Colmap and if so, I'd be glad to get your opinion on it.","Hello all,
I am very interested in this extension for colmap and would like to test it already on my own dataset. Could you maybe give me instructions on how to build a pipeline that takes into account the GPS prior positions of my images? Thanks a lot in advance!",True,{}
colmap/colmap,https://github.com/colmap/colmap,1409,2022-01-27T10:06:30Z,,2022-03-11T07:09:12Z,OPEN,False,1321,50,27,https://github.com/ferreram,Sfm-GPS BA,10,[],https://github.com/colmap/colmap/pull/1409,https://github.com/ferreram,5,https://github.com/colmap/colmap/pull/1409#issuecomment-1055307008,"Hey @ahojnnes ,
I have been working on directly adding prior motions (e.g. from GPS) into the Bundle Adjustment steps of Colmap.
It allows to use the priors on cameras' position directly in the incremental reconstruction as well as in pure BA.
This not ready to be merged yet but I wanted to know if you would feel like adding this option to Colmap and if so, I'd be glad to get your opinion on it.","@EwertzJN you can use the branch https://github.com/ferreram/colmap/tree/sfm_gps_ba_aligner_4_clem
What you need to provide then is either images with their GPS positions set in the EXIF or update the database once you have applied the features extraction step.  You can update the database with python, check the database.py script in colmap repository.  Here is the SQL command that you can apply from python:
    # Update database.
    for img_name, nav_val in zip(img_names, nav_vals):
        db.execute(""UPDATE images SET prior_tx=?, prior_ty=?, prior_tz=? WHERE name=?;"", \
                (nav_val[0], nav_val[1], nav_val[2], img_name))",True,{}
colmap/colmap,https://github.com/colmap/colmap,1409,2022-01-27T10:06:30Z,,2022-03-11T07:09:12Z,OPEN,False,1321,50,27,https://github.com/ferreram,Sfm-GPS BA,10,[],https://github.com/colmap/colmap/pull/1409,https://github.com/EwertzJN,6,https://github.com/colmap/colmap/pull/1409#issuecomment-1055413923,"Hey @ahojnnes ,
I have been working on directly adding prior motions (e.g. from GPS) into the Bundle Adjustment steps of Colmap.
It allows to use the priors on cameras' position directly in the incremental reconstruction as well as in pure BA.
This not ready to be merged yet but I wanted to know if you would feel like adding this option to Colmap and if so, I'd be glad to get your opinion on it.","First, thank you very much for the quick feedback.
My images are indeed equipped with geodata via EXIF, so the first row of the database after feature extraction looked like this, for example:
1,000028_pitch1_yaw1.jpg,1,,,,,40.439502777777776,-79.99679722222223,295
After that, I did an exhaustive feature matching (default settings) and started the reconstruction process, selecting here in addition to the default settings under Reconstruction options → Bundle → Prior Motion Parameters use_prior_motion and is_gps(…). Unfortunately, the reconstruction process did not lead to any result.
Maybe you could help me again, I would be very grateful. Enclosed, you will also find the log of the colmap gui.",True,{}
colmap/colmap,https://github.com/colmap/colmap,1409,2022-01-27T10:06:30Z,,2022-03-11T07:09:12Z,OPEN,False,1321,50,27,https://github.com/ferreram,Sfm-GPS BA,10,[],https://github.com/colmap/colmap/pull/1409,https://github.com/EwertzJN,7,https://github.com/colmap/colmap/pull/1409#issuecomment-1058119363,"Hey @ahojnnes ,
I have been working on directly adding prior motions (e.g. from GPS) into the Bundle Adjustment steps of Colmap.
It allows to use the priors on cameras' position directly in the incremental reconstruction as well as in pure BA.
This not ready to be merged yet but I wanted to know if you would feel like adding this option to Colmap and if so, I'd be glad to get your opinion on it.","I have now been able to calculate a result, but on a different data set. Could it be that the images I want to use are possibly of too poor quality (the images are stitched together from shots taken by an omnidirectional camera and do not have a high resolution)? Or maybe there is something wrong with the EXIF data? Attached is a selection of the images.
What surprises me then, however, is that the reconstruction without the use of the GPS prior produces a result, albeit a partially poor result. The idea was in fact to improve these bad results by using the GPS-Prior.",True,{}
colmap/colmap,https://github.com/colmap/colmap,1409,2022-01-27T10:06:30Z,,2022-03-11T07:09:12Z,OPEN,False,1321,50,27,https://github.com/ferreram,Sfm-GPS BA,10,[],https://github.com/colmap/colmap/pull/1409,https://github.com/EwertzJN,8,https://github.com/colmap/colmap/pull/1409#issuecomment-1064186252,"Hey @ahojnnes ,
I have been working on directly adding prior motions (e.g. from GPS) into the Bundle Adjustment steps of Colmap.
It allows to use the priors on cameras' position directly in the incremental reconstruction as well as in pure BA.
This not ready to be merged yet but I wanted to know if you would feel like adding this option to Colmap and if so, I'd be glad to get your opinion on it.","I tried a little bit more and activated use_enu_coords(...) which initially leads to a more reasonable output. At least this is what this log suggests.
Unfortunately, however, the program always terminates with this error at this point:
F0310 14:49:53.567759 14702 parameter_block.h:186] Check failed: UpdatePlusJacobian() Manifold::PlusJacobian computation failed for x: -nan -nan -nan -nan
*** Check failure stack trace: ***
    @     0x7f6b31ec81c3  google::LogMessage::Fail()
    @     0x7f6b31ecd25b  google::LogMessage::SendToLog()
    @     0x7f6b31ec7ebf  google::LogMessage::Flush()
    @     0x7f6b31ec86ef  google::LogMessageFatal::~LogMessageFatal()
    @     0x55d1be352fa3  ceres::internal::ParameterBlock::SetManifold()
    @     0x55d1be34d56c  ceres::internal::ProblemImpl::InternalSetParameterization()
    @     0x55d1be34d72d  ceres::internal::ProblemImpl::SetParameterization()
    @     0x55d1bd91cafe  colmap::BundleAdjuster::AddImageToProblem()
    @     0x55d1bd91c0c0  colmap::BundleAdjuster::SetUp()
    @     0x55d1bd91b73b  colmap::BundleAdjuster::Solve()
    @     0x55d1bda33760  colmap::IncrementalMapper::AdjustGlobalBundle()
    @     0x55d1bd758bb7  colmap::(anonymous namespace)::AdjustGlobalBundle()
    @     0x55d1bd7590c8  colmap::(anonymous namespace)::IterativeGlobalRefinement()
    @     0x55d1bd75c412  colmap::IncrementalMapperController::Reconstruct()
    @     0x55d1bd75ac35  colmap::IncrementalMapperController::Run()
    @     0x55d1bdab31c8  colmap::Thread::RunFunc()
    @     0x55d1bdabaebe  std::__invoke_impl<>()
    @     0x55d1bdabad81  std::__invoke<>()
    @     0x55d1bdabac4f  _ZNSt6thread8_InvokerISt5tupleIJMN6colmap6ThreadEFvvEPS3_EEE9_M_invokeIJLm0ELm1EEEEvSt12_Index_tupleIJXspT_EEE
    @     0x55d1bdababc1  std::thread::_Invoker<>::operator()()
    @     0x55d1bdabab50  std::thread::_State_impl<>::_M_run()
    @     0x7f6b1646ade4  (unknown)
    @     0x7f6b16590609  start_thread
    @     0x7f6b16115163  clone
Signal: SIGABRT (Aborted)

Therefore, I took a closer look at the program flow with a debugger. I came to the conclusion that the problem is that qvec_data in line 441 of src/optim/bundle_adjustment.cc is set to a vector containing -nan.
This is because on line 670 of src/base/reconstruction.h, transform is assigned a non-invertible matrix, which causes the reconstruction model transformation in the next line to assign [-nan -nan -nan -nan] to all qvec (see SimilarityTransform3::TransformPose(Eigen::Vector4d* qvec, Eigen::Vector3d* tvec) on line 215 of src/base/similarity_transform.cc). How it can happen that transform in line 670 of src/base/reconstruction.h is assigned with a non-invertible matrix at all, I unfortunately could not find out yet.
For reference, this is the non-invertible matrix I was talking about:
[          0,          0,          0,      24.04]
[          0,          0,          0,     -25.29]
[          0,          0,          0, -9.552e-05]
[          0,          0,          0,          1]",True,{}
colmap/colmap,https://github.com/colmap/colmap,1409,2022-01-27T10:06:30Z,,2022-03-11T07:09:12Z,OPEN,False,1321,50,27,https://github.com/ferreram,Sfm-GPS BA,10,[],https://github.com/colmap/colmap/pull/1409,https://github.com/ferreram,9,https://github.com/colmap/colmap/pull/1409#issuecomment-1064835463,"Hey @ahojnnes ,
I have been working on directly adding prior motions (e.g. from GPS) into the Bundle Adjustment steps of Colmap.
It allows to use the priors on cameras' position directly in the incremental reconstruction as well as in pure BA.
This not ready to be merged yet but I wanted to know if you would feel like adding this option to Colmap and if so, I'd be glad to get your opinion on it.",@EwertzJN thanks for your comments.  I have been quite busy lately but I'll try to find some time to get back into this soon.,True,{}
colmap/colmap,https://github.com/colmap/colmap,1410,2022-01-27T10:47:39Z,2022-01-27T12:17:29Z,2022-01-27T12:17:35Z,MERGED,True,22,4,1,https://github.com/ferreram,Updating geo-registration doc.,1,[],https://github.com/colmap/colmap/pull/1410,https://github.com/ferreram,1,https://github.com/colmap/colmap/pull/1410,Updated documentation to match current state of the model_aligner function.,Updated documentation to match current state of the model_aligner function.,True,{}
colmap/colmap,https://github.com/colmap/colmap,1410,2022-01-27T10:47:39Z,2022-01-27T12:17:29Z,2022-01-27T12:17:35Z,MERGED,True,22,4,1,https://github.com/ferreram,Updating geo-registration doc.,1,[],https://github.com/colmap/colmap/pull/1410,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/1410#issuecomment-1023147827,Updated documentation to match current state of the model_aligner function.,Thanks.,True,{}
colmap/colmap,https://github.com/colmap/colmap,1414,2022-01-31T12:50:50Z,2022-01-31T18:46:25Z,2022-02-08T09:40:26Z,MERGED,True,16,1,2,https://github.com/ferreram,Only apply sqlite vacuum command when elements are deleted from the database.,1,[],https://github.com/colmap/colmap/pull/1414,https://github.com/ferreram,1,https://github.com/colmap/colmap/pull/1414,"Fix for #1413 . Vacuum command was applied whenever the close function is called leading to important delay whenever accessing the database.  As the vacuum command is meant to decrease the size of db files by deleting allocated chunks of memory not used anymore, the PR only applies it when elements are deleted from the database.","Fix for #1413 . Vacuum command was applied whenever the close function is called leading to important delay whenever accessing the database.  As the vacuum command is meant to decrease the size of db files by deleting allocated chunks of memory not used anymore, the PR only applies it when elements are deleted from the database.",True,{}
colmap/colmap,https://github.com/colmap/colmap,1414,2022-01-31T12:50:50Z,2022-01-31T18:46:25Z,2022-02-08T09:40:26Z,MERGED,True,16,1,2,https://github.com/ferreram,Only apply sqlite vacuum command when elements are deleted from the database.,1,[],https://github.com/colmap/colmap/pull/1414,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/1414#issuecomment-1026094676,"Fix for #1413 . Vacuum command was applied whenever the close function is called leading to important delay whenever accessing the database.  As the vacuum command is meant to decrease the size of db files by deleting allocated chunks of memory not used anymore, the PR only applies it when elements are deleted from the database.","Setting mutable on fields is feels dangerous, as we are giving the false impression of not mutating the state of the object, which might be problematic when concurrently accessing it. I guess, we could ignore this problem in this specific case, as concurrent database access is anyway prohibited. Thanks for the fix.",True,{}
colmap/colmap,https://github.com/colmap/colmap,1414,2022-01-31T12:50:50Z,2022-01-31T18:46:25Z,2022-02-08T09:40:26Z,MERGED,True,16,1,2,https://github.com/ferreram,Only apply sqlite vacuum command when elements are deleted from the database.,1,[],https://github.com/colmap/colmap/pull/1414,https://github.com/wwh301,3,https://github.com/colmap/colmap/pull/1414#issuecomment-1032404840,"Fix for #1413 . Vacuum command was applied whenever the close function is called leading to important delay whenever accessing the database.  As the vacuum command is meant to decrease the size of db files by deleting allocated chunks of memory not used anymore, the PR only applies it when elements are deleted from the database.","Hi!
This fix a great problem!
But we guess why it needs 5~6 seconds to response, when opening ""Database management""->""Overlapping images"".
Do you met the same situation?
Thank you so much!",True,{}
colmap/colmap,https://github.com/colmap/colmap,1422,2022-02-13T21:42:06Z,2022-02-25T16:10:41Z,2022-02-25T16:10:42Z,MERGED,True,265,26621,85,https://github.com/ahojnnes,Replace Graclus with Metis dependency,11,[],https://github.com/colmap/colmap/pull/1422,https://github.com/ahojnnes,1,https://github.com/colmap/colmap/pull/1422,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,1430,2022-02-18T15:40:35Z,2022-02-25T19:52:14Z,2022-05-17T02:38:45Z,MERGED,True,4,4,1,https://github.com/whuaegeanse,Update ceres download URL in build script,2,[],https://github.com/colmap/colmap/pull/1430,https://github.com/whuaegeanse,1,https://github.com/colmap/colmap/pull/1430,Update build script for ceres solver 2.0.0,Update build script for ceres solver 2.0.0,True,{}
colmap/colmap,https://github.com/colmap/colmap,1440,2022-02-26T17:25:01Z,2022-02-27T07:36:58Z,2022-05-17T02:38:57Z,MERGED,True,5,5,1,https://github.com/whuaegeanse,Fix type errors when building colmap with build.py in windows,1,[],https://github.com/colmap/colmap/pull/1440,https://github.com/whuaegeanse,1,https://github.com/colmap/colmap/pull/1440,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,1440,2022-02-26T17:25:01Z,2022-02-27T07:36:58Z,2022-05-17T02:38:57Z,MERGED,True,5,5,1,https://github.com/whuaegeanse,Fix type errors when building colmap with build.py in windows,1,[],https://github.com/colmap/colmap/pull/1440,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/1440#issuecomment-1053302885,,thanks!,True,{}
colmap/colmap,https://github.com/colmap/colmap,1449,2022-03-05T09:54:07Z,2022-03-05T10:20:48Z,2022-05-17T02:39:03Z,MERGED,True,9,4,1,https://github.com/whuaegeanse,Fix bug in the computation of the statistics Global/Local BA,1,[],https://github.com/colmap/colmap/pull/1449,https://github.com/whuaegeanse,1,https://github.com/colmap/colmap/pull/1449,"Fix bug in the computation of the statistics for Global/Local BA.
The bug is reported in #1447","Fix bug in the computation of the statistics for Global/Local BA.
The bug is reported in #1447",True,{}
colmap/colmap,https://github.com/colmap/colmap,1449,2022-03-05T09:54:07Z,2022-03-05T10:20:48Z,2022-05-17T02:39:03Z,MERGED,True,9,4,1,https://github.com/whuaegeanse,Fix bug in the computation of the statistics Global/Local BA,1,[],https://github.com/colmap/colmap/pull/1449,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/1449#issuecomment-1059737281,"Fix bug in the computation of the statistics for Global/Local BA.
The bug is reported in #1447",Thanks for the fix!,True,{}
colmap/colmap,https://github.com/colmap/colmap,1454,2022-03-09T19:58:31Z,,2022-03-09T19:58:31Z,OPEN,False,1,1,1,https://github.com/ahojnnes,Set minimum required CMake version to 3.3,1,[],https://github.com/colmap/colmap/pull/1454,https://github.com/ahojnnes,1,https://github.com/colmap/colmap/pull/1454,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,1464,2022-03-16T13:31:03Z,2022-03-17T17:36:24Z,2022-03-17T17:36:24Z,MERGED,True,207,2,3,https://github.com/Skydes,Add RefineGeneralizedAbsolutePose and covariance estimation,6,[],https://github.com/colmap/colmap/pull/1464,https://github.com/Skydes,1,https://github.com/colmap/colmap/pull/1464,"Refine the absolute pose of camera rigs with RefineGeneralizedAbsolutePose`
Estimate the 6x6 covariance matrix of (qvec, tvec) for single and rig pose refinement
The code is clang-formatted
Cleaner interface than #1234","Refine the absolute pose of camera rigs with RefineGeneralizedAbsolutePose`
Estimate the 6x6 covariance matrix of (qvec, tvec) for single and rig pose refinement
The code is clang-formatted
Cleaner interface than #1234",True,{}
colmap/colmap,https://github.com/colmap/colmap,1477,2022-04-01T14:28:14Z,2022-04-01T20:30:18Z,2022-04-01T20:30:19Z,MERGED,True,51,51,6,https://github.com/ahojnnes,Upgrade deprecated ceres parameterizations to manifolds,2,[],https://github.com/colmap/colmap/pull/1477,https://github.com/ahojnnes,1,https://github.com/colmap/colmap/pull/1477,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,1478,2022-04-01T14:33:52Z,2022-04-01T17:11:34Z,2022-04-01T17:11:35Z,MERGED,True,6,7,3,https://github.com/ahojnnes,Update docker image definition,1,[],https://github.com/colmap/colmap/pull/1478,https://github.com/ahojnnes,1,https://github.com/colmap/colmap/pull/1478,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,1488,2022-04-12T15:49:50Z,2022-04-19T13:54:49Z,2022-04-19T20:05:08Z,MERGED,True,1,0,1,https://github.com/ibrarmalik,Use masks for stereo fusion on automatic reconstruction,1,[],https://github.com/colmap/colmap/pull/1488,https://github.com/ibrarmalik,1,https://github.com/colmap/colmap/pull/1488,"Hey @ahojnnes
The automatic reconstruction does not make use of the depth map masking (#1148), which I think makes sense if we have the masks available. Just a minor PR!","Hey @ahojnnes
The automatic reconstruction does not make use of the depth map masking (#1148), which I think makes sense if we have the masks available. Just a minor PR!",True,{}
colmap/colmap,https://github.com/colmap/colmap,1488,2022-04-12T15:49:50Z,2022-04-19T13:54:49Z,2022-04-19T20:05:08Z,MERGED,True,1,0,1,https://github.com/ibrarmalik,Use masks for stereo fusion on automatic reconstruction,1,[],https://github.com/colmap/colmap/pull/1488,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/1488#issuecomment-1102686718,"Hey @ahojnnes
The automatic reconstruction does not make use of the depth map masking (#1148), which I think makes sense if we have the masks available. Just a minor PR!","Thanks, makes sense.",True,{}
colmap/colmap,https://github.com/colmap/colmap,1491,2022-04-13T12:17:49Z,,2022-04-19T13:19:37Z,OPEN,False,73,1,1,https://github.com/alanb-sony,Fix memory leaks in Ply.h,1,[],https://github.com/colmap/colmap/pull/1491,https://github.com/alanb-sony,1,https://github.com/colmap/colmap/pull/1491,"PlyWritePolygons leaks some memory.
There is also an incorrect use of delete[] with memory allocated with malloc in PlyReadPolygons","PlyWritePolygons leaks some memory.
There is also an incorrect use of delete[] with memory allocated with malloc in PlyReadPolygons",True,{}
colmap/colmap,https://github.com/colmap/colmap,1491,2022-04-13T12:17:49Z,,2022-04-19T13:19:37Z,OPEN,False,73,1,1,https://github.com/alanb-sony,Fix memory leaks in Ply.h,1,[],https://github.com/colmap/colmap/pull/1491,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/1491#issuecomment-1102640225,"PlyWritePolygons leaks some memory.
There is also an incorrect use of delete[] with memory allocated with malloc in PlyReadPolygons",Thanks! Is this a fix that you copied over from the official poisson recon library or is it your custom fix?,True,{}
colmap/colmap,https://github.com/colmap/colmap,1491,2022-04-13T12:17:49Z,,2022-04-19T13:19:37Z,OPEN,False,73,1,1,https://github.com/alanb-sony,Fix memory leaks in Ply.h,1,[],https://github.com/colmap/colmap/pull/1491,https://github.com/alanb-sony,3,https://github.com/colmap/colmap/pull/1491#issuecomment-1102642338,"PlyWritePolygons leaks some memory.
There is also an incorrect use of delete[] with memory allocated with malloc in PlyReadPolygons",This is my own fix,True,{}
colmap/colmap,https://github.com/colmap/colmap,1494,2022-04-14T06:36:21Z,2022-04-20T06:41:26Z,2022-04-20T06:41:32Z,MERGED,True,2,2,1,https://github.com/nackjaylor,Replace deprecated Eigen nonZeros() call for most recent Eigen versions.,3,[],https://github.com/colmap/colmap/pull/1494,https://github.com/nackjaylor,1,https://github.com/colmap/colmap/pull/1494,"Hi team,
Small change proposed which allows COLMAP to be built from source on the most recent versions of Eigen.
Removal of nonZeros() call which was deprecated in https://gitlab.com/libeigen/eigen/-/commit/08da52eb8537107e2853452bb13c369856d1f84a corresponding to a redundant function call to size().
Issue: COLMAP does not build on Eigen 3.4.90 (and presumably sub-releases since above commit).
Fix: Adjust nonZeros() call to be size().
This is a somewhat interesting issue, because if COLMAP intends to check the number of non-zero elements, the original implementation seemingly did not do that. If the intention was indeed to check non-zero elements a custom check of the matrices is needed pending an appropriate fix in Eigen.
More details on the Eigen front here:
https://gitlab.com/libeigen/eigen/-/issues/2382
Happy to discuss any other workarounds you can think of.
Cheers,
Jack","Hi team,
Small change proposed which allows COLMAP to be built from source on the most recent versions of Eigen.
Removal of nonZeros() call which was deprecated in https://gitlab.com/libeigen/eigen/-/commit/08da52eb8537107e2853452bb13c369856d1f84a corresponding to a redundant function call to size().
Issue: COLMAP does not build on Eigen 3.4.90 (and presumably sub-releases since above commit).
Fix: Adjust nonZeros() call to be size().
This is a somewhat interesting issue, because if COLMAP intends to check the number of non-zero elements, the original implementation seemingly did not do that. If the intention was indeed to check non-zero elements a custom check of the matrices is needed pending an appropriate fix in Eigen.
More details on the Eigen front here:
https://gitlab.com/libeigen/eigen/-/issues/2382
Happy to discuss any other workarounds you can think of.
Cheers,
Jack",True,{}
colmap/colmap,https://github.com/colmap/colmap,1494,2022-04-14T06:36:21Z,2022-04-20T06:41:26Z,2022-04-20T06:41:32Z,MERGED,True,2,2,1,https://github.com/nackjaylor,Replace deprecated Eigen nonZeros() call for most recent Eigen versions.,3,[],https://github.com/colmap/colmap/pull/1494,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/1494#issuecomment-1102681537,"Hi team,
Small change proposed which allows COLMAP to be built from source on the most recent versions of Eigen.
Removal of nonZeros() call which was deprecated in https://gitlab.com/libeigen/eigen/-/commit/08da52eb8537107e2853452bb13c369856d1f84a corresponding to a redundant function call to size().
Issue: COLMAP does not build on Eigen 3.4.90 (and presumably sub-releases since above commit).
Fix: Adjust nonZeros() call to be size().
This is a somewhat interesting issue, because if COLMAP intends to check the number of non-zero elements, the original implementation seemingly did not do that. If the intention was indeed to check non-zero elements a custom check of the matrices is needed pending an appropriate fix in Eigen.
More details on the Eigen front here:
https://gitlab.com/libeigen/eigen/-/issues/2382
Happy to discuss any other workarounds you can think of.
Cheers,
Jack","Thanks for the fix, but the new logic is incorrect. The size of the column is always 3. If .nonZeros() is broken in latest Eigen versions, then we probably want something like .abs().sum() instead ?",True,{}
colmap/colmap,https://github.com/colmap/colmap,1494,2022-04-14T06:36:21Z,2022-04-20T06:41:26Z,2022-04-20T06:41:32Z,MERGED,True,2,2,1,https://github.com/nackjaylor,Replace deprecated Eigen nonZeros() call for most recent Eigen versions.,3,[],https://github.com/colmap/colmap/pull/1494,https://github.com/nackjaylor,3,https://github.com/colmap/colmap/pull/1494#issuecomment-1103197992,"Hi team,
Small change proposed which allows COLMAP to be built from source on the most recent versions of Eigen.
Removal of nonZeros() call which was deprecated in https://gitlab.com/libeigen/eigen/-/commit/08da52eb8537107e2853452bb13c369856d1f84a corresponding to a redundant function call to size().
Issue: COLMAP does not build on Eigen 3.4.90 (and presumably sub-releases since above commit).
Fix: Adjust nonZeros() call to be size().
This is a somewhat interesting issue, because if COLMAP intends to check the number of non-zero elements, the original implementation seemingly did not do that. If the intention was indeed to check non-zero elements a custom check of the matrices is needed pending an appropriate fix in Eigen.
More details on the Eigen front here:
https://gitlab.com/libeigen/eigen/-/issues/2382
Happy to discuss any other workarounds you can think of.
Cheers,
Jack","Thanks @ahojnnes !
Apologies, I should have been clearer: my initial fix was merely removing the redundant function call since as far as I can tell nonZeros() has always returned size() (i.e. nonZeros has always been misleading). I've taken this comment from the Eigen repo issue and included below which implies this:

Antonio Sánchez @cantonios · 4 months ago
Owner
Probably. Going back through blames, Gael introduced it over 12 years ago when creating Array.h, which then got factored out into DenseBase.h. It has always returned .size() for dense arrays. It's not particularly useful for dense objects, and I'd be surprised if it's ever actually used. My vote would be to remove it and see if anything breaks.

Checking through the file history on Gitlab to some random old commits, this looks to be the case. As you say, the size of these in COLMAP is always 3, which I believe means that the condition was never satisfied and those lines of code might not have ever run.
In any case: your proposed fix works, I've just used the inbuilt l1-norm to wrap it up together.",True,{}
colmap/colmap,https://github.com/colmap/colmap,1494,2022-04-14T06:36:21Z,2022-04-20T06:41:26Z,2022-04-20T06:41:32Z,MERGED,True,2,2,1,https://github.com/nackjaylor,Replace deprecated Eigen nonZeros() call for most recent Eigen versions.,3,[],https://github.com/colmap/colmap/pull/1494,https://github.com/ahojnnes,4,https://github.com/colmap/colmap/pull/1494#issuecomment-1103527094,"Hi team,
Small change proposed which allows COLMAP to be built from source on the most recent versions of Eigen.
Removal of nonZeros() call which was deprecated in https://gitlab.com/libeigen/eigen/-/commit/08da52eb8537107e2853452bb13c369856d1f84a corresponding to a redundant function call to size().
Issue: COLMAP does not build on Eigen 3.4.90 (and presumably sub-releases since above commit).
Fix: Adjust nonZeros() call to be size().
This is a somewhat interesting issue, because if COLMAP intends to check the number of non-zero elements, the original implementation seemingly did not do that. If the intention was indeed to check non-zero elements a custom check of the matrices is needed pending an appropriate fix in Eigen.
More details on the Eigen front here:
https://gitlab.com/libeigen/eigen/-/issues/2382
Happy to discuss any other workarounds you can think of.
Cheers,
Jack",Thanks!,True,"{'THUMBS_UP': ['https://github.com/nackjaylor'], 'HOORAY': ['https://github.com/nackjaylor']}"
colmap/colmap,https://github.com/colmap/colmap,1498,2022-04-19T07:18:23Z,2022-04-19T19:04:06Z,2022-04-19T19:04:07Z,MERGED,True,3,1,2,https://github.com/WZG3661,fix random seed set failed from external interface,2,[],https://github.com/colmap/colmap/pull/1498,https://github.com/WZG3661,1,https://github.com/colmap/colmap/pull/1498,"this will allow set random seed from external interface, like:
--random_seed 10
otherwise, random seed will always be defaulted value.","this will allow set random seed from external interface, like:
--random_seed 10
otherwise, random seed will always be defaulted value.",True,{}
colmap/colmap,https://github.com/colmap/colmap,1501,2022-04-22T15:39:41Z,2022-04-22T17:10:55Z,2022-04-22T17:14:24Z,MERGED,True,3,2,1,https://github.com/f-fl0,Fix ceres-solver folder name,1,[],https://github.com/colmap/colmap/pull/1501,https://github.com/f-fl0,1,https://github.com/colmap/colmap/pull/1501,"This PR fixes the following issue when trying to build the docker image:
./build.sh 
Sending build context to Docker daemon  239.6kB
Step 1/8 : FROM nvidia/cuda:11.6.0-devel-ubuntu20.04
 ---> 88f06c9c4dd4
Step 2/8 : ENV DEBIAN_FRONTEND=noninteractive
 ---> Using cache
 ---> e642ae3f706b
Step 3/8 : RUN apt-get update && apt-get install -y     git     cmake     build-essential     libboost-program-options-dev     libboost-filesystem-dev     libboost-graph-dev     libboost-system-dev     libboost-test-dev     libeigen3-dev     libsuitesparse-dev     libfreeimage-dev     libmetis-dev     libgoogle-glog-dev     libgflags-dev     libglew-dev     qtbase5-dev     libqt5opengl5-dev     libcgal-dev
 ---> Using cache
 ---> a77a22ace47f
Step 4/8 : RUN apt-get -y install     libatlas-base-dev     libsuitesparse-dev
 ---> Using cache
 ---> c9031a61c55d
Step 5/8 : RUN git clone https://github.com/ceres-solver/ceres-solver.git --tag 2.1.0
 ---> Using cache
 ---> 9064c456e9ec
Step 6/8 : RUN cd ceres-solver &&   mkdir build &&  cd build &&   cmake .. -DBUILD_TESTING=OFF -DBUILD_EXAMPLES=OFF &&  make -j4 &&   make install
 ---> Running in 1c0044ff599e
/bin/sh: 1: cd: can't cd to ceres-solver
The command '/bin/sh -c cd ceres-solver &&  mkdir build &&  cd build &&   cmake .. -DBUILD_TESTING=OFF -DBUILD_EXAMPLES=OFF &&  make -j4 &&   make install' returned a non-zero code: 2
root@c0175ae36593:/working#","This PR fixes the following issue when trying to build the docker image:
./build.sh 
Sending build context to Docker daemon  239.6kB
Step 1/8 : FROM nvidia/cuda:11.6.0-devel-ubuntu20.04
 ---> 88f06c9c4dd4
Step 2/8 : ENV DEBIAN_FRONTEND=noninteractive
 ---> Using cache
 ---> e642ae3f706b
Step 3/8 : RUN apt-get update && apt-get install -y     git     cmake     build-essential     libboost-program-options-dev     libboost-filesystem-dev     libboost-graph-dev     libboost-system-dev     libboost-test-dev     libeigen3-dev     libsuitesparse-dev     libfreeimage-dev     libmetis-dev     libgoogle-glog-dev     libgflags-dev     libglew-dev     qtbase5-dev     libqt5opengl5-dev     libcgal-dev
 ---> Using cache
 ---> a77a22ace47f
Step 4/8 : RUN apt-get -y install     libatlas-base-dev     libsuitesparse-dev
 ---> Using cache
 ---> c9031a61c55d
Step 5/8 : RUN git clone https://github.com/ceres-solver/ceres-solver.git --tag 2.1.0
 ---> Using cache
 ---> 9064c456e9ec
Step 6/8 : RUN cd ceres-solver &&   mkdir build &&  cd build &&   cmake .. -DBUILD_TESTING=OFF -DBUILD_EXAMPLES=OFF &&  make -j4 &&   make install
 ---> Running in 1c0044ff599e
/bin/sh: 1: cd: can't cd to ceres-solver
The command '/bin/sh -c cd ceres-solver &&  mkdir build &&  cd build &&   cmake .. -DBUILD_TESTING=OFF -DBUILD_EXAMPLES=OFF &&  make -j4 &&   make install' returned a non-zero code: 2
root@c0175ae36593:/working#",True,{}
colmap/colmap,https://github.com/colmap/colmap,1501,2022-04-22T15:39:41Z,2022-04-22T17:10:55Z,2022-04-22T17:14:24Z,MERGED,True,3,2,1,https://github.com/f-fl0,Fix ceres-solver folder name,1,[],https://github.com/colmap/colmap/pull/1501,https://github.com/ahojnnes,2,https://github.com/colmap/colmap/pull/1501#issuecomment-1106708056,"This PR fixes the following issue when trying to build the docker image:
./build.sh 
Sending build context to Docker daemon  239.6kB
Step 1/8 : FROM nvidia/cuda:11.6.0-devel-ubuntu20.04
 ---> 88f06c9c4dd4
Step 2/8 : ENV DEBIAN_FRONTEND=noninteractive
 ---> Using cache
 ---> e642ae3f706b
Step 3/8 : RUN apt-get update && apt-get install -y     git     cmake     build-essential     libboost-program-options-dev     libboost-filesystem-dev     libboost-graph-dev     libboost-system-dev     libboost-test-dev     libeigen3-dev     libsuitesparse-dev     libfreeimage-dev     libmetis-dev     libgoogle-glog-dev     libgflags-dev     libglew-dev     qtbase5-dev     libqt5opengl5-dev     libcgal-dev
 ---> Using cache
 ---> a77a22ace47f
Step 4/8 : RUN apt-get -y install     libatlas-base-dev     libsuitesparse-dev
 ---> Using cache
 ---> c9031a61c55d
Step 5/8 : RUN git clone https://github.com/ceres-solver/ceres-solver.git --tag 2.1.0
 ---> Using cache
 ---> 9064c456e9ec
Step 6/8 : RUN cd ceres-solver &&   mkdir build &&  cd build &&   cmake .. -DBUILD_TESTING=OFF -DBUILD_EXAMPLES=OFF &&  make -j4 &&   make install
 ---> Running in 1c0044ff599e
/bin/sh: 1: cd: can't cd to ceres-solver
The command '/bin/sh -c cd ceres-solver &&  mkdir build &&  cd build &&   cmake .. -DBUILD_TESTING=OFF -DBUILD_EXAMPLES=OFF &&  make -j4 &&   make install' returned a non-zero code: 2
root@c0175ae36593:/working#",Thanks!,True,{}
colmap/colmap,https://github.com/colmap/colmap,1505,2022-04-26T12:56:36Z,2022-04-26T13:46:47Z,2022-04-26T13:46:47Z,MERGED,True,4,3,1,https://github.com/ahojnnes,Improved convergence criterion for XYZ to ELL conversion,1,[],https://github.com/colmap/colmap/pull/1505,https://github.com/ahojnnes,1,https://github.com/colmap/colmap/pull/1505,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,1524,2022-05-17T02:37:37Z,2022-05-18T15:37:56Z,2022-05-18T17:03:02Z,MERGED,True,44,44,4,https://github.com/whuaegeanse,Avoid the calling of copy constructor/assignment,4,[],https://github.com/colmap/colmap/pull/1524,https://github.com/whuaegeanse,1,https://github.com/colmap/colmap/pull/1524,"Features in this PR:

Support move constructor when calling Push of JobQueue.
Avoid copy constructor when calling Pop of JobQueue.

Using the above features, we can avoid calling the copy constructor/assignment in tasks such as feature extraction/machining or meshing.","Features in this PR:

Support move constructor when calling Push of JobQueue.
Avoid copy constructor when calling Pop of JobQueue.

Using the above features, we can avoid calling the copy constructor/assignment in tasks such as feature extraction/machining or meshing.",True,{}
colmap/colmap,https://github.com/colmap/colmap,1525,2022-05-17T02:46:38Z,2022-05-17T10:07:43Z,2022-05-18T09:31:41Z,MERGED,True,3,2,1,https://github.com/whuaegeanse,Fix bug in the function SetPtr of Bitmap,1,[],https://github.com/colmap/colmap/pull/1525,https://github.com/whuaegeanse,1,https://github.com/colmap/colmap/pull/1525,,,True,{}
colmap/colmap,https://github.com/colmap/colmap,1531,2022-05-30T21:38:22Z,,2022-05-30T21:38:22Z,OPEN,False,1,1,1,https://github.com/Serenitysmk,Fix output tile reconstructions are the same as the input reconstruction in `RunModelSplitter` (#1513),1,[],https://github.com/colmap/colmap/pull/1531,https://github.com/Serenitysmk,1,https://github.com/colmap/colmap/pull/1531,"Hi @ahojnnes ,
this fixes the RunModelSplitter() function where the output tile reconstructions are the same as the input reconstruction.
many thanks for taking a look at it.","Hi @ahojnnes ,
this fixes the RunModelSplitter() function where the output tile reconstructions are the same as the input reconstruction.
many thanks for taking a look at it.",True,{}
