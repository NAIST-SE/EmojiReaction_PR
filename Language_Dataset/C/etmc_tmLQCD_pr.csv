etmc/tmLQCD,https://github.com/etmc/tmLQCD,309,2016-02-25T14:53:31Z,2016-07-06T11:57:44Z,2016-07-07T15:19:13Z,MERGED,True,410,145,12,https://github.com/kostrzewa,Additions for lib_wrapper and the QUDA interface,7,[],https://github.com/etmc/tmLQCD/pull/309,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/309,"Added EnableSubprocess option which allows the passing of an external
unique ID to tmLQCD_invert_init such that an external MPI program
can link against the SERIAL version of tmLQCD and the MPI id of the
calling program is passed along. For now, this is used only
for selecting the QUDA device, but could also be used for I/O
purposes or other special usecases. Introduces the global variable
g_external_id.
Added EnableLowmem option which initialises tmLQCD with only the
gauge field memory (no copy) and the essential geometry fields.
Useful for running with the QUDA interface on low memory machines
( < 64 GB RAM ). Lots of warnings are printed to warn the user
about what they are doing.
Switched to QUDA_NORMERR_*_SOLVE parameter in QUDA interface such
that the resduals between QUDA and tmLQCD match exactly. This
now solves (A A^dag) y = b -> x = A^dag y rather than
(A^dag A) x = A^dag b, just like tmLQCD.
Added quda_invert_direct function such that tmLQCD can be used
as a thin wrapper around the QUDA library with input and output
in the lexicographical tmLQCD ordering (TXYZsc) with pointers
to double. The input file must still be loaded and an operator
defined appropriately.","Added EnableSubprocess option which allows the passing of an external
unique ID to tmLQCD_invert_init such that an external MPI program
can link against the SERIAL version of tmLQCD and the MPI id of the
calling program is passed along. For now, this is used only
for selecting the QUDA device, but could also be used for I/O
purposes or other special usecases. Introduces the global variable
g_external_id.
Added EnableLowmem option which initialises tmLQCD with only the
gauge field memory (no copy) and the essential geometry fields.
Useful for running with the QUDA interface on low memory machines
( < 64 GB RAM ). Lots of warnings are printed to warn the user
about what they are doing.
Switched to QUDA_NORMERR_*_SOLVE parameter in QUDA interface such
that the resduals between QUDA and tmLQCD match exactly. This
now solves (A A^dag) y = b -> x = A^dag y rather than
(A^dag A) x = A^dag b, just like tmLQCD.
Added quda_invert_direct function such that tmLQCD can be used
as a thin wrapper around the QUDA library with input and output
in the lexicographical tmLQCD ordering (TXYZsc) with pointers
to double. The input file must still be loaded and an operator
defined appropriately.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,309,2016-02-25T14:53:31Z,2016-07-06T11:57:44Z,2016-07-07T15:19:13Z,MERGED,True,410,145,12,https://github.com/kostrzewa,Additions for lib_wrapper and the QUDA interface,7,[],https://github.com/etmc/tmLQCD/pull/309,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/309#issuecomment-203993430,"Added EnableSubprocess option which allows the passing of an external
unique ID to tmLQCD_invert_init such that an external MPI program
can link against the SERIAL version of tmLQCD and the MPI id of the
calling program is passed along. For now, this is used only
for selecting the QUDA device, but could also be used for I/O
purposes or other special usecases. Introduces the global variable
g_external_id.
Added EnableLowmem option which initialises tmLQCD with only the
gauge field memory (no copy) and the essential geometry fields.
Useful for running with the QUDA interface on low memory machines
( < 64 GB RAM ). Lots of warnings are printed to warn the user
about what they are doing.
Switched to QUDA_NORMERR_*_SOLVE parameter in QUDA interface such
that the resduals between QUDA and tmLQCD match exactly. This
now solves (A A^dag) y = b -> x = A^dag y rather than
(A^dag A) x = A^dag b, just like tmLQCD.
Added quda_invert_direct function such that tmLQCD can be used
as a thin wrapper around the QUDA library with input and output
in the lexicographical tmLQCD ordering (TXYZsc) with pointers
to double. The input file must still be loaded and an operator
defined appropriately.","Please do not merge yet, I will modify this somewhat so that it can also be used with MPI enabled.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,309,2016-02-25T14:53:31Z,2016-07-06T11:57:44Z,2016-07-07T15:19:13Z,MERGED,True,410,145,12,https://github.com/kostrzewa,Additions for lib_wrapper and the QUDA interface,7,[],https://github.com/etmc/tmLQCD/pull/309,https://github.com/urbach,3,https://github.com/etmc/tmLQCD/pull/309#issuecomment-221224752,"Added EnableSubprocess option which allows the passing of an external
unique ID to tmLQCD_invert_init such that an external MPI program
can link against the SERIAL version of tmLQCD and the MPI id of the
calling program is passed along. For now, this is used only
for selecting the QUDA device, but could also be used for I/O
purposes or other special usecases. Introduces the global variable
g_external_id.
Added EnableLowmem option which initialises tmLQCD with only the
gauge field memory (no copy) and the essential geometry fields.
Useful for running with the QUDA interface on low memory machines
( < 64 GB RAM ). Lots of warnings are printed to warn the user
about what they are doing.
Switched to QUDA_NORMERR_*_SOLVE parameter in QUDA interface such
that the resduals between QUDA and tmLQCD match exactly. This
now solves (A A^dag) y = b -> x = A^dag y rather than
(A^dag A) x = A^dag b, just like tmLQCD.
Added quda_invert_direct function such that tmLQCD can be used
as a thin wrapper around the QUDA library with input and output
in the lexicographical tmLQCD ordering (TXYZsc) with pointers
to double. The input file must still be loaded and an operator
defined appropriately.","hmm, has conflicts now, of course. Can this be merged now at some point?",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,309,2016-02-25T14:53:31Z,2016-07-06T11:57:44Z,2016-07-07T15:19:13Z,MERGED,True,410,145,12,https://github.com/kostrzewa,Additions for lib_wrapper and the QUDA interface,7,[],https://github.com/etmc/tmLQCD/pull/309,https://github.com/kostrzewa,4,https://github.com/etmc/tmLQCD/pull/309#issuecomment-221225387,"Added EnableSubprocess option which allows the passing of an external
unique ID to tmLQCD_invert_init such that an external MPI program
can link against the SERIAL version of tmLQCD and the MPI id of the
calling program is passed along. For now, this is used only
for selecting the QUDA device, but could also be used for I/O
purposes or other special usecases. Introduces the global variable
g_external_id.
Added EnableLowmem option which initialises tmLQCD with only the
gauge field memory (no copy) and the essential geometry fields.
Useful for running with the QUDA interface on low memory machines
( < 64 GB RAM ). Lots of warnings are printed to warn the user
about what they are doing.
Switched to QUDA_NORMERR_*_SOLVE parameter in QUDA interface such
that the resduals between QUDA and tmLQCD match exactly. This
now solves (A A^dag) y = b -> x = A^dag y rather than
(A^dag A) x = A^dag b, just like tmLQCD.
Added quda_invert_direct function such that tmLQCD can be used
as a thin wrapper around the QUDA library with input and output
in the lexicographical tmLQCD ordering (TXYZsc) with pointers
to double. The input file must still be loaded and an operator
defined appropriately.","sure, will resolve soon, maybe today",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,309,2016-02-25T14:53:31Z,2016-07-06T11:57:44Z,2016-07-07T15:19:13Z,MERGED,True,410,145,12,https://github.com/kostrzewa,Additions for lib_wrapper and the QUDA interface,7,[],https://github.com/etmc/tmLQCD/pull/309,https://github.com/kostrzewa,5,https://github.com/etmc/tmLQCD/pull/309#issuecomment-229607495,"Added EnableSubprocess option which allows the passing of an external
unique ID to tmLQCD_invert_init such that an external MPI program
can link against the SERIAL version of tmLQCD and the MPI id of the
calling program is passed along. For now, this is used only
for selecting the QUDA device, but could also be used for I/O
purposes or other special usecases. Introduces the global variable
g_external_id.
Added EnableLowmem option which initialises tmLQCD with only the
gauge field memory (no copy) and the essential geometry fields.
Useful for running with the QUDA interface on low memory machines
( < 64 GB RAM ). Lots of warnings are printed to warn the user
about what they are doing.
Switched to QUDA_NORMERR_*_SOLVE parameter in QUDA interface such
that the resduals between QUDA and tmLQCD match exactly. This
now solves (A A^dag) y = b -> x = A^dag y rather than
(A^dag A) x = A^dag b, just like tmLQCD.
Added quda_invert_direct function such that tmLQCD can be used
as a thin wrapper around the QUDA library with input and output
in the lexicographical tmLQCD ordering (TXYZsc) with pointers
to double. The input file must still be loaded and an operator
defined appropriately.","@urbach I've resolved the conflicts as far as I can tell. Because I need to do some stuff with peram_gen, it would be nice to merge this in soon. Cheers.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,309,2016-02-25T14:53:31Z,2016-07-06T11:57:44Z,2016-07-07T15:19:13Z,MERGED,True,410,145,12,https://github.com/kostrzewa,Additions for lib_wrapper and the QUDA interface,7,[],https://github.com/etmc/tmLQCD/pull/309,https://github.com/kostrzewa,6,https://github.com/etmc/tmLQCD/pull/309#issuecomment-229608853,"Added EnableSubprocess option which allows the passing of an external
unique ID to tmLQCD_invert_init such that an external MPI program
can link against the SERIAL version of tmLQCD and the MPI id of the
calling program is passed along. For now, this is used only
for selecting the QUDA device, but could also be used for I/O
purposes or other special usecases. Introduces the global variable
g_external_id.
Added EnableLowmem option which initialises tmLQCD with only the
gauge field memory (no copy) and the essential geometry fields.
Useful for running with the QUDA interface on low memory machines
( < 64 GB RAM ). Lots of warnings are printed to warn the user
about what they are doing.
Switched to QUDA_NORMERR_*_SOLVE parameter in QUDA interface such
that the resduals between QUDA and tmLQCD match exactly. This
now solves (A A^dag) y = b -> x = A^dag y rather than
(A^dag A) x = A^dag b, just like tmLQCD.
Added quda_invert_direct function such that tmLQCD can be used
as a thin wrapper around the QUDA library with input and output
in the lexicographical tmLQCD ordering (TXYZsc) with pointers
to double. The input file must still be loaded and an operator
defined appropriately.","I have to say, I don't like the lowmem and subprocess solutions, but I don't know how else to achieve the reduction in memory usage / ability to use single GPUs for highest efficiency differently...",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,309,2016-02-25T14:53:31Z,2016-07-06T11:57:44Z,2016-07-07T15:19:13Z,MERGED,True,410,145,12,https://github.com/kostrzewa,Additions for lib_wrapper and the QUDA interface,7,[],https://github.com/etmc/tmLQCD/pull/309,https://github.com/kostrzewa,7,https://github.com/etmc/tmLQCD/pull/309#issuecomment-229625403,"Added EnableSubprocess option which allows the passing of an external
unique ID to tmLQCD_invert_init such that an external MPI program
can link against the SERIAL version of tmLQCD and the MPI id of the
calling program is passed along. For now, this is used only
for selecting the QUDA device, but could also be used for I/O
purposes or other special usecases. Introduces the global variable
g_external_id.
Added EnableLowmem option which initialises tmLQCD with only the
gauge field memory (no copy) and the essential geometry fields.
Useful for running with the QUDA interface on low memory machines
( < 64 GB RAM ). Lots of warnings are printed to warn the user
about what they are doing.
Switched to QUDA_NORMERR_*_SOLVE parameter in QUDA interface such
that the resduals between QUDA and tmLQCD match exactly. This
now solves (A A^dag) y = b -> x = A^dag y rather than
(A^dag A) x = A^dag b, just like tmLQCD.
Added quda_invert_direct function such that tmLQCD can be used
as a thin wrapper around the QUDA library with input and output
in the lexicographical tmLQCD ordering (TXYZsc) with pointers
to double. The input file must still be loaded and an operator
defined appropriately.",There seem to be some compilation problems...,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,309,2016-02-25T14:53:31Z,2016-07-06T11:57:44Z,2016-07-07T15:19:13Z,MERGED,True,410,145,12,https://github.com/kostrzewa,Additions for lib_wrapper and the QUDA interface,7,[],https://github.com/etmc/tmLQCD/pull/309,https://github.com/urbach,8,https://github.com/etmc/tmLQCD/pull/309#issuecomment-230751516,"Added EnableSubprocess option which allows the passing of an external
unique ID to tmLQCD_invert_init such that an external MPI program
can link against the SERIAL version of tmLQCD and the MPI id of the
calling program is passed along. For now, this is used only
for selecting the QUDA device, but could also be used for I/O
purposes or other special usecases. Introduces the global variable
g_external_id.
Added EnableLowmem option which initialises tmLQCD with only the
gauge field memory (no copy) and the essential geometry fields.
Useful for running with the QUDA interface on low memory machines
( < 64 GB RAM ). Lots of warnings are printed to warn the user
about what they are doing.
Switched to QUDA_NORMERR_*_SOLVE parameter in QUDA interface such
that the resduals between QUDA and tmLQCD match exactly. This
now solves (A A^dag) y = b -> x = A^dag y rather than
(A^dag A) x = A^dag b, just like tmLQCD.
Added quda_invert_direct function such that tmLQCD can be used
as a thin wrapper around the QUDA library with input and output
in the lexicographical tmLQCD ordering (TXYZsc) with pointers
to double. The input file must still be loaded and an operator
defined appropriately.","okay, looks okay to me. Someone should test this on GPUs, though. I'll pull it in, because I think it does not affect anything else.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,309,2016-02-25T14:53:31Z,2016-07-06T11:57:44Z,2016-07-07T15:19:13Z,MERGED,True,410,145,12,https://github.com/kostrzewa,Additions for lib_wrapper and the QUDA interface,7,[],https://github.com/etmc/tmLQCD/pull/309,https://github.com/kostrzewa,9,https://github.com/etmc/tmLQCD/pull/309#issuecomment-231098260,"Added EnableSubprocess option which allows the passing of an external
unique ID to tmLQCD_invert_init such that an external MPI program
can link against the SERIAL version of tmLQCD and the MPI id of the
calling program is passed along. For now, this is used only
for selecting the QUDA device, but could also be used for I/O
purposes or other special usecases. Introduces the global variable
g_external_id.
Added EnableLowmem option which initialises tmLQCD with only the
gauge field memory (no copy) and the essential geometry fields.
Useful for running with the QUDA interface on low memory machines
( < 64 GB RAM ). Lots of warnings are printed to warn the user
about what they are doing.
Switched to QUDA_NORMERR_*_SOLVE parameter in QUDA interface such
that the resduals between QUDA and tmLQCD match exactly. This
now solves (A A^dag) y = b -> x = A^dag y rather than
(A^dag A) x = A^dag b, just like tmLQCD.
Added quda_invert_direct function such that tmLQCD can be used
as a thin wrapper around the QUDA library with input and output
in the lexicographical tmLQCD ordering (TXYZsc) with pointers
to double. The input file must still be loaded and an operator
defined appropriately.","It affects anyone using lib_wrapper because the signature of tmLQCD_invert_init has changed, other than that, you are correct.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,309,2016-02-25T14:53:31Z,2016-07-06T11:57:44Z,2016-07-07T15:19:13Z,MERGED,True,410,145,12,https://github.com/kostrzewa,Additions for lib_wrapper and the QUDA interface,7,[],https://github.com/etmc/tmLQCD/pull/309,https://github.com/urbach,10,https://github.com/etmc/tmLQCD/pull/309#issuecomment-231105104,"Added EnableSubprocess option which allows the passing of an external
unique ID to tmLQCD_invert_init such that an external MPI program
can link against the SERIAL version of tmLQCD and the MPI id of the
calling program is passed along. For now, this is used only
for selecting the QUDA device, but could also be used for I/O
purposes or other special usecases. Introduces the global variable
g_external_id.
Added EnableLowmem option which initialises tmLQCD with only the
gauge field memory (no copy) and the essential geometry fields.
Useful for running with the QUDA interface on low memory machines
( < 64 GB RAM ). Lots of warnings are printed to warn the user
about what they are doing.
Switched to QUDA_NORMERR_*_SOLVE parameter in QUDA interface such
that the resduals between QUDA and tmLQCD match exactly. This
now solves (A A^dag) y = b -> x = A^dag y rather than
(A^dag A) x = A^dag b, just like tmLQCD.
Added quda_invert_direct function such that tmLQCD can be used
as a thin wrapper around the QUDA library with input and output
in the lexicographical tmLQCD ordering (TXYZsc) with pointers
to double. The input file must still be loaded and an operator
defined appropriately.","We could also print only the hash. ..
On 7 July 2016 16:40:52 CEST, Bartosz Kostrzewa notifications@github.com wrote:

It affects anyone using lib_wrapper because the signature of
tmLQCD_invert_init has changed, other than that, you are correct.

You are receiving this because you modified the open/close state.
Reply to this email directly or view it on GitHub:
#309 (comment)

Carsten Urbach, www.carsten-urbach.eu",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,309,2016-02-25T14:53:31Z,2016-07-06T11:57:44Z,2016-07-07T15:19:13Z,MERGED,True,410,145,12,https://github.com/kostrzewa,Additions for lib_wrapper and the QUDA interface,7,[],https://github.com/etmc/tmLQCD/pull/309,https://github.com/kostrzewa,11,https://github.com/etmc/tmLQCD/pull/309#issuecomment-231110380,"Added EnableSubprocess option which allows the passing of an external
unique ID to tmLQCD_invert_init such that an external MPI program
can link against the SERIAL version of tmLQCD and the MPI id of the
calling program is passed along. For now, this is used only
for selecting the QUDA device, but could also be used for I/O
purposes or other special usecases. Introduces the global variable
g_external_id.
Added EnableLowmem option which initialises tmLQCD with only the
gauge field memory (no copy) and the essential geometry fields.
Useful for running with the QUDA interface on low memory machines
( < 64 GB RAM ). Lots of warnings are printed to warn the user
about what they are doing.
Switched to QUDA_NORMERR_*_SOLVE parameter in QUDA interface such
that the resduals between QUDA and tmLQCD match exactly. This
now solves (A A^dag) y = b -> x = A^dag y rather than
(A^dag A) x = A^dag b, just like tmLQCD.
Added quda_invert_direct function such that tmLQCD can be used
as a thin wrapper around the QUDA library with input and output
in the lexicographical tmLQCD ordering (TXYZsc) with pointers
to double. The input file must still be loaded and an operator
defined appropriately.","We could also print only the hash. ..

I was referring to the quda_interface additions that I did (+ lowmem and subprocess mode). The latter adds the ""external ID"" as one of the arguments of tmLQCD_invert_init",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,311,2016-03-13T09:43:58Z,2016-03-15T16:57:40Z,2016-03-15T16:57:40Z,MERGED,True,12,12,1,https://github.com/kostrzewa,update_tm reversibility check,1,[],https://github.com/etmc/tmLQCD/pull/311,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/311,"add trajectory counter to return_check.data and provide a number also for the relative reversibility violation, ddh/dh, in addition to ddh/H","add trajectory counter to return_check.data and provide a number also for the relative reversibility violation, ddh/dh, in addition to ddh/H",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,312,2016-03-16T11:03:53Z,2016-03-17T12:58:36Z,2017-03-15T15:46:43Z,MERGED,True,102,57,1,https://github.com/kostrzewa,benchmark: estimate appropriate number of iterations and give structured output,2,[],https://github.com/etmc/tmLQCD/pull/312,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/312,"both for E/O H and D_psi, estimate the number of iterations required for ~31 seconds of benchmarking time and provide more structured output, appropriate for preparing scaling information for computer time applications
further down the line this needs to be cleaned up and provide benchmarking interfaces for complete operators, including little_D if possible","both for E/O H and D_psi, estimate the number of iterations required for ~31 seconds of benchmarking time and provide more structured output, appropriate for preparing scaling information for computer time applications
further down the line this needs to be cleaned up and provide benchmarking interfaces for complete operators, including little_D if possible",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,313,2016-03-16T14:27:04Z,2016-03-17T16:04:37Z,2016-03-17T16:04:37Z,MERGED,True,41,32,2,https://github.com/kostrzewa,rg_mixed_cg_her: respect maximum number of iterations,1,[],https://github.com/etmc/tmLQCD/pull/313,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/313,respect the maximum number of iterations defined in input file and adjust computation of maximum number of outer iterations somewhat,respect the maximum number of iterations defined in input file and adjust computation of maximum number of outer iterations somewhat,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,315,2016-04-20T16:09:39Z,2016-04-21T10:50:23Z,2016-05-19T10:06:49Z,MERGED,True,2,4,1,https://github.com/kostrzewa,fix default solver type for ND monomial,1,[],https://github.com/etmc/tmLQCD/pull/315,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/315,"after adding RGMIXEDCG, the default solver type for the ND monomial was incorrect","after adding RGMIXEDCG, the default solver type for the ND monomial was incorrect",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,316,2016-04-21T09:13:52Z,2016-04-21T10:49:57Z,2016-05-19T10:06:41Z,MERGED,True,1,1,1,https://github.com/kostrzewa,correct trajectory metadata when reversibility check is performed,1,[],https://github.com/etmc/tmLQCD/pull/316,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/316,"When a reversibility check is performed, write the correct trajectory metadata into the configuration. Up to now this was set to -1 for some reason.","When a reversibility check is performed, write the correct trajectory metadata into the configuration. Up to now this was set to -1 for some reason.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,317,2016-04-30T15:47:02Z,2016-05-02T11:59:23Z,2016-05-19T10:07:02Z,MERGED,True,7,1,1,https://github.com/kostrzewa,lib_wrapper/tmLQCD_read_gauge: compute and display the plaquette value,1,[],https://github.com/etmc/tmLQCD/pull/317,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/317,,,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,318,2016-05-09T14:55:16Z,2016-05-10T08:50:21Z,2016-05-10T08:50:21Z,MERGED,True,154,9,6,https://github.com/urbach,Reweighting,4,[],https://github.com/etmc/tmLQCD/pull/318,https://github.com/urbach,1,https://github.com/etmc/tmLQCD/pull/318,stripped down cloverdetratio monomial for reweighting,stripped down cloverdetratio monomial for reweighting,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,318,2016-05-09T14:55:16Z,2016-05-10T08:50:21Z,2016-05-10T08:50:21Z,MERGED,True,154,9,6,https://github.com/urbach,Reweighting,4,[],https://github.com/etmc/tmLQCD/pull/318,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/318#issuecomment-218089395,stripped down cloverdetratio monomial for reweighting,"Actually, I think the input file reader does not expose kappa2 for the new monomial",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,318,2016-05-09T14:55:16Z,2016-05-10T08:50:21Z,2016-05-10T08:50:21Z,MERGED,True,154,9,6,https://github.com/urbach,Reweighting,4,[],https://github.com/etmc/tmLQCD/pull/318,https://github.com/urbach,3,https://github.com/etmc/tmLQCD/pull/318#issuecomment-218090271,stripped down cloverdetratio monomial for reweighting,"Actually, I think the input file reader does not expose kappa2 for the new monomial
It does, but there is another problem I don't understand...",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,319,2016-05-10T08:39:49Z,2016-05-10T08:49:42Z,2016-05-24T09:26:25Z,MERGED,True,9,9,1,https://github.com/urbach,check for quda inverter was outside operator loop,1,[],https://github.com/etmc/tmLQCD/pull/319,https://github.com/urbach,1,https://github.com/etmc/tmLQCD/pull/319,,,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,320,2016-05-10T09:13:41Z,2016-05-11T15:30:30Z,2016-05-11T15:35:40Z,MERGED,True,132,31,4,https://github.com/urbach,Reweighting,9,[],https://github.com/etmc/tmLQCD/pull/320,https://github.com/urbach,1,https://github.com/etmc/tmLQCD/pull/320,some more improvements,some more improvements,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,320,2016-05-10T09:13:41Z,2016-05-11T15:30:30Z,2016-05-11T15:35:40Z,MERGED,True,132,31,4,https://github.com/urbach,Reweighting,9,[],https://github.com/etmc/tmLQCD/pull/320,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/320#issuecomment-218104131,some more improvements,"In order to study the error scaling with the number of reweighting samples without having to rerun the full computation each time, I think it would be useful to extend the output further and either provide seperate files for each sample or a sample index in the output file. This of course also means extending the sum[j] and sum_sq[j] arrays with another index.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,320,2016-05-10T09:13:41Z,2016-05-11T15:30:30Z,2016-05-11T15:35:40Z,MERGED,True,132,31,4,https://github.com/urbach,Reweighting,9,[],https://github.com/etmc/tmLQCD/pull/320,https://github.com/urbach,3,https://github.com/etmc/tmLQCD/pull/320#issuecomment-218134950,some more improvements,"ah, the trlog part is still missing, isn't it?",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,320,2016-05-10T09:13:41Z,2016-05-11T15:30:30Z,2016-05-11T15:35:40Z,MERGED,True,132,31,4,https://github.com/urbach,Reweighting,9,[],https://github.com/etmc/tmLQCD/pull/320,https://github.com/kostrzewa,4,https://github.com/etmc/tmLQCD/pull/320#issuecomment-218136923,some more improvements,"True, with different kappas it doesn't cancel...",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,320,2016-05-10T09:13:41Z,2016-05-11T15:30:30Z,2016-05-11T15:35:40Z,MERGED,True,132,31,4,https://github.com/urbach,Reweighting,9,[],https://github.com/etmc/tmLQCD/pull/320,https://github.com/urbach,5,https://github.com/etmc/tmLQCD/pull/320#issuecomment-218142241,some more improvements,@kostrzewa could you crosscheck whether I got the signs correct?,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,320,2016-05-10T09:13:41Z,2016-05-11T15:30:30Z,2016-05-11T15:35:40Z,MERGED,True,132,31,4,https://github.com/urbach,Reweighting,9,[],https://github.com/etmc/tmLQCD/pull/320,https://github.com/kostrzewa,6,https://github.com/etmc/tmLQCD/pull/320#issuecomment-218495733,some more improvements,"Thanks, as discussed ""offline"", this looks fine now.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,321,2016-05-18T13:39:01Z,2016-05-18T13:44:24Z,2016-05-19T13:10:50Z,MERGED,True,3,3,3,https://github.com/urbach,remove g_ka_csw_8 to fix issue #274,1,[],https://github.com/etmc/tmLQCD/pull/321,https://github.com/urbach,1,https://github.com/etmc/tmLQCD/pull/321,fix issue #274,fix issue #274,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,322,2016-05-19T15:29:01Z,2016-05-22T12:14:11Z,2016-05-24T09:06:50Z,MERGED,True,655,659,151,https://github.com/urbach,Replace MPI macro definition,4,[],https://github.com/etmc/tmLQCD/pull/322,https://github.com/urbach,1,https://github.com/etmc/tmLQCD/pull/322,partly solves #314,partly solves #314,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,322,2016-05-19T15:29:01Z,2016-05-22T12:14:11Z,2016-05-24T09:06:50Z,MERGED,True,655,659,151,https://github.com/urbach,Replace MPI macro definition,4,[],https://github.com/etmc/tmLQCD/pull/322,https://github.com/urbach,2,https://github.com/etmc/tmLQCD/pull/322#issuecomment-220621135,partly solves #314,"what I did was to replace
""ifdef[blank]* MPI"" -> ""ifdef TM_USE_MPI""
""ifndef[blank]* MPI"" -> ""ifndef TM_USE_MPI""
""defined[blank]* MPI"" -> ""defined TM_USE_MPI""

and some manual replacements in the GPU directory. And of course corresponding changes to configure.in and config.h.in",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,322,2016-05-19T15:29:01Z,2016-05-22T12:14:11Z,2016-05-24T09:06:50Z,MERGED,True,655,659,151,https://github.com/urbach,Replace MPI macro definition,4,[],https://github.com/etmc/tmLQCD/pull/322,https://github.com/kostrzewa,3,https://github.com/etmc/tmLQCD/pull/322#issuecomment-220821894,partly solves #314,Conflicts from #323,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,322,2016-05-19T15:29:01Z,2016-05-22T12:14:11Z,2016-05-24T09:06:50Z,MERGED,True,655,659,151,https://github.com/urbach,Replace MPI macro definition,4,[],https://github.com/etmc/tmLQCD/pull/322,https://github.com/urbach,4,https://github.com/etmc/tmLQCD/pull/322#issuecomment-220824509,partly solves #314,"fixed!

Carsten Urbach
e-mail: curbach@gmx.de
urbach@hiskp.uni-bonn.de
Fon   : +49 (0)228 73 2379
skype : carsten.urbach
URL: http://www.carsten-urbach.eu",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,322,2016-05-19T15:29:01Z,2016-05-22T12:14:11Z,2016-05-24T09:06:50Z,MERGED,True,655,659,151,https://github.com/urbach,Replace MPI macro definition,4,[],https://github.com/etmc/tmLQCD/pull/322,https://github.com/kostrzewa,5,https://github.com/etmc/tmLQCD/pull/322#issuecomment-220828887,partly solves #314,"Looks okay to me, checked grep MPI *.c *.h */*.c */*.h | grep def | less",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,322,2016-05-19T15:29:01Z,2016-05-22T12:14:11Z,2016-05-24T09:06:50Z,MERGED,True,655,659,151,https://github.com/urbach,Replace MPI macro definition,4,[],https://github.com/etmc/tmLQCD/pull/322,https://github.com/kostrzewa,6,https://github.com/etmc/tmLQCD/pull/322#issuecomment-220829188,partly solves #314,"I'll merge this now. Propagating the changes to the interleaved branches will be a little bit tricky because of the three loop halfspinor hopping matrix, which will likely have to be adjusted manually.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,322,2016-05-19T15:29:01Z,2016-05-22T12:14:11Z,2016-05-24T09:06:50Z,MERGED,True,655,659,151,https://github.com/urbach,Replace MPI macro definition,4,[],https://github.com/etmc/tmLQCD/pull/322,https://github.com/urbach,7,https://github.com/etmc/tmLQCD/pull/322#issuecomment-220829328,partly solves #314,"True,  didn't think that far yet
On 22 May 2016 14:13:59 CEST, Bartosz Kostrzewa notifications@github.com wrote:

I'll merge this now. Propagating the changes to the interleaved
branches will be a little bit tricky because of the three loop
halfspinor hopping matrix, which will likely have to be adjusted
manually.

You are receiving this because you were assigned.
Reply to this email directly or view it on GitHub:
#322 (comment)

Carsten Urbach, www.carsten-urbach.eu",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,322,2016-05-19T15:29:01Z,2016-05-22T12:14:11Z,2016-05-24T09:06:50Z,MERGED,True,655,659,151,https://github.com/urbach,Replace MPI macro definition,4,[],https://github.com/etmc/tmLQCD/pull/322,https://github.com/urbach,8,https://github.com/etmc/tmLQCD/pull/322#issuecomment-221081052,partly solves #314,"so, indeed, the file halfspinor_body.c is causing problems in the interleaving branch. But it seems to me this can be fixed by just doing the replacements of the macros again in this file? What do you think @kostrzewa",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,322,2016-05-19T15:29:01Z,2016-05-22T12:14:11Z,2016-05-24T09:06:50Z,MERGED,True,655,659,151,https://github.com/urbach,Replace MPI macro definition,4,[],https://github.com/etmc/tmLQCD/pull/322,https://github.com/urbach,9,https://github.com/etmc/tmLQCD/pull/322#issuecomment-221085009,partly solves #314,see my branch testMerge which originates from the interleaved branch. Do you think halfspinor_body.c is okay like this?,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,322,2016-05-19T15:29:01Z,2016-05-22T12:14:11Z,2016-05-24T09:06:50Z,MERGED,True,655,659,151,https://github.com/urbach,Replace MPI macro definition,4,[],https://github.com/etmc/tmLQCD/pull/322,https://github.com/kostrzewa,10,https://github.com/etmc/tmLQCD/pull/322#issuecomment-221196444,partly solves #314,"@urbach

But it seems to me this can be fixed by just doing the replacements of the macros again in this file?

I agree, the ""natural"" way to resolve the merge conflict would be to choose the ""ours"" side of the merge for the two halfspinor bodies (64 and 32) and manually replace all mentions MPI and OMP.
However, halfspinor_body.c is fine (did a side-by-side diff, only differences are the macros), but halfspinor_body_32.c in your INDTC branch is missing the overlapping structure. When Florian re-implemted the 32 bit hopping matrix, he took a slightly different approach as well, which I preserved. (the main difference are some prefetches)
See here: https://github.com/kostrzewa/tmLQCD/blob/mixed_cg_merge_hmc_INDTC/operator/halfspinor_body_32.c",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,322,2016-05-19T15:29:01Z,2016-05-22T12:14:11Z,2016-05-24T09:06:50Z,MERGED,True,655,659,151,https://github.com/urbach,Replace MPI macro definition,4,[],https://github.com/etmc/tmLQCD/pull/322,https://github.com/urbach,11,https://github.com/etmc/tmLQCD/pull/322#issuecomment-221198152,partly solves #314,"so, which version of halfspinor_body_32.c I should start from then?",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,322,2016-05-19T15:29:01Z,2016-05-22T12:14:11Z,2016-05-24T09:06:50Z,MERGED,True,655,659,151,https://github.com/urbach,Replace MPI macro definition,4,[],https://github.com/etmc/tmLQCD/pull/322,https://github.com/kostrzewa,12,https://github.com/etmc/tmLQCD/pull/322#issuecomment-221198830,partly solves #314,"I think if you checkout the one from my mixed_cg_merge_hmc_INDTC branch into your testMerge branch and do the replacements, that should be fine. That's the version we have been using all this time.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,322,2016-05-19T15:29:01Z,2016-05-22T12:14:11Z,2016-05-24T09:06:50Z,MERGED,True,655,659,151,https://github.com/urbach,Replace MPI macro definition,4,[],https://github.com/etmc/tmLQCD/pull/322,https://github.com/urbach,13,https://github.com/etmc/tmLQCD/pull/322#issuecomment-221203880,partly solves #314,"okay, done...",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,322,2016-05-19T15:29:01Z,2016-05-22T12:14:11Z,2016-05-24T09:06:50Z,MERGED,True,655,659,151,https://github.com/urbach,Replace MPI macro definition,4,[],https://github.com/etmc/tmLQCD/pull/322,https://github.com/kostrzewa,14,https://github.com/etmc/tmLQCD/pull/322#issuecomment-221206412,partly solves #314,"Okay, thanks a lot!",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,322,2016-05-19T15:29:01Z,2016-05-22T12:14:11Z,2016-05-24T09:06:50Z,MERGED,True,655,659,151,https://github.com/urbach,Replace MPI macro definition,4,[],https://github.com/etmc/tmLQCD/pull/322,https://github.com/urbach,15,https://github.com/etmc/tmLQCD/pull/322#issuecomment-221207583,partly solves #314,"so, I'll merge this back to my interleaving branch, I guess...",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,322,2016-05-19T15:29:01Z,2016-05-22T12:14:11Z,2016-05-24T09:06:50Z,MERGED,True,655,659,151,https://github.com/urbach,Replace MPI macro definition,4,[],https://github.com/etmc/tmLQCD/pull/322,https://github.com/urbach,16,https://github.com/etmc/tmLQCD/pull/322#issuecomment-221209774,partly solves #314,done,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,323,2016-05-19T15:43:48Z,2016-05-22T09:06:12Z,2016-05-23T20:08:37Z,MERGED,True,627,627,100,https://github.com/urbach,replaced OMP macro with TM_USE_OMP macro,1,[],https://github.com/etmc/tmLQCD/pull/323,https://github.com/urbach,1,https://github.com/etmc/tmLQCD/pull/323,second part of issue #314,second part of issue #314,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,323,2016-05-19T15:43:48Z,2016-05-22T09:06:12Z,2016-05-23T20:08:37Z,MERGED,True,627,627,100,https://github.com/urbach,replaced OMP macro with TM_USE_OMP macro,1,[],https://github.com/etmc/tmLQCD/pull/323,https://github.com/urbach,2,https://github.com/etmc/tmLQCD/pull/323#issuecomment-220620818,second part of issue #314,"I replaced
""ifdef[blank]* OMP"" -> ""ifdef TM_USE_OMP""
""ifndef[blank]* OMP"" -> ""ifndef TM_USE_OMP""
""defined[blank]* OMP"" -> ""defined TM_USE_OMP""

in all files. And corresponding adaption of configure.in and config.h.in",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,323,2016-05-19T15:43:48Z,2016-05-22T09:06:12Z,2016-05-23T20:08:37Z,MERGED,True,627,627,100,https://github.com/urbach,replaced OMP macro with TM_USE_OMP macro,1,[],https://github.com/etmc/tmLQCD/pull/323,https://github.com/kostrzewa,3,https://github.com/etmc/tmLQCD/pull/323#issuecomment-220821833,second part of issue #314,"Looks fine to me and compiles, I didn't find any stale mentions of ""OMP"", pulling it in!",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,324,2016-05-19T16:13:04Z,2016-09-02T12:41:45Z,2016-09-02T12:41:45Z,MERGED,True,6,11,6,https://github.com/urbach,removed last instances of DUM_SOLVER,2,[],https://github.com/etmc/tmLQCD/pull/324,https://github.com/urbach,1,https://github.com/etmc/tmLQCD/pull/324,,,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,324,2016-05-19T16:13:04Z,2016-09-02T12:41:45Z,2016-09-02T12:41:45Z,MERGED,True,6,11,6,https://github.com/urbach,removed last instances of DUM_SOLVER,2,[],https://github.com/etmc/tmLQCD/pull/324,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/324#issuecomment-222231498,,"Hmm, do you think we should do something about this in general? DUM_DERI seems even stranger than DUM_SOLVER...",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,324,2016-05-19T16:13:04Z,2016-09-02T12:41:45Z,2016-09-02T12:41:45Z,MERGED,True,6,11,6,https://github.com/urbach,removed last instances of DUM_SOLVER,2,[],https://github.com/etmc/tmLQCD/pull/324,https://github.com/urbach,3,https://github.com/etmc/tmLQCD/pull/324#issuecomment-222235638,,"In principle, yes, but DUM_SOLVER I had removed more or less already some time ago.
Maybe I'll give the buffer thingy a go at some point.
On 27 May 2016 21:17:39 CEST, Bartosz Kostrzewa notifications@github.com wrote:

Hmm, do you think we should do something about this in general?
DUM_DERI seems even stranger than DUM_SOLVER...

You are receiving this because you authored the thread.
Reply to this email directly or view it on GitHub:
#324 (comment)

Carsten Urbach, www.carsten-urbach.eu",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,324,2016-05-19T16:13:04Z,2016-09-02T12:41:45Z,2016-09-02T12:41:45Z,MERGED,True,6,11,6,https://github.com/urbach,removed last instances of DUM_SOLVER,2,[],https://github.com/etmc/tmLQCD/pull/324,https://github.com/urbach,4,https://github.com/etmc/tmLQCD/pull/324#issuecomment-230753405,,I think this could be merged without affecting anything...,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,324,2016-05-19T16:13:04Z,2016-09-02T12:41:45Z,2016-09-02T12:41:45Z,MERGED,True,6,11,6,https://github.com/urbach,removed last instances of DUM_SOLVER,2,[],https://github.com/etmc/tmLQCD/pull/324,https://github.com/kostrzewa,5,https://github.com/etmc/tmLQCD/pull/324#issuecomment-244364051,,"Looks fine to me, I'll merge this now.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,325,2016-05-20T14:10:15Z,2016-05-20T14:20:54Z,2016-05-20T14:20:54Z,MERGED,True,48,45,5,https://github.com/kostrzewa,clean up source types for SourceInfo.type,1,[],https://github.com/etmc/tmLQCD/pull/325,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/325,"Add SRC_TYPE enum to io/params.h to have understandable values for the source type.
In addition, minor refactoring of invert.c","Add SRC_TYPE enum to io/params.h to have understandable values for the source type.
In addition, minor refactoring of invert.c",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,326,2016-05-22T12:24:45Z,2016-05-24T09:17:56Z,2016-05-24T09:18:24Z,MERGED,True,224,76,9,https://github.com/kostrzewa,merge pion <x> branch,21,[],https://github.com/etmc/tmLQCD/pull/326,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/326,,,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,326,2016-05-22T12:24:45Z,2016-05-24T09:17:56Z,2016-05-24T09:18:24Z,MERGED,True,224,76,9,https://github.com/kostrzewa,merge pion <x> branch,21,[],https://github.com/etmc/tmLQCD/pull/326,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/326#issuecomment-220853242,,I've added support for differing propagator and source filenames. It seems to work fine now. I also fixed some apparent logic bugs in the process.,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,326,2016-05-22T12:24:45Z,2016-05-24T09:17:56Z,2016-05-24T09:18:24Z,MERGED,True,224,76,9,https://github.com/kostrzewa,merge pion <x> branch,21,[],https://github.com/etmc/tmLQCD/pull/326,https://github.com/kostrzewa,3,https://github.com/etmc/tmLQCD/pull/326#issuecomment-221210389,,I believe this is fine now.,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,326,2016-05-22T12:24:45Z,2016-05-24T09:17:56Z,2016-05-24T09:18:24Z,MERGED,True,224,76,9,https://github.com/kostrzewa,merge pion <x> branch,21,[],https://github.com/etmc/tmLQCD/pull/326,https://github.com/urbach,4,https://github.com/etmc/tmLQCD/pull/326#issuecomment-221212477,,"okay, seems alright, I'm pulling this in now",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,326,2016-05-22T12:24:45Z,2016-05-24T09:17:56Z,2016-05-24T09:18:24Z,MERGED,True,224,76,9,https://github.com/kostrzewa,merge pion <x> branch,21,[],https://github.com/etmc/tmLQCD/pull/326,https://github.com/kostrzewa,5,https://github.com/etmc/tmLQCD/pull/326#issuecomment-221212603,,Thanks!,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,327,2016-05-24T08:50:42Z,2016-05-24T08:53:59Z,2016-05-24T08:56:30Z,MERGED,True,24,23,1,https://github.com/urbach,found overlooked instances of defined MPI,1,[],https://github.com/etmc/tmLQCD/pull/327,https://github.com/urbach,1,https://github.com/etmc/tmLQCD/pull/327,"we missed one instance of MPI, which was written as
defined(MPI)

which is corrected now","we missed one instance of MPI, which was written as
defined(MPI)

which is corrected now",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,327,2016-05-24T08:50:42Z,2016-05-24T08:53:59Z,2016-05-24T08:56:30Z,MERGED,True,24,23,1,https://github.com/urbach,found overlooked instances of defined MPI,1,[],https://github.com/etmc/tmLQCD/pull/327,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/327#issuecomment-221206715,"we missed one instance of MPI, which was written as
defined(MPI)

which is corrected now",Thanks!,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,329,2016-05-25T08:34:30Z,2016-05-25T08:37:30Z,2016-05-25T09:18:13Z,MERGED,True,5,0,1,https://github.com/kostrzewa,invert_clover_eo: logic for RGMIXEDCG was lost during deflation merge,1,[],https://github.com/etmc/tmLQCD/pull/329,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/329,,,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,329,2016-05-25T08:34:30Z,2016-05-25T08:37:30Z,2016-05-25T09:18:13Z,MERGED,True,5,0,1,https://github.com/kostrzewa,invert_clover_eo: logic for RGMIXEDCG was lost during deflation merge,1,[],https://github.com/etmc/tmLQCD/pull/329,https://github.com/urbach,2,https://github.com/etmc/tmLQCD/pull/329#issuecomment-221509071,,"merged!
Carsten Urbach
e-mail: curbach@gmx.de
urbach@hiskp.uni-bonn.de
Fon   : +49 (0)228 73 2379
skype : carsten.urbach
URL: http://www.carsten-urbach.eu",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,329,2016-05-25T08:34:30Z,2016-05-25T08:37:30Z,2016-05-25T09:18:13Z,MERGED,True,5,0,1,https://github.com/kostrzewa,invert_clover_eo: logic for RGMIXEDCG was lost during deflation merge,1,[],https://github.com/etmc/tmLQCD/pull/329,https://github.com/urbach,3,https://github.com/etmc/tmLQCD/pull/329#issuecomment-221518530,,invert_eo.c seems okay...,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,331,2016-05-31T09:46:05Z,2016-06-02T20:47:41Z,2016-06-02T20:47:41Z,MERGED,True,1,1,1,https://github.com/kostrzewa,invert: initialise the ranlux seed XOR'ed with nstore,1,[],https://github.com/etmc/tmLQCD/pull/331,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/331,for safety reasons it is probably better to initialise ranlux with the seed XOR'ed,for safety reasons it is probably better to initialise ranlux with the seed XOR'ed,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,332,2016-06-17T17:09:03Z,2016-06-17T17:38:31Z,2016-06-17T17:38:31Z,MERGED,True,8,7,1,https://github.com/urbach,Fix bytes to unsigned long int,2,[],https://github.com/etmc/tmLQCD/pull/332,https://github.com/urbach,1,https://github.com/etmc/tmLQCD/pull/332,,,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,334,2016-07-06T11:50:27Z,2016-09-02T13:53:51Z,2016-09-02T13:53:51Z,MERGED,True,22,18,9,https://github.com/urbach,Source Seed,2,[],https://github.com/etmc/tmLQCD/pull/334,https://github.com/urbach,1,https://github.com/etmc/tmLQCD/pull/334,"this is making the random numbers used in the function source_generation_pion_only depending on random_seed. Note that once this is merged, we loose reproducability to previous computations using pion times slice sources.","this is making the random numbers used in the function source_generation_pion_only depending on random_seed. Note that once this is merged, we loose reproducability to previous computations using pion times slice sources.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,334,2016-07-06T11:50:27Z,2016-09-02T13:53:51Z,2016-09-02T13:53:51Z,MERGED,True,22,18,9,https://github.com/urbach,Source Seed,2,[],https://github.com/etmc/tmLQCD/pull/334,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/334#issuecomment-244363563,"this is making the random numbers used in the function source_generation_pion_only depending on random_seed. Note that once this is merged, we loose reproducability to previous computations using pion times slice sources.","For the sequential propagator, do I understand correctly that in principle the choice of time slice is not yet available, but the interface has been prepared accordingly?",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,334,2016-07-06T11:50:27Z,2016-09-02T13:53:51Z,2016-09-02T13:53:51Z,MERGED,True,22,18,9,https://github.com/urbach,Source Seed,2,[],https://github.com/etmc/tmLQCD/pull/334,https://github.com/kostrzewa,3,https://github.com/etmc/tmLQCD/pull/334#issuecomment-244363609,"this is making the random numbers used in the function source_generation_pion_only depending on random_seed. Note that once this is merged, we loose reproducability to previous computations using pion times slice sources.","For the rest, I'm in favour of merging this.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,334,2016-07-06T11:50:27Z,2016-09-02T13:53:51Z,2016-09-02T13:53:51Z,MERGED,True,22,18,9,https://github.com/urbach,Source Seed,2,[],https://github.com/etmc/tmLQCD/pull/334,https://github.com/urbach,4,https://github.com/etmc/tmLQCD/pull/334#issuecomment-244378921,"this is making the random numbers used in the function source_generation_pion_only depending on random_seed. Note that once this is merged, we loose reproducability to previous computations using pion times slice sources.","okay, as discussed, go for it...",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,335,2016-07-06T12:07:41Z,2016-09-02T12:33:36Z,2016-09-02T12:33:36Z,MERGED,True,8,0,1,https://github.com/urbach,make lib_wrapper write parameters and git_hash to stdout and to parameter file,1,[],https://github.com/etmc/tmLQCD/pull/335,https://github.com/urbach,1,https://github.com/etmc/tmLQCD/pull/335,,,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,335,2016-07-06T12:07:41Z,2016-09-02T12:33:36Z,2016-09-02T12:33:36Z,MERGED,True,8,0,1,https://github.com/urbach,make lib_wrapper write parameters and git_hash to stdout and to parameter file,1,[],https://github.com/etmc/tmLQCD/pull/335,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/335#issuecomment-244362331,,"Looks good and compiles fine, merging.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,336,2016-08-04T15:34:23Z,2017-12-22T12:55:12Z,2017-12-22T12:55:12Z,CLOSED,False,126,56,9,https://github.com/kostrzewa,DO NOT MERGE first test of the ndrat monomial with a shift by shift solve,2,[],https://github.com/etmc/tmLQCD/pull/336,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/336,"first test of the ndrat monomial with a shift by shift solve rgmixedcg
I'm sure I'm doing something wrong, but would this work in principle? See solve_mms_nd. Generalisations need to be made for the non-clover matrix, of course, and it probably requires some special treatment for the acceptance step. DO NOT MERGE :)","first test of the ndrat monomial with a shift by shift solve rgmixedcg
I'm sure I'm doing something wrong, but would this work in principle? See solve_mms_nd. Generalisations need to be made for the non-clover matrix, of course, and it probably requires some special treatment for the acceptance step. DO NOT MERGE :)",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,336,2016-08-04T15:34:23Z,2017-12-22T12:55:12Z,2017-12-22T12:55:12Z,CLOSED,False,126,56,9,https://github.com/kostrzewa,DO NOT MERGE first test of the ndrat monomial with a shift by shift solve,2,[],https://github.com/etmc/tmLQCD/pull/336,https://github.com/urbach,2,https://github.com/etmc/tmLQCD/pull/336#issuecomment-237602046,"first test of the ndrat monomial with a shift by shift solve rgmixedcg
I'm sure I'm doing something wrong, but would this work in principle? See solve_mms_nd. Generalisations need to be made for the non-clover matrix, of course, and it probably requires some special treatment for the acceptance step. DO NOT MERGE :)","I don't quite understand yet, how its working...
You try to use rgmixedCG for all shifts in a given monomial?",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,336,2016-08-04T15:34:23Z,2017-12-22T12:55:12Z,2017-12-22T12:55:12Z,CLOSED,False,126,56,9,https://github.com/kostrzewa,DO NOT MERGE first test of the ndrat monomial with a shift by shift solve,2,[],https://github.com/etmc/tmLQCD/pull/336,https://github.com/kostrzewa,3,https://github.com/etmc/tmLQCD/pull/336#issuecomment-237603482,"first test of the ndrat monomial with a shift by shift solve rgmixedcg
I'm sure I'm doing something wrong, but would this work in principle? See solve_mms_nd. Generalisations need to be made for the non-clover matrix, of course, and it probably requires some special treatment for the acceptance step. DO NOT MERGE :)","For now, yes. This also makes sense for production purposes, since we often have the two lightest shifts on the coarsest timescale, while the other partial fractions are grouped by threes or fours, where the benefit of using shift by shift solves is not so obvious.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,336,2016-08-04T15:34:23Z,2017-12-22T12:55:12Z,2017-12-22T12:55:12Z,CLOSED,False,126,56,9,https://github.com/kostrzewa,DO NOT MERGE first test of the ndrat monomial with a shift by shift solve,2,[],https://github.com/etmc/tmLQCD/pull/336,https://github.com/urbach,4,https://github.com/etmc/tmLQCD/pull/336#issuecomment-237607718,"first test of the ndrat monomial with a shift by shift solve rgmixedcg
I'm sure I'm doing something wrong, but would this work in principle? See solve_mms_nd. Generalisations need to be made for the non-clover matrix, of course, and it probably requires some special treatment for the acceptance step. DO NOT MERGE :)","okay, I see.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,336,2016-08-04T15:34:23Z,2017-12-22T12:55:12Z,2017-12-22T12:55:12Z,CLOSED,False,126,56,9,https://github.com/kostrzewa,DO NOT MERGE first test of the ndrat monomial with a shift by shift solve,2,[],https://github.com/etmc/tmLQCD/pull/336,https://github.com/kostrzewa,5,https://github.com/etmc/tmLQCD/pull/336#issuecomment-238184406,"first test of the ndrat monomial with a shift by shift solve rgmixedcg
I'm sure I'm doing something wrong, but would this work in principle? See solve_mms_nd. Generalisations need to be made for the non-clover matrix, of course, and it probably requires some special treatment for the acceptance step. DO NOT MERGE :)","@sbacchio @Finkenrath @urbach
So this is my current solution for solving the multishift systems shift by shift. Choosing a different solver (see solve_mms_nd function) should be rather trivial at this point. It works, but it is not faster, not even for two shifts. The mixed ND solver is about a factor of 1.6 faster than CGMMS, which thus does not compensate for the number of systems to be solved. Of course, once DDalphaAMG is available, this should be beneficial for the smallest shifts.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,336,2016-08-04T15:34:23Z,2017-12-22T12:55:12Z,2017-12-22T12:55:12Z,CLOSED,False,126,56,9,https://github.com/kostrzewa,DO NOT MERGE first test of the ndrat monomial with a shift by shift solve,2,[],https://github.com/etmc/tmLQCD/pull/336,https://github.com/kostrzewa,6,https://github.com/etmc/tmLQCD/pull/336#issuecomment-238195038,"first test of the ndrat monomial with a shift by shift solve rgmixedcg
I'm sure I'm doing something wrong, but would this work in principle? See solve_mms_nd. Generalisations need to be made for the non-clover matrix, of course, and it probably requires some special treatment for the acceptance step. DO NOT MERGE :)","One could now think about taking the lightest or two lightest shifts out of the system and solve these using rgmixedcg, keeping a (more expensive) approximation with more shifts on one of the lower time scales. For this, one would have to study the individual forces though, I believe. One would probably also have to try to estimate which kind of splitting would be optimal. I don't think we can reduce the order, which is already lower than what the CLS consortium seems to use.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,336,2016-08-04T15:34:23Z,2017-12-22T12:55:12Z,2017-12-22T12:55:12Z,CLOSED,False,126,56,9,https://github.com/kostrzewa,DO NOT MERGE first test of the ndrat monomial with a shift by shift solve,2,[],https://github.com/etmc/tmLQCD/pull/336,https://github.com/kostrzewa,7,https://github.com/etmc/tmLQCD/pull/336#issuecomment-255054561,"first test of the ndrat monomial with a shift by shift solve rgmixedcg
I'm sure I'm doing something wrong, but would this work in principle? See solve_mms_nd. Generalisations need to be made for the non-clover matrix, of course, and it probably requires some special treatment for the acceptance step. DO NOT MERGE :)","I have been running a test of this on a 16c32 lattice to see if it causes any biases. Given the small lattice volume, it is a bit difficult to get the kind of statistical precision that would be required for a conclusive test, but the indication seems to be that the two runs are compatible:
Run with shift-by-shift in all ND*RAT monomials:
   L  T    kappa  csw   mul muh musigma mudelta N.online N.plaq skip
1 16 32 0.140065 1.74 0.003   0  0.1408  0.1521     3033   3077  250
                    val         dval     tauint    dtauint Wopt
mpcac_fit  2.009475e-04           NA         NA         NA   NA
mpcac_mc  -1.263659e-05 3.354550e-04  4.7928750 0.93257708   33
mpi        1.520504e-01 2.281873e-03  0.5738911 0.03565074    3
fpi        4.750034e-02 6.998057e-04  0.8957561 0.07700910    6
P          5.408100e-01 5.115257e-05 11.4906936 3.10007378   67
dH         3.154457e-03 1.779947e-03  0.4643404 0.01703494    1
expdH      1.001947e+00 1.758800e-03  0.4629396 0.01699503    1
mineval              NA           NA         NA         NA   NA
maxeval              NA           NA         NA         NA   NA
CG.iter              NA           NA         NA         NA   NA
accrate    9.603639e-01 3.462737e-03  0.4846341 0.01760439    1

Run with CGMSS in all ND*RAT monomials:
   L  T    kappa  csw   mul muh musigma mudelta N.online N.plaq skip
1 16 32 0.140065 1.74 0.003   0  0.1408  0.1521     1529   1573  250
                   val         dval    tauint    dtauint Wopt
mpcac_fit 0.0004999093           NA        NA         NA   NA
mpcac_mc  0.0004830610 2.687640e-04 1.7922657 0.31366429   13
mpi       0.1523535264 4.045645e-03 0.6864417 0.06856383    4
fpi       0.0481764620 1.277655e-03 1.1455753 0.14770256    7
P         0.5407039315 4.298916e-05 4.7628867 1.19418715   29
dH        0.0065529396 2.439074e-03 0.4645563 0.02383029    1
expdH     0.9982449711 2.305189e-03 0.4556316 0.02347299    1
mineval             NA           NA        NA         NA   NA
maxeval             NA           NA        NA         NA   NA
CG.iter             NA           NA        NA         NA   NA
accrate   0.9644218551 5.178730e-03 0.6146579 0.06107673    4

Keep in mind that the former is almost a factor of two longer than the latter. This is due to a scheduling policy on the machine, which effectively prevented the second run from running for the past three weeks or so.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,336,2016-08-04T15:34:23Z,2017-12-22T12:55:12Z,2017-12-22T12:55:12Z,CLOSED,False,126,56,9,https://github.com/kostrzewa,DO NOT MERGE first test of the ndrat monomial with a shift by shift solve,2,[],https://github.com/etmc/tmLQCD/pull/336,https://github.com/kostrzewa,8,https://github.com/etmc/tmLQCD/pull/336#issuecomment-353593184,"first test of the ndrat monomial with a shift by shift solve rgmixedcg
I'm sure I'm doing something wrong, but would this work in principle? See solve_mms_nd. Generalisations need to be made for the non-clover matrix, of course, and it probably requires some special treatment for the acceptance step. DO NOT MERGE :)","This will be merged via the DDalphaAMG_nd changes, closing this pull-request.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,337,2016-08-05T09:45:36Z,2016-08-05T11:55:04Z,2016-08-05T11:55:04Z,MERGED,True,1,1,1,https://github.com/kostrzewa,Hopping_Matrix_32: one forgotten instance of TM_USE_MPI,1,[],https://github.com/etmc/tmLQCD/pull/337,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/337,,,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,338,2016-08-08T15:16:20Z,2016-11-17T08:24:23Z,2016-11-17T08:24:23Z,MERGED,True,40,27,3,https://github.com/kostrzewa,read_spinor: add new flag 'DisableSourceIOChecks' ,2,[],https://github.com/etmc/tmLQCD/pull/338,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/338,"Allow the user to disable the IO check for the reading of sources,
independently from the gauge IO checks.
'DisableGaugeIOChecks' parameter added for consistency and
'DisableIOChecks' retained for backwards compatibility. The latter
disables only gauge IO checks, as it used to be.","Allow the user to disable the IO check for the reading of sources,
independently from the gauge IO checks.
'DisableGaugeIOChecks' parameter added for consistency and
'DisableIOChecks' retained for backwards compatibility. The latter
disables only gauge IO checks, as it used to be.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,338,2016-08-08T15:16:20Z,2016-11-17T08:24:23Z,2016-11-17T08:24:23Z,MERGED,True,40,27,3,https://github.com/kostrzewa,read_spinor: add new flag 'DisableSourceIOChecks' ,2,[],https://github.com/etmc/tmLQCD/pull/338,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/338#issuecomment-255119194,"Allow the user to disable the IO check for the reading of sources,
independently from the gauge IO checks.
'DisableGaugeIOChecks' parameter added for consistency and
'DisableIOChecks' retained for backwards compatibility. The latter
disables only gauge IO checks, as it used to be.",I would like to only merge this after the DDalphaAMG interface has been merged because there will be one conflict.,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,338,2016-08-08T15:16:20Z,2016-11-17T08:24:23Z,2016-11-17T08:24:23Z,MERGED,True,40,27,3,https://github.com/kostrzewa,read_spinor: add new flag 'DisableSourceIOChecks' ,2,[],https://github.com/etmc/tmLQCD/pull/338,https://github.com/kostrzewa,3,https://github.com/etmc/tmLQCD/pull/338#issuecomment-260929281,"Allow the user to disable the IO check for the reading of sources,
independently from the gauge IO checks.
'DisableGaugeIOChecks' parameter added for consistency and
'DisableIOChecks' retained for backwards compatibility. The latter
disables only gauge IO checks, as it used to be.","Updated this to modify the fix for the source io check introduced in the DDalphaAMG branch.
Note @sbacchio, @Finkenrath : this pull-request will add an additional input parameter DisableSourceIOChecks to disable the IO check for input / initial guess spinors.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,339,2016-09-07T09:53:10Z,2016-09-08T05:27:58Z,2016-09-08T05:27:58Z,MERGED,True,1,1,1,https://github.com/kostrzewa,"read_message(), forgotten instance of MPI -> TM_USE_MPI",1,[],https://github.com/etmc/tmLQCD/pull/339,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/339,,,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,339,2016-09-07T09:53:10Z,2016-09-08T05:27:58Z,2016-09-08T05:27:58Z,MERGED,True,1,1,1,https://github.com/kostrzewa,"read_message(), forgotten instance of MPI -> TM_USE_MPI",1,[],https://github.com/etmc/tmLQCD/pull/339,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/339#issuecomment-245255821,,"It might be that the LEMON problem that we observed on Jureca may have originated from this, although I'm not sure whether I had seen the problem also before we switched to TM_USE_MPI.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,340,2016-09-29T09:27:20Z,2016-11-17T08:24:59Z,2016-11-17T08:24:59Z,MERGED,True,1,1,1,https://github.com/kostrzewa,"monitor_forces: output 8 digits for force, otherwise large but steady",1,[],https://github.com/etmc/tmLQCD/pull/340,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/340," forces don't fluctuate, making analysis awkward"," forces don't fluctuate, making analysis awkward",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,340,2016-09-29T09:27:20Z,2016-11-17T08:24:59Z,2016-11-17T08:24:59Z,MERGED,True,1,1,1,https://github.com/kostrzewa,"monitor_forces: output 8 digits for force, otherwise large but steady",1,[],https://github.com/etmc/tmLQCD/pull/340,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/340#issuecomment-260929702," forces don't fluctuate, making analysis awkward","@urbach: would appreciate a merge of this at some point, cheers",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,342,2016-10-17T15:07:47Z,2016-10-17T15:09:16Z,2016-10-17T15:09:16Z,CLOSED,False,1123,24,29,https://github.com/sbacchio,merge of tmLQCD master,22,[],https://github.com/etmc/tmLQCD/pull/342,https://github.com/sbacchio,1,https://github.com/etmc/tmLQCD/pull/342,,,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,342,2016-10-17T15:07:47Z,2016-10-17T15:09:16Z,2016-10-17T15:09:16Z,CLOSED,False,1123,24,29,https://github.com/sbacchio,merge of tmLQCD master,22,[],https://github.com/etmc/tmLQCD/pull/342,https://github.com/sbacchio,2,https://github.com/etmc/tmLQCD/pull/342#issuecomment-254235650,,wrong I wanted to do the opposite,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,343,2016-10-20T11:07:39Z,2016-11-16T11:56:59Z,2016-11-16T11:56:59Z,MERGED,True,1496,84,37,https://github.com/sbacchio,Merging DDalphaAMG interface to etmc/tmLQCD master,37,[],https://github.com/etmc/tmLQCD/pull/343,https://github.com/sbacchio,1,https://github.com/etmc/tmLQCD/pull/343,,,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,343,2016-10-20T11:07:39Z,2016-11-16T11:56:59Z,2016-11-16T11:56:59Z,MERGED,True,1496,84,37,https://github.com/sbacchio,Merging DDalphaAMG interface to etmc/tmLQCD master,37,[],https://github.com/etmc/tmLQCD/pull/343,https://github.com/sbacchio,2,https://github.com/etmc/tmLQCD/pull/343#issuecomment-255076760,,"I cannot solve the conflict, I don't have write access.
@urbach @kostrzewa you should complete the merge.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,343,2016-10-20T11:07:39Z,2016-11-16T11:56:59Z,2016-11-16T11:56:59Z,MERGED,True,1496,84,37,https://github.com/sbacchio,Merging DDalphaAMG interface to etmc/tmLQCD master,37,[],https://github.com/etmc/tmLQCD/pull/343,https://github.com/kostrzewa,3,https://github.com/etmc/tmLQCD/pull/343#issuecomment-255077051,,The conflict should be resolved on the requesting side.,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,343,2016-10-20T11:07:39Z,2016-11-16T11:56:59Z,2016-11-16T11:56:59Z,MERGED,True,1496,84,37,https://github.com/sbacchio,Merging DDalphaAMG interface to etmc/tmLQCD master,37,[],https://github.com/etmc/tmLQCD/pull/343,https://github.com/sbacchio,4,https://github.com/etmc/tmLQCD/pull/343#issuecomment-255077348,,you mean I should before merge the etmc master to Finkenrath master and then do the pull request?,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,343,2016-10-20T11:07:39Z,2016-11-16T11:56:59Z,2016-11-16T11:56:59Z,MERGED,True,1496,84,37,https://github.com/sbacchio,Merging DDalphaAMG interface to etmc/tmLQCD master,37,[],https://github.com/etmc/tmLQCD/pull/343,https://github.com/kostrzewa,5,https://github.com/etmc/tmLQCD/pull/343#issuecomment-255077532,,"you mean I should before merge the etmc master to Finkenrath master and then do the pull request?

Yes, that's how one would usually do it. Alternatively, one can also rebase, but that becomes difficult when there are many changes.",True,{'THUMBS_UP': ['https://github.com/sbacchio']}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,343,2016-10-20T11:07:39Z,2016-11-16T11:56:59Z,2016-11-16T11:56:59Z,MERGED,True,1496,84,37,https://github.com/sbacchio,Merging DDalphaAMG interface to etmc/tmLQCD master,37,[],https://github.com/etmc/tmLQCD/pull/343,https://github.com/urbach,6,https://github.com/etmc/tmLQCD/pull/343#issuecomment-255077607,,"you mean I should before merge the etmc master to Finkenrath master and then do the pull request?

yes...


You are receiving this because you were mentioned.
Reply to this email directly or view it on GitHub:
#343 (comment)
Carsten Urbach
e-mail: curbach@gmx.de
urbach@hiskp.uni-bonn.de
Fon   : +49 (0)228 73 2379
skype : carsten.urbach
URL: http://www.carsten-urbach.eu",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,343,2016-10-20T11:07:39Z,2016-11-16T11:56:59Z,2016-11-16T11:56:59Z,MERGED,True,1496,84,37,https://github.com/sbacchio,Merging DDalphaAMG interface to etmc/tmLQCD master,37,[],https://github.com/etmc/tmLQCD/pull/343,https://github.com/kostrzewa,7,https://github.com/etmc/tmLQCD/pull/343#issuecomment-255077737,,"You can keep the pull request open, any changes that you commit to Finkenrath/tmLQCD/master will automatically propagate here.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,343,2016-10-20T11:07:39Z,2016-11-16T11:56:59Z,2016-11-16T11:56:59Z,MERGED,True,1496,84,37,https://github.com/sbacchio,Merging DDalphaAMG interface to etmc/tmLQCD master,37,[],https://github.com/etmc/tmLQCD/pull/343,https://github.com/sbacchio,8,https://github.com/etmc/tmLQCD/pull/343#issuecomment-255354606,,"I've pushed a new version. I've added the changes we have agreed and as well some improvements in the heatbath and acceptance step. There, indeed, the inversion of the squared operator was called in the MG, when the non squared is enough.
@kostrzewa @urbach: please, check if the use of the chrono function is still fine.. I've tried to understand how they work but I'm not sure if I applied the change correctly there.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,343,2016-10-20T11:07:39Z,2016-11-16T11:56:59Z,2016-11-16T11:56:59Z,MERGED,True,1496,84,37,https://github.com/sbacchio,Merging DDalphaAMG interface to etmc/tmLQCD master,37,[],https://github.com/etmc/tmLQCD/pull/343,https://github.com/kostrzewa,9,https://github.com/etmc/tmLQCD/pull/343#issuecomment-255356090,,"@urbach , could you look into this?

@kostrzewa @urbach: please, check if the use of the chrono function is still fine.. I've tried to understand how they work but I'm not sure if I applied the change correctly there.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,343,2016-10-20T11:07:39Z,2016-11-16T11:56:59Z,2016-11-16T11:56:59Z,MERGED,True,1496,84,37,https://github.com/sbacchio,Merging DDalphaAMG interface to etmc/tmLQCD master,37,[],https://github.com/etmc/tmLQCD/pull/343,https://github.com/kostrzewa,10,https://github.com/etmc/tmLQCD/pull/343#issuecomment-255750703,,"I noticed a problem which I don't quite understand. When I do multiple inversions (random samples or some point sources, say), I need to set MGUpdateSetupIter=0, otherwise MG_pre_solve will call MG_update_mu() and DDalphaAMG_update_setup() between each inversion even though the gauge configuration was not changed...
I believe this could be fixed by setting the default for mg_update_setup_iter to 0, rather than the current 1. If that is undesirable (because it will complicate the HMC logic), then the interface should know that the gauge configuration has not been changed...",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,343,2016-10-20T11:07:39Z,2016-11-16T11:56:59Z,2016-11-16T11:56:59Z,MERGED,True,1496,84,37,https://github.com/sbacchio,Merging DDalphaAMG interface to etmc/tmLQCD master,37,[],https://github.com/etmc/tmLQCD/pull/343,https://github.com/kostrzewa,11,https://github.com/etmc/tmLQCD/pull/343#issuecomment-255750896,,"Maybe the big if condition in MG_pre_solve contains a logic bug, not sure.",True,{'THUMBS_UP': ['https://github.com/sbacchio']}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,343,2016-10-20T11:07:39Z,2016-11-16T11:56:59Z,2016-11-16T11:56:59Z,MERGED,True,1496,84,37,https://github.com/sbacchio,Merging DDalphaAMG interface to etmc/tmLQCD master,37,[],https://github.com/etmc/tmLQCD/pull/343,https://github.com/kostrzewa,12,https://github.com/etmc/tmLQCD/pull/343#issuecomment-256016808,,"For MGMixedPrecision = yes, I experience rather frequent ""converged to the wrong solution"" errors. I also don't really see a performance benefit of using a mixed-precision solver, or was your experience different? (This is using the latest version of DDalphaAMG which includes the global reduction)
Note that the solution is rarely worse than a factor of 3 off from the expected result, accepting it would certainly not be catastrophic.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,343,2016-10-20T11:07:39Z,2016-11-16T11:56:59Z,2016-11-16T11:56:59Z,MERGED,True,1496,84,37,https://github.com/sbacchio,Merging DDalphaAMG interface to etmc/tmLQCD master,37,[],https://github.com/etmc/tmLQCD/pull/343,https://github.com/sbacchio,13,https://github.com/etmc/tmLQCD/pull/343#issuecomment-256261465,,"For MGMixedPrecision = yes, I experience rather frequent ""converged to the wrong solution"" errors. I also don't really see a performance benefit of using a mixed-precision solver, or was your experience different? (This is using the latest version of DDalphaAMG which includes the global reduction)

Sincerely I don't know anymore.. At the beginning I was noticing an improvement but I understand that now maybe it's not anymore. And moreover with the 1+1 implementation the mixed precision solver is not working well at all (but I think due still to some bug). Anyway after this work I will review the mixed precision performance (but I've planned before the AVX implementation).",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,343,2016-10-20T11:07:39Z,2016-11-16T11:56:59Z,2016-11-16T11:56:59Z,MERGED,True,1496,84,37,https://github.com/sbacchio,Merging DDalphaAMG interface to etmc/tmLQCD master,37,[],https://github.com/etmc/tmLQCD/pull/343,https://github.com/sbacchio,14,https://github.com/etmc/tmLQCD/pull/343#issuecomment-256262088,,Can we please go ahead with the merge? I've some new changes to push but I was waiting first the review of @urbach specially about the changing in monomial/* where the chronological solver is involved.,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,343,2016-10-20T11:07:39Z,2016-11-16T11:56:59Z,2016-11-16T11:56:59Z,MERGED,True,1496,84,37,https://github.com/sbacchio,Merging DDalphaAMG interface to etmc/tmLQCD master,37,[],https://github.com/etmc/tmLQCD/pull/343,https://github.com/kostrzewa,15,https://github.com/etmc/tmLQCD/pull/343#issuecomment-256267080,,@urbach should we just proceed?,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,343,2016-10-20T11:07:39Z,2016-11-16T11:56:59Z,2016-11-16T11:56:59Z,MERGED,True,1496,84,37,https://github.com/sbacchio,Merging DDalphaAMG interface to etmc/tmLQCD master,37,[],https://github.com/etmc/tmLQCD/pull/343,https://github.com/kostrzewa,16,https://github.com/etmc/tmLQCD/pull/343#issuecomment-259131629,,"So I think we can pull this in now, unless there are any more bugfixes that you would like to get in @sbacchio @Finkenrath ?",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,343,2016-10-20T11:07:39Z,2016-11-16T11:56:59Z,2016-11-16T11:56:59Z,MERGED,True,1496,84,37,https://github.com/sbacchio,Merging DDalphaAMG interface to etmc/tmLQCD master,37,[],https://github.com/etmc/tmLQCD/pull/343,https://github.com/sbacchio,17,https://github.com/etmc/tmLQCD/pull/343#issuecomment-259141422,,"Yes, I've still some TODO on the list, but no bug fix at the moment. You can merge for me.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,343,2016-10-20T11:07:39Z,2016-11-16T11:56:59Z,2016-11-16T11:56:59Z,MERGED,True,1496,84,37,https://github.com/sbacchio,Merging DDalphaAMG interface to etmc/tmLQCD master,37,[],https://github.com/etmc/tmLQCD/pull/343,https://github.com/kostrzewa,18,https://github.com/etmc/tmLQCD/pull/343#issuecomment-260928426,,"Okay, I'm merging now.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,345,2016-11-19T10:16:21Z,2016-11-24T11:04:34Z,2016-11-24T11:04:34Z,MERGED,True,13,3,2,https://github.com/sbacchio,Bug fix,1,[],https://github.com/etmc/tmLQCD/pull/345,https://github.com/sbacchio,1,https://github.com/etmc/tmLQCD/pull/345,"Fixed input reading of MGSetup2KappaMu ( issue #344 )
Fixed MG inversion in inlinemeasurment when the configuration is rejected (the new conf wasn't updated in the interface and MGTEST was failing there).","Fixed input reading of MGSetup2KappaMu ( issue #344 )
Fixed MG inversion in inlinemeasurment when the configuration is rejected (the new conf wasn't updated in the interface and MGTEST was failing there).",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,347,2016-11-28T15:23:39Z,2016-12-08T11:11:53Z,2016-12-08T11:11:53Z,MERGED,True,75,6,7,https://github.com/sbacchio,Fixing compilation without DDalphaAMG,1,[],https://github.com/etmc/tmLQCD/pull/347,https://github.com/sbacchio,1,https://github.com/etmc/tmLQCD/pull/347,"In response to issue #346.
@kostrzewa @urbach What do you think about this solution?","In response to issue #346.
@kostrzewa @urbach What do you think about this solution?",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,347,2016-11-28T15:23:39Z,2016-12-08T11:11:53Z,2016-12-08T11:11:53Z,MERGED,True,75,6,7,https://github.com/sbacchio,Fixing compilation without DDalphaAMG,1,[],https://github.com/etmc/tmLQCD/pull/347,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/347#issuecomment-264477336,"In response to issue #346.
@kostrzewa @urbach What do you think about this solution?",@urbach could you take a look at this please? I'm okay with the solution proposed by @sbacchio.,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,347,2016-11-28T15:23:39Z,2016-12-08T11:11:53Z,2016-12-08T11:11:53Z,MERGED,True,75,6,7,https://github.com/sbacchio,Fixing compilation without DDalphaAMG,1,[],https://github.com/etmc/tmLQCD/pull/347,https://github.com/kostrzewa,3,https://github.com/etmc/tmLQCD/pull/347#issuecomment-264478564,"In response to issue #346.
@kostrzewa @urbach What do you think about this solution?","I might, at some point in the future, provide a pull-request which moves the mg parameters out of DDalphaAMG and into a global context, thereby providing a uniform parameter set for different MG implementations, as far as possible. (The set of parameters might be extended in the future).",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,347,2016-11-28T15:23:39Z,2016-12-08T11:11:53Z,2016-12-08T11:11:53Z,MERGED,True,75,6,7,https://github.com/sbacchio,Fixing compilation without DDalphaAMG,1,[],https://github.com/etmc/tmLQCD/pull/347,https://github.com/urbach,4,https://github.com/etmc/tmLQCD/pull/347#issuecomment-265694346,"In response to issue #346.
@kostrzewa @urbach What do you think about this solution?","yes, this is fine with me, should I merge it in?",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,347,2016-11-28T15:23:39Z,2016-12-08T11:11:53Z,2016-12-08T11:11:53Z,MERGED,True,75,6,7,https://github.com/sbacchio,Fixing compilation without DDalphaAMG,1,[],https://github.com/etmc/tmLQCD/pull/347,https://github.com/kostrzewa,5,https://github.com/etmc/tmLQCD/pull/347#issuecomment-265709790,"In response to issue #346.
@kostrzewa @urbach What do you think about this solution?","Sure, please go ahead. Thanks!",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,348,2016-12-21T09:41:36Z,2016-12-26T10:42:26Z,2016-12-26T10:42:26Z,CLOSED,False,1510,2,9,https://github.com/marcuspetschlies,added comm in invert/tmLQCD.h,6,[],https://github.com/etmc/tmLQCD/pull/348,https://github.com/marcuspetschlies,1,https://github.com/etmc/tmLQCD/pull/348,,,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,348,2016-12-21T09:41:36Z,2016-12-26T10:42:26Z,2016-12-26T10:42:26Z,CLOSED,False,1510,2,9,https://github.com/marcuspetschlies,added comm in invert/tmLQCD.h,6,[],https://github.com/etmc/tmLQCD/pull/348,https://github.com/marcuspetschlies,2,https://github.com/etmc/tmLQCD/pull/348#issuecomment-268480796,,"Not yet. Those I would add in the next request?

On 12/21/16 10:49, Carsten Urbach wrote:

 ***@***.**** commented on this pull request.

 ------------------------------------------------------------------------

 In include/tmLQCD.h
 <#348 (review)>:

 > @@ -58,6 +61,12 @@ extern ""C""
                      const int op_id, const int gauge_persist);
  #endif

 +  int tmLQCD_invert_eo(double * const propagator, double * const source, const int op_id);
 +
 +  int tmLQCD_get_deflator_params(tmLQCD_deflator_params*params, const int op_id);

 are these three functions available in etmc/master ?

 
 You are receiving this because you authored the thread.
 Reply to this email directly, view it on GitHub
 <#348 (review)>,
 or mute the thread
 <https://github.com/notifications/unsubscribe-auth/AMciodKlooAOOcWTou63eVcuL9FzU8Unks5rKPYQgaJpZM4LSv_a>.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,348,2016-12-21T09:41:36Z,2016-12-26T10:42:26Z,2016-12-26T10:42:26Z,CLOSED,False,1510,2,9,https://github.com/marcuspetschlies,added comm in invert/tmLQCD.h,6,[],https://github.com/etmc/tmLQCD/pull/348,https://github.com/urbach,3,https://github.com/etmc/tmLQCD/pull/348#issuecomment-268482358,,"Not yet. Those I would add in the next request?
thats a bit too fine grained...

You can add the functions in question to you branch, I think it was
called Mybranch and push the changes to github.com. They will
automatically appear in this pull request.


 On 12/21/16 10:49, Carsten Urbach wrote:
 >
 > ***@***.**** commented on this pull request.
 >
 > ------------------------------------------------------------------------
 >
 > In include/tmLQCD.h
 > <#348 (review)>:
 >
 > > @@ -58,6 +61,12 @@ extern ""C""
 >                      const int op_id, const int gauge_persist);
 >  #endif
 >
 > +  int tmLQCD_invert_eo(double * const propagator, double * const source, const int op_id);
 > +
 > +  int tmLQCD_get_deflator_params(tmLQCD_deflator_params*params, const int op_id);
 >
 > are these three functions available in etmc/master ?
 >
 > 
 > You are receiving this because you authored the thread.
 > Reply to this email directly, view it on GitHub
 > <#348 (review)>,
 > or mute the thread
 > <https://github.com/notifications/unsubscribe-auth/AMciodKlooAOOcWTou63eVcuL9FzU8Unks5rKPYQgaJpZM4LSv_a>.
 >



 --
 You are receiving this because you commented.
 Reply to this email directly or view it on GitHub:
 #348 (comment)

--
Carsten Urbach
e-mail: curbach@gmx.de
        urbach@hiskp.uni-bonn.de
Fon   : +49 (0)228 73 2379
skype : carsten.urbach
URL: http://www.carsten-urbach.eu",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,349,2016-12-23T08:01:53Z,,2019-01-08T11:20:17Z,OPEN,False,1483,25,11,https://github.com/gbergner,Reweighting branch merge,25,[],https://github.com/etmc/tmLQCD/pull/349,https://github.com/gbergner,1,https://github.com/etmc/tmLQCD/pull/349,"Currently implemented additions:

measurement reweighting factors with DDalphaAMG support
improved reweighting monomial for alternative computation (CG)
alternative computation of reweighting factors without inversions
so far not working: eigenvalue estimation for clover operators","Currently implemented additions:

measurement reweighting factors with DDalphaAMG support
improved reweighting monomial for alternative computation (CG)
alternative computation of reweighting factors without inversions
so far not working: eigenvalue estimation for clover operators",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,349,2016-12-23T08:01:53Z,,2019-01-08T11:20:17Z,OPEN,False,1483,25,11,https://github.com/gbergner,Reweighting branch merge,25,[],https://github.com/etmc/tmLQCD/pull/349,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/349#issuecomment-269978602,"Currently implemented additions:

measurement reweighting factors with DDalphaAMG support
improved reweighting monomial for alternative computation (CG)
alternative computation of reweighting factors without inversions
so far not working: eigenvalue estimation for clover operators","I haven't yet been able to look at everything, but I'm wondering why we now have yet another executable. In principle, offline_measurement should provide the required functionality, no?",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,349,2016-12-23T08:01:53Z,,2019-01-08T11:20:17Z,OPEN,False,1483,25,11,https://github.com/gbergner,Reweighting branch merge,25,[],https://github.com/etmc/tmLQCD/pull/349,https://github.com/gbergner,3,https://github.com/etmc/tmLQCD/pull/349#issuecomment-269987693,"Currently implemented additions:

measurement reweighting factors with DDalphaAMG support
improved reweighting monomial for alternative computation (CG)
alternative computation of reweighting factors without inversions
so far not working: eigenvalue estimation for clover operators",Well the offline_measurement seems to be outdated. I would prefer to remove it or rework it.,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,349,2016-12-23T08:01:53Z,,2019-01-08T11:20:17Z,OPEN,False,1483,25,11,https://github.com/gbergner,Reweighting branch merge,25,[],https://github.com/etmc/tmLQCD/pull/349,https://github.com/kostrzewa,4,https://github.com/etmc/tmLQCD/pull/349#issuecomment-269988345,"Currently implemented additions:

measurement reweighting factors with DDalphaAMG support
improved reweighting monomial for alternative computation (CG)
alternative computation of reweighting factors without inversions
so far not working: eigenvalue estimation for clover operators","I guess it's missing some of the mixed precision initialisations, correct? Of course, merging the two executables (into measure, say) or removing offline_measurement is absolutely okay, as long as the functionality it provided stays available (which, as far as I can tell, measure proides)",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,349,2016-12-23T08:01:53Z,,2019-01-08T11:20:17Z,OPEN,False,1483,25,11,https://github.com/gbergner,Reweighting branch merge,25,[],https://github.com/etmc/tmLQCD/pull/349,https://github.com/gbergner,5,https://github.com/etmc/tmLQCD/pull/349#issuecomment-270071280,"Currently implemented additions:

measurement reweighting factors with DDalphaAMG support
improved reweighting monomial for alternative computation (CG)
alternative computation of reweighting factors without inversions
so far not working: eigenvalue estimation for clover operators","There seem to be several things like also the random seed initialization, which is quite important for the reweighting factors. It seems to be that the offline_measurement has not been maintained for some time and is outdated compared to the invert.c. Therefore I have created a new measure.c derived from the invert.c. Of course, I would prefer to move the invert.c-functionality in some function that can be optionally called from the measure.c. The duplicated code in offline_measurement, measure, invert is bad. However, I would first like to discuss such kind of major changes since several parts are not independent due to the usage of the same workspace of Dirac-Vectors.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,349,2016-12-23T08:01:53Z,,2019-01-08T11:20:17Z,OPEN,False,1483,25,11,https://github.com/gbergner,Reweighting branch merge,25,[],https://github.com/etmc/tmLQCD/pull/349,https://github.com/gbergner,6,https://github.com/etmc/tmLQCD/pull/349#issuecomment-271867839,"Currently implemented additions:

measurement reweighting factors with DDalphaAMG support
improved reweighting monomial for alternative computation (CG)
alternative computation of reweighting factors without inversions
so far not working: eigenvalue estimation for clover operators","Also, we have made it customary to use 2 spaces instead of tabs (even though there are numerous spots in the code where this is not yet implemented), it would be great if you could adjust your tabs accordingly.
Please let me know all of you conventions in order to implement them. So far I could not deduce any conventions from the current state of the code. I will change this soon.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,349,2016-12-23T08:01:53Z,,2019-01-08T11:20:17Z,OPEN,False,1483,25,11,https://github.com/gbergner,Reweighting branch merge,25,[],https://github.com/etmc/tmLQCD/pull/349,https://github.com/kostrzewa,7,https://github.com/etmc/tmLQCD/pull/349#issuecomment-271869062,"Currently implemented additions:

measurement reweighting factors with DDalphaAMG support
improved reweighting monomial for alternative computation (CG)
alternative computation of reweighting factors without inversions
so far not working: eigenvalue estimation for clover operators","Please let me know all of you conventions in order to implement them. So far I could not deduce any conventions from the current state of the code. I will change this soon.

That's pretty much the only consistent one... I'm afraid there are no official conventions, perhaps I'll take the time to write up a coding style howto at some point...",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,349,2016-12-23T08:01:53Z,,2019-01-08T11:20:17Z,OPEN,False,1483,25,11,https://github.com/gbergner,Reweighting branch merge,25,[],https://github.com/etmc/tmLQCD/pull/349,https://github.com/kostrzewa,8,https://github.com/etmc/tmLQCD/pull/349#issuecomment-295676384,"Currently implemented additions:

measurement reweighting factors with DDalphaAMG support
improved reweighting monomial for alternative computation (CG)
alternative computation of reweighting factors without inversions
so far not working: eigenvalue estimation for clover operators","@urbach please also look at the outdated comments above, which discussed some of the code-doubling which occurs here",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,349,2016-12-23T08:01:53Z,,2019-01-08T11:20:17Z,OPEN,False,1483,25,11,https://github.com/gbergner,Reweighting branch merge,25,[],https://github.com/etmc/tmLQCD/pull/349,https://github.com/kostrzewa,9,https://github.com/etmc/tmLQCD/pull/349#issuecomment-297002843,"Currently implemented additions:

measurement reweighting factors with DDalphaAMG support
improved reweighting monomial for alternative computation (CG)
alternative computation of reweighting factors without inversions
so far not working: eigenvalue estimation for clover operators",Regarding (f)lex on Jureca: you just need to load the module (module load flex) The check should certainly be present because read_input.c is not checked into the repository (nor should it be),True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,349,2016-12-23T08:01:53Z,,2019-01-08T11:20:17Z,OPEN,False,1483,25,11,https://github.com/gbergner,Reweighting branch merge,25,[],https://github.com/etmc/tmLQCD/pull/349,https://github.com/gbergner,10,https://github.com/etmc/tmLQCD/pull/349#issuecomment-297014969,"Currently implemented additions:

measurement reweighting factors with DDalphaAMG support
improved reweighting monomial for alternative computation (CG)
alternative computation of reweighting factors without inversions
so far not working: eigenvalue estimation for clover operators","Yes, I agree the check should be reverted.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,349,2016-12-23T08:01:53Z,,2019-01-08T11:20:17Z,OPEN,False,1483,25,11,https://github.com/gbergner,Reweighting branch merge,25,[],https://github.com/etmc/tmLQCD/pull/349,https://github.com/gbergner,11,https://github.com/etmc/tmLQCD/pull/349#issuecomment-297033074,"Currently implemented additions:

measurement reweighting factors with DDalphaAMG support
improved reweighting monomial for alternative computation (CG)
alternative computation of reweighting factors without inversions
so far not working: eigenvalue estimation for clover operators",I have tried to include your suggestions/revert some changes. Any further suggestions?,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,349,2016-12-23T08:01:53Z,,2019-01-08T11:20:17Z,OPEN,False,1483,25,11,https://github.com/gbergner,Reweighting branch merge,25,[],https://github.com/etmc/tmLQCD/pull/349,https://github.com/kostrzewa,12,https://github.com/etmc/tmLQCD/pull/349#issuecomment-394636230,"Currently implemented additions:

measurement reweighting factors with DDalphaAMG support
improved reweighting monomial for alternative computation (CG)
alternative computation of reweighting factors without inversions
so far not working: eigenvalue estimation for clover operators","@gbergner Since we are continuing the simulation which needs to be reweighted, I wanted to ask about the status of these changes.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,349,2016-12-23T08:01:53Z,,2019-01-08T11:20:17Z,OPEN,False,1483,25,11,https://github.com/gbergner,Reweighting branch merge,25,[],https://github.com/etmc/tmLQCD/pull/349,https://github.com/kostrzewa,13,https://github.com/etmc/tmLQCD/pull/349#issuecomment-400265674,"Currently implemented additions:

measurement reweighting factors with DDalphaAMG support
improved reweighting monomial for alternative computation (CG)
alternative computation of reweighting factors without inversions
so far not working: eigenvalue estimation for clover operators","I realised that you probably didn't see some of my comments because I hadn't ""submitted"" the review... sorry about that.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,349,2016-12-23T08:01:53Z,,2019-01-08T11:20:17Z,OPEN,False,1483,25,11,https://github.com/gbergner,Reweighting branch merge,25,[],https://github.com/etmc/tmLQCD/pull/349,https://github.com/gbergner,14,https://github.com/etmc/tmLQCD/pull/349#issuecomment-426955465,"Currently implemented additions:

measurement reweighting factors with DDalphaAMG support
improved reweighting monomial for alternative computation (CG)
alternative computation of reweighting factors without inversions
so far not working: eigenvalue estimation for clover operators","Some general comment concerning the offline_measurement.c: I had the impression that there are relevant differences between the offline_measurement.c and the invert.c. Some measurements are rather included in the invert.c than in the offline_measurement.c, which indicates that the latter one might be outdated. However, I had some problems with segfaults when running the invert. Therefore I have included the new measure.c based on the invert.c.
I don't know how to deal with this problem. If all of these files are correct, we can try to merge them.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,349,2016-12-23T08:01:53Z,,2019-01-08T11:20:17Z,OPEN,False,1483,25,11,https://github.com/gbergner,Reweighting branch merge,25,[],https://github.com/etmc/tmLQCD/pull/349,https://github.com/gbergner,15,https://github.com/etmc/tmLQCD/pull/349#issuecomment-426955833,"Currently implemented additions:

measurement reweighting factors with DDalphaAMG support
improved reweighting monomial for alternative computation (CG)
alternative computation of reweighting factors without inversions
so far not working: eigenvalue estimation for clover operators","P.S. The segfault appeared when measuring more than one configuration with the invert, as far as I remember.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,349,2016-12-23T08:01:53Z,,2019-01-08T11:20:17Z,OPEN,False,1483,25,11,https://github.com/gbergner,Reweighting branch merge,25,[],https://github.com/etmc/tmLQCD/pull/349,https://github.com/kostrzewa,16,https://github.com/etmc/tmLQCD/pull/349#issuecomment-426967511,"Currently implemented additions:

measurement reweighting factors with DDalphaAMG support
improved reweighting monomial for alternative computation (CG)
alternative computation of reweighting factors without inversions
so far not working: eigenvalue estimation for clover operators","invert doesn't (generally) segfault when doing inversions on multiple configurations, but it is really only designed to do explicit inversions, rather than anything from the ""measurements"" modules. Support for running ""measurements"" together with inversions was added simply for convenience, as it would sometimes be nice to do a gradient flow measurement, say, at the same time as the inversion.
To proceed, the first task would be to resolve the merge conflicts. The second task would be to merge measure and offline_measurement. Again, I have no preference as to which executable remains in the end as long as the functionality is preserved. As I mentioned multiple times, offline_measurement is not outdated and the seed issue that you referred to has also been resolved since (although it never mattered in practice for the measurements that were done).",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,349,2016-12-23T08:01:53Z,,2019-01-08T11:20:17Z,OPEN,False,1483,25,11,https://github.com/gbergner,Reweighting branch merge,25,[],https://github.com/etmc/tmLQCD/pull/349,https://github.com/kostrzewa,17,https://github.com/etmc/tmLQCD/pull/349#issuecomment-426968034,"Currently implemented additions:

measurement reweighting factors with DDalphaAMG support
improved reweighting monomial for alternative computation (CG)
alternative computation of reweighting factors without inversions
so far not working: eigenvalue estimation for clover operators","Also note that the configuration filename has since been extended to 500 characters in all relevant executables and the string is now written safely using snprintf, a change which I've wanted to make for years...",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,349,2016-12-23T08:01:53Z,,2019-01-08T11:20:17Z,OPEN,False,1483,25,11,https://github.com/gbergner,Reweighting branch merge,25,[],https://github.com/etmc/tmLQCD/pull/349,https://github.com/gbergner,18,https://github.com/etmc/tmLQCD/pull/349#issuecomment-427041478,"Currently implemented additions:

measurement reweighting factors with DDalphaAMG support
improved reweighting monomial for alternative computation (CG)
alternative computation of reweighting factors without inversions
so far not working: eigenvalue estimation for clover operators","I have been looking at the mode number measurement, which is invert.c. Therefore I have assumed that the online_measurements was outdated.
I have not checked whether the segfault is now still reproducable. I should try this again now.
More generally I don't understand the policy. There are two options:

One file that does everything. In this case there should be no separate invert.c with a copy of the measurements.
Separate files for different measurements.
Otherwise it is hard to find any conclusive form.

One easy thing for me would be to move the measure.c to offline_measurements.c and delete the original one. I hope everything will still be working in this case.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,349,2016-12-23T08:01:53Z,,2019-01-08T11:20:17Z,OPEN,False,1483,25,11,https://github.com/gbergner,Reweighting branch merge,25,[],https://github.com/etmc/tmLQCD/pull/349,https://github.com/kostrzewa,19,https://github.com/etmc/tmLQCD/pull/349#issuecomment-427043475,"Currently implemented additions:

measurement reweighting factors with DDalphaAMG support
improved reweighting monomial for alternative computation (CG)
alternative computation of reweighting factors without inversions
so far not working: eigenvalue estimation for clover operators","I have been looking at the mode number measurement, which is invert.c. Therefore I have assumed that the online_measurements was outdated.
I have not checked whether the segfault is now still reproducable. I should try this again now.

The modenumber measurement was added before there was code review. It should never have ended up in invert...",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,349,2016-12-23T08:01:53Z,,2019-01-08T11:20:17Z,OPEN,False,1483,25,11,https://github.com/gbergner,Reweighting branch merge,25,[],https://github.com/etmc/tmLQCD/pull/349,https://github.com/kostrzewa,20,https://github.com/etmc/tmLQCD/pull/349#issuecomment-427045109,"Currently implemented additions:

measurement reweighting factors with DDalphaAMG support
improved reweighting monomial for alternative computation (CG)
alternative computation of reweighting factors without inversions
so far not working: eigenvalue estimation for clover operators","One file that does everything. In this case there should be no separate invert.c with a copy of the measurements.

Inversions are quite separate from measurements at present, which is the reason for the split. Some years ago, I introduced offline_measurement to run anything from the measurement modules. At the same time, functionality to do measurements while also doing inversions (i.e., generation of propagators) was introduced into invert for convience reasons.

One easy thing for me would be to move the measure.c to offline_measurements.c and delete the original one. I hope everything will still be working in this case.

This would be good. I would say the reweighting factors are of the measurement type and they should also be accessed via the BeginMeasurement X [...] EndMeasurement syntax in the input file.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,349,2016-12-23T08:01:53Z,,2019-01-08T11:20:17Z,OPEN,False,1483,25,11,https://github.com/gbergner,Reweighting branch merge,25,[],https://github.com/etmc/tmLQCD/pull/349,https://github.com/kostrzewa,21,https://github.com/etmc/tmLQCD/pull/349#issuecomment-427048314,"Currently implemented additions:

measurement reweighting factors with DDalphaAMG support
improved reweighting monomial for alternative computation (CG)
alternative computation of reweighting factors without inversions
so far not working: eigenvalue estimation for clover operators","Inversions are quite separate from measurements at present, which is the reason for the split. Some years ago, I introduced offline_measurement to run anything from the measurement modules. At the same time, functionality to do measurements while also doing inversions (i.e., generation of propagators) was introduced into invert for convience reasons.

The interface for inversions is quite different from that for measurements, since it is positively ancient in comparison. One could probably recast various types of ""propagator generation"" as  measurements and then unify things. That would actually be quite nice.
One has to keep in mind, however, that invert is not going to really be used much in the medium-term future. Rather, tmLQCD is linked into a contraction framework in order to serve as a wrapper for the various solvers and for the loading of gauge fields and/or storage of propagators with all the nice checksum calculations which are a pain to re-implement.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,349,2016-12-23T08:01:53Z,,2019-01-08T11:20:17Z,OPEN,False,1483,25,11,https://github.com/gbergner,Reweighting branch merge,25,[],https://github.com/etmc/tmLQCD/pull/349,https://github.com/kostrzewa,22,https://github.com/etmc/tmLQCD/pull/349#issuecomment-440249698,"Currently implemented additions:

measurement reweighting factors with DDalphaAMG support
improved reweighting monomial for alternative computation (CG)
alternative computation of reweighting factors without inversions
so far not working: eigenvalue estimation for clover operators",Is there a reason for specifying the kappa steps in an additional file? The tmLQCD input file reader can tokenize lists of comma-separated doubles. See FLTLIST in read_input.l,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,349,2016-12-23T08:01:53Z,,2019-01-08T11:20:17Z,OPEN,False,1483,25,11,https://github.com/gbergner,Reweighting branch merge,25,[],https://github.com/etmc/tmLQCD/pull/349,https://github.com/gbergner,23,https://github.com/etmc/tmLQCD/pull/349#issuecomment-440265899,"Currently implemented additions:

measurement reweighting factors with DDalphaAMG support
improved reweighting monomial for alternative computation (CG)
alternative computation of reweighting factors without inversions
so far not working: eigenvalue estimation for clover operators",I had to continue the work with the code and I did not know about the plans for the pull request. Next time I will create a new branch for the continuation of the work while waiting for any response regarding the pull request.,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,349,2016-12-23T08:01:53Z,,2019-01-08T11:20:17Z,OPEN,False,1483,25,11,https://github.com/gbergner,Reweighting branch merge,25,[],https://github.com/etmc/tmLQCD/pull/349,https://github.com/gbergner,24,https://github.com/etmc/tmLQCD/pull/349#issuecomment-440266519,"Currently implemented additions:

measurement reweighting factors with DDalphaAMG support
improved reweighting monomial for alternative computation (CG)
alternative computation of reweighting factors without inversions
so far not working: eigenvalue estimation for clover operators","Probably you mean this kind of solution:
{SPC}*MGNumberOfVectors{EQL}{FLTLIST} {
char paramname[100];
char error_message[200];
int list_end = 0;
int level = 0;
fltlist_tokenize(yytext, paramname, 100);
int n_vec = (int)fltlist_next_token(&list_end);
while( list_end != 1 ){
  if( level >= (QUDA_MAX_MG_LEVEL-1) ){
    snprintf(error_message, 200, ""Exceeded maximum number of levels (%d-1) parsing %s!\n"", QUDA_MAX_MG_LEVEL, paramname);
    yy_fatal_error(error_message);
  }
  
  quda_input.mg_n_vec[level] = n_vec;
  if(myverbose){ 
    printf(""  %s, level %d set to %d line %d\n"", paramname,
            level, quda_input.mg_n_vec[level], line_of_file);
  }
  level++;
  n_vec = fltlist_next_token(&list_end);
}

}
May be this is nicer .... I will think about it.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,349,2016-12-23T08:01:53Z,,2019-01-08T11:20:17Z,OPEN,False,1483,25,11,https://github.com/gbergner,Reweighting branch merge,25,[],https://github.com/etmc/tmLQCD/pull/349,https://github.com/gbergner,25,https://github.com/etmc/tmLQCD/pull/349#issuecomment-440308722,"Currently implemented additions:

measurement reweighting factors with DDalphaAMG support
improved reweighting monomial for alternative computation (CG)
alternative computation of reweighting factors without inversions
so far not working: eigenvalue estimation for clover operators","OK, I have added the FLTLIST way. Is this consistent with what you had in mind?
Personally, I am not a fan of flex.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,349,2016-12-23T08:01:53Z,,2019-01-08T11:20:17Z,OPEN,False,1483,25,11,https://github.com/gbergner,Reweighting branch merge,25,[],https://github.com/etmc/tmLQCD/pull/349,https://github.com/kostrzewa,26,https://github.com/etmc/tmLQCD/pull/349#issuecomment-440316670,"Currently implemented additions:

measurement reweighting factors with DDalphaAMG support
improved reweighting monomial for alternative computation (CG)
alternative computation of reweighting factors without inversions
so far not working: eigenvalue estimation for clover operators","Sure, I would prefer C++ and yaml, but flex works rather nicely for our purposes.
As for the parsing of additional options, dealing with one input file is bad enough in my opinion, so having this inline is probably the better choice. Looks good!",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,349,2016-12-23T08:01:53Z,,2019-01-08T11:20:17Z,OPEN,False,1483,25,11,https://github.com/gbergner,Reweighting branch merge,25,[],https://github.com/etmc/tmLQCD/pull/349,https://github.com/kostrzewa,27,https://github.com/etmc/tmLQCD/pull/349#issuecomment-452259164,"Currently implemented additions:

measurement reweighting factors with DDalphaAMG support
improved reweighting monomial for alternative computation (CG)
alternative computation of reweighting factors without inversions
so far not working: eigenvalue estimation for clover operators",Does this still work when merged with with the https://github.com/etmc/tmlqcd/tree/DDalphaAMG_nd_merge_etmc_master branch? These two branches are the next to go into the code-base so we need to check for regressions. @gbergner could you test merging with the branch in question to see if the reweighting measurement still works correctly?,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,349,2016-12-23T08:01:53Z,,2019-01-08T11:20:17Z,OPEN,False,1483,25,11,https://github.com/gbergner,Reweighting branch merge,25,[],https://github.com/etmc/tmLQCD/pull/349,https://github.com/kostrzewa,28,https://github.com/etmc/tmLQCD/pull/349#issuecomment-452259670,"Currently implemented additions:

measurement reweighting factors with DDalphaAMG support
improved reweighting monomial for alternative computation (CG)
alternative computation of reweighting factors without inversions
so far not working: eigenvalue estimation for clover operators",Could you add some documentation of the parameters to the LaTeX docs?,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,349,2016-12-23T08:01:53Z,,2019-01-08T11:20:17Z,OPEN,False,1483,25,11,https://github.com/gbergner,Reweighting branch merge,25,[],https://github.com/etmc/tmLQCD/pull/349,https://github.com/kostrzewa,29,https://github.com/etmc/tmLQCD/pull/349#issuecomment-452259941,"Currently implemented additions:

measurement reweighting factors with DDalphaAMG support
improved reweighting monomial for alternative computation (CG)
alternative computation of reweighting factors without inversions
so far not working: eigenvalue estimation for clover operators","The fact that this is not general but depends on DDalphAMG still bugs me, but I'm okay with pulling it in if we agree that a general solution should be implemented as soon as possible.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,350,2016-12-29T17:22:26Z,2018-10-08T09:44:02Z,2018-10-08T09:44:02Z,CLOSED,False,3414,4,23,https://github.com/marcuspetschlies,Mybranch,8,[],https://github.com/etmc/tmLQCD/pull/350,https://github.com/marcuspetschlies,1,https://github.com/etmc/tmLQCD/pull/350,missing includes and files for support of ARPACKCG and EXACTDEFLATEDCG solver; still need to add entries in invert_eo etc.,missing includes and files for support of ARPACKCG and EXACTDEFLATEDCG solver; still need to add entries in invert_eo etc.,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,350,2016-12-29T17:22:26Z,2018-10-08T09:44:02Z,2018-10-08T09:44:02Z,CLOSED,False,3414,4,23,https://github.com/marcuspetschlies,Mybranch,8,[],https://github.com/etmc/tmLQCD/pull/350,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/350#issuecomment-427775504,missing includes and files for support of ARPACKCG and EXACTDEFLATEDCG solver; still need to add entries in invert_eo etc.,"I guess this will never be merged, closing.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,352,2017-01-25T14:09:30Z,2017-01-27T10:40:12Z,2017-01-27T10:40:12Z,MERGED,True,36,36,13,https://github.com/sbacchio,"Changed to %.12f most of the print of kappa, mu, beta, c_sw and related quantities.",1,[],https://github.com/etmc/tmLQCD/pull/352,https://github.com/sbacchio,1,https://github.com/etmc/tmLQCD/pull/352,"For solving the issue #351, I've changed the prints of kappa, mu, beta, c_sw and related quantities to ""%.12f"". ""%.12f"" is at the moment uniquely used for those printings; this simplify future changes.","For solving the issue #351, I've changed the prints of kappa, mu, beta, c_sw and related quantities to ""%.12f"". ""%.12f"" is at the moment uniquely used for those printings; this simplify future changes.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,352,2017-01-25T14:09:30Z,2017-01-27T10:40:12Z,2017-01-27T10:40:12Z,MERGED,True,36,36,13,https://github.com/sbacchio,"Changed to %.12f most of the print of kappa, mu, beta, c_sw and related quantities.",1,[],https://github.com/etmc/tmLQCD/pull/352,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/352#issuecomment-275637025,"For solving the issue #351, I've changed the prints of kappa, mu, beta, c_sw and related quantities to ""%.12f"". ""%.12f"" is at the moment uniquely used for those printings; this simplify future changes.","Looks good, I'll pull this in right away.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,352,2017-01-25T14:09:30Z,2017-01-27T10:40:12Z,2017-01-27T10:40:12Z,MERGED,True,36,36,13,https://github.com/sbacchio,"Changed to %.12f most of the print of kappa, mu, beta, c_sw and related quantities.",1,[],https://github.com/etmc/tmLQCD/pull/352,https://github.com/kostrzewa,3,https://github.com/etmc/tmLQCD/pull/352#issuecomment-275637042,"For solving the issue #351, I've changed the prints of kappa, mu, beta, c_sw and related quantities to ""%.12f"". ""%.12f"" is at the moment uniquely used for those printings; this simplify future changes.",Thanks!,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,353,2017-01-30T14:46:46Z,2017-02-06T21:26:48Z,2017-02-06T21:26:48Z,MERGED,True,3,3,2,https://github.com/sbacchio,Bug fix in correction term for rational approximation.,2,[],https://github.com/etmc/tmLQCD/pull/353,https://github.com/sbacchio,1,https://github.com/etmc/tmLQCD/pull/353,"The series expansion of B =  (1+Z)^{1/4} had the wrong factor for the order Z^3 in both, code and documentation.
The series expansion of (1+Z)^{-1/2} was wrong in the documentation but correctly implemented in the code.","The series expansion of B =  (1+Z)^{1/4} had the wrong factor for the order Z^3 in both, code and documentation.
The series expansion of (1+Z)^{-1/2} was wrong in the documentation but correctly implemented in the code.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,353,2017-01-30T14:46:46Z,2017-02-06T21:26:48Z,2017-02-06T21:26:48Z,MERGED,True,3,3,2,https://github.com/sbacchio,Bug fix in correction term for rational approximation.,2,[],https://github.com/etmc/tmLQCD/pull/353,https://github.com/sbacchio,2,https://github.com/etmc/tmLQCD/pull/353#issuecomment-276081659,"The series expansion of B =  (1+Z)^{1/4} had the wrong factor for the order Z^3 in both, code and documentation.
The series expansion of (1+Z)^{-1/2} was wrong in the documentation but correctly implemented in the code.","This bug should not be relevant for the ensemble generated; because from what I see in the 16c32 ensemble, the Z^3 term was not relevant in the series expansion.
It starts to be relevant for the 64c128 ensemble.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,353,2017-01-30T14:46:46Z,2017-02-06T21:26:48Z,2017-02-06T21:26:48Z,MERGED,True,3,3,2,https://github.com/sbacchio,Bug fix in correction term for rational approximation.,2,[],https://github.com/etmc/tmLQCD/pull/353,https://github.com/kostrzewa,3,https://github.com/etmc/tmLQCD/pull/353#issuecomment-276949439,"The series expansion of B =  (1+Z)^{1/4} had the wrong factor for the order Z^3 in both, code and documentation.
The series expansion of (1+Z)^{-1/2} was wrong in the documentation but correctly implemented in the code.","And even so, the mismatch of the coefficient, 122/128, is probably so small, that its effect on the correction monomial will be almost certainly irrelevant. @urbach: I guess this can be merged in right away, yes? How do we proceed with current simulations, continue with the 7/122 factor and earmark the computation of reweighting factors (just to make sure that the effect is really negligible) or switch, mid-simulation, to 7/128 ?",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,353,2017-01-30T14:46:46Z,2017-02-06T21:26:48Z,2017-02-06T21:26:48Z,MERGED,True,3,3,2,https://github.com/sbacchio,Bug fix in correction term for rational approximation.,2,[],https://github.com/etmc/tmLQCD/pull/353,https://github.com/urbach,4,https://github.com/etmc/tmLQCD/pull/353#issuecomment-276959051,"The series expansion of B =  (1+Z)^{1/4} had the wrong factor for the order Z^3 in both, code and documentation.
The series expansion of (1+Z)^{-1/2} was wrong in the documentation but correctly implemented in the code.","And even so, the mismatch of the coefficient, 6/128, is probably so
small, that its effect on the correction monomial will be almost
  certainly irrelevant. @urbach: I guess this can be merged in right
  away, yes? How do we proceed with current simulations, continue with
  the 1/122 factor and earmark the computation of reweighting factors
  (just to make sure that the effect is really negligible) or switch,
  mid-simulation, to 1/128 ?

yes, we can merge. I'd change on the large volumes, since they are not
yet really equilibrated.

 --
 You are receiving this because you were mentioned.
 Reply to this email directly or view it on GitHub:
 #353 (comment)

--
Carsten Urbach
e-mail: curbach@gmx.de
        urbach@hiskp.uni-bonn.de
Fon   : +49 (0)228 73 2379
skype : carsten.urbach
URL: http://www.carsten-urbach.eu",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,353,2017-01-30T14:46:46Z,2017-02-06T21:26:48Z,2017-02-06T21:26:48Z,MERGED,True,3,3,2,https://github.com/sbacchio,Bug fix in correction term for rational approximation.,2,[],https://github.com/etmc/tmLQCD/pull/353,https://github.com/kostrzewa,5,https://github.com/etmc/tmLQCD/pull/353#issuecomment-276962504,"The series expansion of B =  (1+Z)^{1/4} had the wrong factor for the order Z^3 in both, code and documentation.
The series expansion of (1+Z)^{-1/2} was wrong in the documentation but correctly implemented in the code.","yes, we can merge. I'd change on the large volumes, since they are not yet really equilibrated.

Sure, on the runs which are not equilibrated we should switch to the correct factor asap. But what about the other runs?",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,354,2017-02-02T09:17:02Z,2017-04-13T13:29:35Z,2017-04-13T13:29:35Z,MERGED,True,16,1,2,https://github.com/kostrzewa,documentation: make building easier and allow use of pdflatex,2,[],https://github.com/etmc/tmLQCD/pull/354,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/354,"adjust parameters and use 'graphicx' package such that the docs can be built using pdflatex, add Makefile for automatic generation of documentation usign latexmk","adjust parameters and use 'graphicx' package such that the docs can be built using pdflatex, add Makefile for automatic generation of documentation usign latexmk",True,{'THUMBS_UP': ['https://github.com/sbacchio']}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,355,2017-02-07T11:27:54Z,2018-04-26T08:56:16Z,2018-04-26T08:56:16Z,MERGED,True,591,90,14,https://github.com/sbacchio,Improvements to correction monomial,8,[],https://github.com/etmc/tmLQCD/pull/355,https://github.com/sbacchio,1,https://github.com/etmc/tmLQCD/pull/355,"Saved some applications of Z in both heatbath/acc step.
Improved the check of next order correction in both heatbath/acc step (which we should discuss if it was a bug; read following).
Added documentation for guiding the changes.
Everything tested and gives same results of before.
A test is running on supermuc for the ensemble 16c Nf=1+1 with changes included, using just DDalphaAMG. You can find it in /gpfs/work/pr74yo/di49saj/HMC_MG_nd_only_test.
@urbach @kostrzewa @Finkenrath
The improvements in the checks for next order correction are the following;
we should discuss if it was a bug.
The old check for the order nth was
| Z^n R |^2 < acceptance^2
which reads as R^\dagger Z^{2n} R .
The new check is
[ c_n R^\dagger Z^n R ]^2 < acceptance^2
which is actually the correction to the energy given by the order nth.
About the old check we can say
| Z^n R |^2 < |Z|^{2n} |R|^2
and about the new instead
[ R^\dagger Z^n R ]^2 < |Z|^{2n} |R|^4.
So the upper limits differ of a factor |R|^2 between old and new.
The difference between the two checks is more relevant as much the lattice size increases, since |R|~V.
Indeed what we noticed now on the lattice 64c, is that the new check include terms of higher order compared to the old check (e.g. with the new check the terms of order Z^3 are included in the series; while with the old check they weren't).
On smaller lattices, as the 16c, there is no difference between old and new check because both of them cut the series at order Z^2.","Saved some applications of Z in both heatbath/acc step.
Improved the check of next order correction in both heatbath/acc step (which we should discuss if it was a bug; read following).
Added documentation for guiding the changes.
Everything tested and gives same results of before.
A test is running on supermuc for the ensemble 16c Nf=1+1 with changes included, using just DDalphaAMG. You can find it in /gpfs/work/pr74yo/di49saj/HMC_MG_nd_only_test.
@urbach @kostrzewa @Finkenrath
The improvements in the checks for next order correction are the following;
we should discuss if it was a bug.
The old check for the order nth was
| Z^n R |^2 < acceptance^2
which reads as R^\dagger Z^{2n} R .
The new check is
[ c_n R^\dagger Z^n R ]^2 < acceptance^2
which is actually the correction to the energy given by the order nth.
About the old check we can say
| Z^n R |^2 < |Z|^{2n} |R|^2
and about the new instead
[ R^\dagger Z^n R ]^2 < |Z|^{2n} |R|^4.
So the upper limits differ of a factor |R|^2 between old and new.
The difference between the two checks is more relevant as much the lattice size increases, since |R|~V.
Indeed what we noticed now on the lattice 64c, is that the new check include terms of higher order compared to the old check (e.g. with the new check the terms of order Z^3 are included in the series; while with the old check they weren't).
On smaller lattices, as the 16c, there is no difference between old and new check because both of them cut the series at order Z^2.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,355,2017-02-07T11:27:54Z,2018-04-26T08:56:16Z,2018-04-26T08:56:16Z,MERGED,True,591,90,14,https://github.com/sbacchio,Improvements to correction monomial,8,[],https://github.com/etmc/tmLQCD/pull/355,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/355#issuecomment-278612962,"Saved some applications of Z in both heatbath/acc step.
Improved the check of next order correction in both heatbath/acc step (which we should discuss if it was a bug; read following).
Added documentation for guiding the changes.
Everything tested and gives same results of before.
A test is running on supermuc for the ensemble 16c Nf=1+1 with changes included, using just DDalphaAMG. You can find it in /gpfs/work/pr74yo/di49saj/HMC_MG_nd_only_test.
@urbach @kostrzewa @Finkenrath
The improvements in the checks for next order correction are the following;
we should discuss if it was a bug.
The old check for the order nth was
| Z^n R |^2 < acceptance^2
which reads as R^\dagger Z^{2n} R .
The new check is
[ c_n R^\dagger Z^n R ]^2 < acceptance^2
which is actually the correction to the energy given by the order nth.
About the old check we can say
| Z^n R |^2 < |Z|^{2n} |R|^2
and about the new instead
[ R^\dagger Z^n R ]^2 < |Z|^{2n} |R|^4.
So the upper limits differ of a factor |R|^2 between old and new.
The difference between the two checks is more relevant as much the lattice size increases, since |R|~V.
Indeed what we noticed now on the lattice 64c, is that the new check include terms of higher order compared to the old check (e.g. with the new check the terms of order Z^3 are included in the series; while with the old check they weren't).
On smaller lattices, as the 16c, there is no difference between old and new check because both of them cut the series at order Z^2.","I need to sit down and work through this on paper, I hope I find time for it soon...",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,355,2017-02-07T11:27:54Z,2018-04-26T08:56:16Z,2018-04-26T08:56:16Z,MERGED,True,591,90,14,https://github.com/sbacchio,Improvements to correction monomial,8,[],https://github.com/etmc/tmLQCD/pull/355,https://github.com/kostrzewa,3,https://github.com/etmc/tmLQCD/pull/355#issuecomment-341385095,"Saved some applications of Z in both heatbath/acc step.
Improved the check of next order correction in both heatbath/acc step (which we should discuss if it was a bug; read following).
Added documentation for guiding the changes.
Everything tested and gives same results of before.
A test is running on supermuc for the ensemble 16c Nf=1+1 with changes included, using just DDalphaAMG. You can find it in /gpfs/work/pr74yo/di49saj/HMC_MG_nd_only_test.
@urbach @kostrzewa @Finkenrath
The improvements in the checks for next order correction are the following;
we should discuss if it was a bug.
The old check for the order nth was
| Z^n R |^2 < acceptance^2
which reads as R^\dagger Z^{2n} R .
The new check is
[ c_n R^\dagger Z^n R ]^2 < acceptance^2
which is actually the correction to the energy given by the order nth.
About the old check we can say
| Z^n R |^2 < |Z|^{2n} |R|^2
and about the new instead
[ R^\dagger Z^n R ]^2 < |Z|^{2n} |R|^4.
So the upper limits differ of a factor |R|^2 between old and new.
The difference between the two checks is more relevant as much the lattice size increases, since |R|~V.
Indeed what we noticed now on the lattice 64c, is that the new check include terms of higher order compared to the old check (e.g. with the new check the terms of order Z^3 are included in the series; while with the old check they weren't).
On smaller lattices, as the 16c, there is no difference between old and new check because both of them cut the series at order Z^2.",Note that the conflicts should be resolved and threading enabled before the new integrator can be merged.,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,356,2017-02-09T07:50:12Z,2017-02-09T11:08:48Z,2017-02-09T11:11:10Z,MERGED,True,15,12,4,https://github.com/sbacchio,Some bug fix about MG_update.,1,[],https://github.com/etmc/tmLQCD/pull/356,https://github.com/sbacchio,1,https://github.com/etmc/tmLQCD/pull/356,"In response to the issues reported by @kostrzewa:



when using the DDlpahaAMG interface in invert, the MG setup is updated when the source changes or the flavour is switched, unless I set MGUpdateSetupIter = 0.


Worse still, when processing multiple gauge configurations in one job, I've noticed that the DDalphaAMG interface will not update its copy of  the gauge configuration between gauge configurations. This is true whatever value I set MGUpdateSetupIter to. After the new gauge configuration has been read in, it will
a) do MGUpdateSetupIter setup iterations (without updating the gauge field first), if MGUpdateSetupIter > 0
b) attempt to do one inversion, notice that the result is wrong, and restart.


Only after this restart will the gauge field be updated and the setup1 redone fully.


Fixed reset of multigrid when several measurements are done with invert or offline_measurments.
Changed position MG_reset when configuration is rejected.
Fixed update of setup.

@kostrzewa can you please check if now everything works?","In response to the issues reported by @kostrzewa:



when using the DDlpahaAMG interface in invert, the MG setup is updated when the source changes or the flavour is switched, unless I set MGUpdateSetupIter = 0.


Worse still, when processing multiple gauge configurations in one job, I've noticed that the DDalphaAMG interface will not update its copy of  the gauge configuration between gauge configurations. This is true whatever value I set MGUpdateSetupIter to. After the new gauge configuration has been read in, it will
a) do MGUpdateSetupIter setup iterations (without updating the gauge field first), if MGUpdateSetupIter > 0
b) attempt to do one inversion, notice that the result is wrong, and restart.


Only after this restart will the gauge field be updated and the setup1 redone fully.


Fixed reset of multigrid when several measurements are done with invert or offline_measurments.
Changed position MG_reset when configuration is rejected.
Fixed update of setup.

@kostrzewa can you please check if now everything works?",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,356,2017-02-09T07:50:12Z,2017-02-09T11:08:48Z,2017-02-09T11:11:10Z,MERGED,True,15,12,4,https://github.com/sbacchio,Some bug fix about MG_update.,1,[],https://github.com/etmc/tmLQCD/pull/356,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/356#issuecomment-278610218,"In response to the issues reported by @kostrzewa:



when using the DDlpahaAMG interface in invert, the MG setup is updated when the source changes or the flavour is switched, unless I set MGUpdateSetupIter = 0.


Worse still, when processing multiple gauge configurations in one job, I've noticed that the DDalphaAMG interface will not update its copy of  the gauge configuration between gauge configurations. This is true whatever value I set MGUpdateSetupIter to. After the new gauge configuration has been read in, it will
a) do MGUpdateSetupIter setup iterations (without updating the gauge field first), if MGUpdateSetupIter > 0
b) attempt to do one inversion, notice that the result is wrong, and restart.


Only after this restart will the gauge field be updated and the setup1 redone fully.


Fixed reset of multigrid when several measurements are done with invert or offline_measurments.
Changed position MG_reset when configuration is rejected.
Fixed update of setup.

@kostrzewa can you please check if now everything works?","Yes, this seems to work as expected. Haven't tested in the HMC, however. I guess that should also still operate correctly. Should I pull it in?",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,356,2017-02-09T07:50:12Z,2017-02-09T11:08:48Z,2017-02-09T11:11:10Z,MERGED,True,15,12,4,https://github.com/sbacchio,Some bug fix about MG_update.,1,[],https://github.com/etmc/tmLQCD/pull/356,https://github.com/sbacchio,3,https://github.com/etmc/tmLQCD/pull/356#issuecomment-278612101,"In response to the issues reported by @kostrzewa:



when using the DDlpahaAMG interface in invert, the MG setup is updated when the source changes or the flavour is switched, unless I set MGUpdateSetupIter = 0.


Worse still, when processing multiple gauge configurations in one job, I've noticed that the DDalphaAMG interface will not update its copy of  the gauge configuration between gauge configurations. This is true whatever value I set MGUpdateSetupIter to. After the new gauge configuration has been read in, it will
a) do MGUpdateSetupIter setup iterations (without updating the gauge field first), if MGUpdateSetupIter > 0
b) attempt to do one inversion, notice that the result is wrong, and restart.


Only after this restart will the gauge field be updated and the setup1 redone fully.


Fixed reset of multigrid when several measurements are done with invert or offline_measurments.
Changed position MG_reset when configuration is rejected.
Fixed update of setup.

@kostrzewa can you please check if now everything works?","I checked it again and everything looks fine to me.
We don't have at the moment a HMC to try it, because we don't want to change the executables on the way. Anyway I guess it should work correctly.
Can you please have a look to my other pull request when you have time?",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,356,2017-02-09T07:50:12Z,2017-02-09T11:08:48Z,2017-02-09T11:11:10Z,MERGED,True,15,12,4,https://github.com/sbacchio,Some bug fix about MG_update.,1,[],https://github.com/etmc/tmLQCD/pull/356,https://github.com/kostrzewa,4,https://github.com/etmc/tmLQCD/pull/356#issuecomment-278612337,"In response to the issues reported by @kostrzewa:



when using the DDlpahaAMG interface in invert, the MG setup is updated when the source changes or the flavour is switched, unless I set MGUpdateSetupIter = 0.


Worse still, when processing multiple gauge configurations in one job, I've noticed that the DDalphaAMG interface will not update its copy of  the gauge configuration between gauge configurations. This is true whatever value I set MGUpdateSetupIter to. After the new gauge configuration has been read in, it will
a) do MGUpdateSetupIter setup iterations (without updating the gauge field first), if MGUpdateSetupIter > 0
b) attempt to do one inversion, notice that the result is wrong, and restart.


Only after this restart will the gauge field be updated and the setup1 redone fully.


Fixed reset of multigrid when several measurements are done with invert or offline_measurments.
Changed position MG_reset when configuration is rejected.
Fixed update of setup.

@kostrzewa can you please check if now everything works?","Of course, it's high on my list of priorities, but it's a little bit more work to look into and I'm currently rather busy...",True,{'THUMBS_UP': ['https://github.com/sbacchio']}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,356,2017-02-09T07:50:12Z,2017-02-09T11:08:48Z,2017-02-09T11:11:10Z,MERGED,True,15,12,4,https://github.com/sbacchio,Some bug fix about MG_update.,1,[],https://github.com/etmc/tmLQCD/pull/356,https://github.com/sbacchio,5,https://github.com/etmc/tmLQCD/pull/356#issuecomment-278612845,"In response to the issues reported by @kostrzewa:



when using the DDlpahaAMG interface in invert, the MG setup is updated when the source changes or the flavour is switched, unless I set MGUpdateSetupIter = 0.


Worse still, when processing multiple gauge configurations in one job, I've noticed that the DDalphaAMG interface will not update its copy of  the gauge configuration between gauge configurations. This is true whatever value I set MGUpdateSetupIter to. After the new gauge configuration has been read in, it will
a) do MGUpdateSetupIter setup iterations (without updating the gauge field first), if MGUpdateSetupIter > 0
b) attempt to do one inversion, notice that the result is wrong, and restart.


Only after this restart will the gauge field be updated and the setup1 redone fully.


Fixed reset of multigrid when several measurements are done with invert or offline_measurments.
Changed position MG_reset when configuration is rejected.
Fixed update of setup.

@kostrzewa can you please check if now everything works?",thanks! :),True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,358,2017-03-16T12:42:43Z,,2017-03-16T12:42:54Z,OPEN,False,291,247,4,https://github.com/kostrzewa,further refactor bechmark - DO NOT MERGE YET,2,[],https://github.com/etmc/tmLQCD/pull/358,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/358,"Some changes to benchmark to clean up the main function in order to add benchmarks of the single precision operators.
Further work will be done to do the same also for Dpsi.","Some changes to benchmark to clean up the main function in order to add benchmarks of the single precision operators.
Further work will be done to do the same also for Dpsi.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,358,2017-03-16T12:42:43Z,,2017-03-16T12:42:54Z,OPEN,False,291,247,4,https://github.com/kostrzewa,further refactor bechmark - DO NOT MERGE YET,2,[],https://github.com/etmc/tmLQCD/pull/358,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/358#issuecomment-287045361,"Some changes to benchmark to clean up the main function in order to add benchmarks of the single precision operators.
Further work will be done to do the same also for Dpsi.",Please do not merge yet.,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,361,2017-04-13T08:41:50Z,2017-04-13T13:28:36Z,2017-04-19T19:57:31Z,MERGED,True,9,9,1,https://github.com/martin-ueding,Fix a couple of typos in the documentation,8,[],https://github.com/etmc/tmLQCD/pull/361,https://github.com/martin-ueding,1,https://github.com/etmc/tmLQCD/pull/361,,,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,363,2017-04-22T08:59:26Z,2017-04-22T10:08:41Z,2017-04-22T10:08:41Z,CLOSED,False,92,0,2,https://github.com/martin-ueding,Add Travis CI support,1,[],https://github.com/etmc/tmLQCD/pull/363,https://github.com/martin-ueding,1,https://github.com/etmc/tmLQCD/pull/363,"To actually build on Travis CI, go to https://travis-ci.org/etmc/tmLQCD
and log in with an account having admin rights on that repository. There
should be a switch to enable building. Then it is automatically
integrated with GitHub.
Currently it uses one of the HMC input files to run it. It would be even
better to use some proper unit test. The current usage is a smoke test
(as in Does it smoke when it is turned on?) only.","To actually build on Travis CI, go to https://travis-ci.org/etmc/tmLQCD
and log in with an account having admin rights on that repository. There
should be a switch to enable building. Then it is automatically
integrated with GitHub.
Currently it uses one of the HMC input files to run it. It would be even
better to use some proper unit test. The current usage is a smoke test
(as in Does it smoke when it is turned on?) only.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,366,2017-04-22T10:03:22Z,2017-04-23T16:56:44Z,2017-04-24T09:44:03Z,MERGED,True,2,1,1,https://github.com/martin-ueding,Update the header of config.in.h (closes GH-364),1,[],https://github.com/etmc/tmLQCD/pull/366,https://github.com/martin-ueding,1,https://github.com/etmc/tmLQCD/pull/366,"The previous header of config.in.h suggested that it has been
auto-generated with autoheader. tmLQCD does not use the full set of
GNU Autotools, so that file is hand-written.
In order to prevent future confusion, the first line now explicitly
states that it is hand-written.","The previous header of config.in.h suggested that it has been
auto-generated with autoheader. tmLQCD does not use the full set of
GNU Autotools, so that file is hand-written.
In order to prevent future confusion, the first line now explicitly
states that it is hand-written.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,367,2017-04-22T10:09:10Z,2017-04-25T09:51:54Z,2017-05-11T07:07:16Z,MERGED,True,92,0,2,https://github.com/martin-ueding,Add Travis CI support,1,[],https://github.com/etmc/tmLQCD/pull/367,https://github.com/martin-ueding,1,https://github.com/etmc/tmLQCD/pull/367,"To actually build on Travis CI, go to https://travis-ci.org/etmc/tmLQCD
and log in with an account having admin rights on that repository. There
should be a switch to enable building. Then it is automatically
integrated with GitHub.
Currently it uses one of the HMC input files to run it. It would be even
better to use some proper unit test. The current usage is a smoke test
(as in Does it smoke when it is turned on?) only.","To actually build on Travis CI, go to https://travis-ci.org/etmc/tmLQCD
and log in with an account having admin rights on that repository. There
should be a switch to enable building. Then it is automatically
integrated with GitHub.
Currently it uses one of the HMC input files to run it. It would be even
better to use some proper unit test. The current usage is a smoke test
(as in Does it smoke when it is turned on?) only.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,367,2017-04-22T10:09:10Z,2017-04-25T09:51:54Z,2017-05-11T07:07:16Z,MERGED,True,92,0,2,https://github.com/martin-ueding,Add Travis CI support,1,[],https://github.com/etmc/tmLQCD/pull/367,https://github.com/urbach,2,https://github.com/etmc/tmLQCD/pull/367#issuecomment-296979588,"To actually build on Travis CI, go to https://travis-ci.org/etmc/tmLQCD
and log in with an account having admin rights on that repository. There
should be a switch to enable building. Then it is automatically
integrated with GitHub.
Currently it uses one of the HMC input files to run it. It would be even
better to use some proper unit test. The current usage is a smoke test
(as in Does it smoke when it is turned on?) only.","Okay, I merge this in. We have to see how useful it actually is in this form.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,367,2017-04-22T10:09:10Z,2017-04-25T09:51:54Z,2017-05-11T07:07:16Z,MERGED,True,92,0,2,https://github.com/martin-ueding,Add Travis CI support,1,[],https://github.com/etmc/tmLQCD/pull/367,https://github.com/urbach,3,https://github.com/etmc/tmLQCD/pull/367#issuecomment-296980521,"To actually build on Travis CI, go to https://travis-ci.org/etmc/tmLQCD
and log in with an account having admin rights on that repository. There
should be a switch to enable building. Then it is automatically
integrated with GitHub.
Currently it uses one of the HMC input files to run it. It would be even
better to use some proper unit test. The current usage is a smoke test
(as in Does it smoke when it is turned on?) only.",I think I have also activated it now.,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,367,2017-04-22T10:09:10Z,2017-04-25T09:51:54Z,2017-05-11T07:07:16Z,MERGED,True,92,0,2,https://github.com/martin-ueding,Add Travis CI support,1,[],https://github.com/etmc/tmLQCD/pull/367,https://github.com/martin-ueding,4,https://github.com/etmc/tmLQCD/pull/367#issuecomment-297157081,"To actually build on Travis CI, go to https://travis-ci.org/etmc/tmLQCD
and log in with an account having admin rights on that repository. There
should be a switch to enable building. Then it is automatically
integrated with GitHub.
Currently it uses one of the HMC input files to run it. It would be even
better to use some proper unit test. The current usage is a smoke test
(as in Does it smoke when it is turned on?) only.",One has to add more useful tests in travis-ci.sh. Perhaps one can also build it with more fancy options to test-drive a larger part of the codebase.,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,368,2017-04-26T10:30:02Z,2017-05-05T11:55:22Z,2017-05-08T13:39:31Z,MERGED,True,2,2,1,https://github.com/kostrzewa,doc: correct some mistakes in the clover documentation,2,[],https://github.com/etmc/tmLQCD/pull/368,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/368,,,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,368,2017-04-26T10:30:02Z,2017-05-05T11:55:22Z,2017-05-08T13:39:31Z,MERGED,True,2,2,1,https://github.com/kostrzewa,doc: correct some mistakes in the clover documentation,2,[],https://github.com/etmc/tmLQCD/pull/368,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/368#issuecomment-299445038,,It's a atypo :),True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,370,2017-05-02T06:29:28Z,2017-05-05T11:48:47Z,2017-05-05T11:48:47Z,MERGED,True,41,24,1,https://github.com/kostrzewa,quda_interface: support current inv_param setup for mu and clover term,1,[],https://github.com/etmc/tmLQCD/pull/370,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/370,support twisted mass flavour choice in current quda develop branch,support twisted mass flavour choice in current quda develop branch,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,370,2017-05-02T06:29:28Z,2017-05-05T11:48:47Z,2017-05-05T11:48:47Z,MERGED,True,41,24,1,https://github.com/kostrzewa,quda_interface: support current inv_param setup for mu and clover term,1,[],https://github.com/etmc/tmLQCD/pull/370,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/370#issuecomment-298508178,support twisted mass flavour choice in current quda develop branch,"@urbach
it would be great if this could be pulled in soon as it is blocking JSC for their benchmarks as I somehow forgot to push these changes earlier with all the stress.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,373,2017-05-04T16:48:37Z,2017-05-05T11:42:43Z,2017-05-08T13:39:39Z,MERGED,True,5,0,1,https://github.com/kostrzewa,read_input: allow bicgstab as a solver for clover operator,1,[],https://github.com/etmc/tmLQCD/pull/373,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/373,This is mainly for using QUDA BiCGstab with the CLOVER operator (mu=0.0). ```invert_clover_eo`` is properly safeguarded and will just terminate if someone attempts to use the tmLQCD BiCGstab with the CLOVER operator.,This is mainly for using QUDA BiCGstab with the CLOVER operator (mu=0.0). ```invert_clover_eo`` is properly safeguarded and will just terminate if someone attempts to use the tmLQCD BiCGstab with the CLOVER operator.,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,375,2017-05-06T09:47:23Z,2017-05-08T09:59:07Z,2017-05-08T13:36:50Z,MERGED,True,8,2,1,https://github.com/kostrzewa,configure.in: support 64 byte alignment,1,[],https://github.com/etmc/tmLQCD/pull/375,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/375,,,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,376,2017-05-08T09:57:04Z,2017-05-08T09:59:36Z,2017-05-08T13:36:46Z,MERGED,True,1,1,1,https://github.com/kostrzewa,QUDA now requires -lcuda and -lcublas,1,[],https://github.com/etmc/tmLQCD/pull/376,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/376,,,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,377,2017-05-08T14:53:30Z,2018-04-26T08:57:00Z,2018-04-26T08:57:00Z,MERGED,True,2,1,1,https://github.com/kostrzewa,offline_measurement requires git_hash.h as a dependency,2,[],https://github.com/etmc/tmLQCD/pull/377,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/377,,,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,378,2017-05-10T11:04:24Z,2017-05-13T10:54:28Z,2017-05-13T10:54:28Z,MERGED,True,92,96,6,https://github.com/kostrzewa,qphix_interface: fix checkerboard convention,4,[],https://github.com/etmc/tmLQCD/pull/378,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/378,now both test_Dslash and the inversion work correctly for Wilson,now both test_Dslash and the inversion work correctly for Wilson,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,378,2017-05-10T11:04:24Z,2017-05-13T10:54:28Z,2017-05-13T10:54:28Z,MERGED,True,92,96,6,https://github.com/kostrzewa,qphix_interface: fix checkerboard convention,4,[],https://github.com/etmc/tmLQCD/pull/378,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/378#issuecomment-300451792,now both test_Dslash and the inversion work correctly for Wilson,Let's see if the build goes through now.,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,378,2017-05-10T11:04:24Z,2017-05-13T10:54:28Z,2017-05-13T10:54:28Z,MERGED,True,92,96,6,https://github.com/kostrzewa,qphix_interface: fix checkerboard convention,4,[],https://github.com/etmc/tmLQCD/pull/378,https://github.com/kostrzewa,3,https://github.com/etmc/tmLQCD/pull/378#issuecomment-300452375,now both test_Dslash and the inversion work correctly for Wilson,"@martin-ueding thanks a lot for setting up travis, even in this simple setup, it is very useful",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,378,2017-05-10T11:04:24Z,2017-05-13T10:54:28Z,2017-05-13T10:54:28Z,MERGED,True,92,96,6,https://github.com/kostrzewa,qphix_interface: fix checkerboard convention,4,[],https://github.com/etmc/tmLQCD/pull/378,https://github.com/martin-ueding,4,https://github.com/etmc/tmLQCD/pull/378#issuecomment-300843794,now both test_Dslash and the inversion work correctly for Wilson,I have checked the commit where you have changed the magic numbers to cb_even and cb_odd. That looks good to me!,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,380,2017-05-15T14:09:24Z,2018-04-26T08:55:43Z,2018-04-26T08:55:43Z,MERGED,True,3,2,1,https://github.com/kostrzewa,force compilation of main.pdf,2,[],https://github.com/etmc/tmLQCD/pull/380,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/380,"even if there are missing references or other, non-critical errors
occur","even if there are missing references or other, non-critical errors
occur",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,382,2017-05-16T12:00:11Z,2017-05-26T16:47:37Z,2017-05-26T16:47:37Z,CLOSED,False,329,219,11,https://github.com/kostrzewa,make qphix_test_Dslash meaningful,8,[],https://github.com/etmc/tmLQCD/pull/382,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/382,"provide support for reading operator type from input file
implement single application of full operator in qphix interface","provide support for reading operator type from input file
implement single application of full operator in qphix interface",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,382,2017-05-16T12:00:11Z,2017-05-26T16:47:37Z,2017-05-26T16:47:37Z,CLOSED,False,329,219,11,https://github.com/kostrzewa,make qphix_test_Dslash meaningful,8,[],https://github.com/etmc/tmLQCD/pull/382,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/382#issuecomment-301891785,"provide support for reading operator type from input file
implement single application of full operator in qphix interface","Okay, so I think we're ready to finish working on the clover stuff now!",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,382,2017-05-16T12:00:11Z,2017-05-26T16:47:37Z,2017-05-26T16:47:37Z,CLOSED,False,329,219,11,https://github.com/kostrzewa,make qphix_test_Dslash meaningful,8,[],https://github.com/etmc/tmLQCD/pull/382,https://github.com/martin-ueding,3,https://github.com/etmc/tmLQCD/pull/382#issuecomment-301909163,"provide support for reading operator type from input file
implement single application of full operator in qphix interface","So the interface for Wilson and Wilson twisted mass is done? That sounds great! 
Do we want to continue with Wilson clover or TM clover?",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,382,2017-05-16T12:00:11Z,2017-05-26T16:47:37Z,2017-05-26T16:47:37Z,CLOSED,False,329,219,11,https://github.com/kostrzewa,make qphix_test_Dslash meaningful,8,[],https://github.com/etmc/tmLQCD/pull/382,https://github.com/kostrzewa,4,https://github.com/etmc/tmLQCD/pull/382#issuecomment-301990066,"provide support for reading operator type from input file
implement single application of full operator in qphix interface","So the interface for Wilson and Wilson twisted mass is done? That sounds great! 

Up to the problem with communication in two space-time directions simultaneously... I was planning to look at the QDP packers to understand this.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,382,2017-05-16T12:00:11Z,2017-05-26T16:47:37Z,2017-05-26T16:47:37Z,CLOSED,False,329,219,11,https://github.com/kostrzewa,make qphix_test_Dslash meaningful,8,[],https://github.com/etmc/tmLQCD/pull/382,https://github.com/kostrzewa,5,https://github.com/etmc/tmLQCD/pull/382#issuecomment-304332039,"provide support for reading operator type from input file
implement single application of full operator in qphix interface","This is pulled in by #383, closing.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,383,2017-05-26T14:37:44Z,2017-06-02T20:22:10Z,2017-06-02T20:22:10Z,CLOSED,False,769,413,11,https://github.com/kostrzewa,updated qphix_test_Dslash & full 4D parallelisation support,20,[],https://github.com/etmc/tmLQCD/pull/383,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/383,,,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,384,2017-06-02T20:23:43Z,2017-06-13T17:58:47Z,2017-06-13T17:58:47Z,MERGED,True,1340,656,12,https://github.com/kostrzewa,QPhiX support for all degenerate operators in the inverter,28,[],https://github.com/etmc/tmLQCD/pull/384,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/384,"full 4D parallelisation
more meaningfull test structure for operators
eo spinor packers
reworked gauge packer
clover field packers","full 4D parallelisation
more meaningfull test structure for operators
eo spinor packers
reworked gauge packer
clover field packers",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,384,2017-06-02T20:23:43Z,2017-06-13T17:58:47Z,2017-06-13T17:58:47Z,MERGED,True,1340,656,12,https://github.com/kostrzewa,QPhiX support for all degenerate operators in the inverter,28,[],https://github.com/etmc/tmLQCD/pull/384,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/384#issuecomment-308198430,"full 4D parallelisation
more meaningfull test structure for operators
eo spinor packers
reworked gauge packer
clover field packers","Okay, I think I've resolved all remaining issues, merging.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,385,2017-06-13T18:00:03Z,2017-11-08T06:00:09Z,2017-11-08T06:00:10Z,MERGED,True,11137,8916,72,https://github.com/kostrzewa,First stab at QPhiX in HMC. ,50,[],https://github.com/etmc/tmLQCD/pull/385,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/385,"First trajectory with det_monomial works (perfect agreement). After that, it seems that something breaks.

Combined solver_pm_t and solver_params_t (finally!)
Changed how external inverters are called ->
UseExternalInverter = {qphix,quda,no}, rather than
Use{Qphix,Quda}Inverter = {yes,no}
QPhiX solver interface can now do solves with external source
preparation and supports returning the solution to the EO
preconditioned system or the reconstructed solution, as required.
Similarly, it can also return the solution to the M M^dag system
rather than the full solution, as required.
Added external inverter parameter to monomials.
Solver interfaces now also pass through compression and sloppy
precision, as required.
invert_eo and invert_clover_eo call QPhiX with NULL pointers for the
even checkerboards, such that tmLQCD can prepare the source.
added support for QPhiX in solve_degenerate
Ugly hack in det_monomial to insert an additional factor of gamma5
required because QPhiX solves M M^dag rather than {Q^+}{Q^-}
Pass-through of matrix_mult type to invert_qphix_eo. At present this
is not used, but it might prove necessary in the future. Optionally
it can be removed at some point.
Added ""solution_type_t"" enum, such that an object calling solvers
(a monomial or an operator), can tell the solver wrapper whether
the solution to (M M^dag) x = b is required (TM_SOLUTION_M_MDAG) or
whether the solution to M x = b should be extracted before the
solution is returned.","First trajectory with det_monomial works (perfect agreement). After that, it seems that something breaks.

Combined solver_pm_t and solver_params_t (finally!)
Changed how external inverters are called ->
UseExternalInverter = {qphix,quda,no}, rather than
Use{Qphix,Quda}Inverter = {yes,no}
QPhiX solver interface can now do solves with external source
preparation and supports returning the solution to the EO
preconditioned system or the reconstructed solution, as required.
Similarly, it can also return the solution to the M M^dag system
rather than the full solution, as required.
Added external inverter parameter to monomials.
Solver interfaces now also pass through compression and sloppy
precision, as required.
invert_eo and invert_clover_eo call QPhiX with NULL pointers for the
even checkerboards, such that tmLQCD can prepare the source.
added support for QPhiX in solve_degenerate
Ugly hack in det_monomial to insert an additional factor of gamma5
required because QPhiX solves M M^dag rather than {Q^+}{Q^-}
Pass-through of matrix_mult type to invert_qphix_eo. At present this
is not used, but it might prove necessary in the future. Optionally
it can be removed at some point.
Added ""solution_type_t"" enum, such that an object calling solvers
(a monomial or an operator), can tell the solver wrapper whether
the solution to (M M^dag) x = b is required (TM_SOLUTION_M_MDAG) or
whether the solution to M x = b should be extracted before the
solution is returned.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,385,2017-06-13T18:00:03Z,2017-11-08T06:00:09Z,2017-11-08T06:00:10Z,MERGED,True,11137,8916,72,https://github.com/kostrzewa,First stab at QPhiX in HMC. ,50,[],https://github.com/etmc/tmLQCD/pull/385,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/385#issuecomment-308201132,"First trajectory with det_monomial works (perfect agreement). After that, it seems that something breaks.

Combined solver_pm_t and solver_params_t (finally!)
Changed how external inverters are called ->
UseExternalInverter = {qphix,quda,no}, rather than
Use{Qphix,Quda}Inverter = {yes,no}
QPhiX solver interface can now do solves with external source
preparation and supports returning the solution to the EO
preconditioned system or the reconstructed solution, as required.
Similarly, it can also return the solution to the M M^dag system
rather than the full solution, as required.
Added external inverter parameter to monomials.
Solver interfaces now also pass through compression and sloppy
precision, as required.
invert_eo and invert_clover_eo call QPhiX with NULL pointers for the
even checkerboards, such that tmLQCD can prepare the source.
added support for QPhiX in solve_degenerate
Ugly hack in det_monomial to insert an additional factor of gamma5
required because QPhiX solves M M^dag rather than {Q^+}{Q^-}
Pass-through of matrix_mult type to invert_qphix_eo. At present this
is not used, but it might prove necessary in the future. Optionally
it can be removed at some point.
Added ""solution_type_t"" enum, such that an object calling solvers
(a monomial or an operator), can tell the solver wrapper whether
the solution to (M M^dag) x = b is required (TM_SOLUTION_M_MDAG) or
whether the solution to M x = b should be extracted before the
solution is returned.","I have another commit waiting in the pipe-line in which I call clang-format on all the files that were touched here. For brevity of the changes, I am not including it here yet.
I have tested the HMC with all kinds of monomials and our old solvers and I don't see that I've introduced any regressions, but of course I can't be sure.
This commit does not yet include any true refactoring of the solver interfaces, short of some minor tweaks as discussed above.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,385,2017-06-13T18:00:03Z,2017-11-08T06:00:09Z,2017-11-08T06:00:10Z,MERGED,True,11137,8916,72,https://github.com/kostrzewa,First stab at QPhiX in HMC. ,50,[],https://github.com/etmc/tmLQCD/pull/385,https://github.com/kostrzewa,3,https://github.com/etmc/tmLQCD/pull/385#issuecomment-308384891,"First trajectory with det_monomial works (perfect agreement). After that, it seems that something breaks.

Combined solver_pm_t and solver_params_t (finally!)
Changed how external inverters are called ->
UseExternalInverter = {qphix,quda,no}, rather than
Use{Qphix,Quda}Inverter = {yes,no}
QPhiX solver interface can now do solves with external source
preparation and supports returning the solution to the EO
preconditioned system or the reconstructed solution, as required.
Similarly, it can also return the solution to the M M^dag system
rather than the full solution, as required.
Added external inverter parameter to monomials.
Solver interfaces now also pass through compression and sloppy
precision, as required.
invert_eo and invert_clover_eo call QPhiX with NULL pointers for the
even checkerboards, such that tmLQCD can prepare the source.
added support for QPhiX in solve_degenerate
Ugly hack in det_monomial to insert an additional factor of gamma5
required because QPhiX solves M M^dag rather than {Q^+}{Q^-}
Pass-through of matrix_mult type to invert_qphix_eo. At present this
is not used, but it might prove necessary in the future. Optionally
it can be removed at some point.
Added ""solution_type_t"" enum, such that an object calling solvers
(a monomial or an operator), can tell the solver wrapper whether
the solution to (M M^dag) x = b is required (TM_SOLUTION_M_MDAG) or
whether the solution to M x = b should be extracted before the
solution is returned.","Okay, I've figured out the problem. As soon as I have a workaround, we will have the determinant working with QPhiX. The CORRELATORS online measurement (via the operator framework) touches globals, in particular g_kappa. The monomials, as they are currently implemented, modify only g_mu but not g_kappa (they modify boundary(mnl->kappa) instead). If kappa in the online measurement differs from kappa in the monomials, things break after the first trajectory.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,385,2017-06-13T18:00:03Z,2017-11-08T06:00:09Z,2017-11-08T06:00:10Z,MERGED,True,11137,8916,72,https://github.com/kostrzewa,First stab at QPhiX in HMC. ,50,[],https://github.com/etmc/tmLQCD/pull/385,https://github.com/kostrzewa,4,https://github.com/etmc/tmLQCD/pull/385#issuecomment-308386310,"First trajectory with det_monomial works (perfect agreement). After that, it seems that something breaks.

Combined solver_pm_t and solver_params_t (finally!)
Changed how external inverters are called ->
UseExternalInverter = {qphix,quda,no}, rather than
Use{Qphix,Quda}Inverter = {yes,no}
QPhiX solver interface can now do solves with external source
preparation and supports returning the solution to the EO
preconditioned system or the reconstructed solution, as required.
Similarly, it can also return the solution to the M M^dag system
rather than the full solution, as required.
Added external inverter parameter to monomials.
Solver interfaces now also pass through compression and sloppy
precision, as required.
invert_eo and invert_clover_eo call QPhiX with NULL pointers for the
even checkerboards, such that tmLQCD can prepare the source.
added support for QPhiX in solve_degenerate
Ugly hack in det_monomial to insert an additional factor of gamma5
required because QPhiX solves M M^dag rather than {Q^+}{Q^-}
Pass-through of matrix_mult type to invert_qphix_eo. At present this
is not used, but it might prove necessary in the future. Optionally
it can be removed at some point.
Added ""solution_type_t"" enum, such that an object calling solvers
(a monomial or an operator), can tell the solver wrapper whether
the solution to (M M^dag) x = b is required (TM_SOLUTION_M_MDAG) or
whether the solution to M x = b should be extracted before the
solution is returned.","I think it would be consistent, although I have to check carefully for the determinant ratios, that all monomials and all operators treat the globals as a true global state (if we want to keep them around, that is). Hence, ALL monomial and ALL operator functions should set all globals and reset them. The overhead of this will be minimal, compared to the work done in the functions. @urbach, your opinion would be very helpful here.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,385,2017-06-13T18:00:03Z,2017-11-08T06:00:09Z,2017-11-08T06:00:10Z,MERGED,True,11137,8916,72,https://github.com/kostrzewa,First stab at QPhiX in HMC. ,50,[],https://github.com/etmc/tmLQCD/pull/385,https://github.com/kostrzewa,5,https://github.com/etmc/tmLQCD/pull/385#issuecomment-308409985,"First trajectory with det_monomial works (perfect agreement). After that, it seems that something breaks.

Combined solver_pm_t and solver_params_t (finally!)
Changed how external inverters are called ->
UseExternalInverter = {qphix,quda,no}, rather than
Use{Qphix,Quda}Inverter = {yes,no}
QPhiX solver interface can now do solves with external source
preparation and supports returning the solution to the EO
preconditioned system or the reconstructed solution, as required.
Similarly, it can also return the solution to the M M^dag system
rather than the full solution, as required.
Added external inverter parameter to monomials.
Solver interfaces now also pass through compression and sloppy
precision, as required.
invert_eo and invert_clover_eo call QPhiX with NULL pointers for the
even checkerboards, such that tmLQCD can prepare the source.
added support for QPhiX in solve_degenerate
Ugly hack in det_monomial to insert an additional factor of gamma5
required because QPhiX solves M M^dag rather than {Q^+}{Q^-}
Pass-through of matrix_mult type to invert_qphix_eo. At present this
is not used, but it might prove necessary in the future. Optionally
it can be removed at some point.
Added ""solution_type_t"" enum, such that an object calling solvers
(a monomial or an operator), can tell the solver wrapper whether
the solution to (M M^dag) x = b is required (TM_SOLUTION_M_MDAG) or
whether the solution to M x = b should be extracted before the
solution is returned.","QPhiX left, tmLQCD right. Speedup is about a factor of 3 on my laptop. (twisted mass only)
00000000 0.298296940742 -42.631938679559 3.272018e+18 86 1390 1 4.82 |	00000000 0.298296940742 -42.631938679559 3.272018e+18 88 1440 1 1.05
00000001 0.379469819821 -24.518588593597 4.449259e+10 74 1224 1 4.93 |	00000001 0.379469819821 -24.518588593601 4.449259e+10 76 1274 1 1.04
00000002 0.431327967506 -16.879338789833 2.140936e+07 78 1284 1 4.92 |	00000002 0.431327967506 -16.879338789822 2.140936e+07 80 1334 1 1.17
00000003 0.465588476464 -13.339722129993 6.213949e+05 82 1364 1 5.43 |	00000003 0.465588476464 -13.339722130000 6.213949e+05 84 1414 1 1.09
00000004 0.493366555982 -9.938700005659 2.071680e+04 86 1428 1 4.676 |	00000004 0.493366555982 -9.938700005649 2.071680e+04 88 1478 1 1.267
00000005 0.516843734094 -10.637340144527 4.166181e+04 90 1484 1 5.52 |	00000005 0.516843734094 -10.637340144523 4.166181e+04 92 1534 1 1.17
00000006 0.534335326192 -7.043767992283 1.145696e+03 94 1534 1 5.416 |	00000006 0.534335326192 -7.043767992269 1.145696e+03 96 1584 1 1.190
00000007 0.547434307190 -5.667253065636 2.892389e+02 98 1588 1 5.222 |	00000007 0.547434307190 -5.667253065632 2.892389e+02 100 1638 1 1.21
00000008 0.561303803869 -5.489827417474 2.422154e+02 101 1646 1 5.33 |	00000008 0.561303803869 -5.489827417477 2.422154e+02 103 1696 1 1.26
00000009 0.571787207793 -4.405070369197 8.186490e+01 104 1696 1 5.35 |	00000009 0.571787207793 -4.405070369205 8.186490e+01 106 1746 1 1.31
00000010 0.580541797759 -2.401600686258 1.104084e+01 108 1742 1 4.65 |	00000010 0.580541797759 -2.401600686288 1.104084e+01 110 1792 1 1.37
00000011 0.587587442380 -3.277444243529 2.650794e+01 111 1798 1 5.61 |	00000011 0.587587442380 -3.277444243515 2.650794e+01 113 1848 1 1.34
00000012 0.587420548641 -0.631437604017 1.880312e+00 112 1800 1 4.71 |	00000012 0.587420548641 -0.631437604035 1.880312e+00 114 1850 1 1.39
00000013 0.592264793088 -2.150387143985 8.588183e+00 111 1822 1 5.61 |	00000013 0.592264793088 -2.150387143953 8.588183e+00 113 1872 1 1.39
00000014 0.595669656136 -0.468859482349 1.598170e+00 114 1844 1 5.69 |	00000014 0.595669656136 -0.468859482378 1.598170e+00 116 1894 1 1.37
00000015 0.597035565095 -1.810370167932 6.112710e+00 116 1876 1 5.80 |	00000015 0.597035565095 -1.810370167976 6.112710e+00 118 1926 1 1.41
00000016 0.600057201272 -0.610410848654 1.841188e+00 116 1852 1 5.60 |	00000016 0.600057201272 -0.610410848683 1.841188e+00 118 1902 1 1.56
00000017 0.600519978570 -0.048470878421 1.049665e+00 116 1868 1 5.85 |	00000017 0.600519978570 -0.048470878428 1.049665e+00 118 1918 1 1.38
00000018 0.598464102101 0.528457035296 5.895139e-01 115 1850 1 5.125 |	00000018 0.598464102101 0.528457035372 5.895139e-01 117 1900 1 1.431
00000019 0.599780645885 -1.412688958393 4.106984e+00 115 1854 1 6.45 |	00000019 0.599780645885 -1.412688958149 4.106984e+00 117 1904 1 1.33",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,385,2017-06-13T18:00:03Z,2017-11-08T06:00:09Z,2017-11-08T06:00:10Z,MERGED,True,11137,8916,72,https://github.com/kostrzewa,First stab at QPhiX in HMC. ,50,[],https://github.com/etmc/tmLQCD/pull/385,https://github.com/urbach,6,https://github.com/etmc/tmLQCD/pull/385#issuecomment-308420877,"First trajectory with det_monomial works (perfect agreement). After that, it seems that something breaks.

Combined solver_pm_t and solver_params_t (finally!)
Changed how external inverters are called ->
UseExternalInverter = {qphix,quda,no}, rather than
Use{Qphix,Quda}Inverter = {yes,no}
QPhiX solver interface can now do solves with external source
preparation and supports returning the solution to the EO
preconditioned system or the reconstructed solution, as required.
Similarly, it can also return the solution to the M M^dag system
rather than the full solution, as required.
Added external inverter parameter to monomials.
Solver interfaces now also pass through compression and sloppy
precision, as required.
invert_eo and invert_clover_eo call QPhiX with NULL pointers for the
even checkerboards, such that tmLQCD can prepare the source.
added support for QPhiX in solve_degenerate
Ugly hack in det_monomial to insert an additional factor of gamma5
required because QPhiX solves M M^dag rather than {Q^+}{Q^-}
Pass-through of matrix_mult type to invert_qphix_eo. At present this
is not used, but it might prove necessary in the future. Optionally
it can be removed at some point.
Added ""solution_type_t"" enum, such that an object calling solvers
(a monomial or an operator), can tell the solver wrapper whether
the solution to (M M^dag) x = b is required (TM_SOLUTION_M_MDAG) or
whether the solution to M x = b should be extracted before the
solution is returned.","Yes, as long as we have the globals that sounds like a good plan. Monomials also have the info available. Operators not necessarily?

On the long run we need a struct for parameters...

Am 14. Juni 2017 12:06:46 MESZ schrieb Bartosz Kostrzewa <notifications@github.com>:

I think it would be consistent, although I have to check carefully for
the determinant ratios, that all monomials and all operators treat the
globals as a true global state (if we want to keep them around, that
is). Hence, ALL monomial and ALL operator functions should set all
globals and reset them. The overhead of this will be minimal, compared
to the work done in the functions. @urbach, your opinion would be very
helpful here.

-- 
Carsten Urbach, www.carsten-urbach.eu",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,385,2017-06-13T18:00:03Z,2017-11-08T06:00:09Z,2017-11-08T06:00:10Z,MERGED,True,11137,8916,72,https://github.com/kostrzewa,First stab at QPhiX in HMC. ,50,[],https://github.com/etmc/tmLQCD/pull/385,https://github.com/kostrzewa,7,https://github.com/etmc/tmLQCD/pull/385#issuecomment-310046269,"First trajectory with det_monomial works (perfect agreement). After that, it seems that something breaks.

Combined solver_pm_t and solver_params_t (finally!)
Changed how external inverters are called ->
UseExternalInverter = {qphix,quda,no}, rather than
Use{Qphix,Quda}Inverter = {yes,no}
QPhiX solver interface can now do solves with external source
preparation and supports returning the solution to the EO
preconditioned system or the reconstructed solution, as required.
Similarly, it can also return the solution to the M M^dag system
rather than the full solution, as required.
Added external inverter parameter to monomials.
Solver interfaces now also pass through compression and sloppy
precision, as required.
invert_eo and invert_clover_eo call QPhiX with NULL pointers for the
even checkerboards, such that tmLQCD can prepare the source.
added support for QPhiX in solve_degenerate
Ugly hack in det_monomial to insert an additional factor of gamma5
required because QPhiX solves M M^dag rather than {Q^+}{Q^-}
Pass-through of matrix_mult type to invert_qphix_eo. At present this
is not used, but it might prove necessary in the future. Optionally
it can be removed at some point.
Added ""solution_type_t"" enum, such that an object calling solvers
(a monomial or an operator), can tell the solver wrapper whether
the solution to (M M^dag) x = b is required (TM_SOLUTION_M_MDAG) or
whether the solution to M x = b should be extracted before the
solution is returned.","The determinant ratio is running too now, with twisted boundary conditions in all four dimensions and all that jazz.
qphix left, tmlqcd right
00000000 0.291495392592 -39.711934066418 1.764712e+17 131 1376 1 5.91 |	00000000 0.291495392592 -39.711934066421 1.764712e+17 134 1426 1 1.40
00000001 0.373212841723 -24.165465895196 3.125565e+10 108 1220 1 5.90 |	00000001 0.373212841723 -24.165465895196 3.125565e+10 111 1270 1 1.25
00000002 0.422784900642 -17.099852358580 2.669141e+07 113 1284 1 6.15 |	00000002 0.422784900642 -17.099852358573 2.669141e+07 116 1334 1 1.37
00000003 0.456096335690 -11.581722297600 1.071219e+05 118 1336 1 5.42 |	00000003 0.456096335690 -11.581722297593 1.071219e+05 121 1386 1 1.37
00000004 0.483134478262 -9.452817802943 1.274402e+04 123 1392 1 6.711 |	00000004 0.483134478262 -9.452817802943 1.274402e+04 126 1442 1 1.395
00000005 0.504241118133 -9.148982144983 9.404863e+03 128 1440 1 6.961 |	00000005 0.504241118133 -9.148982145001 9.404863e+03 131 1490 1 1.553
00000006 0.520262864534 -5.838706504815 3.433350e+02 133 1514 1 6.472 |	00000006 0.520262864534 -5.838706504819 3.433350e+02 136 1564 1 1.619
00000007 0.531369635960 -4.467497362355 8.713837e+01 136 1546 1 5.603 |	00000007 0.531369635960 -4.467497362311 8.713837e+01 139 1596 1 1.644
00000008 0.540333672518 -3.732057393423 4.176495e+01 138 1566 1 6.747 |	00000008 0.540333672518 -3.732057393427 4.176495e+01 141 1616 1 1.677
00000009 0.549728548987 -3.015291567568 2.039504e+01 140 1600 1 6.949 |	00000009 0.549728548987 -3.015291567572 2.039504e+01 143 1650 1 1.619
00000010 0.557360688442 -2.824776852343 1.685718e+01 144 1650 1 6.921 |	00000010 0.557360688442 -2.824776852336 1.685718e+01 147 1700 1 1.711
00000011 0.566431406496 -2.843008448410 1.716733e+01 147 1680 1 6.497 |	00000011 0.566431406496 -2.843008448406 1.716733e+01 150 1730 1 1.772
00000012 0.567858817366 -1.926096589756 6.862670e+00 150 1728 1 5.865 |	00000012 0.567858817366 -1.926096589774 6.862670e+00 153 1778 1 2.160
00000013 0.571629104611 -1.821771275951 6.182800e+00 151 1742 1 7.340 |	00000013 0.571629104611 -1.821771275900 6.182800e+00 154 1792 1 1.835
00000014 0.576566136522 -2.246796442640 9.457390e+00 153 1750 1 7.248 |	00000014 0.576566136522 -2.246796442829 9.457390e+00 156 1800 1 1.551
00000015 0.578507396604 -0.066232862257 1.068475e+00 153 1762 1 7.310 |	00000015 0.578507396605 -0.066232862158 1.068475e+00 156 1812 1 1.803
00000016 0.580135909373 -0.721010304729 2.056510e+00 152 1750 1 7.190 |	00000016 0.580135909374 -0.721010304766 2.056510e+00 155 1800 1 1.807
00000017 0.580777985191 0.216365398370 8.054409e-01 153 1774 1 5.5451 |	00000017 0.580777985192 0.216365397602 8.054409e-01 156 1824 1 1.7811
00000018 0.580842813818 -0.049916319662 1.051183e+00 153 1790 1 8.352 |	00000018 0.580842813820 -0.049916319829 1.051183e+00 156 1840 1 1.714
00000019 0.585585100353 -1.393572286492 4.029218e+00 154 1790 1 6.914 |	00000019 0.585585100356 -1.393572286834 4.029218e+00 157 1840 1 1.656",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,385,2017-06-13T18:00:03Z,2017-11-08T06:00:09Z,2017-11-08T06:00:10Z,MERGED,True,11137,8916,72,https://github.com/kostrzewa,First stab at QPhiX in HMC. ,50,[],https://github.com/etmc/tmLQCD/pull/385,https://github.com/kostrzewa,8,https://github.com/etmc/tmLQCD/pull/385#issuecomment-340255064,"First trajectory with det_monomial works (perfect agreement). After that, it seems that something breaks.

Combined solver_pm_t and solver_params_t (finally!)
Changed how external inverters are called ->
UseExternalInverter = {qphix,quda,no}, rather than
Use{Qphix,Quda}Inverter = {yes,no}
QPhiX solver interface can now do solves with external source
preparation and supports returning the solution to the EO
preconditioned system or the reconstructed solution, as required.
Similarly, it can also return the solution to the M M^dag system
rather than the full solution, as required.
Added external inverter parameter to monomials.
Solver interfaces now also pass through compression and sloppy
precision, as required.
invert_eo and invert_clover_eo call QPhiX with NULL pointers for the
even checkerboards, such that tmLQCD can prepare the source.
added support for QPhiX in solve_degenerate
Ugly hack in det_monomial to insert an additional factor of gamma5
required because QPhiX solves M M^dag rather than {Q^+}{Q^-}
Pass-through of matrix_mult type to invert_qphix_eo. At present this
is not used, but it might prove necessary in the future. Optionally
it can be removed at some point.
Added ""solution_type_t"" enum, such that an object calling solvers
(a monomial or an operator), can tell the solver wrapper whether
the solution to (M M^dag) x = b is required (TM_SOLUTION_M_MDAG) or
whether the solution to M x = b should be extracted before the
solution is returned.",This is very nearly ready to be merged. @urbach: did you have a chance to look at it yet?,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,385,2017-06-13T18:00:03Z,2017-11-08T06:00:09Z,2017-11-08T06:00:10Z,MERGED,True,11137,8916,72,https://github.com/kostrzewa,First stab at QPhiX in HMC. ,50,[],https://github.com/etmc/tmLQCD/pull/385,https://github.com/kostrzewa,9,https://github.com/etmc/tmLQCD/pull/385#issuecomment-340255080,"First trajectory with det_monomial works (perfect agreement). After that, it seems that something breaks.

Combined solver_pm_t and solver_params_t (finally!)
Changed how external inverters are called ->
UseExternalInverter = {qphix,quda,no}, rather than
Use{Qphix,Quda}Inverter = {yes,no}
QPhiX solver interface can now do solves with external source
preparation and supports returning the solution to the EO
preconditioned system or the reconstructed solution, as required.
Similarly, it can also return the solution to the M M^dag system
rather than the full solution, as required.
Added external inverter parameter to monomials.
Solver interfaces now also pass through compression and sloppy
precision, as required.
invert_eo and invert_clover_eo call QPhiX with NULL pointers for the
even checkerboards, such that tmLQCD can prepare the source.
added support for QPhiX in solve_degenerate
Ugly hack in det_monomial to insert an additional factor of gamma5
required because QPhiX solves M M^dag rather than {Q^+}{Q^-}
Pass-through of matrix_mult type to invert_qphix_eo. At present this
is not used, but it might prove necessary in the future. Optionally
it can be removed at some point.
Added ""solution_type_t"" enum, such that an object calling solvers
(a monomial or an operator), can tell the solver wrapper whether
the solution to (M M^dag) x = b is required (TM_SOLUTION_M_MDAG) or
whether the solution to M x = b should be extracted before the
solution is returned.",I only have some documentation stuff to finish up.,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,388,2017-07-13T14:08:08Z,2017-07-14T14:12:27Z,2017-07-14T14:12:27Z,CLOSED,False,145,104,4,https://github.com/kostrzewa,add time slice by time slice measurement of correlators,2,[],https://github.com/etmc/tmLQCD/pull/388,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/388,and support for multiple samples per measurement,and support for multiple samples per measurement,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,388,2017-07-13T14:08:08Z,2017-07-14T14:12:27Z,2017-07-14T14:12:27Z,CLOSED,False,145,104,4,https://github.com/kostrzewa,add time slice by time slice measurement of correlators,2,[],https://github.com/etmc/tmLQCD/pull/388,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/388#issuecomment-315351311,and support for multiple samples per measurement,@urbach could you pull this in please?,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,388,2017-07-13T14:08:08Z,2017-07-14T14:12:27Z,2017-07-14T14:12:27Z,CLOSED,False,145,104,4,https://github.com/kostrzewa,add time slice by time slice measurement of correlators,2,[],https://github.com/etmc/tmLQCD/pull/388,https://github.com/kostrzewa,3,https://github.com/etmc/tmLQCD/pull/388#issuecomment-315369684,and support for multiple samples per measurement,"This will be meregd via #389, closing.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,389,2017-07-14T13:52:30Z,2017-07-17T08:15:29Z,2017-07-17T08:15:29Z,MERGED,True,318,175,15,https://github.com/kostrzewa,Add support for forced (A)PBC in QUDA interface,5,[],https://github.com/etmc/tmLQCD/pull/389,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/389,Also fixes a few small bugs and cleans up some parts of the QUDA integration. Contains #388,Also fixes a few small bugs and cleans up some parts of the QUDA integration. Contains #388,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,394,2017-08-01T10:31:02Z,2017-12-22T12:52:03Z,2017-12-22T12:52:03Z,MERGED,True,272,236,2,https://github.com/urbach,Fix issue #393,5,[],https://github.com/etmc/tmLQCD/pull/394,https://github.com/urbach,1,https://github.com/etmc/tmLQCD/pull/394,"This is a fix to issue #393.
The problem are the explicit SSE version of non-even/odd D_psi and
Dsw_psi.
The only feasible workaround at the moment is to disable SSE2|3 in
D_psi.
This will not affect the even/odd versions, which are still available
in SSE2|3.

In the future we'll remove these macros completely.","This is a fix to issue #393.
The problem are the explicit SSE version of non-even/odd D_psi and
Dsw_psi.
The only feasible workaround at the moment is to disable SSE2|3 in
D_psi.
This will not affect the even/odd versions, which are still available
in SSE2|3.

In the future we'll remove these macros completely.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,394,2017-08-01T10:31:02Z,2017-12-22T12:52:03Z,2017-12-22T12:52:03Z,MERGED,True,272,236,2,https://github.com/urbach,Fix issue #393,5,[],https://github.com/etmc/tmLQCD/pull/394,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/394#issuecomment-319652359,"This is a fix to issue #393.
The problem are the explicit SSE version of non-even/odd D_psi and
Dsw_psi.
The only feasible workaround at the moment is to disable SSE2|3 in
D_psi.
This will not affect the even/odd versions, which are still available
in SSE2|3.

In the future we'll remove these macros completely.",MPI should be TM_USE_MPI and OMP should be TM_USE_OMP,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,394,2017-08-01T10:31:02Z,2017-12-22T12:52:03Z,2017-12-22T12:52:03Z,MERGED,True,272,236,2,https://github.com/urbach,Fix issue #393,5,[],https://github.com/etmc/tmLQCD/pull/394,https://github.com/urbach,3,https://github.com/etmc/tmLQCD/pull/394#issuecomment-319671480,"This is a fix to issue #393.
The problem are the explicit SSE version of non-even/odd D_psi and
Dsw_psi.
The only feasible workaround at the moment is to disable SSE2|3 in
D_psi.
This will not affect the even/odd versions, which are still available
in SSE2|3.

In the future we'll remove these macros completely.","merci, should be fixed now
 ```MPI``` should be ```TM_USE_MPI``` and ```OMP``` should be ```TM_USE_OMP```

 --
 You are receiving this because you authored the thread.
 Reply to this email directly or view it on GitHub:
 #394 (comment)

--
Carsten Urbach
e-mail: curbach@gmx.de
        urbach@hiskp.uni-bonn.de
Fon   : +49 (0)228 73 2379
skype : carsten.urbach
URL: http://www.carsten-urbach.eu",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,394,2017-08-01T10:31:02Z,2017-12-22T12:52:03Z,2017-12-22T12:52:03Z,MERGED,True,272,236,2,https://github.com/urbach,Fix issue #393,5,[],https://github.com/etmc/tmLQCD/pull/394,https://github.com/kostrzewa,4,https://github.com/etmc/tmLQCD/pull/394#issuecomment-319690766,"This is a fix to issue #393.
The problem are the explicit SSE version of non-even/odd D_psi and
Dsw_psi.
The only feasible workaround at the moment is to disable SSE2|3 in
D_psi.
This will not affect the even/odd versions, which are still available
in SSE2|3.

In the future we'll remove these macros completely.",Now would probably also be a good time to expand which functionality is covered by travis...,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,394,2017-08-01T10:31:02Z,2017-12-22T12:52:03Z,2017-12-22T12:52:03Z,MERGED,True,272,236,2,https://github.com/urbach,Fix issue #393,5,[],https://github.com/etmc/tmLQCD/pull/394,https://github.com/martin-ueding,5,https://github.com/etmc/tmLQCD/pull/394#issuecomment-319703479,"This is a fix to issue #393.
The problem are the explicit SSE version of non-even/odd D_psi and
Dsw_psi.
The only feasible workaround at the moment is to disable SSE2|3 in
D_psi.
This will not affect the even/odd versions, which are still available
in SSE2|3.

In the future we'll remove these macros completely.","I suppose you want to build with different sets of  --enable-sse2 and --enable-sse3? One can use the Travis CI build matrix and supply various sets of environment variables. The builders support AVX but not AVX2, so SSE2 should be fine but SSE3 will likely not be supported.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,394,2017-08-01T10:31:02Z,2017-12-22T12:52:03Z,2017-12-22T12:52:03Z,MERGED,True,272,236,2,https://github.com/urbach,Fix issue #393,5,[],https://github.com/etmc/tmLQCD/pull/394,https://github.com/kostrzewa,6,https://github.com/etmc/tmLQCD/pull/394#issuecomment-353592624,"This is a fix to issue #393.
The problem are the explicit SSE version of non-even/odd D_psi and
Dsw_psi.
The only feasible workaround at the moment is to disable SSE2|3 in
D_psi.
This will not affect the even/odd versions, which are still available
in SSE2|3.

In the future we'll remove these macros completely.","This looks fine to me, meging.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,398,2017-09-01T14:25:48Z,2017-11-14T15:19:19Z,2017-11-14T15:19:19Z,MERGED,True,27,8,1,https://github.com/kostrzewa,Invert the correct flavour in invert_quda_direct ,1,[],https://github.com/etmc/tmLQCD/pull/398,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/398,"(this version of the code has never been used in production). Do not reorder the input spinor after the inversion (not sure why this was ever done). In addition, use threads in reordering routines.","(this version of the code has never been used in production). Do not reorder the input spinor after the inversion (not sure why this was ever done). In addition, use threads in reordering routines.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,398,2017-09-01T14:25:48Z,2017-11-14T15:19:19Z,2017-11-14T15:19:19Z,MERGED,True,27,8,1,https://github.com/kostrzewa,Invert the correct flavour in invert_quda_direct ,1,[],https://github.com/etmc/tmLQCD/pull/398,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/398#issuecomment-338194906,"(this version of the code has never been used in production). Do not reorder the input spinor after the inversion (not sure why this was ever done). In addition, use threads in reordering routines.",ping,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,402,2017-11-02T10:31:36Z,2017-11-14T15:18:02Z,2017-11-19T10:19:39Z,MERGED,True,1,1,1,https://github.com/kostrzewa,"Fix GH#400, DDalphaAMG interface should use correct TM_USE_OMP prepro",1,[],https://github.com/etmc/tmLQCD/pull/402,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/402,cessor macro,cessor macro,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,402,2017-11-02T10:31:36Z,2017-11-14T15:18:02Z,2017-11-19T10:19:39Z,MERGED,True,1,1,1,https://github.com/kostrzewa,"Fix GH#400, DDalphaAMG interface should use correct TM_USE_OMP prepro",1,[],https://github.com/etmc/tmLQCD/pull/402,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/402#issuecomment-341380532,cessor macro,"This should fix #400 . One needs to be careful to specify MGOmpNumThreads explicitly, however, because it is often better to have fewer threads in DDalphaAMG than in tmLQCD/QPhiX. Right now, it is not clear to me if this doesn't have the side-effect of reducing the thread count everywhere. In principle one should thus call omp_set_num_threads()  in tmLQCD upon leaving the DDalphaAMG context.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,402,2017-11-02T10:31:36Z,2017-11-14T15:18:02Z,2017-11-19T10:19:39Z,MERGED,True,1,1,1,https://github.com/kostrzewa,"Fix GH#400, DDalphaAMG interface should use correct TM_USE_OMP prepro",1,[],https://github.com/etmc/tmLQCD/pull/402,https://github.com/kostrzewa,3,https://github.com/etmc/tmLQCD/pull/402#issuecomment-344290631,cessor macro,"I will merge this now and we'll worry about the consequences later. In combination in QPhiX, there is no problem because QPhiX sets the number of threads each time a geometry is created (which is at each solve in our case, causing some limited overhead). Similarly, DDalphaAMG sets the number of threads each time it's called, so we can safely specify different numbers of threads.
What I'm not sure about, of course, are the other parts of tmLQCD. There is probably one side-case which could even create real problems. This is related to the reduction arrays which depend on the number of threads. As a result, MGOmpNumThreads should never be chosen larger than OMPNumThreads.
One way of resolving this relatively easily would be to save the current number of threads in the DDalphaAMG interface (I'm referring to the interface code within tmLQCD), start the DDalphaAMG solve and then reset the number of threads upon returning.
@sbacchio, @Finkenrath : could you mark that as a TODO in the DDalphaAMG interface code?",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,403,2017-11-08T06:01:02Z,2017-11-14T15:20:25Z,2018-04-26T09:02:55Z,MERGED,True,13782,8259,79,https://github.com/kostrzewa,Qphix devel,224,[],https://github.com/etmc/tmLQCD/pull/403,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/403,"Finally, this is the full QPhiX interface, ready to be merged into master.","Finally, this is the full QPhiX interface, ready to be merged into master.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,403,2017-11-08T06:01:02Z,2017-11-14T15:20:25Z,2018-04-26T09:02:55Z,MERGED,True,13782,8259,79,https://github.com/kostrzewa,Qphix devel,224,[],https://github.com/etmc/tmLQCD/pull/403,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/403#issuecomment-342721848,"Finally, this is the full QPhiX interface, ready to be merged into master.","I might remove the QPhiX operator base classes, since these are essentially duplicated in QPhiX now and increase the maintenance burden. Before the final merge, I need to fix some things up in the qphix/devel branch, so I can run a final test.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,403,2017-11-08T06:01:02Z,2017-11-14T15:20:25Z,2018-04-26T09:02:55Z,MERGED,True,13782,8259,79,https://github.com/kostrzewa,Qphix devel,224,[],https://github.com/etmc/tmLQCD/pull/403,https://github.com/kostrzewa,3,https://github.com/etmc/tmLQCD/pull/403#issuecomment-344182731,"Finally, this is the full QPhiX interface, ready to be merged into master.","It's ""go"" time. As soon as JeffersonLab/qphix#112 has landed, this branch of tmLQCD will compile out of the box with the QPhiX devel branch. We've lost the qphix Dslash test in the process and it should be recovered at some point (at the latest when we plan to get the QPhiX interface covered by Travis), but the code should be usable in production now, modulo the tests that @sunpho84 is still performing.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,403,2017-11-08T06:01:02Z,2017-11-14T15:20:25Z,2018-04-26T09:02:55Z,MERGED,True,13782,8259,79,https://github.com/kostrzewa,Qphix devel,224,[],https://github.com/etmc/tmLQCD/pull/403,https://github.com/martin-ueding,4,https://github.com/etmc/tmLQCD/pull/403#issuecomment-344199582,"Finally, this is the full QPhiX interface, ready to be merged into master.","The pull request on the QPhiX side has been merged, so you can go ahead here.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,403,2017-11-08T06:01:02Z,2017-11-14T15:20:25Z,2018-04-26T09:02:55Z,MERGED,True,13782,8259,79,https://github.com/kostrzewa,Qphix devel,224,[],https://github.com/etmc/tmLQCD/pull/403,https://github.com/kostrzewa,5,https://github.com/etmc/tmLQCD/pull/403#issuecomment-344291978,"Finally, this is the full QPhiX interface, ready to be merged into master.","Okay, I'm just going to go ahead, otherwise we will never merge this...",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,407,2017-11-19T15:10:46Z,2017-11-25T13:23:29Z,2017-11-25T13:23:29Z,MERGED,True,20,8,1,https://github.com/kostrzewa,qphix_interface adjust for new residual flag in QPhiX,1,[],https://github.com/etmc/tmLQCD/pull/407,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/407,"call all QPhiX solvers which support it with the QPhiX::RELATIVE flag, thus making explicit how we make the tmLQCD and QPhiX residuals agree for whatever is given in the input file","call all QPhiX solvers which support it with the QPhiX::RELATIVE flag, thus making explicit how we make the tmLQCD and QPhiX residuals agree for whatever is given in the input file",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,407,2017-11-19T15:10:46Z,2017-11-25T13:23:29Z,2017-11-25T13:23:29Z,MERGED,True,20,8,1,https://github.com/kostrzewa,qphix_interface adjust for new residual flag in QPhiX,1,[],https://github.com/etmc/tmLQCD/pull/407,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/407#issuecomment-345523806,"call all QPhiX solvers which support it with the QPhiX::RELATIVE flag, thus making explicit how we make the tmLQCD and QPhiX residuals agree for whatever is given in the input file",Takes care of #405,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,409,2017-12-22T12:36:30Z,2018-04-26T08:57:19Z,2018-04-26T08:57:19Z,MERGED,True,11,29,3,https://github.com/kostrzewa,propagate QPhiX changs toe offline_measurement executable and fix the,2,[],https://github.com/etmc/tmLQCD/pull/409,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/409," setting of the correlators parameters 'no_samples' and 'all_time_slices', which were overridden in init_measurements"," setting of the correlators parameters 'no_samples' and 'all_time_slices', which were overridden in init_measurements",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,411,2017-12-28T14:42:15Z,2018-09-28T09:14:17Z,2018-09-28T09:14:17Z,MERGED,True,1082,296,16,https://github.com/kostrzewa,Final QUDA-MG interface,39,[],https://github.com/etmc/tmLQCD/pull/411,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/411,"This is mostly done. The main remaining issue is that of enabling size 3 aggregrates, which seem to be currently unsupported by a default QUDA installation due to lack of the necessary instantiations (at least for the lattice size that was tested). Having support for these would probably be useful, however.
The default parameters selected here seem to work rather well as is, giving speedups of 3 or so over BiCGstab for Wilson clover fermions at around 270 MeV and speedups of well over 6 for twisted clover fermions at around 240 MeV. These speedups are likely about twice as large around the physical light quark mass.
These speedups are calculated against the minimum number of cards that a given problem fits on. While the CG and BiCGstab solves fit on a single P100, four cards are required for the corresponding MG solve. These are thus ""worst-case"" speedups, where the simple solvers are running in the most efficient way possible.","This is mostly done. The main remaining issue is that of enabling size 3 aggregrates, which seem to be currently unsupported by a default QUDA installation due to lack of the necessary instantiations (at least for the lattice size that was tested). Having support for these would probably be useful, however.
The default parameters selected here seem to work rather well as is, giving speedups of 3 or so over BiCGstab for Wilson clover fermions at around 270 MeV and speedups of well over 6 for twisted clover fermions at around 240 MeV. These speedups are likely about twice as large around the physical light quark mass.
These speedups are calculated against the minimum number of cards that a given problem fits on. While the CG and BiCGstab solves fit on a single P100, four cards are required for the corresponding MG solve. These are thus ""worst-case"" speedups, where the simple solvers are running in the most efficient way possible.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,411,2017-12-28T14:42:15Z,2018-09-28T09:14:17Z,2018-09-28T09:14:17Z,MERGED,True,1082,296,16,https://github.com/kostrzewa,Final QUDA-MG interface,39,[],https://github.com/etmc/tmLQCD/pull/411,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/411#issuecomment-354298899,"This is mostly done. The main remaining issue is that of enabling size 3 aggregrates, which seem to be currently unsupported by a default QUDA installation due to lack of the necessary instantiations (at least for the lattice size that was tested). Having support for these would probably be useful, however.
The default parameters selected here seem to work rather well as is, giving speedups of 3 or so over BiCGstab for Wilson clover fermions at around 270 MeV and speedups of well over 6 for twisted clover fermions at around 240 MeV. These speedups are likely about twice as large around the physical light quark mass.
These speedups are calculated against the minimum number of cards that a given problem fits on. While the CG and BiCGstab solves fit on a single P100, four cards are required for the corresponding MG solve. These are thus ""worst-case"" speedups, where the simple solvers are running in the most efficient way possible.","TODO LIST

 Check whether compilation without QUDA works as expected (travis should do this)
 See if parameter scans may reveal better default parameters.
 Add support for setting number of vectors, currently this defaults to 24.
 Add support for switching on size ""3"" aggregation lengths as an optional parameter (rather than hard-coding them to be disabled). This way, once the option is enabled, only QUDA needs to be adjusted to provide the necessary instances.
 Add support for Schwarz-preconditioner as a smoother (see https://github.com/lattice/quda/wiki/Multigrid-Solver)",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,411,2017-12-28T14:42:15Z,2018-09-28T09:14:17Z,2018-09-28T09:14:17Z,MERGED,True,1082,296,16,https://github.com/kostrzewa,Final QUDA-MG interface,39,[],https://github.com/etmc/tmLQCD/pull/411,https://github.com/kostrzewa,3,https://github.com/etmc/tmLQCD/pull/411#issuecomment-361049177,"This is mostly done. The main remaining issue is that of enabling size 3 aggregrates, which seem to be currently unsupported by a default QUDA installation due to lack of the necessary instantiations (at least for the lattice size that was tested). Having support for these would probably be useful, however.
The default parameters selected here seem to work rather well as is, giving speedups of 3 or so over BiCGstab for Wilson clover fermions at around 270 MeV and speedups of well over 6 for twisted clover fermions at around 240 MeV. These speedups are likely about twice as large around the physical light quark mass.
These speedups are calculated against the minimum number of cards that a given problem fits on. While the CG and BiCGstab solves fit on a single P100, four cards are required for the corresponding MG solve. These are thus ""worst-case"" speedups, where the simple solvers are running in the most efficient way possible.",Just need to update the docs and this can be merged I think.,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,411,2017-12-28T14:42:15Z,2018-09-28T09:14:17Z,2018-09-28T09:14:17Z,MERGED,True,1082,296,16,https://github.com/kostrzewa,Final QUDA-MG interface,39,[],https://github.com/etmc/tmLQCD/pull/411,https://github.com/kostrzewa,4,https://github.com/etmc/tmLQCD/pull/411#issuecomment-362221198,"This is mostly done. The main remaining issue is that of enabling size 3 aggregrates, which seem to be currently unsupported by a default QUDA installation due to lack of the necessary instantiations (at least for the lattice size that was tested). Having support for these would probably be useful, however.
The default parameters selected here seem to work rather well as is, giving speedups of 3 or so over BiCGstab for Wilson clover fermions at around 270 MeV and speedups of well over 6 for twisted clover fermions at around 240 MeV. These speedups are likely about twice as large around the physical light quark mass.
These speedups are calculated against the minimum number of cards that a given problem fits on. While the CG and BiCGstab solves fit on a single P100, four cards are required for the corresponding MG solve. These are thus ""worst-case"" speedups, where the simple solvers are running in the most efficient way possible.","Since the Schwarz-preconditioner is an experimental feature, I would like to postpone its inclusion in the interface to a later date. From my side, this should now be complete and functional.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,411,2017-12-28T14:42:15Z,2018-09-28T09:14:17Z,2018-09-28T09:14:17Z,MERGED,True,1082,296,16,https://github.com/kostrzewa,Final QUDA-MG interface,39,[],https://github.com/etmc/tmLQCD/pull/411,https://github.com/kostrzewa,5,https://github.com/etmc/tmLQCD/pull/411#issuecomment-384566774,"This is mostly done. The main remaining issue is that of enabling size 3 aggregrates, which seem to be currently unsupported by a default QUDA installation due to lack of the necessary instantiations (at least for the lattice size that was tested). Having support for these would probably be useful, however.
The default parameters selected here seem to work rather well as is, giving speedups of 3 or so over BiCGstab for Wilson clover fermions at around 270 MeV and speedups of well over 6 for twisted clover fermions at around 240 MeV. These speedups are likely about twice as large around the physical light quark mass.
These speedups are calculated against the minimum number of cards that a given problem fits on. While the CG and BiCGstab solves fit on a single P100, four cards are required for the corresponding MG solve. These are thus ""worst-case"" speedups, where the simple solvers are running in the most efficient way possible.",@urbach I would be happy to get this merged. It would be great if you could take a look to see if you spot anything untoward...,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,411,2017-12-28T14:42:15Z,2018-09-28T09:14:17Z,2018-09-28T09:14:17Z,MERGED,True,1082,296,16,https://github.com/kostrzewa,Final QUDA-MG interface,39,[],https://github.com/etmc/tmLQCD/pull/411,https://github.com/kostrzewa,6,https://github.com/etmc/tmLQCD/pull/411#issuecomment-398751674,"This is mostly done. The main remaining issue is that of enabling size 3 aggregrates, which seem to be currently unsupported by a default QUDA installation due to lack of the necessary instantiations (at least for the lattice size that was tested). Having support for these would probably be useful, however.
The default parameters selected here seem to work rather well as is, giving speedups of 3 or so over BiCGstab for Wilson clover fermions at around 270 MeV and speedups of well over 6 for twisted clover fermions at around 240 MeV. These speedups are likely about twice as large around the physical light quark mass.
These speedups are calculated against the minimum number of cards that a given problem fits on. While the CG and BiCGstab solves fit on a single P100, four cards are required for the corresponding MG solve. These are thus ""worst-case"" speedups, where the simple solvers are running in the most efficient way possible.","So, I've resolved #420 mostly. For measurements, everything runs with gauge persistence mode and nstore is used to make sure that the currently loaded gauge configuration in host memory and the gauge configuration in device memory, as well as all depdendent fields, match. This makes doing many inversions on the same gauge background using the default invert_quda code path with residual checks quite a bit faster because it removes superfluous host-device transfers. For the MG, this change is essential because the setup is now also persistent and will only be recomputed when necessary.
Note that our travis is broken because some package or other changed on travis...",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,411,2017-12-28T14:42:15Z,2018-09-28T09:14:17Z,2018-09-28T09:14:17Z,MERGED,True,1082,296,16,https://github.com/kostrzewa,Final QUDA-MG interface,39,[],https://github.com/etmc/tmLQCD/pull/411,https://github.com/kostrzewa,7,https://github.com/etmc/tmLQCD/pull/411#issuecomment-398752886,"This is mostly done. The main remaining issue is that of enabling size 3 aggregrates, which seem to be currently unsupported by a default QUDA installation due to lack of the necessary instantiations (at least for the lattice size that was tested). Having support for these would probably be useful, however.
The default parameters selected here seem to work rather well as is, giving speedups of 3 or so over BiCGstab for Wilson clover fermions at around 270 MeV and speedups of well over 6 for twisted clover fermions at around 240 MeV. These speedups are likely about twice as large around the physical light quark mass.
These speedups are calculated against the minimum number of cards that a given problem fits on. While the CG and BiCGstab solves fit on a single P100, four cards are required for the corresponding MG solve. These are thus ""worst-case"" speedups, where the simple solvers are running in the most efficient way possible.","This also paves the way, potentially, for using QUDA solvers in the HMC, but we need to write some wrappers for passing eo-ordered sources to the QUDA solver, not sure how easy / hard this will be.
The ""gauge id"" tracking can then be used, perhaps augmented to a double representing (nstore + tau*curr_step/N_steps) or something like that to

update the fields as we move along the trajectory
run the MG setup update when a given number of integration sub steps has been performed. (much like we do in DDalphaAMG)",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,411,2017-12-28T14:42:15Z,2018-09-28T09:14:17Z,2018-09-28T09:14:17Z,MERGED,True,1082,296,16,https://github.com/kostrzewa,Final QUDA-MG interface,39,[],https://github.com/etmc/tmLQCD/pull/411,https://github.com/kostrzewa,8,https://github.com/etmc/tmLQCD/pull/411#issuecomment-402742124,"This is mostly done. The main remaining issue is that of enabling size 3 aggregrates, which seem to be currently unsupported by a default QUDA installation due to lack of the necessary instantiations (at least for the lattice size that was tested). Having support for these would probably be useful, however.
The default parameters selected here seem to work rather well as is, giving speedups of 3 or so over BiCGstab for Wilson clover fermions at around 270 MeV and speedups of well over 6 for twisted clover fermions at around 240 MeV. These speedups are likely about twice as large around the physical light quark mass.
These speedups are calculated against the minimum number of cards that a given problem fits on. While the CG and BiCGstab solves fit on a single P100, four cards are required for the corresponding MG solve. These are thus ""worst-case"" speedups, where the simple solvers are running in the most efficient way possible.",It would be great if we could merge this...,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,411,2017-12-28T14:42:15Z,2018-09-28T09:14:17Z,2018-09-28T09:14:17Z,MERGED,True,1082,296,16,https://github.com/kostrzewa,Final QUDA-MG interface,39,[],https://github.com/etmc/tmLQCD/pull/411,https://github.com/kostrzewa,9,https://github.com/etmc/tmLQCD/pull/411#issuecomment-403043331,"This is mostly done. The main remaining issue is that of enabling size 3 aggregrates, which seem to be currently unsupported by a default QUDA installation due to lack of the necessary instantiations (at least for the lattice size that was tested). Having support for these would probably be useful, however.
The default parameters selected here seem to work rather well as is, giving speedups of 3 or so over BiCGstab for Wilson clover fermions at around 270 MeV and speedups of well over 6 for twisted clover fermions at around 240 MeV. These speedups are likely about twice as large around the physical light quark mass.
These speedups are calculated against the minimum number of cards that a given problem fits on. While the CG and BiCGstab solves fit on a single P100, four cards are required for the corresponding MG solve. These are thus ""worst-case"" speedups, where the simple solvers are running in the most efficient way possible.","Note that there is still a major caveat here... Right now, the the device creation of the clover field and the MG setup are performed for a particular csw, kappa and mu and then re-used unless the gauge id counter has changed. If one now were to do inversions with different mu values, one would run into trouble, I believe. In practice we use QUDA_DYNAMIC_CLOVER, which I think will result in the correct thing being done regardless in terms of getting the right solution, but I need to actually try and see what happens when AddDownPropagator is passed...",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,411,2017-12-28T14:42:15Z,2018-09-28T09:14:17Z,2018-09-28T09:14:17Z,MERGED,True,1082,296,16,https://github.com/kostrzewa,Final QUDA-MG interface,39,[],https://github.com/etmc/tmLQCD/pull/411,https://github.com/kostrzewa,10,https://github.com/etmc/tmLQCD/pull/411#issuecomment-403052694,"This is mostly done. The main remaining issue is that of enabling size 3 aggregrates, which seem to be currently unsupported by a default QUDA installation due to lack of the necessary instantiations (at least for the lattice size that was tested). Having support for these would probably be useful, however.
The default parameters selected here seem to work rather well as is, giving speedups of 3 or so over BiCGstab for Wilson clover fermions at around 270 MeV and speedups of well over 6 for twisted clover fermions at around 240 MeV. These speedups are likely about twice as large around the physical light quark mass.
These speedups are calculated against the minimum number of cards that a given problem fits on. While the CG and BiCGstab solves fit on a single P100, four cards are required for the corresponding MG solve. These are thus ""worst-case"" speedups, where the simple solvers are running in the most efficient way possible.","Indeed, this does not work. Let's see what answers emerge from lattice/quda#709",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,411,2017-12-28T14:42:15Z,2018-09-28T09:14:17Z,2018-09-28T09:14:17Z,MERGED,True,1082,296,16,https://github.com/kostrzewa,Final QUDA-MG interface,39,[],https://github.com/etmc/tmLQCD/pull/411,https://github.com/kostrzewa,11,https://github.com/etmc/tmLQCD/pull/411#issuecomment-403197906,"This is mostly done. The main remaining issue is that of enabling size 3 aggregrates, which seem to be currently unsupported by a default QUDA installation due to lack of the necessary instantiations (at least for the lattice size that was tested). Having support for these would probably be useful, however.
The default parameters selected here seem to work rather well as is, giving speedups of 3 or so over BiCGstab for Wilson clover fermions at around 270 MeV and speedups of well over 6 for twisted clover fermions at around 240 MeV. These speedups are likely about twice as large around the physical light quark mass.
These speedups are calculated against the minimum number of cards that a given problem fits on. While the CG and BiCGstab solves fit on a single P100, four cards are required for the corresponding MG solve. These are thus ""worst-case"" speedups, where the simple solvers are running in the most efficient way possible.","Okay, that last issue is now also resolved. Of course, in practice one would calculate up and down separately, but at least the program flow with AddDownPropagator works as expected also with the MG solver.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,411,2017-12-28T14:42:15Z,2018-09-28T09:14:17Z,2018-09-28T09:14:17Z,MERGED,True,1082,296,16,https://github.com/kostrzewa,Final QUDA-MG interface,39,[],https://github.com/etmc/tmLQCD/pull/411,https://github.com/urbach,12,https://github.com/etmc/tmLQCD/pull/411#issuecomment-403419751,"This is mostly done. The main remaining issue is that of enabling size 3 aggregrates, which seem to be currently unsupported by a default QUDA installation due to lack of the necessary instantiations (at least for the lattice size that was tested). Having support for these would probably be useful, however.
The default parameters selected here seem to work rather well as is, giving speedups of 3 or so over BiCGstab for Wilson clover fermions at around 270 MeV and speedups of well over 6 for twisted clover fermions at around 240 MeV. These speedups are likely about twice as large around the physical light quark mass.
These speedups are calculated against the minimum number of cards that a given problem fits on. While the CG and BiCGstab solves fit on a single P100, four cards are required for the corresponding MG solve. These are thus ""worst-case"" speedups, where the simple solvers are running in the most efficient way possible.","kostrzewa commented on this pull request.



 > @@ -79,7 +79,7 @@ int invert_clover_eo(spinor * const Even_new, spinor * const Odd_new,
        return invert_eo_quda(Even_new, Odd_new, Even, Odd,
                              precision, max_iter,
                              solver_flag, rel_prec,
 -                            1, solver_params,
 +                            even_odd_flag, solver_params,

 I don't quite understand, ```even_odd_flag``` specifies whether the solver should use e/o preconditioning or not. Further down the line, when this is set to ```1```, this sets the QUDA solve type.
sorry, was a confusion from my side...",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,411,2017-12-28T14:42:15Z,2018-09-28T09:14:17Z,2018-09-28T09:14:17Z,MERGED,True,1082,296,16,https://github.com/kostrzewa,Final QUDA-MG interface,39,[],https://github.com/etmc/tmLQCD/pull/411,https://github.com/kostrzewa,13,https://github.com/etmc/tmLQCD/pull/411#issuecomment-409148953,"This is mostly done. The main remaining issue is that of enabling size 3 aggregrates, which seem to be currently unsupported by a default QUDA installation due to lack of the necessary instantiations (at least for the lattice size that was tested). Having support for these would probably be useful, however.
The default parameters selected here seem to work rather well as is, giving speedups of 3 or so over BiCGstab for Wilson clover fermions at around 270 MeV and speedups of well over 6 for twisted clover fermions at around 240 MeV. These speedups are likely about twice as large around the physical light quark mass.
These speedups are calculated against the minimum number of cards that a given problem fits on. While the CG and BiCGstab solves fit on a single P100, four cards are required for the corresponding MG solve. These are thus ""worst-case"" speedups, where the simple solvers are running in the most efficient way possible.","One more modification required: for some reason I missed that the setup needs to be tossed out and redone completely (rather than updated) when a new configuration is loaded. I thought I had that covered, but apparently not. It's an easy fix, however.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,411,2017-12-28T14:42:15Z,2018-09-28T09:14:17Z,2018-09-28T09:14:17Z,MERGED,True,1082,296,16,https://github.com/kostrzewa,Final QUDA-MG interface,39,[],https://github.com/etmc/tmLQCD/pull/411,https://github.com/kostrzewa,14,https://github.com/etmc/tmLQCD/pull/411#issuecomment-409257453,"This is mostly done. The main remaining issue is that of enabling size 3 aggregrates, which seem to be currently unsupported by a default QUDA installation due to lack of the necessary instantiations (at least for the lattice size that was tested). Having support for these would probably be useful, however.
The default parameters selected here seem to work rather well as is, giving speedups of 3 or so over BiCGstab for Wilson clover fermions at around 270 MeV and speedups of well over 6 for twisted clover fermions at around 240 MeV. These speedups are likely about twice as large around the physical light quark mass.
These speedups are calculated against the minimum number of cards that a given problem fits on. While the CG and BiCGstab solves fit on a single P100, four cards are required for the corresponding MG solve. These are thus ""worst-case"" speedups, where the simple solvers are running in the most efficient way possible.","Okay, so I've introduced some changes which should cover the situations that one encounters in practice. Technically, one should probably also introduce thresholds for the various operator parameters, i.e. if:

c_sw changes significantly, one might have to redo the setup rather than just update the coarse operators
similarly for kappa, although here one should be careful because the relevant quantity is the subtracted mass (increasing that should be no problem while decreasing it will affect how well the setup preconditions the solve)
for mu the same issues apply as for kappa: increasing is fine, decreasing can be problematic

We'll touch on those issues if and when we get there, however!",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,411,2017-12-28T14:42:15Z,2018-09-28T09:14:17Z,2018-09-28T09:14:17Z,MERGED,True,1082,296,16,https://github.com/kostrzewa,Final QUDA-MG interface,39,[],https://github.com/etmc/tmLQCD/pull/411,https://github.com/kostrzewa,15,https://github.com/etmc/tmLQCD/pull/411#issuecomment-409263163,"This is mostly done. The main remaining issue is that of enabling size 3 aggregrates, which seem to be currently unsupported by a default QUDA installation due to lack of the necessary instantiations (at least for the lattice size that was tested). Having support for these would probably be useful, however.
The default parameters selected here seem to work rather well as is, giving speedups of 3 or so over BiCGstab for Wilson clover fermions at around 270 MeV and speedups of well over 6 for twisted clover fermions at around 240 MeV. These speedups are likely about twice as large around the physical light quark mass.
These speedups are calculated against the minimum number of cards that a given problem fits on. While the CG and BiCGstab solves fit on a single P100, four cards are required for the corresponding MG solve. These are thus ""worst-case"" speedups, where the simple solvers are running in the most efficient way possible.","Okay, I've tested the MGResetSetupThreshold input parameter and it works as expected, causing the setup to be redone completely if the gauge_id of the current setup exceeds the gauge_id of the gauge field by more than this threshold or, otherwise, simply updating the coarse operators. This should also prepare us for using QUDA-MG in the HMC down the line, at least from the point of view of ""overall structure"".
However, there is still something going wrong at the QUDA end of the chain when the setup is destroyed and redone with some illegal memory access occurring. Might require a more recent QUDA version for testing...
In any case, the interface as it is can be used when only a single gauge field is done in a given job.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,411,2017-12-28T14:42:15Z,2018-09-28T09:14:17Z,2018-09-28T09:14:17Z,MERGED,True,1082,296,16,https://github.com/kostrzewa,Final QUDA-MG interface,39,[],https://github.com/etmc/tmLQCD/pull/411,https://github.com/sunpho84,16,https://github.com/etmc/tmLQCD/pull/411#issuecomment-409387614,"This is mostly done. The main remaining issue is that of enabling size 3 aggregrates, which seem to be currently unsupported by a default QUDA installation due to lack of the necessary instantiations (at least for the lattice size that was tested). Having support for these would probably be useful, however.
The default parameters selected here seem to work rather well as is, giving speedups of 3 or so over BiCGstab for Wilson clover fermions at around 270 MeV and speedups of well over 6 for twisted clover fermions at around 240 MeV. These speedups are likely about twice as large around the physical light quark mass.
These speedups are calculated against the minimum number of cards that a given problem fits on. While the CG and BiCGstab solves fit on a single P100, four cards are required for the corresponding MG solve. These are thus ""worst-case"" speedups, where the simple solvers are running in the most efficient way possible.","And what about twisting? With Nissa linked to DDalphaAMG I'm forcing redoing the setup whenever I change boundary conditions (which I do quite often), presumably one could live with a small change, but I never tested.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,411,2017-12-28T14:42:15Z,2018-09-28T09:14:17Z,2018-09-28T09:14:17Z,MERGED,True,1082,296,16,https://github.com/kostrzewa,Final QUDA-MG interface,39,[],https://github.com/etmc/tmLQCD/pull/411,https://github.com/kostrzewa,17,https://github.com/etmc/tmLQCD/pull/411#issuecomment-409472483,"This is mostly done. The main remaining issue is that of enabling size 3 aggregrates, which seem to be currently unsupported by a default QUDA installation due to lack of the necessary instantiations (at least for the lattice size that was tested). Having support for these would probably be useful, however.
The default parameters selected here seem to work rather well as is, giving speedups of 3 or so over BiCGstab for Wilson clover fermions at around 270 MeV and speedups of well over 6 for twisted clover fermions at around 240 MeV. These speedups are likely about twice as large around the physical light quark mass.
These speedups are calculated against the minimum number of cards that a given problem fits on. While the CG and BiCGstab solves fit on a single P100, four cards are required for the corresponding MG solve. These are thus ""worst-case"" speedups, where the simple solvers are running in the most efficient way possible.","DDalphaAMG supports twisted boundary conditions natively, there's no need to do anything when switching from one twist to another. (well, one needs to update the twist angles)",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,411,2017-12-28T14:42:15Z,2018-09-28T09:14:17Z,2018-09-28T09:14:17Z,MERGED,True,1082,296,16,https://github.com/kostrzewa,Final QUDA-MG interface,39,[],https://github.com/etmc/tmLQCD/pull/411,https://github.com/kostrzewa,18,https://github.com/etmc/tmLQCD/pull/411#issuecomment-409473095,"This is mostly done. The main remaining issue is that of enabling size 3 aggregrates, which seem to be currently unsupported by a default QUDA installation due to lack of the necessary instantiations (at least for the lattice size that was tested). Having support for these would probably be useful, however.
The default parameters selected here seem to work rather well as is, giving speedups of 3 or so over BiCGstab for Wilson clover fermions at around 270 MeV and speedups of well over 6 for twisted clover fermions at around 240 MeV. These speedups are likely about twice as large around the physical light quark mass.
These speedups are calculated against the minimum number of cards that a given problem fits on. While the CG and BiCGstab solves fit on a single P100, four cards are required for the corresponding MG solve. These are thus ""worst-case"" speedups, where the simple solvers are running in the most efficient way possible.","For QUDA-MG, the setup will at the very least need to be updated and I'm not sure whether it might not even need to be reset. Currently, if we use twisted boundary conditions, the phases are multiplied into the gaugefield when using QUDA.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,411,2017-12-28T14:42:15Z,2018-09-28T09:14:17Z,2018-09-28T09:14:17Z,MERGED,True,1082,296,16,https://github.com/kostrzewa,Final QUDA-MG interface,39,[],https://github.com/etmc/tmLQCD/pull/411,https://github.com/sunpho84,19,https://github.com/etmc/tmLQCD/pull/411#issuecomment-409497083,"This is mostly done. The main remaining issue is that of enabling size 3 aggregrates, which seem to be currently unsupported by a default QUDA installation due to lack of the necessary instantiations (at least for the lattice size that was tested). Having support for these would probably be useful, however.
The default parameters selected here seem to work rather well as is, giving speedups of 3 or so over BiCGstab for Wilson clover fermions at around 270 MeV and speedups of well over 6 for twisted clover fermions at around 240 MeV. These speedups are likely about twice as large around the physical light quark mass.
These speedups are calculated against the minimum number of cards that a given problem fits on. While the CG and BiCGstab solves fit on a single P100, four cards are required for the corresponding MG solve. These are thus ""worst-case"" speedups, where the simple solvers are running in the most efficient way possible.","Really? I know that in DD the twist can be specified, and the phase gets incorporated in the configuration on the coarse level, but does that have an impact on the setup of the fine operator?
I think that the spectrum of Dirac operator, and its eigenvectors, change dramatically when changing b.c., is that taken into account in the setup? To the least, I guess some phasing of the null vector is due, but the impact of twisting is difficult to imagine... I understood from @sbacchio @sbacchio @sbacchio that it was not... Did I miss something?",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,411,2017-12-28T14:42:15Z,2018-09-28T09:14:17Z,2018-09-28T09:14:17Z,MERGED,True,1082,296,16,https://github.com/kostrzewa,Final QUDA-MG interface,39,[],https://github.com/etmc/tmLQCD/pull/411,https://github.com/sbacchio,20,https://github.com/etmc/tmLQCD/pull/411#issuecomment-409512783,"This is mostly done. The main remaining issue is that of enabling size 3 aggregrates, which seem to be currently unsupported by a default QUDA installation due to lack of the necessary instantiations (at least for the lattice size that was tested). Having support for these would probably be useful, however.
The default parameters selected here seem to work rather well as is, giving speedups of 3 or so over BiCGstab for Wilson clover fermions at around 270 MeV and speedups of well over 6 for twisted clover fermions at around 240 MeV. These speedups are likely about twice as large around the physical light quark mass.
These speedups are calculated against the minimum number of cards that a given problem fits on. While the CG and BiCGstab solves fit on a single P100, four cards are required for the corresponding MG solve. These are thus ""worst-case"" speedups, where the simple solvers are running in the most efficient way possible.","Yes, also in DDalphaAMG the shift is added directly to the gauge-links, but here it is done in the interface on the DDalphaAMG side and not on the tmLQCD side.
It's easy to try if an update of the setup is enough, but I agree with @sunpho84 that changing the twist in the gauge-field will considerably affect the eigenmodes; and specially at the physical point is very important to construct the MG setup correctly.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,411,2017-12-28T14:42:15Z,2018-09-28T09:14:17Z,2018-09-28T09:14:17Z,MERGED,True,1082,296,16,https://github.com/kostrzewa,Final QUDA-MG interface,39,[],https://github.com/etmc/tmLQCD/pull/411,https://github.com/kostrzewa,21,https://github.com/etmc/tmLQCD/pull/411#issuecomment-409526170,"This is mostly done. The main remaining issue is that of enabling size 3 aggregrates, which seem to be currently unsupported by a default QUDA installation due to lack of the necessary instantiations (at least for the lattice size that was tested). Having support for these would probably be useful, however.
The default parameters selected here seem to work rather well as is, giving speedups of 3 or so over BiCGstab for Wilson clover fermions at around 270 MeV and speedups of well over 6 for twisted clover fermions at around 240 MeV. These speedups are likely about twice as large around the physical light quark mass.
These speedups are calculated against the minimum number of cards that a given problem fits on. While the CG and BiCGstab solves fit on a single P100, four cards are required for the corresponding MG solve. These are thus ""worst-case"" speedups, where the simple solvers are running in the most efficient way possible.","@sunpho84 @sbacchio Hmm, I think I was remembering incorrectly. Yes, in the vector form factor calculation, I performed all inversions for a given theta in one job and then even restarted tmLQCD because it of course doesn't support changing the twist angle mid-execution. You are right.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,411,2017-12-28T14:42:15Z,2018-09-28T09:14:17Z,2018-09-28T09:14:17Z,MERGED,True,1082,296,16,https://github.com/kostrzewa,Final QUDA-MG interface,39,[],https://github.com/etmc/tmLQCD/pull/411,https://github.com/kostrzewa,22,https://github.com/etmc/tmLQCD/pull/411#issuecomment-423738575,"This is mostly done. The main remaining issue is that of enabling size 3 aggregrates, which seem to be currently unsupported by a default QUDA installation due to lack of the necessary instantiations (at least for the lattice size that was tested). Having support for these would probably be useful, however.
The default parameters selected here seem to work rather well as is, giving speedups of 3 or so over BiCGstab for Wilson clover fermions at around 270 MeV and speedups of well over 6 for twisted clover fermions at around 240 MeV. These speedups are likely about twice as large around the physical light quark mass.
These speedups are calculated against the minimum number of cards that a given problem fits on. While the CG and BiCGstab solves fit on a single P100, four cards are required for the corresponding MG solve. These are thus ""worst-case"" speedups, where the simple solvers are running in the most efficient way possible.",I would like to merge this ASAP since we will need it for the eta-eta project tests which will take place on QBIG soon (@marcus-petschlies @blons will require these changes),True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,411,2017-12-28T14:42:15Z,2018-09-28T09:14:17Z,2018-09-28T09:14:17Z,MERGED,True,1082,296,16,https://github.com/kostrzewa,Final QUDA-MG interface,39,[],https://github.com/etmc/tmLQCD/pull/411,https://github.com/urbach,23,https://github.com/etmc/tmLQCD/pull/411#issuecomment-425360167,"This is mostly done. The main remaining issue is that of enabling size 3 aggregrates, which seem to be currently unsupported by a default QUDA installation due to lack of the necessary instantiations (at least for the lattice size that was tested). Having support for these would probably be useful, however.
The default parameters selected here seem to work rather well as is, giving speedups of 3 or so over BiCGstab for Wilson clover fermions at around 270 MeV and speedups of well over 6 for twisted clover fermions at around 240 MeV. These speedups are likely about twice as large around the physical light quark mass.
These speedups are calculated against the minimum number of cards that a given problem fits on. While the CG and BiCGstab solves fit on a single P100, four cards are required for the corresponding MG solve. These are thus ""worst-case"" speedups, where the simple solvers are running in the most efficient way possible.",for me this is fine to be merged in. Just checks are failing...,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,411,2017-12-28T14:42:15Z,2018-09-28T09:14:17Z,2018-09-28T09:14:17Z,MERGED,True,1082,296,16,https://github.com/kostrzewa,Final QUDA-MG interface,39,[],https://github.com/etmc/tmLQCD/pull/411,https://github.com/kostrzewa,24,https://github.com/etmc/tmLQCD/pull/411#issuecomment-425360966,"This is mostly done. The main remaining issue is that of enabling size 3 aggregrates, which seem to be currently unsupported by a default QUDA installation due to lack of the necessary instantiations (at least for the lattice size that was tested). Having support for these would probably be useful, however.
The default parameters selected here seem to work rather well as is, giving speedups of 3 or so over BiCGstab for Wilson clover fermions at around 270 MeV and speedups of well over 6 for twisted clover fermions at around 240 MeV. These speedups are likely about twice as large around the physical light quark mass.
These speedups are calculated against the minimum number of cards that a given problem fits on. While the CG and BiCGstab solves fit on a single P100, four cards are required for the corresponding MG solve. These are thus ""worst-case"" speedups, where the simple solvers are running in the most efficient way possible.",The checks are failing because travis is broken again...,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,411,2017-12-28T14:42:15Z,2018-09-28T09:14:17Z,2018-09-28T09:14:17Z,MERGED,True,1082,296,16,https://github.com/kostrzewa,Final QUDA-MG interface,39,[],https://github.com/etmc/tmLQCD/pull/411,https://github.com/kostrzewa,25,https://github.com/etmc/tmLQCD/pull/411#issuecomment-425364181,"This is mostly done. The main remaining issue is that of enabling size 3 aggregrates, which seem to be currently unsupported by a default QUDA installation due to lack of the necessary instantiations (at least for the lattice size that was tested). Having support for these would probably be useful, however.
The default parameters selected here seem to work rather well as is, giving speedups of 3 or so over BiCGstab for Wilson clover fermions at around 270 MeV and speedups of well over 6 for twisted clover fermions at around 240 MeV. These speedups are likely about twice as large around the physical light quark mass.
These speedups are calculated against the minimum number of cards that a given problem fits on. While the CG and BiCGstab solves fit on a single P100, four cards are required for the corresponding MG solve. These are thus ""worst-case"" speedups, where the simple solvers are running in the most efficient way possible.",Fixed in #431,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,411,2017-12-28T14:42:15Z,2018-09-28T09:14:17Z,2018-09-28T09:14:17Z,MERGED,True,1082,296,16,https://github.com/kostrzewa,Final QUDA-MG interface,39,[],https://github.com/etmc/tmLQCD/pull/411,https://github.com/urbach,26,https://github.com/etmc/tmLQCD/pull/411#issuecomment-425366436,"This is mostly done. The main remaining issue is that of enabling size 3 aggregrates, which seem to be currently unsupported by a default QUDA installation due to lack of the necessary instantiations (at least for the lattice size that was tested). Having support for these would probably be useful, however.
The default parameters selected here seem to work rather well as is, giving speedups of 3 or so over BiCGstab for Wilson clover fermions at around 270 MeV and speedups of well over 6 for twisted clover fermions at around 240 MeV. These speedups are likely about twice as large around the physical light quark mass.
These speedups are calculated against the minimum number of cards that a given problem fits on. While the CG and BiCGstab solves fit on a single P100, four cards are required for the corresponding MG solve. These are thus ""worst-case"" speedups, where the simple solvers are running in the most efficient way possible.","okay, if there is no protest I'll merge this in",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,411,2017-12-28T14:42:15Z,2018-09-28T09:14:17Z,2018-09-28T09:14:17Z,MERGED,True,1082,296,16,https://github.com/kostrzewa,Final QUDA-MG interface,39,[],https://github.com/etmc/tmLQCD/pull/411,https://github.com/kostrzewa,27,https://github.com/etmc/tmLQCD/pull/411#issuecomment-425367701,"This is mostly done. The main remaining issue is that of enabling size 3 aggregrates, which seem to be currently unsupported by a default QUDA installation due to lack of the necessary instantiations (at least for the lattice size that was tested). Having support for these would probably be useful, however.
The default parameters selected here seem to work rather well as is, giving speedups of 3 or so over BiCGstab for Wilson clover fermions at around 270 MeV and speedups of well over 6 for twisted clover fermions at around 240 MeV. These speedups are likely about twice as large around the physical light quark mass.
These speedups are calculated against the minimum number of cards that a given problem fits on. While the CG and BiCGstab solves fit on a single P100, four cards are required for the corresponding MG solve. These are thus ""worst-case"" speedups, where the simple solvers are running in the most efficient way possible.","To be safe, you can merge 431 and I'll update this pull such as to include those changes, then the checks will go through (or compilation will fail, if I messed up)",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,411,2017-12-28T14:42:15Z,2018-09-28T09:14:17Z,2018-09-28T09:14:17Z,MERGED,True,1082,296,16,https://github.com/kostrzewa,Final QUDA-MG interface,39,[],https://github.com/etmc/tmLQCD/pull/411,https://github.com/urbach,28,https://github.com/etmc/tmLQCD/pull/411#issuecomment-425368482,"This is mostly done. The main remaining issue is that of enabling size 3 aggregrates, which seem to be currently unsupported by a default QUDA installation due to lack of the necessary instantiations (at least for the lattice size that was tested). Having support for these would probably be useful, however.
The default parameters selected here seem to work rather well as is, giving speedups of 3 or so over BiCGstab for Wilson clover fermions at around 270 MeV and speedups of well over 6 for twisted clover fermions at around 240 MeV. These speedups are likely about twice as large around the physical light quark mass.
These speedups are calculated against the minimum number of cards that a given problem fits on. While the CG and BiCGstab solves fit on a single P100, four cards are required for the corresponding MG solve. These are thus ""worst-case"" speedups, where the simple solvers are running in the most efficient way possible.","merged already...
--
Carsten Urbach
e-mail: curbach@gmx.de
        urbach@hiskp.uni-bonn.de
Fon   : +49 (0)228 73 2379
skype : carsten.urbach
URL: http://www.carsten-urbach.eu",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,411,2017-12-28T14:42:15Z,2018-09-28T09:14:17Z,2018-09-28T09:14:17Z,MERGED,True,1082,296,16,https://github.com/kostrzewa,Final QUDA-MG interface,39,[],https://github.com/etmc/tmLQCD/pull/411,https://github.com/kostrzewa,29,https://github.com/etmc/tmLQCD/pull/411#issuecomment-425368876,"This is mostly done. The main remaining issue is that of enabling size 3 aggregrates, which seem to be currently unsupported by a default QUDA installation due to lack of the necessary instantiations (at least for the lattice size that was tested). Having support for these would probably be useful, however.
The default parameters selected here seem to work rather well as is, giving speedups of 3 or so over BiCGstab for Wilson clover fermions at around 270 MeV and speedups of well over 6 for twisted clover fermions at around 240 MeV. These speedups are likely about twice as large around the physical light quark mass.
These speedups are calculated against the minimum number of cards that a given problem fits on. While the CG and BiCGstab solves fit on a single P100, four cards are required for the corresponding MG solve. These are thus ""worst-case"" speedups, where the simple solvers are running in the most efficient way possible.","Good thing we checked, there is indeed a build problem..",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,411,2017-12-28T14:42:15Z,2018-09-28T09:14:17Z,2018-09-28T09:14:17Z,MERGED,True,1082,296,16,https://github.com/kostrzewa,Final QUDA-MG interface,39,[],https://github.com/etmc/tmLQCD/pull/411,https://github.com/kostrzewa,30,https://github.com/etmc/tmLQCD/pull/411#issuecomment-425370964,"This is mostly done. The main remaining issue is that of enabling size 3 aggregrates, which seem to be currently unsupported by a default QUDA installation due to lack of the necessary instantiations (at least for the lattice size that was tested). Having support for these would probably be useful, however.
The default parameters selected here seem to work rather well as is, giving speedups of 3 or so over BiCGstab for Wilson clover fermions at around 270 MeV and speedups of well over 6 for twisted clover fermions at around 240 MeV. These speedups are likely about twice as large around the physical light quark mass.
These speedups are calculated against the minimum number of cards that a given problem fits on. While the CG and BiCGstab solves fit on a single P100, four cards are required for the corresponding MG solve. These are thus ""worst-case"" speedups, where the simple solvers are running in the most efficient way possible.","Not my fault though, apparently. gcc is having trouble with the isnan macro in io/utils.h",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,411,2017-12-28T14:42:15Z,2018-09-28T09:14:17Z,2018-09-28T09:14:17Z,MERGED,True,1082,296,16,https://github.com/kostrzewa,Final QUDA-MG interface,39,[],https://github.com/etmc/tmLQCD/pull/411,https://github.com/urbach,31,https://github.com/etmc/tmLQCD/pull/411#issuecomment-425372146,"This is mostly done. The main remaining issue is that of enabling size 3 aggregrates, which seem to be currently unsupported by a default QUDA installation due to lack of the necessary instantiations (at least for the lattice size that was tested). Having support for these would probably be useful, however.
The default parameters selected here seem to work rather well as is, giving speedups of 3 or so over BiCGstab for Wilson clover fermions at around 270 MeV and speedups of well over 6 for twisted clover fermions at around 240 MeV. These speedups are likely about twice as large around the physical light quark mass.
These speedups are calculated against the minimum number of cards that a given problem fits on. While the CG and BiCGstab solves fit on a single P100, four cards are required for the corresponding MG solve. These are thus ""worst-case"" speedups, where the simple solvers are running in the most efficient way possible.","hmm, so what do we do...?",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,411,2017-12-28T14:42:15Z,2018-09-28T09:14:17Z,2018-09-28T09:14:17Z,MERGED,True,1082,296,16,https://github.com/kostrzewa,Final QUDA-MG interface,39,[],https://github.com/etmc/tmLQCD/pull/411,https://github.com/kostrzewa,32,https://github.com/etmc/tmLQCD/pull/411#issuecomment-425372984,"This is mostly done. The main remaining issue is that of enabling size 3 aggregrates, which seem to be currently unsupported by a default QUDA installation due to lack of the necessary instantiations (at least for the lattice size that was tested). Having support for these would probably be useful, however.
The default parameters selected here seem to work rather well as is, giving speedups of 3 or so over BiCGstab for Wilson clover fermions at around 270 MeV and speedups of well over 6 for twisted clover fermions at around 240 MeV. These speedups are likely about twice as large around the physical light quark mass.
These speedups are calculated against the minimum number of cards that a given problem fits on. While the CG and BiCGstab solves fit on a single P100, four cards are required for the corresponding MG solve. These are thus ""worst-case"" speedups, where the simple solvers are running in the most efficient way possible.",I'll try to fix it. I can't reproduce it locally.,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,411,2017-12-28T14:42:15Z,2018-09-28T09:14:17Z,2018-09-28T09:14:17Z,MERGED,True,1082,296,16,https://github.com/kostrzewa,Final QUDA-MG interface,39,[],https://github.com/etmc/tmLQCD/pull/411,https://github.com/kostrzewa,33,https://github.com/etmc/tmLQCD/pull/411#issuecomment-425373365,"This is mostly done. The main remaining issue is that of enabling size 3 aggregrates, which seem to be currently unsupported by a default QUDA installation due to lack of the necessary instantiations (at least for the lattice size that was tested). Having support for these would probably be useful, however.
The default parameters selected here seem to work rather well as is, giving speedups of 3 or so over BiCGstab for Wilson clover fermions at around 270 MeV and speedups of well over 6 for twisted clover fermions at around 240 MeV. These speedups are likely about twice as large around the physical light quark mass.
These speedups are calculated against the minimum number of cards that a given problem fits on. While the CG and BiCGstab solves fit on a single P100, four cards are required for the corresponding MG solve. These are thus ""worst-case"" speedups, where the simple solvers are running in the most efficient way possible.","I think I know what the problem is, there was a commented out line in travis-ci.sh which broke a multi-line command",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,411,2017-12-28T14:42:15Z,2018-09-28T09:14:17Z,2018-09-28T09:14:17Z,MERGED,True,1082,296,16,https://github.com/kostrzewa,Final QUDA-MG interface,39,[],https://github.com/etmc/tmLQCD/pull/411,https://github.com/kostrzewa,34,https://github.com/etmc/tmLQCD/pull/411#issuecomment-425373475,"This is mostly done. The main remaining issue is that of enabling size 3 aggregrates, which seem to be currently unsupported by a default QUDA installation due to lack of the necessary instantiations (at least for the lattice size that was tested). Having support for these would probably be useful, however.
The default parameters selected here seem to work rather well as is, giving speedups of 3 or so over BiCGstab for Wilson clover fermions at around 270 MeV and speedups of well over 6 for twisted clover fermions at around 240 MeV. These speedups are likely about twice as large around the physical light quark mass.
These speedups are calculated against the minimum number of cards that a given problem fits on. While the CG and BiCGstab solves fit on a single P100, four cards are required for the corresponding MG solve. These are thus ""worst-case"" speedups, where the simple solvers are running in the most efficient way possible.",This meant that tmLQCD was being compiled without the --std=c99 flag,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,411,2017-12-28T14:42:15Z,2018-09-28T09:14:17Z,2018-09-28T09:14:17Z,MERGED,True,1082,296,16,https://github.com/kostrzewa,Final QUDA-MG interface,39,[],https://github.com/etmc/tmLQCD/pull/411,https://github.com/kostrzewa,35,https://github.com/etmc/tmLQCD/pull/411#issuecomment-425373753,"This is mostly done. The main remaining issue is that of enabling size 3 aggregrates, which seem to be currently unsupported by a default QUDA installation due to lack of the necessary instantiations (at least for the lattice size that was tested). Having support for these would probably be useful, however.
The default parameters selected here seem to work rather well as is, giving speedups of 3 or so over BiCGstab for Wilson clover fermions at around 270 MeV and speedups of well over 6 for twisted clover fermions at around 240 MeV. These speedups are likely about twice as large around the physical light quark mass.
These speedups are calculated against the minimum number of cards that a given problem fits on. While the CG and BiCGstab solves fit on a single P100, four cards are required for the corresponding MG solve. These are thus ""worst-case"" speedups, where the simple solvers are running in the most efficient way possible.","In c99, a mulit-purpose isnan was introduced, such that the hand-written one was never ever called anywhere else. Should I remove the hand-written one? This seems to be a possible source of odd build errors.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,411,2017-12-28T14:42:15Z,2018-09-28T09:14:17Z,2018-09-28T09:14:17Z,MERGED,True,1082,296,16,https://github.com/kostrzewa,Final QUDA-MG interface,39,[],https://github.com/etmc/tmLQCD/pull/411,https://github.com/martin-ueding,36,https://github.com/etmc/tmLQCD/pull/411#issuecomment-425374141,"This is mostly done. The main remaining issue is that of enabling size 3 aggregrates, which seem to be currently unsupported by a default QUDA installation due to lack of the necessary instantiations (at least for the lattice size that was tested). Having support for these would probably be useful, however.
The default parameters selected here seem to work rather well as is, giving speedups of 3 or so over BiCGstab for Wilson clover fermions at around 270 MeV and speedups of well over 6 for twisted clover fermions at around 240 MeV. These speedups are likely about twice as large around the physical light quark mass.
These speedups are calculated against the minimum number of cards that a given problem fits on. While the CG and BiCGstab solves fit on a single P100, four cards are required for the corresponding MG solve. These are thus ""worst-case"" speedups, where the simple solvers are running in the most efficient way possible.","Yes, bash does not handle that well, had hit me in the chroma installation script multiple times ",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,414,2018-01-10T14:02:31Z,2018-01-16T11:48:14Z,2018-01-16T11:48:14Z,MERGED,True,762,203,13,https://github.com/kostrzewa,gradflow topological charge measurement,11,[],https://github.com/etmc/tmLQCD/pull/414,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/414,"TODO

 Our OpenMP accumulators assume that only one quantity is accumulated, this needs to be generalised.
 It must be ensured that Q is correctly normalised.
 Output of Q must be enabled
 1-to-1 cross-check of energy density measurement on realistic lattice to make sure that I didn't break anything","TODO

 Our OpenMP accumulators assume that only one quantity is accumulated, this needs to be generalised.
 It must be ensured that Q is correctly normalised.
 Output of Q must be enabled
 1-to-1 cross-check of energy density measurement on realistic lattice to make sure that I didn't break anything",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,414,2018-01-10T14:02:31Z,2018-01-16T11:48:14Z,2018-01-16T11:48:14Z,MERGED,True,762,203,13,https://github.com/kostrzewa,gradflow topological charge measurement,11,[],https://github.com/etmc/tmLQCD/pull/414,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/414#issuecomment-356620990,"TODO

 Our OpenMP accumulators assume that only one quantity is accumulated, this needs to be generalised.
 It must be ensured that Q is correctly normalised.
 Output of Q must be enabled
 1-to-1 cross-check of energy density measurement on realistic lattice to make sure that I didn't break anything","@urbach: This version contains measurements of the communication overhead at g_debug_level >= 4, so we can check if it makes sense to implement two-row gauge compression for communication.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,414,2018-01-10T14:02:31Z,2018-01-16T11:48:14Z,2018-01-16T11:48:14Z,MERGED,True,762,203,13,https://github.com/kostrzewa,gradflow topological charge measurement,11,[],https://github.com/etmc/tmLQCD/pull/414,https://github.com/kostrzewa,3,https://github.com/etmc/tmLQCD/pull/414#issuecomment-357217874,"TODO

 Our OpenMP accumulators assume that only one quantity is accumulated, this needs to be generalised.
 It must be ensured that Q is correctly normalised.
 Output of Q must be enabled
 1-to-1 cross-check of energy density measurement on realistic lattice to make sure that I didn't break anything","Okay, it seems that just one more check is required and we'll have a working topo charge measurement.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,414,2018-01-10T14:02:31Z,2018-01-16T11:48:14Z,2018-01-16T11:48:14Z,MERGED,True,762,203,13,https://github.com/kostrzewa,gradflow topological charge measurement,11,[],https://github.com/etmc/tmLQCD/pull/414,https://github.com/kostrzewa,4,https://github.com/etmc/tmLQCD/pull/414#issuecomment-357253766,"TODO

 Our OpenMP accumulators assume that only one quantity is accumulated, this needs to be generalised.
 It must be ensured that Q is correctly normalised.
 Output of Q must be enabled
 1-to-1 cross-check of energy density measurement on realistic lattice to make sure that I didn't break anything","The code has now been validated on three gauge configurations against @uwenger's (thanks!) and only round-off differences were found, which likely arise due to our use of Kahan sums in the process and thread-local reductions.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,415,2018-02-04T22:47:20Z,,2021-03-29T13:38:59Z,OPEN,False,365,1626,19,https://github.com/sunpho84,Full Autotools build,14,[],https://github.com/etmc/tmLQCD/pull/415,https://github.com/sunpho84,1,https://github.com/etmc/tmLQCD/pull/415,"GPU and SPI not yet enabled
A single long Makefile.am: this might be broken in many files if you prefer, though I can't see a practical reason for doing that","GPU and SPI not yet enabled
A single long Makefile.am: this might be broken in many files if you prefer, though I can't see a practical reason for doing that",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,415,2018-02-04T22:47:20Z,,2021-03-29T13:38:59Z,OPEN,False,365,1626,19,https://github.com/sunpho84,Full Autotools build,14,[],https://github.com/etmc/tmLQCD/pull/415,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/415#issuecomment-368304189,"GPU and SPI not yet enabled
A single long Makefile.am: this might be broken in many files if you prefer, though I can't see a practical reason for doing that","Thanks, I'll take a look at this next week. I'm not sure I like the single list of all source files too much, but if that's the only way to achieve the desired goal, so be it.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,415,2018-02-04T22:47:20Z,,2021-03-29T13:38:59Z,OPEN,False,365,1626,19,https://github.com/sunpho84,Full Autotools build,14,[],https://github.com/etmc/tmLQCD/pull/415,https://github.com/sunpho84,3,https://github.com/etmc/tmLQCD/pull/415#issuecomment-368316153,"GPU and SPI not yet enabled
A single long Makefile.am: this might be broken in many files if you prefer, though I can't see a practical reason for doing that","No no one can certainly split the Makefile.am across multiple files and use include directive to collect them in the main Makefile.am, if you prefer. I can do that quickly.
What I find cumbersome, is to split the build into (in)convenient sublibraries. Given that you always link all of them, there is little reason to have a libsolver, a libhmc, etc etc, I would keep just libtmlQCD as a single target. That's also beneficial to parallel compilation.
In any case, I can arrange for split sublibs if you wish.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,415,2018-02-04T22:47:20Z,,2021-03-29T13:38:59Z,OPEN,False,365,1626,19,https://github.com/sunpho84,Full Autotools build,14,[],https://github.com/etmc/tmLQCD/pull/415,https://github.com/sunpho84,4,https://github.com/etmc/tmLQCD/pull/415#issuecomment-368944419,"GPU and SPI not yet enabled
A single long Makefile.am: this might be broken in many files if you prefer, though I can't see a practical reason for doing that","Ok now the Makefile.am is split across different files, included in subdirs, there is still a bit of a mess in the master Makefile.am and one would probably split the main folder sourcefiles list into a dedicated file (or put the files in an appropriate directory?)",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,415,2018-02-04T22:47:20Z,,2021-03-29T13:38:59Z,OPEN,False,365,1626,19,https://github.com/sunpho84,Full Autotools build,14,[],https://github.com/etmc/tmLQCD/pull/415,https://github.com/urbach,5,https://github.com/etmc/tmLQCD/pull/415#issuecomment-373032676,"GPU and SPI not yet enabled
A single long Makefile.am: this might be broken in many files if you prefer, though I can't see a practical reason for doing that","did I tell already how much I love automake!? ;)
anyhow, I guess I have to type automake in the main directory, correct?
Here
automake-warnings.txt the list of warnings and errors... anyone?",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,415,2018-02-04T22:47:20Z,,2021-03-29T13:38:59Z,OPEN,False,365,1626,19,https://github.com/sunpho84,Full Autotools build,14,[],https://github.com/etmc/tmLQCD/pull/415,https://github.com/urbach,6,https://github.com/etmc/tmLQCD/pull/415#issuecomment-373033862,"GPU and SPI not yet enabled
A single long Makefile.am: this might be broken in many files if you prefer, though I can't see a practical reason for doing that",btw: I have automake (GNU automake) 1.15,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,415,2018-02-04T22:47:20Z,,2021-03-29T13:38:59Z,OPEN,False,365,1626,19,https://github.com/sunpho84,Full Autotools build,14,[],https://github.com/etmc/tmLQCD/pull/415,https://github.com/urbach,7,https://github.com/etmc/tmLQCD/pull/415#issuecomment-373034550,"GPU and SPI not yet enabled
A single long Makefile.am: this might be broken in many files if you prefer, though I can't see a practical reason for doing that",even if I invoke automake --add-missing I do not get a configure script that would be working,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,415,2018-02-04T22:47:20Z,,2021-03-29T13:38:59Z,OPEN,False,365,1626,19,https://github.com/sunpho84,Full Autotools build,14,[],https://github.com/etmc/tmLQCD/pull/415,https://github.com/kostrzewa,8,https://github.com/etmc/tmLQCD/pull/415#issuecomment-373036254,"GPU and SPI not yet enabled
A single long Makefile.am: this might be broken in many files if you prefer, though I can't see a practical reason for doing that","Works for me.
$ automake --add-missing
$ autoreconf",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,415,2018-02-04T22:47:20Z,,2021-03-29T13:38:59Z,OPEN,False,365,1626,19,https://github.com/sunpho84,Full Autotools build,14,[],https://github.com/etmc/tmLQCD/pull/415,https://github.com/kostrzewa,9,https://github.com/etmc/tmLQCD/pull/415#issuecomment-373036721,"GPU and SPI not yet enabled
A single long Makefile.am: this might be broken in many files if you prefer, though I can't see a practical reason for doing that","include files are not installed by make install, the rest seems to work as expected",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,415,2018-02-04T22:47:20Z,,2021-03-29T13:38:59Z,OPEN,False,365,1626,19,https://github.com/sunpho84,Full Autotools build,14,[],https://github.com/etmc/tmLQCD/pull/415,https://github.com/kostrzewa,10,https://github.com/etmc/tmLQCD/pull/415#issuecomment-373036803,"GPU and SPI not yet enabled
A single long Makefile.am: this might be broken in many files if you prefer, though I can't see a practical reason for doing that","of course, the external libraries should be taken care of",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,415,2018-02-04T22:47:20Z,,2021-03-29T13:38:59Z,OPEN,False,365,1626,19,https://github.com/sunpho84,Full Autotools build,14,[],https://github.com/etmc/tmLQCD/pull/415,https://github.com/urbach,11,https://github.com/etmc/tmLQCD/pull/415#issuecomment-373038086,"GPU and SPI not yet enabled
A single long Makefile.am: this might be broken in many files if you prefer, though I can't see a practical reason for doing that","well, this is what I get after an `autoreconf`:

```
$> autoreconf
configure.ac:15: error: required file './compile' not found
configure.ac:15:   'automake --add-missing' can install 'compile'
configure.ac:13: error: required file './missing' not found
configure.ac:13:   'automake --add-missing' can install 'missing'
autoreconf: automake failed with exit status: 1
```

another round of `automake --add-missing` solves it then. Is this ment
seriously?
 Works for me.

 ```
 $ automake --add-missing
 $ autoreconf
 ```



 --
 You are receiving this because you commented.
 Reply to this email directly or view it on GitHub:
 #415 (comment)

--
Carsten Urbach
e-mail: curbach@gmx.de
        urbach@hiskp.uni-bonn.de
Fon   : +49 (0)228 73 2379
skype : carsten.urbach
URL: http://www.carsten-urbach.eu",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,415,2018-02-04T22:47:20Z,,2021-03-29T13:38:59Z,OPEN,False,365,1626,19,https://github.com/sunpho84,Full Autotools build,14,[],https://github.com/etmc/tmLQCD/pull/415,https://github.com/kostrzewa,12,https://github.com/etmc/tmLQCD/pull/415#issuecomment-373038834,"GPU and SPI not yet enabled
A single long Makefile.am: this might be broken in many files if you prefer, though I can't see a practical reason for doing that","That's why one usually has an autogen.sh script.
It worked with a single invocation of automake --add-missing for me though (in a fresh source directory). Should be tested on Marconi and Jureca, just in case problems arise there.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,415,2018-02-04T22:47:20Z,,2021-03-29T13:38:59Z,OPEN,False,365,1626,19,https://github.com/sunpho84,Full Autotools build,14,[],https://github.com/etmc/tmLQCD/pull/415,https://github.com/urbach,13,https://github.com/etmc/tmLQCD/pull/415#issuecomment-373038917,"GPU and SPI not yet enabled
A single long Makefile.am: this might be broken in many files if you prefer, though I can't see a practical reason for doing that","has this been tried with `--enable-sse2`?

 well, this is what I get after an `autoreconf`:

 ```
 $> autoreconf
 configure.ac:15: error: required file './compile' not found
 configure.ac:15:   'automake --add-missing' can install 'compile'
 configure.ac:13: error: required file './missing' not found
 configure.ac:13:   'automake --add-missing' can install 'missing'
 autoreconf: automake failed with exit status: 1
 ```

 another round of `automake --add-missing` solves it then. Is this ment
 seriously?

 > Works for me.
 >
 > ```
 > $ automake --add-missing
 > $ autoreconf
 > ```
 >
 >
 >
 > --
 > You are receiving this because you commented.
 > Reply to this email directly or view it on GitHub:
 > #415 (comment)
 --
 Carsten Urbach
 e-mail: ***@***.***
         ***@***.***
 Fon   : +49 (0)228 73 2379
 skype : carsten.urbach
 URL: http://www.carsten-urbach.eu


--
Carsten Urbach
e-mail: curbach@gmx.de
        urbach@hiskp.uni-bonn.de
Fon   : +49 (0)228 73 2379
skype : carsten.urbach
URL: http://www.carsten-urbach.eu",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,415,2018-02-04T22:47:20Z,,2021-03-29T13:38:59Z,OPEN,False,365,1626,19,https://github.com/sunpho84,Full Autotools build,14,[],https://github.com/etmc/tmLQCD/pull/415,https://github.com/kostrzewa,14,https://github.com/etmc/tmLQCD/pull/415#issuecomment-373039119,"GPU and SPI not yet enabled
A single long Makefile.am: this might be broken in many files if you prefer, though I can't see a practical reason for doing that",I think the full set of configure options needs to be mapped out. Ideally one would do this via travis...,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,415,2018-02-04T22:47:20Z,,2021-03-29T13:38:59Z,OPEN,False,365,1626,19,https://github.com/sunpho84,Full Autotools build,14,[],https://github.com/etmc/tmLQCD/pull/415,https://github.com/kostrzewa,15,https://github.com/etmc/tmLQCD/pull/415#issuecomment-373040168,"GPU and SPI not yet enabled
A single long Makefile.am: this might be broken in many files if you prefer, though I can't see a practical reason for doing that","SSE2 / SSE3 seem to work, but produce the kinds of errors upon compilation that we got a while ago from the single precision stuff",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,415,2018-02-04T22:47:20Z,,2021-03-29T13:38:59Z,OPEN,False,365,1626,19,https://github.com/sunpho84,Full Autotools build,14,[],https://github.com/etmc/tmLQCD/pull/415,https://github.com/urbach,16,https://github.com/etmc/tmLQCD/pull/415#issuecomment-373040305,"GPU and SPI not yet enabled
A single long Makefile.am: this might be broken in many files if you prefer, though I can't see a practical reason for doing that",for me it does not compile with SSE2,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,415,2018-02-04T22:47:20Z,,2021-03-29T13:38:59Z,OPEN,False,365,1626,19,https://github.com/sunpho84,Full Autotools build,14,[],https://github.com/etmc/tmLQCD/pull/415,https://github.com/urbach,17,https://github.com/etmc/tmLQCD/pull/415#issuecomment-373040460,"GPU and SPI not yet enabled
A single long Makefile.am: this might be broken in many files if you prefer, though I can't see a practical reason for doing that",but this might not be due to automake,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,415,2018-02-04T22:47:20Z,,2021-03-29T13:38:59Z,OPEN,False,365,1626,19,https://github.com/sunpho84,Full Autotools build,14,[],https://github.com/etmc/tmLQCD/pull/415,https://github.com/kostrzewa,18,https://github.com/etmc/tmLQCD/pull/415#issuecomment-373040759,"GPU and SPI not yet enabled
A single long Makefile.am: this might be broken in many files if you prefer, though I can't see a practical reason for doing that","for me it does not compile with SSE2

no, it doesn't compile, but the flags seem to be defined correctly
the errors come from the single precision hopping matrix...",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,415,2018-02-04T22:47:20Z,,2021-03-29T13:38:59Z,OPEN,False,365,1626,19,https://github.com/sunpho84,Full Autotools build,14,[],https://github.com/etmc/tmLQCD/pull/415,https://github.com/kostrzewa,19,https://github.com/etmc/tmLQCD/pull/415#issuecomment-373040952,"GPU and SPI not yet enabled
A single long Makefile.am: this might be broken in many files if you prefer, though I can't see a practical reason for doing that","and D_psi, respectively",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,415,2018-02-04T22:47:20Z,,2021-03-29T13:38:59Z,OPEN,False,365,1626,19,https://github.com/sunpho84,Full Autotools build,14,[],https://github.com/etmc/tmLQCD/pull/415,https://github.com/sunpho84,20,https://github.com/etmc/tmLQCD/pull/415#issuecomment-373041817,"GPU and SPI not yet enabled
A single long Makefile.am: this might be broken in many files if you prefer, though I can't see a practical reason for doing that","My autgen.sh -like script (for nissa) goes like this
#!/bin/sh

rm -fr \
    aclocal.m4 \
    autom4te.cache \
    $(find . -name ""Makefile.in"") \
    config/{compile,config.guess,config.sub,depcomp,install-sh,missing,ylwrap} \
    configure

aclocal
autoreconf --verbose --install --force",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,415,2018-02-04T22:47:20Z,,2021-03-29T13:38:59Z,OPEN,False,365,1626,19,https://github.com/sunpho84,Full Autotools build,14,[],https://github.com/etmc/tmLQCD/pull/415,https://github.com/urbach,21,https://github.com/etmc/tmLQCD/pull/415#issuecomment-373041882,"GPU and SPI not yet enabled
A single long Makefile.am: this might be broken in many files if you prefer, though I can't see a practical reason for doing that","and D_psi, respectively
same for me...

--
Carsten Urbach
e-mail: curbach@gmx.de
        urbach@hiskp.uni-bonn.de
Fon   : +49 (0)228 73 2379
skype : carsten.urbach
URL: http://www.carsten-urbach.eu",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,415,2018-02-04T22:47:20Z,,2021-03-29T13:38:59Z,OPEN,False,365,1626,19,https://github.com/sunpho84,Full Autotools build,14,[],https://github.com/etmc/tmLQCD/pull/415,https://github.com/sunpho84,22,https://github.com/etmc/tmLQCD/pull/415#issuecomment-373042223,"GPU and SPI not yet enabled
A single long Makefile.am: this might be broken in many files if you prefer, though I can't see a practical reason for doing that","For what concern flags, I've modified the ALIGN stuff, adding or removing the description (if I believe correctly), but it would be better if you could check it...",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,415,2018-02-04T22:47:20Z,,2021-03-29T13:38:59Z,OPEN,False,365,1626,19,https://github.com/sunpho84,Full Autotools build,14,[],https://github.com/etmc/tmLQCD/pull/415,https://github.com/kostrzewa,23,https://github.com/etmc/tmLQCD/pull/415#issuecomment-373051577,"GPU and SPI not yet enabled
A single long Makefile.am: this might be broken in many files if you prefer, though I can't see a practical reason for doing that","The README should probably be adjusted to contain
aclocal
autoreconf --verbose --install --force

as an instruction for generating configure.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,415,2018-02-04T22:47:20Z,,2021-03-29T13:38:59Z,OPEN,False,365,1626,19,https://github.com/sunpho84,Full Autotools build,14,[],https://github.com/etmc/tmLQCD/pull/415,https://github.com/sunpho84,24,https://github.com/etmc/tmLQCD/pull/415#issuecomment-373053886,"GPU and SPI not yet enabled
A single long Makefile.am: this might be broken in many files if you prefer, though I can't see a practical reason for doing that","Yes, but the autogen.sh or boostrap.shwould be advisable",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,415,2018-02-04T22:47:20Z,,2021-03-29T13:38:59Z,OPEN,False,365,1626,19,https://github.com/sunpho84,Full Autotools build,14,[],https://github.com/etmc/tmLQCD/pull/415,https://github.com/kostrzewa,25,https://github.com/etmc/tmLQCD/pull/415#issuecomment-373054388,"GPU and SPI not yet enabled
A single long Makefile.am: this might be broken in many files if you prefer, though I can't see a practical reason for doing that",Agreed.,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,415,2018-02-04T22:47:20Z,,2021-03-29T13:38:59Z,OPEN,False,365,1626,19,https://github.com/sunpho84,Full Autotools build,14,[],https://github.com/etmc/tmLQCD/pull/415,https://github.com/urbach,26,https://github.com/etmc/tmLQCD/pull/415#issuecomment-373064239,"GPU and SPI not yet enabled
A single long Makefile.am: this might be broken in many files if you prefer, though I can't see a practical reason for doing that","Yes, but the `autogen.sh` or `boostrap.sh`would be advisable
yes, add it please. I have no experience with automake whatsoever...

 --
 You are receiving this because you commented.
 Reply to this email directly or view it on GitHub:
 #415 (comment)

--
Carsten Urbach
e-mail: curbach@gmx.de
        urbach@hiskp.uni-bonn.de
Fon   : +49 (0)228 73 2379
skype : carsten.urbach
URL: http://www.carsten-urbach.eu",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,415,2018-02-04T22:47:20Z,,2021-03-29T13:38:59Z,OPEN,False,365,1626,19,https://github.com/sunpho84,Full Autotools build,14,[],https://github.com/etmc/tmLQCD/pull/415,https://github.com/martin-ueding,27,https://github.com/etmc/tmLQCD/pull/415#issuecomment-373122510,"GPU and SPI not yet enabled
A single long Makefile.am: this might be broken in many files if you prefer, though I can't see a practical reason for doing that","The wikipedia article about GNU Autotools has a nice flowchart, this really helped me when I tried to compile the USQCD code.
I have found that aclocal && autoreconf -fiv is indeed sufficient. Just calling autoconf (even with flags like --install or --add-missing) does not do everything that is needed. In principle one does not need to call autoconf manually. automake should not be called manually, the configure script will do that.
For USQCD projects the following commands do all I need:
aclocal
autoreconf -fiv
./configure
make
make install",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,415,2018-02-04T22:47:20Z,,2021-03-29T13:38:59Z,OPEN,False,365,1626,19,https://github.com/sunpho84,Full Autotools build,14,[],https://github.com/etmc/tmLQCD/pull/415,https://github.com/sunpho84,28,https://github.com/etmc/tmLQCD/pull/415#issuecomment-373197544,"GPU and SPI not yet enabled
A single long Makefile.am: this might be broken in many files if you prefer, though I can't see a practical reason for doing that","The wikipedia article about GNU Autotools has a nice flowchart, this really helped me when I tried to compile the USQCD code.

If this is nice, I don't want to hear what's the feeling of setting up a project with cmake

autoreconf -fiv

same same
So what about the gpu side?",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,415,2018-02-04T22:47:20Z,,2021-03-29T13:38:59Z,OPEN,False,365,1626,19,https://github.com/sunpho84,Full Autotools build,14,[],https://github.com/etmc/tmLQCD/pull/415,https://github.com/urbach,29,https://github.com/etmc/tmLQCD/pull/415#issuecomment-373301092,"GPU and SPI not yet enabled
A single long Makefile.am: this might be broken in many files if you prefer, though I can't see a practical reason for doing that",there are very good reasons that I never used cmake or automake for tmLQCD... ;),True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,416,2018-02-08T11:36:55Z,2018-02-08T11:44:11Z,2018-02-08T11:44:11Z,MERGED,True,2,2,1,https://github.com/martin-ueding,Fix stray {,1,[],https://github.com/etmc/tmLQCD/pull/416,https://github.com/martin-ueding,1,https://github.com/etmc/tmLQCD/pull/416,,,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,417,2018-02-13T14:48:23Z,2021-08-10T13:04:49Z,2021-08-10T13:04:50Z,CLOSED,False,570,114,13,https://github.com/urbach,SMD and omf4,9,[],https://github.com/etmc/tmLQCD/pull/417,https://github.com/urbach,1,https://github.com/etmc/tmLQCD/pull/417,This is a (preliminary) implementation of the SMD algorithm together with a fix for the OMF4 integration scheme,This is a (preliminary) implementation of the SMD algorithm together with a fix for the OMF4 integration scheme,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,417,2018-02-13T14:48:23Z,2021-08-10T13:04:49Z,2021-08-10T13:04:50Z,CLOSED,False,570,114,13,https://github.com/urbach,SMD and omf4,9,[],https://github.com/etmc/tmLQCD/pull/417,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/417#issuecomment-384566306,This is a (preliminary) implementation of the SMD algorithm together with a fix for the OMF4 integration scheme,I'm afraid this has developed some conflicts as a result of the merges that I committed today.,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,417,2018-02-13T14:48:23Z,2021-08-10T13:04:49Z,2021-08-10T13:04:50Z,CLOSED,False,570,114,13,https://github.com/urbach,SMD and omf4,9,[],https://github.com/etmc/tmLQCD/pull/417,https://github.com/urbach,3,https://github.com/etmc/tmLQCD/pull/417#issuecomment-896010176,This is a (preliminary) implementation of the SMD algorithm together with a fix for the OMF4 integration scheme,this is outdated,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,418,2018-02-25T12:06:35Z,2018-04-26T08:58:59Z,2018-04-26T09:02:31Z,MERGED,True,1,0,1,https://github.com/kostrzewa,tmLQCD_invert_init should return if the input file cannot be found,2,[],https://github.com/etmc/tmLQCD/pull/418,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/418,"expose global.h and struct_accessors.h through tmLQCD.h, return error state in lib_wrapper if invert.input cannot be found","expose global.h and struct_accessors.h through tmLQCD.h, return error state in lib_wrapper if invert.input cannot be found",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,418,2018-02-25T12:06:35Z,2018-04-26T08:58:59Z,2018-04-26T09:02:31Z,MERGED,True,1,0,1,https://github.com/kostrzewa,tmLQCD_invert_init should return if the input file cannot be found,2,[],https://github.com/etmc/tmLQCD/pull/418,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/418#issuecomment-372236848,"expose global.h and struct_accessors.h through tmLQCD.h, return error state in lib_wrapper if invert.input cannot be found","Actually, I'm not sure about global.h anymore...",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,418,2018-02-25T12:06:35Z,2018-04-26T08:58:59Z,2018-04-26T09:02:31Z,MERGED,True,1,0,1,https://github.com/kostrzewa,tmLQCD_invert_init should return if the input file cannot be found,2,[],https://github.com/etmc/tmLQCD/pull/418,https://github.com/kostrzewa,3,https://github.com/etmc/tmLQCD/pull/418#issuecomment-372990457,"expose global.h and struct_accessors.h through tmLQCD.h, return error state in lib_wrapper if invert.input cannot be found",I removed the inclusion of struct_accessors.h and global.h because it leads to problems in C++ applications...,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,422,2018-07-10T21:10:55Z,2018-07-25T10:28:41Z,2018-07-25T10:28:41Z,CLOSED,False,3605,617,68,https://github.com/kostrzewa,DO NOT MERGE: this is a comparison PR between Finkenrath/DDalphaAMG_nd  and etmc/master,77,[],https://github.com/etmc/tmLQCD/pull/422,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/422,,,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,423,2018-07-11T10:14:52Z,2019-05-13T16:00:58Z,2021-02-23T17:54:31Z,MERGED,True,2986,540,58,https://github.com/kostrzewa,merge DDalphaAMG_nd branch into etmc/tmLQCD/master,104,[],https://github.com/etmc/tmLQCD/pull/423,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/423,,,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,423,2018-07-11T10:14:52Z,2019-05-13T16:00:58Z,2021-02-23T17:54:31Z,MERGED,True,2986,540,58,https://github.com/kostrzewa,merge DDalphaAMG_nd branch into etmc/tmLQCD/master,104,[],https://github.com/etmc/tmLQCD/pull/423,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/423#issuecomment-404124933,,"@urbach @Finkenrath @sbacchio
okay, so this is the correct comparison between etmc/tmLQCD [master] and Finkenrath/tmLQCD [DDalphaAMG_nd]
How should we proceed?",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,423,2018-07-11T10:14:52Z,2019-05-13T16:00:58Z,2021-02-23T17:54:31Z,MERGED,True,2986,540,58,https://github.com/kostrzewa,merge DDalphaAMG_nd branch into etmc/tmLQCD/master,104,[],https://github.com/etmc/tmLQCD/pull/423,https://github.com/kostrzewa,3,https://github.com/etmc/tmLQCD/pull/423#issuecomment-407434997,,There are so many interconnected changes here it's very difficult to review...,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,423,2018-07-11T10:14:52Z,2019-05-13T16:00:58Z,2021-02-23T17:54:31Z,MERGED,True,2986,540,58,https://github.com/kostrzewa,merge DDalphaAMG_nd branch into etmc/tmLQCD/master,104,[],https://github.com/etmc/tmLQCD/pull/423,https://github.com/kostrzewa,4,https://github.com/etmc/tmLQCD/pull/423#issuecomment-428922097,,"Quite a few things left to check / change / fix. Also, there might be conflicts with @gbergner's reweighting branch #349",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,423,2018-07-11T10:14:52Z,2019-05-13T16:00:58Z,2021-02-23T17:54:31Z,MERGED,True,2986,540,58,https://github.com/kostrzewa,merge DDalphaAMG_nd branch into etmc/tmLQCD/master,104,[],https://github.com/etmc/tmLQCD/pull/423,https://github.com/sbacchio,5,https://github.com/etmc/tmLQCD/pull/423#issuecomment-429274652,,"Pushed, I think now you can pull",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,423,2018-07-11T10:14:52Z,2019-05-13T16:00:58Z,2021-02-23T17:54:31Z,MERGED,True,2986,540,58,https://github.com/kostrzewa,merge DDalphaAMG_nd branch into etmc/tmLQCD/master,104,[],https://github.com/etmc/tmLQCD/pull/423,https://github.com/kostrzewa,6,https://github.com/etmc/tmLQCD/pull/423#issuecomment-489326129,,"Okay, pending some final test runs I will merge this in in the next few hours.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,423,2018-07-11T10:14:52Z,2019-05-13T16:00:58Z,2021-02-23T17:54:31Z,MERGED,True,2986,540,58,https://github.com/kostrzewa,merge DDalphaAMG_nd branch into etmc/tmLQCD/master,104,[],https://github.com/etmc/tmLQCD/pull/423,https://github.com/kostrzewa,7,https://github.com/etmc/tmLQCD/pull/423#issuecomment-491883402,,"Alright, did some high statistics runs especially to test the effect of 2MNFG and I can't detect any statistically significant deviations in  for different combinations of MPI tasks / OpenMP threads after O(70k) trajectories on a small lattice. Will merge this now.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,424,2018-07-11T10:18:34Z,2018-07-25T10:26:25Z,2018-07-25T10:26:25Z,CLOSED,False,0,0,0,https://github.com/kostrzewa,DO NOT MERGE: check what happened in this branch,2,[],https://github.com/etmc/tmLQCD/pull/424,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/424,,,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,425,2018-07-18T16:02:06Z,2018-10-08T09:43:29Z,2018-10-08T09:43:29Z,CLOSED,False,105,0,3,https://github.com/kostrzewa,add single flavour point source generator which takes a four-element ,1,[],https://github.com/etmc/tmLQCD/pull/425,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/425,array of global source coordinates (txyz) as a source location,array of global source coordinates (txyz) as a source location,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,425,2018-07-18T16:02:06Z,2018-10-08T09:43:29Z,2018-10-08T09:43:29Z,CLOSED,False,105,0,3,https://github.com/kostrzewa,add single flavour point source generator which takes a four-element ,1,[],https://github.com/etmc/tmLQCD/pull/425,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/425#issuecomment-405985400,array of global source coordinates (txyz) as a source location,This seems to be a useful utility function which is currently missing in this form.,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,426,2018-07-20T13:15:13Z,2018-09-28T07:48:39Z,2018-10-08T09:31:28Z,MERGED,True,53,20,2,https://github.com/kostrzewa,update QPhiX interface documentation,1,[],https://github.com/etmc/tmLQCD/pull/426,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/426,,,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,428,2018-07-31T07:43:42Z,2018-07-31T11:30:40Z,2018-07-31T11:45:15Z,MERGED,True,4,0,1,https://github.com/kostrzewa,using tmLQCD via libwrapper leads to inconsistent nstore,1,[],https://github.com/etmc/tmLQCD/pull/428,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/428,"When used as a library, the gauge field can be loaded via the external application by passing an integer configuration number to tmLQCD_read_gauge. Unfortunately, doing so does not set nstoreand thus tmLQCD may be left in an inconsistent state.","When used as a library, the gauge field can be loaded via the external application by passing an integer configuration number to tmLQCD_read_gauge. Unfortunately, doing so does not set nstoreand thus tmLQCD may be left in an inconsistent state.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,428,2018-07-31T07:43:42Z,2018-07-31T11:30:40Z,2018-07-31T11:45:15Z,MERGED,True,4,0,1,https://github.com/kostrzewa,using tmLQCD via libwrapper leads to inconsistent nstore,1,[],https://github.com/etmc/tmLQCD/pull/428,https://github.com/urbach,2,https://github.com/etmc/tmLQCD/pull/428#issuecomment-409173672,"When used as a library, the gauge field can be loaded via the external application by passing an integer configuration number to tmLQCD_read_gauge. Unfortunately, doing so does not set nstoreand thus tmLQCD may be left in an inconsistent state.",I could merge this in. Why does travis fail?,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,428,2018-07-31T07:43:42Z,2018-07-31T11:30:40Z,2018-07-31T11:45:15Z,MERGED,True,4,0,1,https://github.com/kostrzewa,using tmLQCD via libwrapper leads to inconsistent nstore,1,[],https://github.com/etmc/tmLQCD/pull/428,https://github.com/kostrzewa,3,https://github.com/etmc/tmLQCD/pull/428#issuecomment-409187187,"When used as a library, the gauge field can be loaded via the external application by passing an integer configuration number to tmLQCD_read_gauge. Unfortunately, doing so does not set nstoreand thus tmLQCD may be left in an inconsistent state.",Because of travis... They keep updating the environment which breaks builds. I don't know if one could't force the environment to remain constant somehow. It's really annoying...,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,431,2018-09-27T15:39:15Z,2018-09-28T08:42:42Z,2018-10-08T09:31:24Z,MERGED,True,39,8,4,https://github.com/kostrzewa,finally add protection from string buffer overflows in configuration ,3,[],https://github.com/etmc/tmLQCD/pull/431,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/431,filenames,filenames,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,431,2018-09-27T15:39:15Z,2018-09-28T08:42:42Z,2018-10-08T09:31:24Z,MERGED,True,39,8,4,https://github.com/kostrzewa,finally add protection from string buffer overflows in configuration ,3,[],https://github.com/etmc/tmLQCD/pull/431,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/431#issuecomment-425141002,filenames,"I would be happy to also move CONF_FILENAME_LENGTH to some global include file, such as to not duplicate this sereral times. Beyond that, the whole reading routine should probably be in its own function with consistent variable names.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,432,2018-09-28T09:16:43Z,2018-09-28T09:26:58Z,2018-10-08T09:31:22Z,MERGED,True,0,11,1,https://github.com/kostrzewa,"in line with our requirement for a c99 compiler, remove hand-written ",1,[],https://github.com/etmc/tmLQCD/pull/432,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/432,isnan macro because it may lead to hard-to-diagnose build errors,isnan macro because it may lead to hard-to-diagnose build errors,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,434,2018-10-08T09:33:43Z,2019-04-16T19:23:03Z,2019-04-16T19:23:03Z,CLOSED,False,1461,353,36,https://github.com/kostrzewa,"DO NOT MERGE various improvements necessary to make working with QUDA efficient ""everywhere""",74,[],https://github.com/etmc/tmLQCD/pull/434,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/434,,,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,434,2018-10-08T09:33:43Z,2019-04-16T19:23:03Z,2019-04-16T19:23:03Z,CLOSED,False,1461,353,36,https://github.com/kostrzewa,"DO NOT MERGE various improvements necessary to make working with QUDA efficient ""everywhere""",74,[],https://github.com/etmc/tmLQCD/pull/434,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/434#issuecomment-428573344,,"@urbach
Okay, so here's the basic idea to track the state of the gauge field globally (and the clover and inverse clover fields, eventually).
In misc_types.h I create some new types to hold state information. Instances of these are are added to the global scope and initialised at program start (via init/init_global_states).
At various points where the gauge field is modified, the function update_tm_gauge_id(&gauge_state, step) is called which will either initialises (upon first call) or steps the gauge_id counter in the gauge_state struct. There is of course some complication due to hf.gaugefield not strictly having to represent g_gauge_field, but in current practice, the two are identical.
I've made some arbitrary choices:

When g_gauge_field is passed to read_gauge, the gauge state is incremented by TM_GAUGE_PROPAGATE_THRESHOLD, which is set to 10.0 at present.
SU(3) restoration causes an increment of TM_GAUGE_PROPAGATE_MIN.
During update_gauge, the integrator step is used.
There is also a field which specifies whether the halo has been exchanged or not and a complementary function to update this element of the struct.

I've tested this for 1000 trajectories in a single run and at that level it is quite resilient to round-off issues. The idea is that at some point in the very near future we can avoid the update and inversion of the clover field if this is consistent with the gauge field, the required clover inverse and the parameters that the latter has been created with.
At the same time, this will help to streamline the existing approach that I've taken in the QUDA interface to ensure that neither the MG setup nor the various device fields are updated / recreated too frequently. Having this well-defined state means that I simply have to compare to that, rather than having to rely on some internal tracked state (see QUDA interface for how this is done presently). This will help when we decide to implement a QUDA monomial solver interface.
Similarly, the corresponding updates in the DDalphaAMG interface can be integrated with this, thus unifying this aspect of the code.
Finally, we might also decide to switch to keeping the QPhiX operators resident and updating their respective field copies as required by testing their state against those tracked in these new global variables.
Of course, a much cleaner approach would be to wrap all fields in structs and to keep all this meta-data tightly coupled to the fields themselves. This would involve a larger number of modifications in the entire code base, but it might be worth the effort even in the short run...
I would really like to hear opinions before we proceed further.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,434,2018-10-08T09:33:43Z,2019-04-16T19:23:03Z,2019-04-16T19:23:03Z,CLOSED,False,1461,353,36,https://github.com/kostrzewa,"DO NOT MERGE various improvements necessary to make working with QUDA efficient ""everywhere""",74,[],https://github.com/etmc/tmLQCD/pull/434,https://github.com/kostrzewa,3,https://github.com/etmc/tmLQCD/pull/434#issuecomment-428574320,,"If this kind of approach looks good, the g_update_gauge_copy can be removed in favour of adding an element to the present struct with the same effect.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,434,2018-10-08T09:33:43Z,2019-04-16T19:23:03Z,2019-04-16T19:23:03Z,CLOSED,False,1461,353,36,https://github.com/kostrzewa,"DO NOT MERGE various improvements necessary to make working with QUDA efficient ""everywhere""",74,[],https://github.com/etmc/tmLQCD/pull/434,https://github.com/kostrzewa,4,https://github.com/etmc/tmLQCD/pull/434#issuecomment-428580104,,"On a different note I tried to make the requested MPI thread level configurable via the input file (this might be important when QUDA is used on something like PizDaint), but I'm afraid that this of course doesn't work properly. The input file is read after MPI is initialised and if I reverse the order of operations, the input file reader produces too much output...
I guess I will have to convert this to a command line argument...",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,434,2018-10-08T09:33:43Z,2019-04-16T19:23:03Z,2019-04-16T19:23:03Z,CLOSED,False,1461,353,36,https://github.com/kostrzewa,"DO NOT MERGE various improvements necessary to make working with QUDA efficient ""everywhere""",74,[],https://github.com/etmc/tmLQCD/pull/434,https://github.com/kostrzewa,5,https://github.com/etmc/tmLQCD/pull/434#issuecomment-428615113,,"At high debug levels (4 and above), the gauge state tracking behaves as shown in the attachment below:
2traj.txt",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,434,2018-10-08T09:33:43Z,2019-04-16T19:23:03Z,2019-04-16T19:23:03Z,CLOSED,False,1461,353,36,https://github.com/kostrzewa,"DO NOT MERGE various improvements necessary to make working with QUDA efficient ""everywhere""",74,[],https://github.com/etmc/tmLQCD/pull/434,https://github.com/urbach,6,https://github.com/etmc/tmLQCD/pull/434#issuecomment-430618343,,"@kostrzewa
to me this looks like a good way forward. It seems to be the sort of minimal way of implementing this.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,434,2018-10-08T09:33:43Z,2019-04-16T19:23:03Z,2019-04-16T19:23:03Z,CLOSED,False,1461,353,36,https://github.com/kostrzewa,"DO NOT MERGE various improvements necessary to make working with QUDA efficient ""everywhere""",74,[],https://github.com/etmc/tmLQCD/pull/434,https://github.com/kostrzewa,7,https://github.com/etmc/tmLQCD/pull/434#issuecomment-430953083,,"Okay, I'll proceed then. Thanks!",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,434,2018-10-08T09:33:43Z,2019-04-16T19:23:03Z,2019-04-16T19:23:03Z,CLOSED,False,1461,353,36,https://github.com/kostrzewa,"DO NOT MERGE various improvements necessary to make working with QUDA efficient ""everywhere""",74,[],https://github.com/etmc/tmLQCD/pull/434,https://github.com/kostrzewa,8,https://github.com/etmc/tmLQCD/pull/434#issuecomment-436612777,,"@pittlerf Once Harald has set up multi-threaded OpenMPI, you will need to use this branch to test it on QBIG, passing the flag -m multiple to the executable.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,434,2018-10-08T09:33:43Z,2019-04-16T19:23:03Z,2019-04-16T19:23:03Z,CLOSED,False,1461,353,36,https://github.com/kostrzewa,"DO NOT MERGE various improvements necessary to make working with QUDA efficient ""everywhere""",74,[],https://github.com/etmc/tmLQCD/pull/434,https://github.com/kostrzewa,9,https://github.com/etmc/tmLQCD/pull/434#issuecomment-436697487,,@pittlerf don't forget to use the OpenMPI version that Harald installed though :),True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,436,2018-10-13T07:11:16Z,2018-10-17T13:01:01Z,2018-11-11T08:24:23Z,MERGED,True,2,0,1,https://github.com/kostrzewa,document MGNumberOfVectors input parameter for QUDA-MG,1,[],https://github.com/etmc/tmLQCD/pull/436,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/436,,,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,443,2018-11-05T09:58:46Z,2018-11-07T12:23:35Z,2018-11-07T12:23:35Z,CLOSED,False,211,27,7,https://github.com/kostrzewa,QUDA MG solver and smoother settings as well as support for tracking TBCs,14,[],https://github.com/etmc/tmLQCD/pull/443,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/443,,,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,443,2018-11-05T09:58:46Z,2018-11-07T12:23:35Z,2018-11-07T12:23:35Z,CLOSED,False,211,27,7,https://github.com/kostrzewa,QUDA MG solver and smoother settings as well as support for tracking TBCs,14,[],https://github.com/etmc/tmLQCD/pull/443,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/443#issuecomment-435818106,,"@marcus-petschlies Since you have this running on QBIG, can you test if these changes don't break anything?",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,443,2018-11-05T09:58:46Z,2018-11-07T12:23:35Z,2018-11-07T12:23:35Z,CLOSED,False,211,27,7,https://github.com/kostrzewa,QUDA MG solver and smoother settings as well as support for tracking TBCs,14,[],https://github.com/etmc/tmLQCD/pull/443,https://github.com/kostrzewa,3,https://github.com/etmc/tmLQCD/pull/443#issuecomment-435818252,,I would be happy to also pull in your changes to the wrapper functions here so there's no hassle.,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,443,2018-11-05T09:58:46Z,2018-11-07T12:23:35Z,2018-11-07T12:23:35Z,CLOSED,False,211,27,7,https://github.com/kostrzewa,QUDA MG solver and smoother settings as well as support for tracking TBCs,14,[],https://github.com/etmc/tmLQCD/pull/443,https://github.com/kostrzewa,4,https://github.com/etmc/tmLQCD/pull/443#issuecomment-436606233,,This will be merged via #434,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,445,2018-11-09T13:36:35Z,2018-11-09T15:54:54Z,2018-11-10T09:17:27Z,CLOSED,False,9,2,3,https://github.com/kostrzewa,Do MPI initialisation in tmLQCD_invert_init,2,[],https://github.com/etmc/tmLQCD/pull/445,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/445,"It seems that having tmLQCD initialise MPI will be beneficial at least for the design of some programs (CVC for example).
@sunpho84 How would this change affect Nissa? I would like to find a compromise which works for all (potential) client codes, but someone needs to call MPI_Init. There's a change about to land which allows runtime selection of the MPI thread level.","It seems that having tmLQCD initialise MPI will be beneficial at least for the design of some programs (CVC for example).
@sunpho84 How would this change affect Nissa? I would like to find a compromise which works for all (potential) client codes, but someone needs to call MPI_Init. There's a change about to land which allows runtime selection of the MPI thread level.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,445,2018-11-09T13:36:35Z,2018-11-09T15:54:54Z,2018-11-10T09:17:27Z,CLOSED,False,9,2,3,https://github.com/kostrzewa,Do MPI initialisation in tmLQCD_invert_init,2,[],https://github.com/etmc/tmLQCD/pull/445,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/445#issuecomment-437361662,"It seems that having tmLQCD initialise MPI will be beneficial at least for the design of some programs (CVC for example).
@sunpho84 How would this change affect Nissa? I would like to find a compromise which works for all (potential) client codes, but someone needs to call MPI_Init. There's a change about to land which allows runtime selection of the MPI thread level.",We can also declare that the client code takes responsibility of initialising MPI. Ideally we would then have the MPI thread level passed down through the interface.,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,445,2018-11-09T13:36:35Z,2018-11-09T15:54:54Z,2018-11-10T09:17:27Z,CLOSED,False,9,2,3,https://github.com/kostrzewa,Do MPI initialisation in tmLQCD_invert_init,2,[],https://github.com/etmc/tmLQCD/pull/445,https://github.com/sunpho84,3,https://github.com/etmc/tmLQCD/pull/445#issuecomment-437397997,"It seems that having tmLQCD initialise MPI will be beneficial at least for the design of some programs (CVC for example).
@sunpho84 How would this change affect Nissa? I would like to find a compromise which works for all (potential) client codes, but someone needs to call MPI_Init. There's a change about to land which allows runtime selection of the MPI thread level.","According to the MPI standard, MPI_Init should be called as soon as possible, as you note in bff0e61. This means that the client is forced to call tmLQCD_invert_init before doing anything else.
I could certainly rearrange the initialization of the nissa library to cope with this, but what would happen if every linked library claimed the same prerogative...?
Why is initializing MPI inside tmLQCD needed?",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,445,2018-11-09T13:36:35Z,2018-11-09T15:54:54Z,2018-11-10T09:17:27Z,CLOSED,False,9,2,3,https://github.com/kostrzewa,Do MPI initialisation in tmLQCD_invert_init,2,[],https://github.com/etmc/tmLQCD/pull/445,https://github.com/kostrzewa,4,https://github.com/etmc/tmLQCD/pull/445#issuecomment-437402168,"It seems that having tmLQCD initialise MPI will be beneficial at least for the design of some programs (CVC for example).
@sunpho84 How would this change affect Nissa? I would like to find a compromise which works for all (potential) client codes, but someone needs to call MPI_Init. There's a change about to land which allows runtime selection of the MPI thread level.","Why is initializing MPI inside tmLQCD needed?

It's not and I would prefer not to do it. In fact, I'm going to revert the change. It was a misunderstanding in the CVC source code.
There might be some subtlety with the new thread level settings, but I will solve that differently.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,445,2018-11-09T13:36:35Z,2018-11-09T15:54:54Z,2018-11-10T09:17:27Z,CLOSED,False,9,2,3,https://github.com/kostrzewa,Do MPI initialisation in tmLQCD_invert_init,2,[],https://github.com/etmc/tmLQCD/pull/445,https://github.com/kostrzewa,5,https://github.com/etmc/tmLQCD/pull/445#issuecomment-437568394,"It seems that having tmLQCD initialise MPI will be beneficial at least for the design of some programs (CVC for example).
@sunpho84 How would this change affect Nissa? I would like to find a compromise which works for all (potential) client codes, but someone needs to call MPI_Init. There's a change about to land which allows runtime selection of the MPI thread level.","Ugh, this is problematic after all. We need to initialise QMP for QPhiX to work. Perhaps I should expose the initialisation function and the client code should then call this instead of MPI_Init.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,445,2018-11-09T13:36:35Z,2018-11-09T15:54:54Z,2018-11-10T09:17:27Z,CLOSED,False,9,2,3,https://github.com/kostrzewa,Do MPI initialisation in tmLQCD_invert_init,2,[],https://github.com/etmc/tmLQCD/pull/445,https://github.com/sunpho84,6,https://github.com/etmc/tmLQCD/pull/445#issuecomment-437569120,"It seems that having tmLQCD initialise MPI will be beneficial at least for the design of some programs (CVC for example).
@sunpho84 How would this change affect Nissa? I would like to find a compromise which works for all (potential) client codes, but someone needs to call MPI_Init. There's a change about to land which allows runtime selection of the MPI thread level.","Can you summarize in which order are things initialized currently, and which are the unavoidable dependency?",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,445,2018-11-09T13:36:35Z,2018-11-09T15:54:54Z,2018-11-10T09:17:27Z,CLOSED,False,9,2,3,https://github.com/kostrzewa,Do MPI initialisation in tmLQCD_invert_init,2,[],https://github.com/etmc/tmLQCD/pull/445,https://github.com/kostrzewa,7,https://github.com/etmc/tmLQCD/pull/445#issuecomment-437569979,"It seems that having tmLQCD initialise MPI will be beneficial at least for the design of some programs (CVC for example).
@sunpho84 How would this change affect Nissa? I would like to find a compromise which works for all (potential) client codes, but someone needs to call MPI_Init. There's a change about to land which allows runtime selection of the MPI thread level.","In order to use QPhiX, MPI initialisation goes via QMP. In order to avoid this, the client code would have to initialise QMP...",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,445,2018-11-09T13:36:35Z,2018-11-09T15:54:54Z,2018-11-10T09:17:27Z,CLOSED,False,9,2,3,https://github.com/kostrzewa,Do MPI initialisation in tmLQCD_invert_init,2,[],https://github.com/etmc/tmLQCD/pull/445,https://github.com/kostrzewa,8,https://github.com/etmc/tmLQCD/pull/445#issuecomment-437570270,"It seems that having tmLQCD initialise MPI will be beneficial at least for the design of some programs (CVC for example).
@sunpho84 How would this change affect Nissa? I would like to find a compromise which works for all (potential) client codes, but someone needs to call MPI_Init. There's a change about to land which allows runtime selection of the MPI thread level.","To answer your question in more detail:
init_parallel_and_read_input
initialises QMP or MPI (wihch one is used is chosen via a preprocessor macro defined in the installed qphix_config.h). Immediately after that the input file is read and init_omp() is called to set the number of threads. The ordering of the latter is because the number of threads is given in the input file and I wanted to get everything to do with parallelisation into a single routine. It can be split back up, however.
What is unavoidable is the choice between MPI and QMP.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,446,2018-11-10T07:19:23Z,2018-11-25T07:43:47Z,2018-11-25T07:43:47Z,CLOSED,False,309,141,3,https://github.com/kostrzewa,some generalisations for lib_wrapper,16,[],https://github.com/etmc/tmLQCD/pull/446,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/446,This will allow for much more straightforward use of the inverter interface by giving users the possibility to set up one or a few dummy operators (of the right class and with the right solver parameters) in the input file and then giving client code the ability to modify these at runtime.,This will allow for much more straightforward use of the inverter interface by giving users the possibility to set up one or a few dummy operators (of the right class and with the right solver parameters) in the input file and then giving client code the ability to modify these at runtime.,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,446,2018-11-10T07:19:23Z,2018-11-25T07:43:47Z,2018-11-25T07:43:47Z,CLOSED,False,309,141,3,https://github.com/kostrzewa,some generalisations for lib_wrapper,16,[],https://github.com/etmc/tmLQCD/pull/446,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/446#issuecomment-437571741,This will allow for much more straightforward use of the inverter interface by giving users the possibility to set up one or a few dummy operators (of the right class and with the right solver parameters) in the input file and then giving client code the ability to modify these at runtime.,This now also includes a tmLQCD_invert_eo routine which allows the solver for a particular operator to be called with the propagator and source specified in odd / even format.,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,446,2018-11-10T07:19:23Z,2018-11-25T07:43:47Z,2018-11-25T07:43:47Z,CLOSED,False,309,141,3,https://github.com/kostrzewa,some generalisations for lib_wrapper,16,[],https://github.com/etmc/tmLQCD/pull/446,https://github.com/kostrzewa,3,https://github.com/etmc/tmLQCD/pull/446#issuecomment-437571753,This will allow for much more straightforward use of the inverter interface by giving users the possibility to set up one or a few dummy operators (of the right class and with the right solver parameters) in the input file and then giving client code the ability to modify these at runtime.,@marcus-petschlies I guess this stuff will also be interesting for CVC.,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,446,2018-11-10T07:19:23Z,2018-11-25T07:43:47Z,2018-11-25T07:43:47Z,CLOSED,False,309,141,3,https://github.com/kostrzewa,some generalisations for lib_wrapper,16,[],https://github.com/etmc/tmLQCD/pull/446,https://github.com/kostrzewa,4,https://github.com/etmc/tmLQCD/pull/446#issuecomment-437584522,This will allow for much more straightforward use of the inverter interface by giving users the possibility to set up one or a few dummy operators (of the right class and with the right solver parameters) in the input file and then giving client code the ability to modify these at runtime.,"@sunpho84
okay, with tmLQCD_invert_qphix_direct and tmLQCD_[get,set]_op_params it should now be possible to do the inversions using the QPhiX double-single or double solver as an inner solver for your quadruple precision solver",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,446,2018-11-10T07:19:23Z,2018-11-25T07:43:47Z,2018-11-25T07:43:47Z,CLOSED,False,309,141,3,https://github.com/kostrzewa,some generalisations for lib_wrapper,16,[],https://github.com/etmc/tmLQCD/pull/446,https://github.com/kostrzewa,5,https://github.com/etmc/tmLQCD/pull/446#issuecomment-437584569,This will allow for much more straightforward use of the inverter interface by giving users the possibility to set up one or a few dummy operators (of the right class and with the right solver parameters) in the input file and then giving client code the ability to modify these at runtime.,"Note, however, that we work in kappa normalisation such that a rescaling will be necessary before entering and after leaving the inner solver...",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,446,2018-11-10T07:19:23Z,2018-11-25T07:43:47Z,2018-11-25T07:43:47Z,CLOSED,False,309,141,3,https://github.com/kostrzewa,some generalisations for lib_wrapper,16,[],https://github.com/etmc/tmLQCD/pull/446,https://github.com/sunpho84,6,https://github.com/etmc/tmLQCD/pull/446#issuecomment-437599982,This will allow for much more straightforward use of the inverter interface by giving users the possibility to set up one or a few dummy operators (of the right class and with the right solver parameters) in the input file and then giving client code the ability to modify these at runtime.,"ok, we can multiply or divide by 2k the source or solution. Wha t is this tmLQCD_invert_qphix_direct supposed to do? does it bypass the usual control through the operators?",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,446,2018-11-10T07:19:23Z,2018-11-25T07:43:47Z,2018-11-25T07:43:47Z,CLOSED,False,309,141,3,https://github.com/kostrzewa,some generalisations for lib_wrapper,16,[],https://github.com/etmc/tmLQCD/pull/446,https://github.com/kostrzewa,7,https://github.com/etmc/tmLQCD/pull/446#issuecomment-437606022,This will allow for much more straightforward use of the inverter interface by giving users the possibility to set up one or a few dummy operators (of the right class and with the right solver parameters) in the input file and then giving client code the ability to modify these at runtime.,"No, it does not do so fully. But it bypasses the source preparation and solution reconstruction and passes directly to the QPhiX solver (which is odd-sites only and takes a prepared source as argument). This was the only quick way which I saw to make QPhiX easily externally accessible as a ""pure solver"".
In order to use it, one would define a single operator in the input file with the right parameters (and suitably adjust these at runtime using tmLQCD_[get,set]_op_params to set the twisted mass to whatever one desires). Then from the client one would call
tmLQCD_invert_qphix_direct(odd_solution, odd_source, op_id)
where op_id would be 0 for most usecases. There's also some parameter tracking to make sure that the clover field and its inverse are always current, although the way it's set up presently would fail upon change of configuration, I guess. As I mentioned I'm in the process of implementing a whole plethora of state tracking in tmLQCD to make sure that the various global fields are always properly defined, but I'm not quite done with that yet. I can easily add some basic gauge state tracking to the interface for our present purposes and rework that once the more wideranging implementation is about to land.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,446,2018-11-10T07:19:23Z,2018-11-25T07:43:47Z,2018-11-25T07:43:47Z,CLOSED,False,309,141,3,https://github.com/kostrzewa,some generalisations for lib_wrapper,16,[],https://github.com/etmc/tmLQCD/pull/446,https://github.com/kostrzewa,8,https://github.com/etmc/tmLQCD/pull/446#issuecomment-438058763,This will allow for much more straightforward use of the inverter interface by giving users the possibility to set up one or a few dummy operators (of the right class and with the right solver parameters) in the input file and then giving client code the ability to modify these at runtime.,"@sunpho84 after working out the input file with Marco today I checked what we can really gain by using QPhiX as an inner solver on KNL. While in the regime of O(1000) iterations it's about a factor of 4 faster than Nissa, the gain in the charm+ region is not worth the effort, I think. That is, unless the situation on the 64c128 lattice is different. The speedup drops to a measly factor of 2 because of various overheads and, as reported previously, at 27 nodes we are already hit by the scaling problems on KNL, which is a shame. I know that the kernels themselves are capable of at least a factor of four more... I still hope that huge pages and threaded comms may help at some point...",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,446,2018-11-10T07:19:23Z,2018-11-25T07:43:47Z,2018-11-25T07:43:47Z,CLOSED,False,309,141,3,https://github.com/kostrzewa,some generalisations for lib_wrapper,16,[],https://github.com/etmc/tmLQCD/pull/446,https://github.com/kostrzewa,9,https://github.com/etmc/tmLQCD/pull/446#issuecomment-441421840,This will allow for much more straightforward use of the inverter interface by giving users the possibility to set up one or a few dummy operators (of the right class and with the right solver parameters) in the input file and then giving client code the ability to modify these at runtime.,This will be merged via the https://github.com/etmc/tmLQCD/tree/get_cvc_to_work branch,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,450,2018-11-25T07:47:21Z,2019-04-16T19:24:28Z,2019-04-16T19:25:27Z,CLOSED,False,1461,353,36,https://github.com/kostrzewa,QUDA interface / lib_wrapper work,72,['DO NOT MERGE'],https://github.com/etmc/tmLQCD/pull/450,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/450,Making progress on the interface with the things that we need in order to run the various cpff tasks for the flavor_singlet project.,Making progress on the interface with the things that we need in order to run the various cpff tasks for the flavor_singlet project.,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,450,2018-11-25T07:47:21Z,2019-04-16T19:24:28Z,2019-04-16T19:25:27Z,CLOSED,False,1461,353,36,https://github.com/kostrzewa,QUDA interface / lib_wrapper work,72,['DO NOT MERGE'],https://github.com/etmc/tmLQCD/pull/450,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/450#issuecomment-441422007,Making progress on the interface with the things that we need in order to run the various cpff tasks for the flavor_singlet project.,@marcus-petschlies This is the branch to target for CVC. Let's please coordinate much more closely how we progress.,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,451,2018-12-14T14:41:00Z,2019-01-29T13:53:14Z,2019-03-27T15:49:42Z,MERGED,True,9,6,1,https://github.com/kostrzewa,"for multi-sample and multi-timeslice correlator measurements, always ",1,[],https://github.com/etmc/tmLQCD/pull/451,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/451,put the trajectory number in the last position in the filename,put the trajectory number in the last position in the filename,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,452,2019-01-29T08:40:19Z,2019-01-29T08:54:57Z,2019-02-06T21:04:50Z,MERGED,True,8,1,1,https://github.com/kostrzewa,quda_interface: set two forgotten precision parameters ,1,[],https://github.com/etmc/tmLQCD/pull/452,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/452,This prevents issues with newest QUDA versions and makes the code faster to boot!,This prevents issues with newest QUDA versions and makes the code faster to boot!,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,455,2019-02-18T14:17:52Z,2019-02-18T14:23:15Z,2019-02-18T14:23:15Z,MERGED,True,8,0,1,https://github.com/pittlerf,Quda work,4,[],https://github.com/etmc/tmLQCD/pull/455,https://github.com/pittlerf,1,https://github.com/etmc/tmLQCD/pull/455,,,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,457,2019-03-23T18:46:02Z,2019-03-23T18:46:13Z,2019-03-27T15:49:39Z,MERGED,True,87,0,4,https://github.com/kostrzewa,Hotfix/quda mg blocking,3,[],https://github.com/etmc/tmLQCD/pull/457,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/457,,,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,458,2019-04-16T18:38:45Z,2019-04-16T18:44:10Z,2019-04-16T18:44:10Z,CLOSED,False,126,18,8,https://github.com/kostrzewa,Quda work,12,[],https://github.com/etmc/tmLQCD/pull/458,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/458,keep get_cvc_to_work branch current with quda interface developments as much as possible,keep get_cvc_to_work branch current with quda interface developments as much as possible,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,459,2019-04-16T18:44:33Z,2019-04-16T19:03:04Z,2019-04-16T19:20:33Z,MERGED,True,99,14,6,https://github.com/kostrzewa,Cvc merge quda work,14,[],https://github.com/etmc/tmLQCD/pull/459,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/459,,,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,460,2019-04-16T19:25:02Z,,2021-08-10T11:58:49Z,OPEN,False,2628,1120,316,https://github.com/kostrzewa,work on lib_wrapper / QUDA interface and CVC integration,128,[],https://github.com/etmc/tmLQCD/pull/460,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/460,,,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,460,2019-04-16T19:25:02Z,,2021-08-10T11:58:49Z,OPEN,False,2628,1120,316,https://github.com/kostrzewa,work on lib_wrapper / QUDA interface and CVC integration,128,[],https://github.com/etmc/tmLQCD/pull/460,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/460#issuecomment-523979749,,"It seems that I've set up the parameter input for coarse grid deflation correctly, but there are still a number of things that need to be upgraded in the input file parser to have more fine-grained control over several per-level parameters. I'm also not quite sure yet whether it is actually doing anything or if I still have to mess around with some things. Help with testing/exploration would be welcome!",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,460,2019-04-16T19:25:02Z,,2021-08-10T11:58:49Z,OPEN,False,2628,1120,316,https://github.com/kostrzewa,work on lib_wrapper / QUDA interface and CVC integration,128,[],https://github.com/etmc/tmLQCD/pull/460,https://github.com/kostrzewa,3,https://github.com/etmc/tmLQCD/pull/460#issuecomment-525040160,,"I got the coarse-grid deflation working. Poly acceleration doesn't really work yet on my test ensemble, but I will try on the physical point lattice to see if I can make it purr there based on the settings by Kate. One thing to note: the input complexity for this thing is now way beyond reasonable...",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,460,2019-04-16T19:25:02Z,,2021-08-10T11:58:49Z,OPEN,False,2628,1120,316,https://github.com/kostrzewa,work on lib_wrapper / QUDA interface and CVC integration,128,[],https://github.com/etmc/tmLQCD/pull/460,https://github.com/kostrzewa,4,https://github.com/etmc/tmLQCD/pull/460#issuecomment-812212157,,This is now synced with the master branch. The effect of the modifications on the HMC can thus be tested.,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,469,2019-06-14T13:17:35Z,2019-08-21T13:13:23Z,2019-08-21T13:19:54Z,MERGED,True,1,1,1,https://github.com/palao,bug fix: wrong plaquette in metadata just after reversibility check,1,[],https://github.com/etmc/tmLQCD/pull/469,https://github.com/palao,1,https://github.com/etmc/tmLQCD/pull/469,"The xlf-info LIME record contained a wrong value of the plaquette when the reversibility check occurs.
To reproduce it, take for instance ""sample-input/sample-hmc0.input"" and set (to make it simpler and faster) for instance:
Measurements = 11
ReversibilityCheckIntervall = 10
The plaquette value in the ""xlf-info"" header of the resulting conf is wrong (it corresponds to the plaquette computed on the reversed trajectory).
I checked that the averaged plaquette computed and the value written in ""output.data"" agree and both disagree with the value in the ""xlf-info"".","The xlf-info LIME record contained a wrong value of the plaquette when the reversibility check occurs.
To reproduce it, take for instance ""sample-input/sample-hmc0.input"" and set (to make it simpler and faster) for instance:
Measurements = 11
ReversibilityCheckIntervall = 10
The plaquette value in the ""xlf-info"" header of the resulting conf is wrong (it corresponds to the plaquette computed on the reversed trajectory).
I checked that the averaged plaquette computed and the value written in ""output.data"" agree and both disagree with the value in the ""xlf-info"".",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,469,2019-06-14T13:17:35Z,2019-08-21T13:13:23Z,2019-08-21T13:19:54Z,MERGED,True,1,1,1,https://github.com/palao,bug fix: wrong plaquette in metadata just after reversibility check,1,[],https://github.com/etmc/tmLQCD/pull/469,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/469#issuecomment-523450734,"The xlf-info LIME record contained a wrong value of the plaquette when the reversibility check occurs.
To reproduce it, take for instance ""sample-input/sample-hmc0.input"" and set (to make it simpler and faster) for instance:
Measurements = 11
ReversibilityCheckIntervall = 10
The plaquette value in the ""xlf-info"" header of the resulting conf is wrong (it corresponds to the plaquette computed on the reversed trajectory).
I checked that the averaged plaquette computed and the value written in ""output.data"" agree and both disagree with the value in the ""xlf-info"".","Agreed, this was not correct!",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,469,2019-06-14T13:17:35Z,2019-08-21T13:13:23Z,2019-08-21T13:19:54Z,MERGED,True,1,1,1,https://github.com/palao,bug fix: wrong plaquette in metadata just after reversibility check,1,[],https://github.com/etmc/tmLQCD/pull/469,https://github.com/kostrzewa,3,https://github.com/etmc/tmLQCD/pull/469#issuecomment-523453241,"The xlf-info LIME record contained a wrong value of the plaquette when the reversibility check occurs.
To reproduce it, take for instance ""sample-input/sample-hmc0.input"" and set (to make it simpler and faster) for instance:
Measurements = 11
ReversibilityCheckIntervall = 10
The plaquette value in the ""xlf-info"" header of the resulting conf is wrong (it corresponds to the plaquette computed on the reversed trajectory).
I checked that the averaged plaquette computed and the value written in ""output.data"" agree and both disagree with the value in the ""xlf-info"".",thanks David!,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,472,2019-09-19T13:09:29Z,2019-09-19T13:09:43Z,2019-09-19T13:10:36Z,MERGED,True,50,51,2,https://github.com/kostrzewa,Make complex c++11 compliant,2,[],https://github.com/etmc/tmLQCD/pull/472,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/472,,,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,473,2019-11-11T22:37:13Z,2019-11-12T16:17:15Z,2021-02-23T17:54:08Z,MERGED,True,387,329,313,https://github.com/kostrzewa,useful backports from quda_work branch,6,[],https://github.com/etmc/tmLQCD/pull/473,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/473,"mainly, this changes config.h -> tmlqcd_config.h and installs this file in include in the build directory so it can be easily externally included as it should be
secondly, for some reason we lost
<TMSOLVER,CSWSOLVER>{
  mg {
    optr->solver=MG;
    if(myverbose) printf(""  Solver set to MG line %d operator %d\n"", line_of_file, current_operator);
    BEGIN(name_caller);
  }
}

from read_input.l. This reintroduces it.","mainly, this changes config.h -> tmlqcd_config.h and installs this file in include in the build directory so it can be easily externally included as it should be
secondly, for some reason we lost
<TMSOLVER,CSWSOLVER>{
  mg {
    optr->solver=MG;
    if(myverbose) printf(""  Solver set to MG line %d operator %d\n"", line_of_file, current_operator);
    BEGIN(name_caller);
  }
}

from read_input.l. This reintroduces it.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,473,2019-11-11T22:37:13Z,2019-11-12T16:17:15Z,2021-02-23T17:54:08Z,MERGED,True,387,329,313,https://github.com/kostrzewa,useful backports from quda_work branch,6,[],https://github.com/etmc/tmLQCD/pull/473,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/473#issuecomment-552955567,"mainly, this changes config.h -> tmlqcd_config.h and installs this file in include in the build directory so it can be easily externally included as it should be
secondly, for some reason we lost
<TMSOLVER,CSWSOLVER>{
  mg {
    optr->solver=MG;
    if(myverbose) printf(""  Solver set to MG line %d operator %d\n"", line_of_file, current_operator);
    BEGIN(name_caller);
  }
}

from read_input.l. This reintroduces it.","Thanks for the review, always helpful to have more eyes on code... I've fixed the erroneous replacements.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,473,2019-11-11T22:37:13Z,2019-11-12T16:17:15Z,2021-02-23T17:54:08Z,MERGED,True,387,329,313,https://github.com/kostrzewa,useful backports from quda_work branch,6,[],https://github.com/etmc/tmLQCD/pull/473,https://github.com/urbach,3,https://github.com/etmc/tmLQCD/pull/473#issuecomment-552957716,"mainly, this changes config.h -> tmlqcd_config.h and installs this file in include in the build directory so it can be easily externally included as it should be
secondly, for some reason we lost
<TMSOLVER,CSWSOLVER>{
  mg {
    optr->solver=MG;
    if(myverbose) printf(""  Solver set to MG line %d operator %d\n"", line_of_file, current_operator);
    BEGIN(name_caller);
  }
}

from read_input.l. This reintroduces it.","Thanks for the review, always helpful to have more eyes on code... I've fixed the erroneous replacements.
thanks, good to be merged!",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,477,2020-08-04T12:49:09Z,2021-02-12T08:37:53Z,2021-02-23T17:54:05Z,MERGED,True,1014,966,394,https://github.com/kostrzewa,fix compilation on Hawk,7,[],https://github.com/etmc/tmLQCD/pull/477,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/477,"Using gcc 9.2.0 revealed some issues with circular dependencies in header files as well as problems dealing with manipulations that https://github.com/usqcd-software/c-lime does to preprocessor macros coming from its own AC_INIT and which are included via lime.h. (basically things like PACKAGE_VERSION are undef'ed).
I've cleaned up many of the include satements in the code and have attempted a workaround for the problem with c-lime.","Using gcc 9.2.0 revealed some issues with circular dependencies in header files as well as problems dealing with manipulations that https://github.com/usqcd-software/c-lime does to preprocessor macros coming from its own AC_INIT and which are included via lime.h. (basically things like PACKAGE_VERSION are undef'ed).
I've cleaned up many of the include satements in the code and have attempted a workaround for the problem with c-lime.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,477,2020-08-04T12:49:09Z,2021-02-12T08:37:53Z,2021-02-23T17:54:05Z,MERGED,True,1014,966,394,https://github.com/kostrzewa,fix compilation on Hawk,7,[],https://github.com/etmc/tmLQCD/pull/477,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/477#issuecomment-771059532,"Using gcc 9.2.0 revealed some issues with circular dependencies in header files as well as problems dealing with manipulations that https://github.com/usqcd-software/c-lime does to preprocessor macros coming from its own AC_INIT and which are included via lime.h. (basically things like PACKAGE_VERSION are undef'ed).
I've cleaned up many of the include satements in the code and have attempted a workaround for the problem with c-lime.","The problem is one of include order and what other autoconf-based packages do with defines like PACKAGE_VERSION. C-lime, for example, undefs these and then they are gone.
Now, one would think that one could simply include lime.h first and then tmlqcd_config.h, but unfortunately, that doesn't always help because tmlqcd_config.h might have been included somewhere, where lime.h was NOT included. As a result, _CONFIG_H is now defined. When the compiler then gets to a file wherelime.h is actually included, the PACKAGE_* definitions will be undeffed by lime.h and won't be available anymore.
Hence the deferral to an include file without header guards and the redefinition.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,479,2021-02-22T19:21:10Z,2021-08-10T12:53:41Z,2021-09-09T17:13:42Z,MERGED,True,9,9,3,https://github.com/kostrzewa,Gamma doc,3,[],https://github.com/etmc/tmLQCD/pull/479,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/479,I think this should be correct now,I think this should be correct now,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,479,2021-02-22T19:21:10Z,2021-08-10T12:53:41Z,2021-09-09T17:13:42Z,MERGED,True,9,9,3,https://github.com/kostrzewa,Gamma doc,3,[],https://github.com/etmc/tmLQCD/pull/479,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/479#issuecomment-790000836,I think this should be correct now,"Note that this finally makes the code and the documentation consistent again (sorry about that)...
Lscher

tmLQCD docs (now)",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,482,2021-04-01T15:29:23Z,2021-04-01T15:30:40Z,2021-04-01T15:30:40Z,CLOSED,False,17,21,4,https://github.com/sunpho84,Renaming structures and added extern to avoid compile clash,1,[],https://github.com/etmc/tmLQCD/pull/482,https://github.com/sunpho84,1,https://github.com/etmc/tmLQCD/pull/482,Fix #481,Fix #481,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,483,2021-04-01T15:40:39Z,2021-04-06T09:59:28Z,2021-04-06T09:59:28Z,MERGED,True,16,20,5,https://github.com/sunpho84,"Renaming structures and added extern, removed Direction to avoid compile clash",4,[],https://github.com/etmc/tmLQCD/pull/483,https://github.com/sunpho84,1,https://github.com/etmc/tmLQCD/pull/483,fix #481 and  #485 #484,fix #481 and  #485 #484,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,483,2021-04-01T15:40:39Z,2021-04-06T09:59:28Z,2021-04-06T09:59:28Z,MERGED,True,16,20,5,https://github.com/sunpho84,"Renaming structures and added extern, removed Direction to avoid compile clash",4,[],https://github.com/etmc/tmLQCD/pull/483,https://github.com/sunpho84,2,https://github.com/etmc/tmLQCD/pull/483#issuecomment-812750497,fix #481 and  #485 #484,I've included the commits needed to fix #484,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,486,2021-04-01T17:30:52Z,2021-04-01T22:30:51Z,2021-04-06T10:05:34Z,MERGED,True,601,588,178,https://github.com/kostrzewa,Quda work merge master,31,[],https://github.com/etmc/tmLQCD/pull/486,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/486,"Here's my attempt to synchronise master and quda_work. I've not tested compilation and hence also not done any regression tests. To be honest, I never wanted to touch this code again...","Here's my attempt to synchronise master and quda_work. I've not tested compilation and hence also not done any regression tests. To be honest, I never wanted to touch this code again...",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,486,2021-04-01T17:30:52Z,2021-04-01T22:30:51Z,2021-04-06T10:05:34Z,MERGED,True,601,588,178,https://github.com/kostrzewa,Quda work merge master,31,[],https://github.com/etmc/tmLQCD/pull/486,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/486#issuecomment-812060149,"Here's my attempt to synchronise master and quda_work. I've not tested compilation and hence also not done any regression tests. To be honest, I never wanted to touch this code again...",It would be nice if someone could set up github actions to at least automatically test the build system...,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,486,2021-04-01T17:30:52Z,2021-04-01T22:30:51Z,2021-04-06T10:05:34Z,MERGED,True,601,588,178,https://github.com/kostrzewa,Quda work merge master,31,[],https://github.com/etmc/tmLQCD/pull/486,https://github.com/sunpho84,3,https://github.com/etmc/tmLQCD/pull/486#issuecomment-812063441,"Here's my attempt to synchronise master and quda_work. I've not tested compilation and hence also not done any regression tests. To be honest, I never wanted to touch this code again...",what do you mean? isn't travis cehcking the build?,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,486,2021-04-01T17:30:52Z,2021-04-01T22:30:51Z,2021-04-06T10:05:34Z,MERGED,True,601,588,178,https://github.com/kostrzewa,Quda work merge master,31,[],https://github.com/etmc/tmLQCD/pull/486,https://github.com/kostrzewa,4,https://github.com/etmc/tmLQCD/pull/486#issuecomment-812083231,"Here's my attempt to synchronise master and quda_work. I've not tested compilation and hence also not done any regression tests. To be honest, I never wanted to touch this code again...","what do you mean? isn't travis cehcking the build?

that has been broken for ages.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,486,2021-04-01T17:30:52Z,2021-04-01T22:30:51Z,2021-04-06T10:05:34Z,MERGED,True,601,588,178,https://github.com/kostrzewa,Quda work merge master,31,[],https://github.com/etmc/tmLQCD/pull/486,https://github.com/kostrzewa,5,https://github.com/etmc/tmLQCD/pull/486#issuecomment-812083804,"Here's my attempt to synchronise master and quda_work. I've not tested compilation and hence also not done any regression tests. To be honest, I never wanted to touch this code again...","Anyway, this builds now on my machine but one has to be careful to create a new build directory (or appropriately empty the current one) because there is a change to the files generated in ${top_build_dir}/include.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,486,2021-04-01T17:30:52Z,2021-04-01T22:30:51Z,2021-04-06T10:05:34Z,MERGED,True,601,588,178,https://github.com/kostrzewa,Quda work merge master,31,[],https://github.com/etmc/tmLQCD/pull/486,https://github.com/kostrzewa,6,https://github.com/etmc/tmLQCD/pull/486#issuecomment-812088406,"Here's my attempt to synchronise master and quda_work. I've not tested compilation and hence also not done any regression tests. To be honest, I never wanted to touch this code again...","Doing the following:
CC=mpicc CXX=mpicxx F77=f77 \                                                                                                                                
CFLAGS=""-mtune=znver2 -march=znver2 -O3 -mavx2 -mfma -fopenmp"" \
LDFLAGS=""-fopenmp"" \
~/code/tmLQCD.merge_quda_work/configure \
  --enable-mpi \
  --with-mpidimension=4 \
  --disable-sse2 --disable-sse3 \
  --with-cudadir=/usr/local/cuda/lib64 \
  --with-qudadir=$(pwd)/../quda_develop/install_dir \
  --with-limedir=$(pwd)/../lime/install_dir \
  --with-lapack=""-lblas -llapack""

in an empty build directory works for me, but maybe there is still some compiler dependence...",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,486,2021-04-01T17:30:52Z,2021-04-01T22:30:51Z,2021-04-06T10:05:34Z,MERGED,True,601,588,178,https://github.com/kostrzewa,Quda work merge master,31,[],https://github.com/etmc/tmLQCD/pull/486,https://github.com/sunpho84,7,https://github.com/etmc/tmLQCD/pull/486#issuecomment-812091345,"Here's my attempt to synchronise master and quda_work. I've not tested compilation and hence also not done any regression tests. To be honest, I never wanted to touch this code again...","Doing the following:
CC=mpicc CXX=mpicxx F77=f77 \                                                                                                                                
CFLAGS=""-mtune=znver2 -march=znver2 -O3 -mavx2 -mfma -fopenmp"" \
LDFLAGS=""-fopenmp"" \
~/code/tmLQCD.merge_quda_work/configure \
  --enable-mpi \
  --with-mpidimension=4 \
  --disable-sse2 --disable-sse3 \
  --with-cudadir=/usr/local/cuda/lib64 \
  --with-qudadir=$(pwd)/../quda_develop/install_dir \
  --with-limedir=$(pwd)/../lime/install_dir \
  --with-lapack=""-lblas -llapack""

in an empty build directory works for me, but maybe there is still some compiler dependence...

yes actually it almost does, now I get
../../io/utils_write_first_message.c: In function write_first_messages:
../../io/utils_write_first_message.c:27:115: error: TMLQCD_PACKAGE_VERSION undeclared (first use in this function); did you mean LIME_PACKAGE_VERSION?
   27 |   snprintf(message, 1024, ""This is the %s code for twisted mass Wilson QCD\n\nVersion %s, commit %s\n"",executable,TMLQCD_PACKAGE_VERSION,git_hash);
      |                                                                                                                   ^~~~~~~~~~~~~~~~~~~~~~
      |                                                                                                                   LIME_PACKAGE_VERSION
../../io/utils_write_first_message.c:27:115: note: each undeclared identifier is reported only once for each function it appears in",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,486,2021-04-01T17:30:52Z,2021-04-01T22:30:51Z,2021-04-06T10:05:34Z,MERGED,True,601,588,178,https://github.com/kostrzewa,Quda work merge master,31,[],https://github.com/etmc/tmLQCD/pull/486,https://github.com/kostrzewa,8,https://github.com/etmc/tmLQCD/pull/486#issuecomment-812099620,"Here's my attempt to synchronise master and quda_work. I've not tested compilation and hence also not done any regression tests. To be honest, I never wanted to touch this code again...","yes actually it almost does, now I get

delete the file include/tmlqcd_config.h in your build dir, it's a left-over from a previous build which is not deleted by the build system (since now a different file is auto-generated)",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,486,2021-04-01T17:30:52Z,2021-04-01T22:30:51Z,2021-04-06T10:05:34Z,MERGED,True,601,588,178,https://github.com/kostrzewa,Quda work merge master,31,[],https://github.com/etmc/tmLQCD/pull/486,https://github.com/sunpho84,9,https://github.com/etmc/tmLQCD/pull/486#issuecomment-812178800,"Here's my attempt to synchronise master and quda_work. I've not tested compilation and hence also not done any regression tests. To be honest, I never wanted to touch this code again...","ok I see, a make distclean did the trick",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,486,2021-04-01T17:30:52Z,2021-04-01T22:30:51Z,2021-04-06T10:05:34Z,MERGED,True,601,588,178,https://github.com/kostrzewa,Quda work merge master,31,[],https://github.com/etmc/tmLQCD/pull/486,https://github.com/kostrzewa,10,https://github.com/etmc/tmLQCD/pull/486#issuecomment-812209401,"Here's my attempt to synchronise master and quda_work. I've not tested compilation and hence also not done any regression tests. To be honest, I never wanted to touch this code again...","Had to make one more modif, moving the non-generated file into the include/ directory in the source dir. This is in order to be able to grab the settings when using tmLQCD as a library in an external program as in that case, one doesn't want to have to specify the source directory itself as an include dir (as there might be include files with the same names between the client app and tmLQCD). In the end, both tmlqcd_config.h and tmlqcd_config_internal.h should of course be installed.
I've checked this now linked against my cvc_depgraph extension of CVC and the changes merged in from master don't seem to break the QUDA behaviour.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,486,2021-04-01T17:30:52Z,2021-04-01T22:30:51Z,2021-04-06T10:05:34Z,MERGED,True,601,588,178,https://github.com/kostrzewa,Quda work merge master,31,[],https://github.com/etmc/tmLQCD/pull/486,https://github.com/sunpho84,11,https://github.com/etmc/tmLQCD/pull/486#issuecomment-812750060,"Here's my attempt to synchronise master and quda_work. I've not tested compilation and hence also not done any regression tests. To be honest, I never wanted to touch this code again...","what do you mean? isn't travis cehcking the build?

that has been broken for ages.

? travis is checking my fork and he seems to be rather happy...
https://travis-ci.com/github/sunpho84/tmLQCD/builds/222046903",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,487,2021-04-06T10:13:43Z,2021-07-29T06:14:18Z,2021-07-29T13:52:28Z,MERGED,True,0,11,1,https://github.com/sunpho84,Additional Direction not needed,1,[],https://github.com/etmc/tmLQCD/pull/487,https://github.com/sunpho84,1,https://github.com/etmc/tmLQCD/pull/487,"Solving this additional error, similar to #485
/usr/bin/ld: ./lib/libxchange.a(little_field_gather.o):/home/francesco/QCD/SORGENTI/tmLQCD/build_quda/xchange/../../xchange/little_field_gather.c:47: multiple definition of `Direction'; ./lib/libhmc.a(block.o):/home/francesco/QCD/SORGENTI/tmLQCD/build_quda/../block.c:78: first defined here","Solving this additional error, similar to #485
/usr/bin/ld: ./lib/libxchange.a(little_field_gather.o):/home/francesco/QCD/SORGENTI/tmLQCD/build_quda/xchange/../../xchange/little_field_gather.c:47: multiple definition of `Direction'; ./lib/libhmc.a(block.o):/home/francesco/QCD/SORGENTI/tmLQCD/build_quda/../block.c:78: first defined here",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,487,2021-04-06T10:13:43Z,2021-07-29T06:14:18Z,2021-07-29T13:52:28Z,MERGED,True,0,11,1,https://github.com/sunpho84,Additional Direction not needed,1,[],https://github.com/etmc/tmLQCD/pull/487,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/487#issuecomment-815044382,"Solving this additional error, similar to #485
/usr/bin/ld: ./lib/libxchange.a(little_field_gather.o):/home/francesco/QCD/SORGENTI/tmLQCD/build_quda/xchange/../../xchange/little_field_gather.c:47: multiple definition of `Direction'; ./lib/libhmc.a(block.o):/home/francesco/QCD/SORGENTI/tmLQCD/build_quda/../block.c:78: first defined here","In the current quda_work branch, there's only a single definition of this enum in block.c. Have you perhaps changed things locally?",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,487,2021-04-06T10:13:43Z,2021-07-29T06:14:18Z,2021-07-29T13:52:28Z,MERGED,True,0,11,1,https://github.com/sunpho84,Additional Direction not needed,1,[],https://github.com/etmc/tmLQCD/pull/487,https://github.com/kostrzewa,3,https://github.com/etmc/tmLQCD/pull/487#issuecomment-815045619,"Solving this additional error, similar to #485
/usr/bin/ld: ./lib/libxchange.a(little_field_gather.o):/home/francesco/QCD/SORGENTI/tmLQCD/build_quda/xchange/../../xchange/little_field_gather.c:47: multiple definition of `Direction'; ./lib/libhmc.a(block.o):/home/francesco/QCD/SORGENTI/tmLQCD/build_quda/../block.c:78: first defined here","Ah, no, I see, there's another one in little_field_gather.c, but with a different numbering!",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,487,2021-04-06T10:13:43Z,2021-07-29T06:14:18Z,2021-07-29T13:52:28Z,MERGED,True,0,11,1,https://github.com/sunpho84,Additional Direction not needed,1,[],https://github.com/etmc/tmLQCD/pull/487,https://github.com/kostrzewa,4,https://github.com/etmc/tmLQCD/pull/487#issuecomment-815046905,"Solving this additional error, similar to #485
/usr/bin/ld: ./lib/libxchange.a(little_field_gather.o):/home/francesco/QCD/SORGENTI/tmLQCD/build_quda/xchange/../../xchange/little_field_gather.c:47: multiple definition of `Direction'; ./lib/libhmc.a(block.o):/home/francesco/QCD/SORGENTI/tmLQCD/build_quda/../block.c:78: first defined here","block.c:
enum{
  NONE = 0, 
  T_UP = 1, 
  T_DN = 2, 
  X_UP = 3, 
  X_DN = 4, 
  Y_UP = 5, 
  Y_DN = 6, 
  Z_UP = 7, 
  Z_DN = 8
} Direction;                                                                                                                               

xchange/little_field_gather.c:
enum{
  T_UP = 0,
  T_DN = 1,
  X_UP = 2,
  X_DN = 3,
  Y_UP = 4,
  Y_DN = 5,
  Z_UP = 6,
  Z_DN = 7 
} Direction;",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,487,2021-04-06T10:13:43Z,2021-07-29T06:14:18Z,2021-07-29T13:52:28Z,MERGED,True,0,11,1,https://github.com/sunpho84,Additional Direction not needed,1,[],https://github.com/etmc/tmLQCD/pull/487,https://github.com/kostrzewa,5,https://github.com/etmc/tmLQCD/pull/487#issuecomment-815050348,"Solving this additional error, similar to #485
/usr/bin/ld: ./lib/libxchange.a(little_field_gather.o):/home/francesco/QCD/SORGENTI/tmLQCD/build_quda/xchange/../../xchange/little_field_gather.c:47: multiple definition of `Direction'; ./lib/libhmc.a(block.o):/home/francesco/QCD/SORGENTI/tmLQCD/build_quda/../block.c:78: first defined here","NONE is never used apparently, but I honestly can't tell if this won't break things. It's not like we need a Lscher-style deflated solver given the availability of DDalphaAMG. I thus don't much care if this breaks, but @urbach should decide since he spent so much time fixing this stuff...",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,487,2021-04-06T10:13:43Z,2021-07-29T06:14:18Z,2021-07-29T13:52:28Z,MERGED,True,0,11,1,https://github.com/sunpho84,Additional Direction not needed,1,[],https://github.com/etmc/tmLQCD/pull/487,https://github.com/sunpho84,6,https://github.com/etmc/tmLQCD/pull/487#issuecomment-815267769,"Solving this additional error, similar to #485
/usr/bin/ld: ./lib/libxchange.a(little_field_gather.o):/home/francesco/QCD/SORGENTI/tmLQCD/build_quda/xchange/../../xchange/little_field_gather.c:47: multiple definition of `Direction'; ./lib/libhmc.a(block.o):/home/francesco/QCD/SORGENTI/tmLQCD/build_quda/../block.c:78: first defined here","It looks to me like the Direction structure in block.c is simply dead code, as it is not referred anywhere in the TU, so I would be tempted to say that removing it should have no impact.
Indeed both are contained in a .c file, and block.c compiles no matter the presence of the structure. Am I too naive...?",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,487,2021-04-06T10:13:43Z,2021-07-29T06:14:18Z,2021-07-29T13:52:28Z,MERGED,True,0,11,1,https://github.com/sunpho84,Additional Direction not needed,1,[],https://github.com/etmc/tmLQCD/pull/487,https://github.com/kostrzewa,7,https://github.com/etmc/tmLQCD/pull/487#issuecomment-888833323,"Solving this additional error, similar to #485
/usr/bin/ld: ./lib/libxchange.a(little_field_gather.o):/home/francesco/QCD/SORGENTI/tmLQCD/build_quda/xchange/../../xchange/little_field_gather.c:47: multiple definition of `Direction'; ./lib/libhmc.a(block.o):/home/francesco/QCD/SORGENTI/tmLQCD/build_quda/../block.c:78: first defined here","I will just merge this in now. If it breaks things, somebody else will have to fix it...",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,487,2021-04-06T10:13:43Z,2021-07-29T06:14:18Z,2021-07-29T13:52:28Z,MERGED,True,0,11,1,https://github.com/sunpho84,Additional Direction not needed,1,[],https://github.com/etmc/tmLQCD/pull/487,https://github.com/sunpho84,8,https://github.com/etmc/tmLQCD/pull/487#issuecomment-889162826,"Solving this additional error, similar to #485
/usr/bin/ld: ./lib/libxchange.a(little_field_gather.o):/home/francesco/QCD/SORGENTI/tmLQCD/build_quda/xchange/../../xchange/little_field_gather.c:47: multiple definition of `Direction'; ./lib/libhmc.a(block.o):/home/francesco/QCD/SORGENTI/tmLQCD/build_quda/../block.c:78: first defined here",I'll keep my fingers crossed...,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,488,2021-04-06T10:20:10Z,2021-07-29T06:11:28Z,2021-07-29T06:11:28Z,MERGED,True,1,1,1,https://github.com/sunpho84,no_eigenvalues already defined extern in the related header,1,[],https://github.com/etmc/tmLQCD/pull/488,https://github.com/sunpho84,1,https://github.com/etmc/tmLQCD/pull/488,"Fix this
/usr/bin/ld: ./lib/libsolver.a(eigenvalues.o):/home/francesco/QCD/SORGENTI/tmLQCD/build_quda/solver/../../solver/eigenvalues.c:61: multiple definition of `no_eigenvalues'; ./lib/libhmc.a(read_input.o):/home/francesco/QCD/SORGENTI/tmLQCD/build_quda/../read_input.l:222: first defined here","Fix this
/usr/bin/ld: ./lib/libsolver.a(eigenvalues.o):/home/francesco/QCD/SORGENTI/tmLQCD/build_quda/solver/../../solver/eigenvalues.c:61: multiple definition of `no_eigenvalues'; ./lib/libhmc.a(read_input.o):/home/francesco/QCD/SORGENTI/tmLQCD/build_quda/../read_input.l:222: first defined here",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,488,2021-04-06T10:20:10Z,2021-07-29T06:11:28Z,2021-07-29T06:11:28Z,MERGED,True,1,1,1,https://github.com/sunpho84,no_eigenvalues already defined extern in the related header,1,[],https://github.com/etmc/tmLQCD/pull/488,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/488#issuecomment-815033379,"Fix this
/usr/bin/ld: ./lib/libsolver.a(eigenvalues.o):/home/francesco/QCD/SORGENTI/tmLQCD/build_quda/solver/../../solver/eigenvalues.c:61: multiple definition of `no_eigenvalues'; ./lib/libhmc.a(read_input.o):/home/francesco/QCD/SORGENTI/tmLQCD/build_quda/../read_input.l:222: first defined here","Argh, this is super nasty. Variables with this name are used (and modified) in various places throughout the codebase and I don't think that the various instances of this variable are supposed to mean the same thing...",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,488,2021-04-06T10:20:10Z,2021-07-29T06:11:28Z,2021-07-29T06:11:28Z,MERGED,True,1,1,1,https://github.com/sunpho84,no_eigenvalues already defined extern in the related header,1,[],https://github.com/etmc/tmLQCD/pull/488,https://github.com/kostrzewa,3,https://github.com/etmc/tmLQCD/pull/488#issuecomment-815035444,"Fix this
/usr/bin/ld: ./lib/libsolver.a(eigenvalues.o):/home/francesco/QCD/SORGENTI/tmLQCD/build_quda/solver/../../solver/eigenvalues.c:61: multiple definition of `no_eigenvalues'; ./lib/libhmc.a(read_input.o):/home/francesco/QCD/SORGENTI/tmLQCD/build_quda/../read_input.l:222: first defined here",It's also used as global input AND output ... soooo nasty. ,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,488,2021-04-06T10:20:10Z,2021-07-29T06:11:28Z,2021-07-29T06:11:28Z,MERGED,True,1,1,1,https://github.com/sunpho84,no_eigenvalues already defined extern in the related header,1,[],https://github.com/etmc/tmLQCD/pull/488,https://github.com/sunpho84,4,https://github.com/etmc/tmLQCD/pull/488#issuecomment-815259344,"Fix this
/usr/bin/ld: ./lib/libsolver.a(eigenvalues.o):/home/francesco/QCD/SORGENTI/tmLQCD/build_quda/solver/../../solver/eigenvalues.c:61: multiple definition of `no_eigenvalues'; ./lib/libhmc.a(read_input.o):/home/francesco/QCD/SORGENTI/tmLQCD/build_quda/../read_input.l:222: first defined here","Very good... so my naive fix is simply avoiding the error but not changing the behaviour, as I guess the compiler was somehow melding the two instances as if one was defined with extern linkage.
Is it somehow clear how to proceed?",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,490,2021-04-07T15:57:34Z,,2022-06-01T18:21:00Z,OPEN,False,52333,1299,143,https://github.com/kostrzewa,extension of the QUDA interface to use QUDA solvers in the HMC,314,[],https://github.com/etmc/tmLQCD/pull/490,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/490,"three build types:

plain
with DDalphaAMG
with QPhiX

For QPhiX, the integration tests don't pass and should be checked manually by someone else by running sample-hmc-qphix-tmcloverdetratio.input and comparing the respective sample-output/hmc-qphix-tmcloverdetratio/* using the master branch of tmLQCD. There might be issues with the machine that the sample-output files were generated on that manifest only in that case. Alternatively, the changes to the quda_work branch might have affected the correct functioning of external solvers. (in fact, I'm almost certain that's the case for DDalphaAMG as discussed here: #460 (comment)).","three build types:

plain
with DDalphaAMG
with QPhiX

For QPhiX, the integration tests don't pass and should be checked manually by someone else by running sample-hmc-qphix-tmcloverdetratio.input and comparing the respective sample-output/hmc-qphix-tmcloverdetratio/* using the master branch of tmLQCD. There might be issues with the machine that the sample-output files were generated on that manifest only in that case. Alternatively, the changes to the quda_work branch might have affected the correct functioning of external solvers. (in fact, I'm almost certain that's the case for DDalphaAMG as discussed here: #460 (comment)).",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,490,2021-04-07T15:57:34Z,,2022-06-01T18:21:00Z,OPEN,False,52333,1299,143,https://github.com/kostrzewa,extension of the QUDA interface to use QUDA solvers in the HMC,314,[],https://github.com/etmc/tmLQCD/pull/490,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/490#issuecomment-886986469,"three build types:

plain
with DDalphaAMG
with QPhiX

For QPhiX, the integration tests don't pass and should be checked manually by someone else by running sample-hmc-qphix-tmcloverdetratio.input and comparing the respective sample-output/hmc-qphix-tmcloverdetratio/* using the master branch of tmLQCD. There might be issues with the machine that the sample-output files were generated on that manifest only in that case. Alternatively, the changes to the quda_work branch might have affected the correct functioning of external solvers. (in fact, I'm almost certain that's the case for DDalphaAMG as discussed here: #460 (comment)).",This damn thing has broken because of an Ubuntu problem on the runner...,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,490,2021-04-07T15:57:34Z,,2022-06-01T18:21:00Z,OPEN,False,52333,1299,143,https://github.com/kostrzewa,extension of the QUDA interface to use QUDA solvers in the HMC,314,[],https://github.com/etmc/tmLQCD/pull/490,https://github.com/kostrzewa,3,https://github.com/etmc/tmLQCD/pull/490#issuecomment-908347747,"three build types:

plain
with DDalphaAMG
with QPhiX

For QPhiX, the integration tests don't pass and should be checked manually by someone else by running sample-hmc-qphix-tmcloverdetratio.input and comparing the respective sample-output/hmc-qphix-tmcloverdetratio/* using the master branch of tmLQCD. There might be issues with the machine that the sample-output files were generated on that manifest only in that case. Alternatively, the changes to the quda_work branch might have affected the correct functioning of external solvers. (in fact, I'm almost certain that's the case for DDalphaAMG as discussed here: #460 (comment)).",quda_work_hmc_refresh_setup and quda_work_hmc should be reviewed and merged here before any more work is done,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,490,2021-04-07T15:57:34Z,,2022-06-01T18:21:00Z,OPEN,False,52333,1299,143,https://github.com/kostrzewa,extension of the QUDA interface to use QUDA solvers in the HMC,314,[],https://github.com/etmc/tmLQCD/pull/490,https://github.com/kostrzewa,4,https://github.com/etmc/tmLQCD/pull/490#issuecomment-910126175,"three build types:

plain
with DDalphaAMG
with QPhiX

For QPhiX, the integration tests don't pass and should be checked manually by someone else by running sample-hmc-qphix-tmcloverdetratio.input and comparing the respective sample-output/hmc-qphix-tmcloverdetratio/* using the master branch of tmLQCD. There might be issues with the machine that the sample-output files were generated on that manifest only in that case. Alternatively, the changes to the quda_work branch might have affected the correct functioning of external solvers. (in fact, I'm almost certain that's the case for DDalphaAMG as discussed here: #460 (comment)).","The next step here is to check if the new changes for the HMC have not affected the exisiting functionality for using tmLQCD as an interface to QUDA (as done, for example, by CVC)",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,490,2021-04-07T15:57:34Z,,2022-06-01T18:21:00Z,OPEN,False,52333,1299,143,https://github.com/kostrzewa,extension of the QUDA interface to use QUDA solvers in the HMC,314,[],https://github.com/etmc/tmLQCD/pull/490,https://github.com/kostrzewa,5,https://github.com/etmc/tmLQCD/pull/490#issuecomment-912947726,"three build types:

plain
with DDalphaAMG
with QPhiX

For QPhiX, the integration tests don't pass and should be checked manually by someone else by running sample-hmc-qphix-tmcloverdetratio.input and comparing the respective sample-output/hmc-qphix-tmcloverdetratio/* using the master branch of tmLQCD. There might be issues with the machine that the sample-output files were generated on that manifest only in that case. Alternatively, the changes to the quda_work branch might have affected the correct functioning of external solvers. (in fact, I'm almost certain that's the case for DDalphaAMG as discussed here: #460 (comment)).",The merge with the current GK branch seems to have introduced a correctness regression in our twisted-clover HMC. Investigating...,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,490,2021-04-07T15:57:34Z,,2022-06-01T18:21:00Z,OPEN,False,52333,1299,143,https://github.com/kostrzewa,extension of the QUDA interface to use QUDA solvers in the HMC,314,[],https://github.com/etmc/tmLQCD/pull/490,https://github.com/kostrzewa,6,https://github.com/etmc/tmLQCD/pull/490#issuecomment-912963464,"three build types:

plain
with DDalphaAMG
with QPhiX

For QPhiX, the integration tests don't pass and should be checked manually by someone else by running sample-hmc-qphix-tmcloverdetratio.input and comparing the respective sample-output/hmc-qphix-tmcloverdetratio/* using the master branch of tmLQCD. There might be issues with the machine that the sample-output files were generated on that manifest only in that case. Alternatively, the changes to the quda_work branch might have affected the correct functioning of external solvers. (in fact, I'm almost certain that's the case for DDalphaAMG as discussed here: #460 (comment)).",I think something got messed up before (possibly on the tmLQCD side) as I seem to be able to reproduce this also with ndeg-twisted-clover before the last merge with GK.,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,490,2021-04-07T15:57:34Z,,2022-06-01T18:21:00Z,OPEN,False,52333,1299,143,https://github.com/kostrzewa,extension of the QUDA interface to use QUDA solvers in the HMC,314,[],https://github.com/etmc/tmLQCD/pull/490,https://github.com/kostrzewa,7,https://github.com/etmc/tmLQCD/pull/490#issuecomment-912964781,"three build types:

plain
with DDalphaAMG
with QPhiX

For QPhiX, the integration tests don't pass and should be checked manually by someone else by running sample-hmc-qphix-tmcloverdetratio.input and comparing the respective sample-output/hmc-qphix-tmcloverdetratio/* using the master branch of tmLQCD. There might be issues with the machine that the sample-output files were generated on that manifest only in that case. Alternatively, the changes to the quda_work branch might have affected the correct functioning of external solvers. (in fact, I'm almost certain that's the case for DDalphaAMG as discussed here: #460 (comment)).",Seems like I introduced some issue with multiple clover determinant ratios (proably related to tm_rho). Hopefully I can figure this out next week...,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,490,2021-04-07T15:57:34Z,,2022-06-01T18:21:00Z,OPEN,False,52333,1299,143,https://github.com/kostrzewa,extension of the QUDA interface to use QUDA solvers in the HMC,314,[],https://github.com/etmc/tmLQCD/pull/490,https://github.com/kostrzewa,8,https://github.com/etmc/tmLQCD/pull/490#issuecomment-912988368,"three build types:

plain
with DDalphaAMG
with QPhiX

For QPhiX, the integration tests don't pass and should be checked manually by someone else by running sample-hmc-qphix-tmcloverdetratio.input and comparing the respective sample-output/hmc-qphix-tmcloverdetratio/* using the master branch of tmLQCD. There might be issues with the machine that the sample-output files were generated on that manifest only in that case. Alternatively, the changes to the quda_work branch might have affected the correct functioning of external solvers. (in fact, I'm almost certain that's the case for DDalphaAMG as discussed here: #460 (comment)).",Issue with tm_rho fixed in be4f1de. I had forgotten to make sure to reset it appropriately...,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,490,2021-04-07T15:57:34Z,,2022-06-01T18:21:00Z,OPEN,False,52333,1299,143,https://github.com/kostrzewa,extension of the QUDA interface to use QUDA solvers in the HMC,314,[],https://github.com/etmc/tmLQCD/pull/490,https://github.com/kostrzewa,9,https://github.com/etmc/tmLQCD/pull/490#issuecomment-912992938,"three build types:

plain
with DDalphaAMG
with QPhiX

For QPhiX, the integration tests don't pass and should be checked manually by someone else by running sample-hmc-qphix-tmcloverdetratio.input and comparing the respective sample-output/hmc-qphix-tmcloverdetratio/* using the master branch of tmLQCD. There might be issues with the machine that the sample-output files were generated on that manifest only in that case. Alternatively, the changes to the quda_work branch might have affected the correct functioning of external solvers. (in fact, I'm almost certain that's the case for DDalphaAMG as discussed here: #460 (comment)).","I've also introduced a stack-based timer which, given some more work to replace some of the existing measurements, should allow for nested profiling.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,490,2021-04-07T15:57:34Z,,2022-06-01T18:21:00Z,OPEN,False,52333,1299,143,https://github.com/kostrzewa,extension of the QUDA interface to use QUDA solvers in the HMC,314,[],https://github.com/etmc/tmLQCD/pull/490,https://github.com/kostrzewa,10,https://github.com/etmc/tmLQCD/pull/490#issuecomment-912996817,"three build types:

plain
with DDalphaAMG
with QPhiX

For QPhiX, the integration tests don't pass and should be checked manually by someone else by running sample-hmc-qphix-tmcloverdetratio.input and comparing the respective sample-output/hmc-qphix-tmcloverdetratio/* using the master branch of tmLQCD. There might be issues with the machine that the sample-output files were generated on that manifest only in that case. Alternatively, the changes to the quda_work branch might have affected the correct functioning of external solvers. (in fact, I'm almost certain that's the case for DDalphaAMG as discussed here: #460 (comment)).","Alright, got 3-level MG working with the generic kernel branch (it works, but I'm not sure that it's completely correct, waiting for Kate to confirm in the GK PR):
diff --git a/lib/coarse_op.cuh b/lib/coarse_op.cuh
index e6eee80e8..161768ded 100644
--- a/lib/coarse_op.cuh
+++ b/lib/coarse_op.cuh
@@ -421,7 +421,7 @@ namespace quda {
         errorQuda(""add_coarse_staggered_mass not enabled for non-staggered coarsenings"");
 #endif
       } else if (type == COMPUTE_TMDIAGONAL) {
-#if defined(WILSONCOARSE)
+#if defined(WILSONCOARSE) || defined(COARSECOARSE)
         launch_device<add_coarse_tm>(tp, stream, arg);
 #else
         errorQuda(""add_coarse_tm not enabled for non-wilson coarsenings"");",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,490,2021-04-07T15:57:34Z,,2022-06-01T18:21:00Z,OPEN,False,52333,1299,143,https://github.com/kostrzewa,extension of the QUDA interface to use QUDA solvers in the HMC,314,[],https://github.com/etmc/tmLQCD/pull/490,https://github.com/kostrzewa,11,https://github.com/etmc/tmLQCD/pull/490#issuecomment-912997946,"three build types:

plain
with DDalphaAMG
with QPhiX

For QPhiX, the integration tests don't pass and should be checked manually by someone else by running sample-hmc-qphix-tmcloverdetratio.input and comparing the respective sample-output/hmc-qphix-tmcloverdetratio/* using the master branch of tmLQCD. There might be issues with the machine that the sample-output files were generated on that manifest only in that case. Alternatively, the changes to the quda_work branch might have affected the correct functioning of external solvers. (in fact, I'm almost certain that's the case for DDalphaAMG as discussed here: #460 (comment)).",I've pushed to feature/ndeg-twisted-clover anyway so that we can test some realistic runs with small quark mass.,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,490,2021-04-07T15:57:34Z,,2022-06-01T18:21:00Z,OPEN,False,52333,1299,143,https://github.com/kostrzewa,extension of the QUDA interface to use QUDA solvers in the HMC,314,[],https://github.com/etmc/tmLQCD/pull/490,https://github.com/kostrzewa,12,https://github.com/etmc/tmLQCD/pull/490#issuecomment-914422274,"three build types:

plain
with DDalphaAMG
with QPhiX

For QPhiX, the integration tests don't pass and should be checked manually by someone else by running sample-hmc-qphix-tmcloverdetratio.input and comparing the respective sample-output/hmc-qphix-tmcloverdetratio/* using the master branch of tmLQCD. There might be issues with the machine that the sample-output files were generated on that manifest only in that case. Alternatively, the changes to the quda_work branch might have affected the correct functioning of external solvers. (in fact, I'm almost certain that's the case for DDalphaAMG as discussed here: #460 (comment)).","I've pushed in many more uses of the stack-based timers. The result is far from perfect (or complete) and I'm not quite happy with the readability. See, for example, a call of ndrat_derivative from update_momenta.
# solve_mms_nd: Time for gamma5 2.498160e-03 s level: 3 proc_id: 0
# TM_QUDA: Using half prec. as sloppy!
# TM_QUDA: Using mixed precision CG!
# TM_QUDA: Using EO preconditioning!
# TM_QUDA: mu = 0.306748466258, epsilon = 0.153374233129 kappa = 0.163000000000, csw = -1.000000000000
# TM_QUDA: Time for reorder_spinor_eo_toQuda 4.381409e-03 s level: 4 proc_id: 0
# QUDA: MultiShift CG: Converged after 42 iterations
# QUDA:  shift=0, 42 iterations, relative residual: iterated = 1.069589e-05
# QUDA:  shift=1, 42 iterations, relative residual: iterated = 4.737972e-07
# QUDA:  shift=2, 31 iterations, relative residual: iterated = 3.226969e-07
# QUDA: Refining shift 0: L2 residual inf / 3.162278e-08, heavy quark 0.000000e+00 / 0.000000e+00 (actual / requested)
# QUDA: CG: Convergence at 57 iterations, L2 relative residual: iterated = 2.270846e-11, true = 2.270846e-11 (requested = 2.632426e-11)
# QUDA: Refining shift 1: L2 residual inf / 3.162278e-08, heavy quark 0.000000e+00 / 0.000000e+00 (actual / requested)
# QUDA: CG: Convergence at 41 iterations, L2 relative residual: iterated = 2.351888e-11, true = 2.351888e-11 (requested = 2.632426e-11)
# QUDA: Refining shift 2: L2 residual inf / 3.162278e-08, heavy quark 0.000000e+00 / 0.000000e+00 (actual / requested)
# QUDA: CG: Convergence at 30 iterations, L2 relative residual: iterated = 2.480254e-11, true = 2.480254e-11 (requested = 2.632426e-11)
# TM_QUDA: Time for invertMultiShiftQuda 9.982428e-01 s level: 4 proc_id: 0
# TM_QUDA: Time for reorder_spinor_eo_fromQuda 5.027221e-03 s level: 5 proc_id: 0
# TM_QUDA: Time for reorder_spinor_eo_fromQuda 4.961261e-03 s level: 5 proc_id: 0
# TM_QUDA: Time for reorder_spinor_eo_fromQuda 4.694299e-03 s level: 5 proc_id: 0
# TM_QUDA: Time for multishift_output_overhead 2.302024e-02 s level: 4 proc_id: 0
# TM_QUDA: QpQm solve done: 170 iter / 0.870356 secs = 173.208 Gflops
# TM_QUDA: Time for invert_eo_quda_twoflavour_mshift 1.031182e+00 s level: 3 proc_id: 0
# solve_mms_nd: Time for mshift_mul_r_gamm5 3.330184e-03 s level: 3 proc_id: 0
# : Time for solve_mms_nd 1.037577e+00 s level: 2 proc_id: 0
# ndrat_derivative: Time for Q_tau1_sub_const_ndpsi 4.423422e-02 s level: 2 proc_id: 0
# ndrat_derivative: Time for H_eo_tm_ndpsi 1.989946e-02 s level: 2 proc_id: 0
# : Time for deriv_Sb 1.680145e-02 s level: 2 proc_id: 0
# : Time for deriv_Sb 1.661034e-02 s level: 2 proc_id: 0
# ndrat_derivative: Time for H_eo_[sw,tm]_ndpsi 1.957391e-02 s level: 2 proc_id: 0
# : Time for deriv_Sb 1.741884e-02 s level: 2 proc_id: 0
# : Time for deriv_Sb 1.733338e-02 s level: 2 proc_id: 0
# ndrat_derivative: Time for Q_tau1_sub_const_ndpsi 4.365956e-02 s level: 2 proc_id: 0
# ndrat_derivative: Time for H_eo_tm_ndpsi 1.996137e-02 s level: 2 proc_id: 0
# : Time for deriv_Sb 1.685861e-02 s level: 2 proc_id: 0
# : Time for deriv_Sb 1.674535e-02 s level: 2 proc_id: 0
# ndrat_derivative: Time for H_eo_[sw,tm]_ndpsi 2.059529e-02 s level: 2 proc_id: 0
# : Time for deriv_Sb 2.021802e-02 s level: 2 proc_id: 0
# : Time for deriv_Sb 1.726222e-02 s level: 2 proc_id: 0
# ndrat_derivative: Time for Q_tau1_sub_const_ndpsi 4.357695e-02 s level: 2 proc_id: 0
# ndrat_derivative: Time for H_eo_tm_ndpsi 2.010726e-02 s level: 2 proc_id: 0
# : Time for deriv_Sb 1.702856e-02 s level: 2 proc_id: 0
# : Time for deriv_Sb 1.672618e-02 s level: 2 proc_id: 0
# ndrat_derivative: Time for H_eo_[sw,tm]_ndpsi 1.969201e-02 s level: 2 proc_id: 0
# : Time for deriv_Sb 1.680372e-02 s level: 2 proc_id: 0
# : Time for deriv_Sb 1.661798e-02 s level: 2 proc_id: 0
# ndrat_5_7: Time for ndrat_derivative 1.495478e+00 s level: 1 proc_id: 0
# : Time for update_momenta 1.506387e+00 s level: 0 proc_id: 0

Things become even worse when one attempts to keep track of what happens in the FG integrator...",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,490,2021-04-07T15:57:34Z,,2022-06-01T18:21:00Z,OPEN,False,52333,1299,143,https://github.com/kostrzewa,extension of the QUDA interface to use QUDA solvers in the HMC,314,[],https://github.com/etmc/tmLQCD/pull/490,https://github.com/kostrzewa,13,https://github.com/etmc/tmLQCD/pull/490#issuecomment-914428098,"three build types:

plain
with DDalphaAMG
with QPhiX

For QPhiX, the integration tests don't pass and should be checked manually by someone else by running sample-hmc-qphix-tmcloverdetratio.input and comparing the respective sample-output/hmc-qphix-tmcloverdetratio/* using the master branch of tmLQCD. There might be issues with the machine that the sample-output files were generated on that manifest only in that case. Alternatively, the changes to the quda_work branch might have affected the correct functioning of external solvers. (in fact, I'm almost certain that's the case for DDalphaAMG as discussed here: #460 (comment)).","In particular, I think the partial context provided in a line like
# ndrat_derivative: Time for Q_tau1_sub_const_ndpsi 4.423422e-02 s level: 2 proc_id: 0

which is at the same level as the call to deriv_Sb in the same function
# : Time for deriv_Sb 1.702856e-02 s level: 2 proc_id: 0

is confusing. Providing context to the latter involves changing a lot of stuff (or instrumenting all calls to deriv_Sb explicitly, which I don't really want tot do...). I might thus just remove the context at the beginning of the line (i.e. ndrat_derivative:) and only keep it in places where the context is user-configured, for example, such as in:
# ndrat_5_7: Time for ndrat_derivative 1.495478e+00 s level: 1 proc_id: 0",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,490,2021-04-07T15:57:34Z,,2022-06-01T18:21:00Z,OPEN,False,52333,1299,143,https://github.com/kostrzewa,extension of the QUDA interface to use QUDA solvers in the HMC,314,[],https://github.com/etmc/tmLQCD/pull/490,https://github.com/kostrzewa,14,https://github.com/etmc/tmLQCD/pull/490#issuecomment-914460530,"three build types:

plain
with DDalphaAMG
with QPhiX

For QPhiX, the integration tests don't pass and should be checked manually by someone else by running sample-hmc-qphix-tmcloverdetratio.input and comparing the respective sample-output/hmc-qphix-tmcloverdetratio/* using the master branch of tmLQCD. There might be issues with the machine that the sample-output files were generated on that manifest only in that case. Alternatively, the changes to the quda_work branch might have affected the correct functioning of external solvers. (in fact, I'm almost certain that's the case for DDalphaAMG as discussed here: #460 (comment)).","I've removed the context in 413ce1e and it can easily be reintroduced. To me this looks cleaner:
# TM_QUDA: Using half prec. as sloppy!
# TM_QUDA: Using mixed precision CG!
# TM_QUDA: Using EO preconditioning!
# TM_QUDA: Clover field and inverse already loaded for gauge 0.000000
# TM_QUDA: mu = 0.306748466258, epsilon = 0.153374233129 kappa = 0.163000000000, csw = 1.000000000000
# TM_QUDA: Time for reorder_spinor_eo_toQuda 4.183512e-03 s level: 4 proc_id: 0
# QUDA: MultiShift CG: Converged after 75 iterations
# QUDA:  shift=0, 75 iterations, relative residual: iterated = 1.390547e-06
# QUDA:  shift=1, 75 iterations, relative residual: iterated = 4.269281e-07
# QUDA: Refining shift 0: L2 residual inf / 3.162278e-08, heavy quark 0.000000e+00 / 0.000000e+00 (actual / requested)
# QUDA: CG: Convergence at 70 iterations, L2 relative residual: iterated = 2.355300e-11, true = 2.355300e-11 (requested = 2.531149e-11)
# QUDA: Refining shift 1: L2 residual inf / 3.162278e-08, heavy quark 0.000000e+00 / 0.000000e+00 (actual / requested)
# QUDA: CG: Convergence at 73 iterations, L2 relative residual: iterated = 2.167418e-11, true = 2.167418e-11 (requested = 2.531149e-11)
# TM_QUDA: Time for invertMultiShiftQuda 1.404832e+00 s level: 4 proc_id: 0
# TM_QUDA: Time for reorder_spinor_eo_fromQuda 4.730562e-03 s level: 5 proc_id: 0
# TM_QUDA: Time for reorder_spinor_eo_fromQuda 5.002763e-03 s level: 5 proc_id: 0
# TM_QUDA: Time for multishift_output_overhead 1.539710e-02 s level: 4 proc_id: 0
# TM_QUDA: QpQm solve done: 218 iter / 1.31038 secs = 184.99 Gflops
# TM_QUDA: Time for invert_eo_quda_twoflavour_mshift 1.429501e+00 s level: 3 proc_id: 0
# solve_mms_nd: Time for mshift_mul_r_gamm5 2.134861e-03 s level: 3 proc_id: 0
# solve_mms_nd residual check: shift 0 (1.105573e-04), res. 8.658786e-16
# solve_mms_nd residual check: shift 1 (1.116214e-03), res. 7.332464e-16
# : Time for solve_mms_nd 1.658463e+00 s level: 2 proc_id: 0
# : Time for Qsw_tau1_sub_const_ndpsi 6.060014e-02 s level: 2 proc_id: 0
# : Time for H_eo_sw_ndpsi 2.850301e-02 s level: 2 proc_id: 0
# : Time for deriv_Sb 1.946674e-02 s level: 2 proc_id: 0
# : Time for deriv_Sb 1.998732e-02 s level: 2 proc_id: 0
# : Time for H_eo_sw_ndpsi 2.692045e-02 s level: 2 proc_id: 0
# : Time for deriv_Sb 1.901408e-02 s level: 2 proc_id: 0
# : Time for deriv_Sb 1.859284e-02 s level: 2 proc_id: 0
# : Time for sw_spinor_eo 6.559874e-03 s level: 2 proc_id: 0
# : Time for sw_spinor_eo 6.857285e-03 s level: 2 proc_id: 0
# : Time for sw_spinor_eo 6.974024e-03 s level: 2 proc_id: 0
# : Time for sw_spinor_eo 6.872104e-03 s level: 2 proc_id: 0
# : Time for Qsw_tau1_sub_const_ndpsi 5.505562e-02 s level: 2 proc_id: 0
# : Time for H_eo_sw_ndpsi 2.738234e-02 s level: 2 proc_id: 0
# : Time for deriv_Sb 1.760590e-02 s level: 2 proc_id: 0
# : Time for deriv_Sb 1.742311e-02 s level: 2 proc_id: 0
# : Time for H_eo_sw_ndpsi 2.712331e-02 s level: 2 proc_id: 0
# : Time for deriv_Sb 1.807833e-02 s level: 2 proc_id: 0
# : Time for deriv_Sb 1.818175e-02 s level: 2 proc_id: 0
# : Time for sw_spinor_eo 7.193194e-03 s level: 2 proc_id: 0
# : Time for sw_spinor_eo 6.880055e-03 s level: 2 proc_id: 0
# : Time for sw_spinor_eo 6.813154e-03 s level: 2 proc_id: 0
# : Time for sw_spinor_eo 6.952154e-03 s level: 2 proc_id: 0
# : Time for sw_all 3.189702e-01 s level: 2 proc_id: 0
# ndrat_8_9: Time for ndrat_derivative 2.583201e+00 s level: 1 proc_id: 0",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,490,2021-04-07T15:57:34Z,,2022-06-01T18:21:00Z,OPEN,False,52333,1299,143,https://github.com/kostrzewa,extension of the QUDA interface to use QUDA solvers in the HMC,314,[],https://github.com/etmc/tmLQCD/pull/490,https://github.com/kostrzewa,15,https://github.com/etmc/tmLQCD/pull/490#issuecomment-914510420,"three build types:

plain
with DDalphaAMG
with QPhiX

For QPhiX, the integration tests don't pass and should be checked manually by someone else by running sample-hmc-qphix-tmcloverdetratio.input and comparing the respective sample-output/hmc-qphix-tmcloverdetratio/* using the master branch of tmLQCD. There might be issues with the machine that the sample-output files were generated on that manifest only in that case. Alternatively, the changes to the quda_work branch might have affected the correct functioning of external solvers. (in fact, I'm almost certain that's the case for DDalphaAMG as discussed here: #460 (comment)).","In a run on Booster, this is what the overheads look like, for example in a derivative of an ndcloverrat monomial where the derivative takes 8 seconds as discussed on Monday and the solver itself accounts for only 0.56 seconds while the call to invertMultiShiftQuda takes about 1.2 seconds in total (so this is dominated by host-device transfers of the output fields, I guess), plus another 0.2 seconds to reorder all the fields on the CPU side.
All the remainder is spent in various CPU functions, all of which will need to run on the GPU in the future.
# : Time for su3_zero 2.838294e-02 s level: 2 proc_id: 0
# : Time for sw_term 4.119006e-01 s level: 2 proc_id: 0
# : Time for sw_invert_nd 1.720084e-01 s level: 2 proc_id: 0
# solve_mms_nd: Time for gamma5 9.351093e-03 s level: 3 proc_id: 0
# TM_QUDA: Using single prec. as sloppy!
# TM_QUDA: Using mixed precision CG!
# TM_QUDA: Using EO preconditioning!
# TM_QUDA: Clover field and inverse already loaded for gauge 0.009375
# TM_QUDA: mu = 0.124686399987, epsilon = 0.131505200008 kappa = 0.139426700000, csw = 1.690000000000
# TM_QUDA: Time for reorder_spinor_eo_toQuda 2.321822e-02 s level: 4 proc_id: 0
MultiShift CG: Converged after 53 iterations
 shift=0, 53 iterations, relative residual: iterated = 4.002840e-05
 shift=1, 53 iterations, relative residual: iterated = 2.889575e-08
 shift=2, 28 iterations, relative residual: iterated = 2.094232e-08
 shift=3, 14 iterations, relative residual: iterated = 2.250499e-08
 shift=4, 7 iterations, relative residual: iterated = 1.034281e-08
Refining shift 0: L2 residual inf / 1.000000e-08, heavy quark 0.000000e+00 / 0.000000e+00 (actual / requested)
CG: Convergence at 58 iterations, L2 relative residual: iterated = 9.644183e-09, true = 9.644183e-09 (requested = 1.000000e-08)
Refining shift 1: L2 residual inf / 1.000000e-08, heavy quark 0.000000e+00 / 0.000000e+00 (actual / requested)
CG: Convergence at 8 iterations, L2 relative residual: iterated = 8.038671e-09, true = 8.038671e-09 (requested = 1.000000e-08)
Refining shift 2: L2 residual inf / 1.000000e-08, heavy quark 0.000000e+00 / 0.000000e+00 (actual / requested)
CG: Convergence at 4 iterations, L2 relative residual: iterated = 8.880854e-09, true = 8.880854e-09 (requested = 1.000000e-08)
Refining shift 3: L2 residual inf / 1.000000e-08, heavy quark 0.000000e+00 / 0.000000e+00 (actual / requested)
CG: Convergence at 2 iterations, L2 relative residual: iterated = 6.822438e-09, true = 6.822438e-09 (requested = 1.000000e-08)
Refining shift 4: L2 residual inf / 1.000000e-08, heavy quark 0.000000e+00 / 0.000000e+00 (actual / requested)
CG: Convergence at 1 iterations, L2 relative residual: iterated = 2.585498e-09, true = 2.585498e-09 (requested = 1.000000e-08)
# TM_QUDA: Time for invertMultiShiftQuda 1.190052e+00 s level: 4 proc_id: 0
# TM_QUDA: Time for reorder_spinor_eo_fromQuda 2.411113e-02 s level: 5 proc_id: 0
# TM_QUDA: Time for reorder_spinor_eo_fromQuda 2.346242e-02 s level: 5 proc_id: 0
# TM_QUDA: Time for reorder_spinor_eo_fromQuda 2.339547e-02 s level: 5 proc_id: 0
# TM_QUDA: Time for reorder_spinor_eo_fromQuda 2.328414e-02 s level: 5 proc_id: 0
# TM_QUDA: Time for reorder_spinor_eo_fromQuda 2.339242e-02 s level: 5 proc_id: 0
# TM_QUDA: Time for multishift_output_overhead 1.785818e-01 s level: 4 proc_id: 0
# TM_QUDA: QpQm solve done: 126 iter / 0.561773 secs = 28021 Gflops
# TM_QUDA: Time for invert_eo_quda_twoflavour_mshift 1.415733e+00 s level: 3 proc_id: 0
# solve_mms_nd: Time for mshift_mul_r_gamm5 4.290332e-02 s level: 3 proc_id: 0
# : Time for solve_mms_nd 1.468456e+00 s level: 2 proc_id: 0
# : Time for Qsw_tau1_sub_const_ndpsi 2.259685e-01 s level: 2 proc_id: 0
# : Time for H_eo_sw_ndpsi 1.120288e-01 s level: 2 proc_id: 0
# : Time for deriv_Sb 7.598881e-02 s level: 2 proc_id: 0
# : Time for deriv_Sb 7.210845e-02 s level: 2 proc_id: 0
# : Time for H_eo_sw_ndpsi 1.095201e-01 s level: 2 proc_id: 0
# : Time for deriv_Sb 7.198362e-02 s level: 2 proc_id: 0
# : Time for deriv_Sb 7.272405e-02 s level: 2 proc_id: 0
# : Time for sw_spinor_eo 2.712106e-02 s level: 2 proc_id: 0
# : Time for sw_spinor_eo 2.744416e-02 s level: 2 proc_id: 0
# : Time for sw_spinor_eo 2.745592e-02 s level: 2 proc_id: 0
# : Time for sw_spinor_eo 2.745045e-02 s level: 2 proc_id: 0
# : Time for Qsw_tau1_sub_const_ndpsi 2.244489e-01 s level: 2 proc_id: 0
# : Time for H_eo_sw_ndpsi 1.092240e-01 s level: 2 proc_id: 0
# : Time for deriv_Sb 7.553661e-02 s level: 2 proc_id: 0
# : Time for deriv_Sb 7.345508e-02 s level: 2 proc_id: 0
# : Time for H_eo_sw_ndpsi 1.085700e-01 s level: 2 proc_id: 0
# : Time for deriv_Sb 7.200438e-02 s level: 2 proc_id: 0
# : Time for deriv_Sb 7.194646e-02 s level: 2 proc_id: 0
# : Time for sw_spinor_eo 2.697295e-02 s level: 2 proc_id: 0
# : Time for sw_spinor_eo 2.726760e-02 s level: 2 proc_id: 0
# : Time for sw_spinor_eo 2.743715e-02 s level: 2 proc_id: 0
# : Time for sw_spinor_eo 2.735236e-02 s level: 2 proc_id: 0
# : Time for Qsw_tau1_sub_const_ndpsi 2.241286e-01 s level: 2 proc_id: 0
# : Time for H_eo_sw_ndpsi 1.098317e-01 s level: 2 proc_id: 0
# : Time for deriv_Sb 7.524991e-02 s level: 2 proc_id: 0
# : Time for deriv_Sb 7.199216e-02 s level: 2 proc_id: 0
# : Time for H_eo_sw_ndpsi 1.098054e-01 s level: 2 proc_id: 0
# : Time for deriv_Sb 7.225873e-02 s level: 2 proc_id: 0
# : Time for deriv_Sb 7.243308e-02 s level: 2 proc_id: 0
# : Time for sw_spinor_eo 2.701527e-02 s level: 2 proc_id: 0
# : Time for sw_spinor_eo 2.743087e-02 s level: 2 proc_id: 0
# : Time for sw_spinor_eo 2.745948e-02 s level: 2 proc_id: 0
# : Time for sw_spinor_eo 2.744659e-02 s level: 2 proc_id: 0
# : Time for Qsw_tau1_sub_const_ndpsi 2.244854e-01 s level: 2 proc_id: 0
# : Time for H_eo_sw_ndpsi 1.103811e-01 s level: 2 proc_id: 0
# : Time for deriv_Sb 7.830236e-02 s level: 2 proc_id: 0
# : Time for deriv_Sb 7.174395e-02 s level: 2 proc_id: 0
# : Time for H_eo_sw_ndpsi 1.107424e-01 s level: 2 proc_id: 0
# : Time for deriv_Sb 7.157294e-02 s level: 2 proc_id: 0
# : Time for deriv_Sb 7.216093e-02 s level: 2 proc_id: 0
# : Time for sw_spinor_eo 2.704141e-02 s level: 2 proc_id: 0
# : Time for sw_spinor_eo 2.729130e-02 s level: 2 proc_id: 0
# : Time for sw_spinor_eo 2.729717e-02 s level: 2 proc_id: 0
# : Time for sw_spinor_eo 2.738000e-02 s level: 2 proc_id: 0
# : Time for Qsw_tau1_sub_const_ndpsi 2.252583e-01 s level: 2 proc_id: 0
# : Time for H_eo_sw_ndpsi 1.094722e-01 s level: 2 proc_id: 0
# : Time for deriv_Sb 7.461486e-02 s level: 2 proc_id: 0
# : Time for deriv_Sb 7.203536e-02 s level: 2 proc_id: 0
# : Time for H_eo_sw_ndpsi 1.106153e-01 s level: 2 proc_id: 0
# : Time for deriv_Sb 7.226443e-02 s level: 2 proc_id: 0
# : Time for deriv_Sb 7.231228e-02 s level: 2 proc_id: 0
# : Time for sw_spinor_eo 2.730029e-02 s level: 2 proc_id: 0
# : Time for sw_spinor_eo 2.732716e-02 s level: 2 proc_id: 0
# : Time for sw_spinor_eo 2.747000e-02 s level: 2 proc_id: 0
# : Time for sw_spinor_eo 2.737936e-02 s level: 2 proc_id: 0
# : Time for sw_deriv_nd 7.219962e-02 s level: 2 proc_id: 0
# : Time for sw_all 1.348470e+00 s level: 2 proc_id: 0
# ndcloverrat1: Time for ndrat_derivative 7.924570e+00 s level: 1 proc_id: 0",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,490,2021-04-07T15:57:34Z,,2022-06-01T18:21:00Z,OPEN,False,52333,1299,143,https://github.com/kostrzewa,extension of the QUDA interface to use QUDA solvers in the HMC,314,[],https://github.com/etmc/tmLQCD/pull/490,https://github.com/Marcogarofalo,16,https://github.com/etmc/tmLQCD/pull/490#issuecomment-924753253,"three build types:

plain
with DDalphaAMG
with QPhiX

For QPhiX, the integration tests don't pass and should be checked manually by someone else by running sample-hmc-qphix-tmcloverdetratio.input and comparing the respective sample-output/hmc-qphix-tmcloverdetratio/* using the master branch of tmLQCD. There might be issues with the machine that the sample-output files were generated on that manifest only in that case. Alternatively, the changes to the quda_work branch might have affected the correct functioning of external solvers. (in fact, I'm almost certain that's the case for DDalphaAMG as discussed here: #460 (comment)).","I try to test these changes on m100 but I got:
ERROR: Gauge force has not been built (rank 0, host r246n18, gauge_force.cu:62 in gaugeForce())
       last kernel called was (name=N4quda14ExtractGhostExINS_5gauge11FloatNOrderIdLi18ELi2ELi18EL20QudaStaggeredPhase_s0ELb1EL19QudaGhostExchange_sn2147483648ELb0EEEEE,volume=8x8x8x12,aux=GPU-offline,vol=6144,stride=3072,precision=8,geometry=4,Nc=3,r=0002,inject,dim3)

I activate quda for the gauge derivative with
BeginMonomial GAUGE
  Type = Iwasaki
  beta = 1.726
  Timescale = 0
  UseExternalLibrary = quda
EndMonomial

is it something wrong I did or it is still a work in progress?",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,490,2021-04-07T15:57:34Z,,2022-06-01T18:21:00Z,OPEN,False,52333,1299,143,https://github.com/kostrzewa,extension of the QUDA interface to use QUDA solvers in the HMC,314,[],https://github.com/etmc/tmLQCD/pull/490,https://github.com/kostrzewa,17,https://github.com/etmc/tmLQCD/pull/490#issuecomment-924761993,"three build types:

plain
with DDalphaAMG
with QPhiX

For QPhiX, the integration tests don't pass and should be checked manually by someone else by running sample-hmc-qphix-tmcloverdetratio.input and comparing the respective sample-output/hmc-qphix-tmcloverdetratio/* using the master branch of tmLQCD. There might be issues with the machine that the sample-output files were generated on that manifest only in that case. Alternatively, the changes to the quda_work branch might have affected the correct functioning of external solvers. (in fact, I'm almost certain that's the case for DDalphaAMG as discussed here: #460 (comment)).","I try to test these changes on m100 but I got:

You need to compile QUDA with the gauge force enabled: -DQUDA_FORCE_GAUGE=ON and need to use the latest commit of lattice/quda#1121",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,491,2021-07-23T15:57:01Z,2021-08-11T09:15:19Z,2021-08-11T09:15:19Z,MERGED,True,1523,120,35,https://github.com/Marcogarofalo,QUDA inverter in the HMC,64,[],https://github.com/etmc/tmLQCD/pull/491,https://github.com/Marcogarofalo,1,https://github.com/etmc/tmLQCD/pull/491,tentative to use quda inverter in hmc.,tentative to use quda inverter in hmc.,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,491,2021-07-23T15:57:01Z,2021-08-11T09:15:19Z,2021-08-11T09:15:19Z,MERGED,True,1523,120,35,https://github.com/Marcogarofalo,QUDA inverter in the HMC,64,[],https://github.com/etmc/tmLQCD/pull/491,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/491#issuecomment-888844056,tentative to use quda inverter in hmc.,"@Marcogarofalo @sunpho84 this now has the first working call from solve_degenerate to the QUDA solvers. I think based on this it should now be mostly a matter of setting parameters properly to also get CLOVERDET running without mass preconditioning (there's an issue with reloading the clover field wihch I never resolved...).
For the determinant ratios

The correct usage of the mu2 and kappa2 parameters for DETRATIO must be ensured
Work in QUDA is required to support CLOVERDETRATIO due to its usage of the rho parameter. This is also required to use mass preconditioning in CLOVERDET.

For the RHMC, an interface to QUDA's multi-shift solver is required and the rescaling that is also done in the QPhiX interface.
Because the reordering routines will have some overhead, support should be added to QUDA to perform the gamma basis change on the device as well as the ability to load and store tmLQCD fields directly. See qcdcode/quda#13",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,491,2021-07-23T15:57:01Z,2021-08-11T09:15:19Z,2021-08-11T09:15:19Z,MERGED,True,1523,120,35,https://github.com/Marcogarofalo,QUDA inverter in the HMC,64,[],https://github.com/etmc/tmLQCD/pull/491,https://github.com/kostrzewa,3,https://github.com/etmc/tmLQCD/pull/491#issuecomment-888845825,tentative to use quda inverter in hmc.,"To use the MG in the HMC, a lot more work is required as one needs to do setup evolution. There's a test in QUDA's test directories which demonstrates how this is done.
It also requires quite a bit of work to figure out the correct parameters to solve the eo-precon problem using direct solves. I think on that point we'll definitely have to talk to Kate.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,491,2021-07-23T15:57:01Z,2021-08-11T09:15:19Z,2021-08-11T09:15:19Z,MERGED,True,1523,120,35,https://github.com/Marcogarofalo,QUDA inverter in the HMC,64,[],https://github.com/etmc/tmLQCD/pull/491,https://github.com/kostrzewa,4,https://github.com/etmc/tmLQCD/pull/491#issuecomment-889419895,tentative to use quda inverter in hmc.,"Just as a note: the MG solver ""works"" in this way, but I'm almost certain that it's not correct to use it like this (in terms of getting a good algorithm). I think the MG-preconditioner actually isn't doing anything to precondition the fine system. The number of outer iterations is currently at the level of a few hundred on a 24c32 lattice with 2kappamu = 0.1, which is simply a very poor GCR ;)",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,491,2021-07-23T15:57:01Z,2021-08-11T09:15:19Z,2021-08-11T09:15:19Z,MERGED,True,1523,120,35,https://github.com/Marcogarofalo,QUDA inverter in the HMC,64,[],https://github.com/etmc/tmLQCD/pull/491,https://github.com/Marcogarofalo,5,https://github.com/etmc/tmLQCD/pull/491#issuecomment-889755245,tentative to use quda inverter in hmc.,"@Marcogarofalo @sunpho84 this now has the first working call from solve_degenerate to the QUDA solvers. I think based on this it should now be mostly a matter of setting parameters properly to also get CLOVERDET running without mass preconditioning (there's an issue with reloading the clover field wihch I never resolved...).

I think that the CLOVERDET monomial works fine in quda. I generate two configurations with sample-hmc-tmcloverdet.input with the modification:
BeginMonomial CLOVERDET
  Timescale = 1
  2KappaMu = 0.01
  rho = 0.0
  CSW = 1.00
  kappa = 0.138
  AcceptancePrecision =  1.e-20
  ForcePrecision = 1.e-12
  Name = cloverdet
  useexternalinverter = quda
  usesloppyprecision = single
#  usecompression = 12
#  solver = CG
EndMonomial

the gauge configurations are the same up to 1e-6 and the only difference in the online measuraments is
diff onlinemeas.000002 ../run_reference/onlinemeas.000002_tmcloverdet
8c8
< 6  1  1  9.685959e-02  -3.568352e-02
---
> 6  1  1  9.685960e-02  -3.568352e-02


For the RHMC, an interface to QUDA's multi-shift solver is required and the rescaling that is also done in the QPhiX interface.
Because the reordering routines will have some overhead, support should be added to QUDA to perform the gamma basis change on the device as well as the ability to load and store tmLQCD fields directly. See qcdcode/quda#13

adding the tmLQCD gamma matrices in quda is not an option?",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,491,2021-07-23T15:57:01Z,2021-08-11T09:15:19Z,2021-08-11T09:15:19Z,MERGED,True,1523,120,35,https://github.com/Marcogarofalo,QUDA inverter in the HMC,64,[],https://github.com/etmc/tmLQCD/pull/491,https://github.com/kostrzewa,6,https://github.com/etmc/tmLQCD/pull/491#issuecomment-889796310,tentative to use quda inverter in hmc.,"I think that the CLOVERDET monomial works fine in quda. I generate two configurations with sample-hmc-tmcloverdet.input with the modification:

Yes, it works. The problem is that for the next trajectory, reloading the clover field hits an issue with the parameter struct which I know about but never resolved because we usually don't do multiple configs per run in analysis.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,491,2021-07-23T15:57:01Z,2021-08-11T09:15:19Z,2021-08-11T09:15:19Z,MERGED,True,1523,120,35,https://github.com/Marcogarofalo,QUDA inverter in the HMC,64,[],https://github.com/etmc/tmLQCD/pull/491,https://github.com/kostrzewa,7,https://github.com/etmc/tmLQCD/pull/491#issuecomment-889799555,tentative to use quda inverter in hmc.,"adding the tmLQCD gamma matrices in quda is not an option?

many parts in QUDA are hard-coded for algorithmic reasons: the DeGrand-Rossi basis is used in the MG (it's very similar to ours) because it's chiral (and this allows the chiralities to be split on the coarse grid) and the UKQCD (non-relativistic) basis is used elsewhere
the trick is to add the correct reorderings to QUDA (all the machinery is there). On the GPU, the reordering before a solve, for example, is a tiny overhead compared to actually sending the field to the device.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,491,2021-07-23T15:57:01Z,2021-08-11T09:15:19Z,2021-08-11T09:15:19Z,MERGED,True,1523,120,35,https://github.com/Marcogarofalo,QUDA inverter in the HMC,64,[],https://github.com/etmc/tmLQCD/pull/491,https://github.com/kostrzewa,8,https://github.com/etmc/tmLQCD/pull/491#issuecomment-895897715,tentative to use quda inverter in hmc.,please note #494 (comment),True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,491,2021-07-23T15:57:01Z,2021-08-11T09:15:19Z,2021-08-11T09:15:19Z,MERGED,True,1523,120,35,https://github.com/Marcogarofalo,QUDA inverter in the HMC,64,[],https://github.com/etmc/tmLQCD/pull/491,https://github.com/urbach,9,https://github.com/etmc/tmLQCD/pull/491#issuecomment-896569352,tentative to use quda inverter in hmc.,Is there anything speaking against merging this in and work directly on tmLQCD:quda_work_add_actions?,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,491,2021-07-23T15:57:01Z,2021-08-11T09:15:19Z,2021-08-11T09:15:19Z,MERGED,True,1523,120,35,https://github.com/Marcogarofalo,QUDA inverter in the HMC,64,[],https://github.com/etmc/tmLQCD/pull/491,https://github.com/kostrzewa,10,https://github.com/etmc/tmLQCD/pull/491#issuecomment-896607565,tentative to use quda inverter in hmc.,"Is there anything speaking against merging this in and work directly on tmLQCD:quda_work_add_actions?

I wanted to give everyone a chance to follow what's happening by looking at the updates in this PR. I would say at this point we should merge it in and continue in a new PR (not in Marco's fork but directly in etmc/tmLQCD)",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,492,2021-07-26T21:42:44Z,2021-07-26T21:43:44Z,2021-07-26T21:43:44Z,MERGED,True,1,1,1,https://github.com/Marcogarofalo,sudo apt-get update && sudo apt-get install ...,1,[],https://github.com/etmc/tmLQCD/pull/492,https://github.com/Marcogarofalo,1,https://github.com/etmc/tmLQCD/pull/492,it should fix the error in the action workflow,it should fix the error in the action workflow,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,492,2021-07-26T21:42:44Z,2021-07-26T21:43:44Z,2021-07-26T21:43:44Z,MERGED,True,1,1,1,https://github.com/Marcogarofalo,sudo apt-get update && sudo apt-get install ...,1,[],https://github.com/etmc/tmLQCD/pull/492,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/492#issuecomment-887047875,it should fix the error in the action workflow,thanks!,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,498,2021-08-10T11:53:29Z,2021-08-10T12:09:44Z,2021-08-10T19:30:16Z,MERGED,True,7,6,2,https://github.com/urbach,Dash in filename,2,[],https://github.com/etmc/tmLQCD/pull/498,https://github.com/urbach,1,https://github.com/etmc/tmLQCD/pull/498,should fix #478,should fix #478,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,499,2021-08-11T11:12:20Z,2021-09-01T09:54:53Z,2021-09-01T09:55:00Z,MERGED,True,251,313,11,https://github.com/kostrzewa,WIP PR to continue the work of getting the HMC to run fully on GPUs,14,[],https://github.com/etmc/tmLQCD/pull/499,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/499,,,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,499,2021-08-11T11:12:20Z,2021-09-01T09:54:53Z,2021-09-01T09:55:00Z,MERGED,True,251,313,11,https://github.com/kostrzewa,WIP PR to continue the work of getting the HMC to run fully on GPUs,14,[],https://github.com/etmc/tmLQCD/pull/499,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/499#issuecomment-897075869,,"Alright folks, the integration tests run through now.
I think we can trust them sufficiently to see if modifications to the gauge derivative function (to enable GPU offload) might break the behaviour in CPU-only runs.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,499,2021-08-11T11:12:20Z,2021-09-01T09:54:53Z,2021-09-01T09:55:00Z,MERGED,True,251,313,11,https://github.com/kostrzewa,WIP PR to continue the work of getting the HMC to run fully on GPUs,14,[],https://github.com/etmc/tmLQCD/pull/499,https://github.com/kostrzewa,3,https://github.com/etmc/tmLQCD/pull/499#issuecomment-910124588,,"Alright, I'll merge this in and then the next big quality-control step that I will do is to run some CVC jobs (using my cvc_depgraph fork) which rely on tmLQCD to interface with QUDA, just to test that we didn't break any expected behaviour.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,500,2021-08-12T09:31:09Z,2021-08-31T09:56:53Z,2021-09-04T06:35:31Z,MERGED,True,236,302,5,https://github.com/kostrzewa,first implementation of MG setup refresh ,3,[],https://github.com/etmc/tmLQCD/pull/500,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/500,"refreshes the setup correctly but then leads to the solve failing with a QUDA error coming from GCR
Will open an issue with the QUDA devs to see what we're doing incorrectly.","refreshes the setup correctly but then leads to the solve failing with a QUDA error coming from GCR
Will open an issue with the QUDA devs to see what we're doing incorrectly.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,500,2021-08-12T09:31:09Z,2021-08-31T09:56:53Z,2021-09-04T06:35:31Z,MERGED,True,236,302,5,https://github.com/kostrzewa,first implementation of MG setup refresh ,3,[],https://github.com/etmc/tmLQCD/pull/500,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/500#issuecomment-897512752,"refreshes the setup correctly but then leads to the solve failing with a QUDA error coming from GCR
Will open an issue with the QUDA devs to see what we're doing incorrectly.","Note that I've also reintroduced TM_QUDA_EXPERIMENTAL which allows this branch to be built against the 1.1.x branch of QUDA (or develop) when this is disabled (--disable-quda_experimental) but of course then does not support 1+1 twisted-clover or twisted-clover mass preconditioning.
To compile it against the feature/ndeg-twisted-clover QUDA branch and with all features, configure should be called with --enable-quda_experimental.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,500,2021-08-12T09:31:09Z,2021-08-31T09:56:53Z,2021-09-04T06:35:31Z,MERGED,True,236,302,5,https://github.com/kostrzewa,first implementation of MG setup refresh ,3,[],https://github.com/etmc/tmLQCD/pull/500,https://github.com/kostrzewa,3,https://github.com/etmc/tmLQCD/pull/500#issuecomment-897605430,"refreshes the setup correctly but then leads to the solve failing with a QUDA error coming from GCR
Will open an issue with the QUDA devs to see what we're doing incorrectly.",QUDA issue asking for help: lattice/quda#1170,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,500,2021-08-12T09:31:09Z,2021-08-31T09:56:53Z,2021-09-04T06:35:31Z,MERGED,True,236,302,5,https://github.com/kostrzewa,first implementation of MG setup refresh ,3,[],https://github.com/etmc/tmLQCD/pull/500,https://github.com/kostrzewa,4,https://github.com/etmc/tmLQCD/pull/500#issuecomment-898373197,"refreshes the setup correctly but then leads to the solve failing with a QUDA error coming from GCR
Will open an issue with the QUDA devs to see what we're doing incorrectly.","This works now. MGRefreshSetupMaxSolverIterations and MGRefreshSetupMDUThreshold are now yet other parameters to be tuned in runs. Note that also MGResetSetupMDUThreshold needs to bet set appropriately (to the trajectory length, for example) to prevent unwanted resets.
Fixes #494",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,500,2021-08-12T09:31:09Z,2021-08-31T09:56:53Z,2021-09-04T06:35:31Z,MERGED,True,236,302,5,https://github.com/kostrzewa,first implementation of MG setup refresh ,3,[],https://github.com/etmc/tmLQCD/pull/500,https://github.com/kostrzewa,5,https://github.com/etmc/tmLQCD/pull/500#issuecomment-898374841,"refreshes the setup correctly but then leads to the solve failing with a QUDA error coming from GCR
Will open an issue with the QUDA devs to see what we're doing incorrectly.","Behaviour along a trajectory (keep in mind this is 2-level MG and still faster than the corresponding CG, at least on my test machine):
GCR: Convergence at 114 iterations, L2 relative residual: iterated = 2.623039e-14, true = 2.623039e-14 (requested = 3.275482e-14)
GCR: Convergence at 62 iterations, L2 relative residual: iterated = 3.251018e-14, true = 3.251018e-14 (requested = 3.270564e-14)
GCR: Convergence at 145 iterations, L2 relative residual: iterated = 3.080900e-13, true = 3.080900e-13 (requested = 3.270564e-13)
GCR: Convergence at 178 iterations, L2 relative residual: iterated = 3.387833e-13, true = 3.387833e-13 (requested = 3.560340e-13)
GCR: Convergence at 58 iterations, L2 relative residual: iterated = 2.449851e-13, true = 2.449851e-13 (requested = 3.275482e-13)
GCR: Convergence at 61 iterations, L2 relative residual: iterated = 2.722033e-13, true = 2.722033e-13 (requested = 3.565397e-13)
GCR: Convergence at 57 iterations, L2 relative residual: iterated = 2.777510e-13, true = 2.777510e-13 (requested = 3.275680e-13)
GCR: Convergence at 61 iterations, L2 relative residual: iterated = 3.175343e-13, true = 3.175343e-13 (requested = 3.565370e-13)
GCR: Convergence at 57 iterations, L2 relative residual: iterated = 2.938131e-13, true = 2.938131e-13 (requested = 3.275665e-13)
GCR: Convergence at 61 iterations, L2 relative residual: iterated = 2.998862e-13, true = 2.998862e-13 (requested = 3.565381e-13)
GCR: Convergence at 58 iterations, L2 relative residual: iterated = 2.756795e-13, true = 2.756795e-13 (requested = 3.275843e-13)
GCR: Convergence at 63 iterations, L2 relative residual: iterated = 2.546070e-13, true = 2.546070e-13 (requested = 3.565364e-13)
GCR: Convergence at 148 iterations, L2 relative residual: iterated = 3.054770e-13, true = 3.054770e-13 (requested = 3.270728e-13)
GCR: Convergence at 177 iterations, L2 relative residual: iterated = 3.075183e-13, true = 3.075183e-13 (requested = 3.560334e-13)
GCR: Convergence at 148 iterations, L2 relative residual: iterated = 3.156105e-13, true = 3.156105e-13 (requested = 3.270727e-13)
GCR: Convergence at 179 iterations, L2 relative residual: iterated = 3.130081e-13, true = 3.130081e-13 (requested = 3.560336e-13)
GCR: Convergence at 63 iterations, L2 relative residual: iterated = 2.702935e-13, true = 2.702935e-13 (requested = 3.276044e-13)
GCR: Convergence at 67 iterations, L2 relative residual: iterated = 3.237049e-13, true = 3.237049e-13 (requested = 3.565343e-13)
GCR: Convergence at 63 iterations, L2 relative residual: iterated = 2.763467e-13, true = 2.763467e-13 (requested = 3.276029e-13)
GCR: Convergence at 67 iterations, L2 relative residual: iterated = 3.152173e-13, true = 3.152173e-13 (requested = 3.565354e-13)
GCR: Convergence at 58 iterations, L2 relative residual: iterated = 2.380761e-13, true = 2.380761e-13 (requested = 3.276222e-13)
GCR: Convergence at 62 iterations, L2 relative residual: iterated = 2.374933e-13, true = 2.374933e-13 (requested = 3.565350e-13)
GCR: Convergence at 149 iterations, L2 relative residual: iterated = 3.181837e-13, true = 3.181837e-13 (requested = 3.270916e-13)
GCR: Convergence at 178 iterations, L2 relative residual: iterated = 3.553751e-13, true = 3.553751e-13 (requested = 3.560336e-13)
GCR: Convergence at 59 iterations, L2 relative residual: iterated = 2.543924e-13, true = 2.543924e-13 (requested = 3.276432e-13)
GCR: Convergence at 62 iterations, L2 relative residual: iterated = 3.405832e-13, true = 3.405832e-13 (requested = 3.565331e-13)
GCR: Convergence at 59 iterations, L2 relative residual: iterated = 2.581603e-13, true = 2.581603e-13 (requested = 3.276417e-13)
GCR: Convergence at 62 iterations, L2 relative residual: iterated = 3.373860e-13, true = 3.373860e-13 (requested = 3.565342e-13)
GCR: Convergence at 60 iterations, L2 relative residual: iterated = 3.153152e-13, true = 3.153152e-13 (requested = 3.276593e-13)
GCR: Convergence at 63 iterations, L2 relative residual: iterated = 3.480639e-13, true = 3.480639e-13 (requested = 3.565331e-13)
GCR: Convergence at 147 iterations, L2 relative residual: iterated = 3.124625e-13, true = 3.124625e-13 (requested = 3.271104e-13)
GCR: Convergence at 181 iterations, L2 relative residual: iterated = 3.450262e-13, true = 3.450262e-13 (requested = 3.560343e-13)
GCR: Convergence at 147 iterations, L2 relative residual: iterated = 3.080868e-13, true = 3.080868e-13 (requested = 3.271103e-13)
GCR: Convergence at 179 iterations, L2 relative residual: iterated = 3.505172e-13, true = 3.505172e-13 (requested = 3.560345e-13)
GCR: Convergence at 65 iterations, L2 relative residual: iterated = 2.560672e-13, true = 2.560672e-13 (requested = 3.276746e-13)
GCR: Convergence at 68 iterations, L2 relative residual: iterated = 3.287401e-13, true = 3.287401e-13 (requested = 3.565310e-13)
GCR: Convergence at 65 iterations, L2 relative residual: iterated = 2.558926e-13, true = 2.558926e-13 (requested = 3.276730e-13)
GCR: Convergence at 68 iterations, L2 relative residual: iterated = 3.251902e-13, true = 3.251902e-13 (requested = 3.565322e-13)
GCR: Convergence at 60 iterations, L2 relative residual: iterated = 2.459156e-13, true = 2.459156e-13 (requested = 3.276810e-13)
GCR: Convergence at 63 iterations, L2 relative residual: iterated = 3.308923e-13, true = 3.308923e-13 (requested = 3.565324e-13)",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,500,2021-08-12T09:31:09Z,2021-08-31T09:56:53Z,2021-09-04T06:35:31Z,MERGED,True,236,302,5,https://github.com/kostrzewa,first implementation of MG setup refresh ,3,[],https://github.com/etmc/tmLQCD/pull/500,https://github.com/kostrzewa,6,https://github.com/etmc/tmLQCD/pull/500#issuecomment-898375261,"refreshes the setup correctly but then leads to the solve failing with a QUDA error coming from GCR
Will open an issue with the QUDA devs to see what we're doing incorrectly.",Might be useful to start updating the documentation at this stage...,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,500,2021-08-12T09:31:09Z,2021-08-31T09:56:53Z,2021-09-04T06:35:31Z,MERGED,True,236,302,5,https://github.com/kostrzewa,first implementation of MG setup refresh ,3,[],https://github.com/etmc/tmLQCD/pull/500,https://github.com/kostrzewa,7,https://github.com/etmc/tmLQCD/pull/500#issuecomment-898889749,"refreshes the setup correctly but then leads to the solve failing with a QUDA error coming from GCR
Will open an issue with the QUDA devs to see what we're doing incorrectly.","This is working well also with a 3-level MG in a simulation of D15.48 on 6 nodes of Juwels Booster (using the 1.1.x branch of QUDA, of course). A trajectory of unit length takes 2200 seconds (without any tuning of the MG or the integrator setup). Out of these 2200 seconds, about 87.5 seconds go into setup evolution and MG parameter updates:

The time spent on updates can be reduced significantly by implementing true parameter updates in updateMultigridQuda's thin_update_only mode.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,500,2021-08-12T09:31:09Z,2021-08-31T09:56:53Z,2021-09-04T06:35:31Z,MERGED,True,236,302,5,https://github.com/kostrzewa,first implementation of MG setup refresh ,3,[],https://github.com/etmc/tmLQCD/pull/500,https://github.com/kostrzewa,8,https://github.com/etmc/tmLQCD/pull/500#issuecomment-898931468,"refreshes the setup correctly but then leads to the solve failing with a QUDA error coming from GCR
Will open an issue with the QUDA devs to see what we're doing incorrectly.","I had forgotten to enable GDR. With it enabled (and ensuring that the job is in one bcell for all cases), trajectory timings and scaling are better:



nds
traj. time (s)
GCR
notes




3
3173
QpQm solve done: 63 iter / 3.27874 secs = 15742.6 Gflops



6
1829
QpQm solve done: 61 iter / 2.16022 secs = 23188.8 Gflops



12
1225
QpQm solve done: 77 iter / 2.439 secs = 32756.6 Gflops
slightly different (worse) MG setup!",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,500,2021-08-12T09:31:09Z,2021-08-31T09:56:53Z,2021-09-04T06:35:31Z,MERGED,True,236,302,5,https://github.com/kostrzewa,first implementation of MG setup refresh ,3,[],https://github.com/etmc/tmLQCD/pull/500,https://github.com/kostrzewa,9,https://github.com/etmc/tmLQCD/pull/500#issuecomment-898940955,"refreshes the setup correctly but then leads to the solve failing with a QUDA error coming from GCR
Will open an issue with the QUDA devs to see what we're doing incorrectly.","The gauge derivative contribution (divided by two because I did two trajectories) is still significant also on Juwels Booster for this lattice size:

although on 12 nodes it contributes only about 10% of the total.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,500,2021-08-12T09:31:09Z,2021-08-31T09:56:53Z,2021-09-04T06:35:31Z,MERGED,True,236,302,5,https://github.com/kostrzewa,first implementation of MG setup refresh ,3,[],https://github.com/etmc/tmLQCD/pull/500,https://github.com/kostrzewa,10,https://github.com/etmc/tmLQCD/pull/500#issuecomment-899035960,"refreshes the setup correctly but then leads to the solve failing with a QUDA error coming from GCR
Will open an issue with the QUDA devs to see what we're doing incorrectly.",Getting deriv_Sb running on the device will also be necessary:,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,500,2021-08-12T09:31:09Z,2021-08-31T09:56:53Z,2021-09-04T06:35:31Z,MERGED,True,236,302,5,https://github.com/kostrzewa,first implementation of MG setup refresh ,3,[],https://github.com/etmc/tmLQCD/pull/500,https://github.com/kostrzewa,11,https://github.com/etmc/tmLQCD/pull/500#issuecomment-908343084,"refreshes the setup correctly but then leads to the solve failing with a QUDA error coming from GCR
Will open an issue with the QUDA devs to see what we're doing incorrectly.",ping @urbach,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,500,2021-08-12T09:31:09Z,2021-08-31T09:56:53Z,2021-09-04T06:35:31Z,MERGED,True,236,302,5,https://github.com/kostrzewa,first implementation of MG setup refresh ,3,[],https://github.com/etmc/tmLQCD/pull/500,https://github.com/kostrzewa,12,https://github.com/etmc/tmLQCD/pull/500#issuecomment-908344635,"refreshes the setup correctly but then leads to the solve failing with a QUDA error coming from GCR
Will open an issue with the QUDA devs to see what we're doing incorrectly.","before any more work is done, this branch should be merged into quda_work_hmc and that should in turn be merged into quda_work_add_actions",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,500,2021-08-12T09:31:09Z,2021-08-31T09:56:53Z,2021-09-04T06:35:31Z,MERGED,True,236,302,5,https://github.com/kostrzewa,first implementation of MG setup refresh ,3,[],https://github.com/etmc/tmLQCD/pull/500,https://github.com/urbach,13,https://github.com/etmc/tmLQCD/pull/500#issuecomment-908404820,"refreshes the setup correctly but then leads to the solve failing with a QUDA error coming from GCR
Will open an issue with the QUDA devs to see what we're doing incorrectly.","4 because we have four dimensions
okay, makes sense!",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,502,2021-08-30T13:36:58Z,2021-09-20T09:30:03Z,2022-01-28T18:41:48Z,MERGED,True,647,274,11,https://github.com/urbach,Split gauge update,39,[],https://github.com/etmc/tmLQCD/pull/502,https://github.com/urbach,1,https://github.com/etmc/tmLQCD/pull/502,some steps towards gauge update on GPUs,some steps towards gauge update on GPUs,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,502,2021-08-30T13:36:58Z,2021-09-20T09:30:03Z,2022-01-28T18:41:48Z,MERGED,True,647,274,11,https://github.com/urbach,Split gauge update,39,[],https://github.com/etmc/tmLQCD/pull/502,https://github.com/urbach,2,https://github.com/etmc/tmLQCD/pull/502#issuecomment-908353118,some steps towards gauge update on GPUs,"@kostrzewa commented on this pull request.



 > @@ -89,6 +89,13 @@ typedef enum ExternalInverter_s {
    QPHIX_INVERTER
  } ExternalInverter;

 +/* enumeration type for the external inverter */

 @urbach does it perhaps make sense to merge this and `ExternalInverter` ?
thought about it, but then decided against it.

ExternalLibrary is going to put the whole GaugeUpdate on the GPU, I
hope. In the other case only the inverter is on the GPU. So, in my
opinion two very different things. However, I can easily change this,
if there are good arguments.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,502,2021-08-30T13:36:58Z,2021-09-20T09:30:03Z,2022-01-28T18:41:48Z,MERGED,True,647,274,11,https://github.com/urbach,Split gauge update,39,[],https://github.com/etmc/tmLQCD/pull/502,https://github.com/kostrzewa,3,https://github.com/etmc/tmLQCD/pull/502#issuecomment-909321032,some steps towards gauge update on GPUs,@urbach should we split the work on this somehow? In principle I have some time available in the next two weeks here or there.,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,502,2021-08-30T13:36:58Z,2021-09-20T09:30:03Z,2022-01-28T18:41:48Z,MERGED,True,647,274,11,https://github.com/urbach,Split gauge update,39,[],https://github.com/etmc/tmLQCD/pull/502,https://github.com/urbach,4,https://github.com/etmc/tmLQCD/pull/502#issuecomment-909996556,some steps towards gauge update on GPUs,"@urbach should we split the work on this somehow? In principle I have some time available in the next two weeks here or there.
sure that would be great. I need to understand first, what the QUDA
routine actually does. Maybe @sbacchio can help there?",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,502,2021-08-30T13:36:58Z,2021-09-20T09:30:03Z,2022-01-28T18:41:48Z,MERGED,True,647,274,11,https://github.com/urbach,Split gauge update,39,[],https://github.com/etmc/tmLQCD/pull/502,https://github.com/sbacchio,5,https://github.com/etmc/tmLQCD/pull/502#issuecomment-910009055,some steps towards gauge update on GPUs,Hi yes I can also help. Do you want to have any discussion on how to distribute it? and what you have in mind for now?,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,502,2021-08-30T13:36:58Z,2021-09-20T09:30:03Z,2022-01-28T18:41:48Z,MERGED,True,647,274,11,https://github.com/urbach,Split gauge update,39,[],https://github.com/etmc/tmLQCD/pull/502,https://github.com/urbach,6,https://github.com/etmc/tmLQCD/pull/502#issuecomment-910171833,some steps towards gauge update on GPUs,"Hi yes I can also help. Do you want to have any discussion on how to distribute it? and what you have in mind for now?
discussion would be good. Bartek has certainly more inside already, for the following steps are needed/unclear

- what exactly does the QUDA function `computeGaugeForceQuda` and how
  to call it
- as far as I understand `computeGaugeForceQuda` updates the momenta
  directly. How to join this with the tmLQCD momenta?
- do we want to start with forking off in `gauge_derivative` first and
  then generalise when it is working, or do we start directly with a
  more general interface function?",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,502,2021-08-30T13:36:58Z,2021-09-20T09:30:03Z,2022-01-28T18:41:48Z,MERGED,True,647,274,11,https://github.com/urbach,Split gauge update,39,[],https://github.com/etmc/tmLQCD/pull/502,https://github.com/urbach,7,https://github.com/etmc/tmLQCD/pull/502#issuecomment-912314858,some steps towards gauge update on GPUs,what about a short meeting today at 1pm or 2pm?,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,502,2021-08-30T13:36:58Z,2021-09-20T09:30:03Z,2022-01-28T18:41:48Z,MERGED,True,647,274,11,https://github.com/urbach,Split gauge update,39,[],https://github.com/etmc/tmLQCD/pull/502,https://github.com/sbacchio,8,https://github.com/etmc/tmLQCD/pull/502#issuecomment-912321474,some steps towards gauge update on GPUs,Both timings would be fine for me,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,502,2021-08-30T13:36:58Z,2021-09-20T09:30:03Z,2022-01-28T18:41:48Z,MERGED,True,647,274,11,https://github.com/urbach,Split gauge update,39,[],https://github.com/etmc/tmLQCD/pull/502,https://github.com/kostrzewa,9,https://github.com/etmc/tmLQCD/pull/502#issuecomment-912332104,some steps towards gauge update on GPUs,Same here although I would slightly prefer 2pm,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,502,2021-08-30T13:36:58Z,2021-09-20T09:30:03Z,2022-01-28T18:41:48Z,MERGED,True,647,274,11,https://github.com/urbach,Split gauge update,39,[],https://github.com/etmc/tmLQCD/pull/502,https://github.com/urbach,10,https://github.com/etmc/tmLQCD/pull/502#issuecomment-912341660,some steps towards gauge update on GPUs,"Same here although I would slightly prefer 2pm
then let's say 2pm.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,502,2021-08-30T13:36:58Z,2021-09-20T09:30:03Z,2022-01-28T18:41:48Z,MERGED,True,647,274,11,https://github.com/urbach,Split gauge update,39,[],https://github.com/etmc/tmLQCD/pull/502,https://github.com/sunpho84,11,https://github.com/etmc/tmLQCD/pull/502#issuecomment-912504992,some steps towards gauge update on GPUs,"Hi

sorry I'm late, where can I join?

On 03/09/2021 10:01, Carsten Urbach wrote:
  > Same here although I would slightly prefer 2pm

 then let's say 2pm.

 
 You are receiving this because you are subscribed to this thread.
 Reply to this email directly, view it on GitHub
 <#502 (comment)>, or
 unsubscribe
 <https://github.com/notifications/unsubscribe-auth/AANAL5SCZCP65XXWLLU4P3TUAB6GRANCNFSM5DB4VOIA>.
 Triage notifications on the go with GitHub Mobile for iOS
 <https://apps.apple.com/app/apple-store/id1477376905?ct=notification-email&mt=8&pt=524675>
 or Android
 <https://play.google.com/store/apps/details?id=com.github.android&referrer=utm_campaign%3Dnotification-email%26utm_medium%3Demail%26utm_source%3Dgithub>.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,502,2021-08-30T13:36:58Z,2021-09-20T09:30:03Z,2022-01-28T18:41:48Z,MERGED,True,647,274,11,https://github.com/urbach,Split gauge update,39,[],https://github.com/etmc/tmLQCD/pull/502,https://github.com/kostrzewa,12,https://github.com/etmc/tmLQCD/pull/502#issuecomment-916319551,some steps towards gauge update on GPUs,Just doing some dummy work to see if I can easily get a working call to the QUDA gauge force set up. Refinements can be made later (such as doing the projection onto the adjoint rep already in QUDA).,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,502,2021-08-30T13:36:58Z,2021-09-20T09:30:03Z,2022-01-28T18:41:48Z,MERGED,True,647,274,11,https://github.com/urbach,Split gauge update,39,[],https://github.com/etmc/tmLQCD/pull/502,https://github.com/sbacchio,13,https://github.com/etmc/tmLQCD/pull/502#issuecomment-916807277,some steps towards gauge update on GPUs,"Hi Bartek, just for not doing the work twice, we are working on it... We have almost everything figured out and at some point early next week we are going to push here the implementation. @pittlerf is working on it with me",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,502,2021-08-30T13:36:58Z,2021-09-20T09:30:03Z,2022-01-28T18:41:48Z,MERGED,True,647,274,11,https://github.com/urbach,Split gauge update,39,[],https://github.com/etmc/tmLQCD/pull/502,https://github.com/kostrzewa,14,https://github.com/etmc/tmLQCD/pull/502#issuecomment-916808700,some steps towards gauge update on GPUs,"Alright, good to know. I'll push my latest additions (which still result in a segfault unfortunately) in a separate branch and you can then force-push here if you'd like.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,502,2021-08-30T13:36:58Z,2021-09-20T09:30:03Z,2022-01-28T18:41:48Z,MERGED,True,647,274,11,https://github.com/urbach,Split gauge update,39,[],https://github.com/etmc/tmLQCD/pull/502,https://github.com/sbacchio,15,https://github.com/etmc/tmLQCD/pull/502#issuecomment-916809366,some steps towards gauge update on GPUs,ok great!,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,502,2021-08-30T13:36:58Z,2021-09-20T09:30:03Z,2022-01-28T18:41:48Z,MERGED,True,647,274,11,https://github.com/urbach,Split gauge update,39,[],https://github.com/etmc/tmLQCD/pull/502,https://github.com/kostrzewa,16,https://github.com/etmc/tmLQCD/pull/502#issuecomment-916809537,some steps towards gauge update on GPUs,Would be good to have some WIP commits to look at if possible.,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,502,2021-08-30T13:36:58Z,2021-09-20T09:30:03Z,2022-01-28T18:41:48Z,MERGED,True,647,274,11,https://github.com/urbach,Split gauge update,39,[],https://github.com/etmc/tmLQCD/pull/502,https://github.com/sbacchio,17,https://github.com/etmc/tmLQCD/pull/502#issuecomment-916812525,some steps towards gauge update on GPUs,"ok we have clean up to do, later today..",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,502,2021-08-30T13:36:58Z,2021-09-20T09:30:03Z,2022-01-28T18:41:48Z,MERGED,True,647,274,11,https://github.com/urbach,Split gauge update,39,[],https://github.com/etmc/tmLQCD/pull/502,https://github.com/kostrzewa,18,https://github.com/etmc/tmLQCD/pull/502#issuecomment-917107352,some steps towards gauge update on GPUs,"no worries, I didn't mean to imply any pressure, I'm just really interested in what you came up with",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,502,2021-08-30T13:36:58Z,2021-09-20T09:30:03Z,2022-01-28T18:41:48Z,MERGED,True,647,274,11,https://github.com/urbach,Split gauge update,39,[],https://github.com/etmc/tmLQCD/pull/502,https://github.com/sbacchio,19,https://github.com/etmc/tmLQCD/pull/502#issuecomment-917903127,some steps towards gauge update on GPUs,"@kostrzewa can we be added to etmc so we can push here directly?
At the moment changes are under https://github.com/pittlerf/tmLQCD/tree/testing_gauge_force_ferenc",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,502,2021-08-30T13:36:58Z,2021-09-20T09:30:03Z,2022-01-28T18:41:48Z,MERGED,True,647,274,11,https://github.com/urbach,Split gauge update,39,[],https://github.com/etmc/tmLQCD/pull/502,https://github.com/kostrzewa,20,https://github.com/etmc/tmLQCD/pull/502#issuecomment-917928455,some steps towards gauge update on GPUs,"@pittlerf was already a member and I've just added you, @sbacchio",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,502,2021-08-30T13:36:58Z,2021-09-20T09:30:03Z,2022-01-28T18:41:48Z,MERGED,True,647,274,11,https://github.com/urbach,Split gauge update,39,[],https://github.com/etmc/tmLQCD/pull/502,https://github.com/kostrzewa,21,https://github.com/etmc/tmLQCD/pull/502#issuecomment-918012300,some steps towards gauge update on GPUs,Thanks @pittlerf and @sbacchio. Needs some minor conflict resolution,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,502,2021-08-30T13:36:58Z,2021-09-20T09:30:03Z,2022-01-28T18:41:48Z,MERGED,True,647,274,11,https://github.com/urbach,Split gauge update,39,[],https://github.com/etmc/tmLQCD/pull/502,https://github.com/sbacchio,22,https://github.com/etmc/tmLQCD/pull/502#issuecomment-918033987,some steps towards gauge update on GPUs,"We checked serially the current implementation and as far as we can tell it matches the gauge_derivative implementation.
Now we have some issue running in parallel.. It dies in the initialization of QUDA.. still have to investigate further",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,502,2021-08-30T13:36:58Z,2021-09-20T09:30:03Z,2022-01-28T18:41:48Z,MERGED,True,647,274,11,https://github.com/urbach,Split gauge update,39,[],https://github.com/etmc/tmLQCD/pull/502,https://github.com/kostrzewa,23,https://github.com/etmc/tmLQCD/pull/502#issuecomment-918045955,some steps towards gauge update on GPUs,"We checked serially the current implementation and as far as we can tell it matches the gauge_derivative implementation. Now we have some issue running in parallel.. It dies in the initialization of QUDA.. still have to investigate further

It (e.g. tmLQCD's hmc_tm or invert or offline_measurement) launches fine in parallel for me, but I have some dH issues when the gauge monomial is on the GPU (which are likely to do with the fact that I forgot to pull in the changes to QUDA that you've made w.r.t. to the double alignment). The lib is recompiling as we speak and I'll test again in a few minutes.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,502,2021-08-30T13:36:58Z,2021-09-20T09:30:03Z,2022-01-28T18:41:48Z,MERGED,True,647,274,11,https://github.com/urbach,Split gauge update,39,[],https://github.com/etmc/tmLQCD/pull/502,https://github.com/kostrzewa,24,https://github.com/etmc/tmLQCD/pull/502#issuecomment-918091090,some steps towards gauge update on GPUs,I'm afraid that also with the additional commits in feature/ndeg-twisted-clover I see large dH in a pure-gauge run using the QUDA version of the gauge force.,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,502,2021-08-30T13:36:58Z,2021-09-20T09:30:03Z,2022-01-28T18:41:48Z,MERGED,True,647,274,11,https://github.com/urbach,Split gauge update,39,[],https://github.com/etmc/tmLQCD/pull/502,https://github.com/sbacchio,25,https://github.com/etmc/tmLQCD/pull/502#issuecomment-918094789,some steps towards gauge update on GPUs,"Thanks for checking, but yes it is still WIP.. so far we did unit tests with our executable.",True,{'THUMBS_UP': ['https://github.com/kostrzewa']}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,502,2021-08-30T13:36:58Z,2021-09-20T09:30:03Z,2022-01-28T18:41:48Z,MERGED,True,647,274,11,https://github.com/urbach,Split gauge update,39,[],https://github.com/etmc/tmLQCD/pull/502,https://github.com/pittlerf,26,https://github.com/etmc/tmLQCD/pull/502#issuecomment-918098521,some steps towards gauge update on GPUs,"We checked serially the current implementation and as far as we can tell it matches the gauge_derivative implementation.
Now we have some issue running in parallel.. It dies in the initialization of QUDA.. still have to investigate further

Now this is solved, for we had problems running interactively, using script it works also parallel",True,{'THUMBS_UP': ['https://github.com/kostrzewa']}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,502,2021-08-30T13:36:58Z,2021-09-20T09:30:03Z,2022-01-28T18:41:48Z,MERGED,True,647,274,11,https://github.com/urbach,Split gauge update,39,[],https://github.com/etmc/tmLQCD/pull/502,https://github.com/pittlerf,27,https://github.com/etmc/tmLQCD/pull/502#issuecomment-918185523,some steps towards gauge update on GPUs,"I'm afraid that also with the additional commits in feature/ndeg-twisted-clover I see large dH in a pure-gauge run using the QUDA version of the gauge force.

Hi Bartek, could we have your input script, we have implemented some checks and would like to try.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,502,2021-08-30T13:36:58Z,2021-09-20T09:30:03Z,2022-01-28T18:41:48Z,MERGED,True,647,274,11,https://github.com/urbach,Split gauge update,39,[],https://github.com/etmc/tmLQCD/pull/502,https://github.com/kostrzewa,28,https://github.com/etmc/tmLQCD/pull/502#issuecomment-918220543,some steps towards gauge update on GPUs,"Sure, I just do something like:
L=16
T=32

nrxprocs = 1
nryprocs = 1
nrzprocs = 1
ompnumthreads = 3

Measurements = 10000
StartCondition = hot

NSave = 500000
ThetaT = 1.0

UseEvenOdd = yes
ReversibilityCheck = no
ReversibilityCheckIntervall = 100
DebugLevel = 2

BeginMonomial GAUGE
  Type = Iwasaki
  beta = 1.9
  Timescale = 0
  UseExternalLibrary = quda
EndMonomial

BeginIntegrator 
  Type0 = 2MN
  IntegrationSteps0 = 100
  Tau = 1.0
  Lambda0 = 0.193
  NumberOfTimescales = 1
EndIntegrator

for pure gauge.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,502,2021-08-30T13:36:58Z,2021-09-20T09:30:03Z,2022-01-28T18:41:48Z,MERGED,True,647,274,11,https://github.com/urbach,Split gauge update,39,[],https://github.com/etmc/tmLQCD/pull/502,https://github.com/pittlerf,29,https://github.com/etmc/tmLQCD/pull/502#issuecomment-918230631,some steps towards gauge update on GPUs,"Sure, I just do something like:
L=16
T=32

nrxprocs = 1
nryprocs = 1
nrzprocs = 1
ompnumthreads = 3

Measurements = 10000
StartCondition = hot

NSave = 500000
ThetaT = 1.0

UseEvenOdd = yes
ReversibilityCheck = no
ReversibilityCheckIntervall = 100
DebugLevel = 2

BeginMonomial GAUGE
  Type = Iwasaki
  beta = 1.9
  Timescale = 0
  UseExternalLibrary = quda
EndMonomial

BeginIntegrator 
  Type0 = 2MN
  IntegrationSteps0 = 100
  Tau = 1.0
  Lambda0 = 0.193
  NumberOfTimescales = 1
EndIntegrator

for pure gauge.

Thank you, we also see the problem, now try to identify the issue",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,502,2021-08-30T13:36:58Z,2021-09-20T09:30:03Z,2022-01-28T18:41:48Z,MERGED,True,647,274,11,https://github.com/urbach,Split gauge update,39,[],https://github.com/etmc/tmLQCD/pull/502,https://github.com/kostrzewa,30,https://github.com/etmc/tmLQCD/pull/502#issuecomment-918237599,some steps towards gauge update on GPUs,"For a full nf=2+1+1 twisted clover run (based on cA211.53.24 but on a 16c32 lattice instead):
NrXProcs = 1
NrYProcs = 1
NrZProcs = 1
ompnumthreads = 6

L=16
T=32

Measurements = 1000
# StartCondition = hot
StartCondition = continue
InitialStoreCounter = readin

2KappaMu = 0.0014846837
2KappaMuBar = 0.0394421632
2KappaEpsBar = 0.0426076209
CSW = 1.74
kappa = 0.1400645

NSave = 500000
ThetaT = 1.0
UseEvenOdd = yes
ReversibilityCheck = no
ReversibilityCheckIntervall = 100
DebugLevel = 2

# StrictResidualCheck = yes
UseRelativePrecision = yes

BeginExternalInverter QUDA
  Pipeline = 10
  gcrNkrylov = 20
  MGCoarseMuFactor = 1.0, 1.0, 20.0
  MGNumberOfLevels = 3
  MGNumberOfVectors = 24, 24, 24
  MGSetupSolver = cg
  MGSetup2KappaMu = 0.0014846837
  MGVerbosity = silent, silent, silent
  MGSetupSolverTolerance = 5e-7, 5e-7
  MGSetupMaxSolverIterations = 1500, 1500
  MGCoarseSolverType = gcr, gcr, cagcr
  MgCoarseSolverTolerance = 0.1, 0.1, 0.1
  MGCoarseMaxSolverIterations = 15, 15, 15
  MGSmootherType = cagcr, cagcr, cagcr
  MGSmootherTolerance = 0.2, 0.2, 0.2
  MGSmootherPreIterations = 0, 0, 0
  MGSmootherPostIterations = 4, 4, 4
  MGBlockSizesX = 4,2
  MGBlockSizesY = 4,2
  MGBlockSizesZ = 4,2
  MGBlockSizesT = 4,2
  MGOverUnderRelaxationFactor = 0.90, 0.90, 0.90
  
  MGResetSetupMDUThreshold = 1.0
  MGRefreshSetupMDUThreshold = 0.06249
  MGRefreshSetupMaxSolverIterations = 15, 15
EndExternalInverter

BeginMeasurement CORRELATORS
  Frequency = 1
EndMeasurement

BeginMonomial GAUGE
  Type = Iwasaki
  beta = 1.726
  Timescale = 0
  UseExternalLibrary = no
EndMonomial

BeginMonomial CLOVERDET
  Timescale = 1
  kappa = 0.1400645
  2KappaMu = 0.0014846837
  CSW = 1.74
  rho = 0.09353509
  MaxSolverIterations = 1000
  AcceptancePrecision =  1.e-21
  ForcePrecision = 1.e-16
  Name = cloverdetlight
  solver = cg
  useexternalinverter = quda
  usesloppyprecision = half
EndMonomial

BeginMonomial CLOVERDETRATIO
  Timescale = 2
  kappa = 0.1400645
  2KappaMu = 0.0014846837
  rho = 0.01039279
  rho2 = 0.09353509
  CSW = 1.74
  MaxSolverIterations = 500
  AcceptancePrecision =  1.e-21
  ForcePrecision = 1.e-18
  Name = cloverdetratio1light
  solver = mg
  useexternalinverter = quda
  usesloppyprecision = single
EndMonomial

BeginMonomial CLOVERDETRATIO
  Timescale = 3
  kappa = 0.1400645
  2KappaMu = 0.0014846837
  rho = 0.0
  rho2 = 0.01039279
  CSW = 1.74
  MaxSolverIterations = 500
  AcceptancePrecision =  1.e-21
  ForcePrecision = 1.e-18
  Name = cloverdetratio2light
  solver = mg
  useexternalinverter = quda
  usesloppyprecision = single
EndMonomial

BeginMonomial NDCLOVERRAT
  Timescale = 1
  kappa = 0.1400645
  CSW = 1.74
  AcceptancePrecision =  1e-21
  ForcePrecision = 1e-16
  StildeMin = 0.0000376
  StildeMax = 4.7
  MaxSolverIterations = 500
  Name = ndcloverrat_0_3
  DegreeOfRational = 10
  Cmin = 0
  Cmax = 3
  ComputeEVFreq = 0
  2Kappamubar = 0.0394421632
  2Kappaepsbar = 0.0426076209
  AddTrLog = yes
  useexternalinverter = quda
  usesloppyprecision = single
  solver = cgmmsnd
EndMonomial

BeginMonomial NDCLOVERRAT
  Timescale = 2
  kappa = 0.1400645
  CSW = 1.74
  MaxSolverIterations = 1000
  AcceptancePrecision =  1e-21
  ForcePrecision = 1e-16
  # lambda_min = 8e-6 (min evals go as low as 1.5e-5), maximal evals are found as high as 0.85 and fluctuate strongly
  StildeMin = 0.0000376
  StildeMax = 4.7
  Name = ndcloverrat_4_6
  DegreeOfRational = 10
  Cmin = 4
  Cmax = 6
  ComputeEVFreq = 0
  2Kappamubar = 0.0394421632
  2Kappaepsbar = 0.0426076209
  AddTrLog = no
  useexternalinverter = quda
  usesloppyprecision = single
  solver = cgmmsnd
EndMonomial

BeginMonomial NDCLOVERRAT
  Timescale = 3
  kappa = 0.1400645
  CSW = 1.74
  AcceptancePrecision =  1e-21
  ForcePrecision = 1e-16
  MaxSolverIterations = 5000
  StildeMin = 0.0000376
  StildeMax = 4.7
  Name = ndcloverrat_7_9
  DegreeOfRational = 10
  Cmin = 7
  Cmax = 9
  ComputeEVFreq = 0
  2Kappamubar = 0.0394421632
  2Kappaepsbar = 0.0426076209
  AddTrLog = no
  useexternalinverter = quda
  usesloppyprecision = single
  solver = cgmmsnd
EndMonomial

BeginMonomial NDCLOVERRATCOR
  Timescale = 1
  kappa = 0.1400645
  CSW = 1.74
  AcceptancePrecision =  1e-20
  ForcePrecision = 1e-16
  MaxSolverIterations = 5000
  StildeMin = 0.0000376
  StildeMax = 4.7
  Name = ndcloverratcor
  DegreeOfRational = 10
  ComputeEVFreq = 0
  2Kappamubar = 0.0394421632
  2Kappaepsbar = 0.0426076209
  useexternalinverter = quda
  usesloppyprecision = double
  solver = cgmmsnd
EndMonomial

BeginIntegrator 
  Type0 = 2MNFG
  Type1 = 2MNFG
  Type2 = 2MNFG
  Type3 = 2MNFG
  IntegrationSteps0 = 1
  IntegrationSteps1 = 1
  IntegrationSteps2 = 1
  IntegrationSteps3 = 8
  Tau = 1.0
  Lambda0 = 0.166667
  Lambda1 = 0.166667
  Lambda2 = 0.166667
  Lambda3 = 0.166667
  NumberOfTimescales = 4
EndIntegrator

BeginOperator CLOVER
  kappa = 0.1400645
  2KappaMu = 0.0014846837
  CSW = 1.74
  UseEvenOdd = no
  SolverPrecision = 1e-20
  MaxSolverIterations = 500
  UseExternalInverter = QUDA
  Solver = mg
  usesloppyprecision = single
EndOperator",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,502,2021-08-30T13:36:58Z,2021-09-20T09:30:03Z,2022-01-28T18:41:48Z,MERGED,True,647,274,11,https://github.com/urbach,Split gauge update,39,[],https://github.com/etmc/tmLQCD/pull/502,https://github.com/pittlerf,31,https://github.com/etmc/tmLQCD/pull/502#issuecomment-919212543,some steps towards gauge update on GPUs,"Sure, I just do something like:
L=16
T=32

nrxprocs = 1
nryprocs = 1
nrzprocs = 1
ompnumthreads = 3

Measurements = 10000
StartCondition = hot

NSave = 500000
ThetaT = 1.0

UseEvenOdd = yes
ReversibilityCheck = no
ReversibilityCheckIntervall = 100
DebugLevel = 2

BeginMonomial GAUGE
  Type = Iwasaki
  beta = 1.9
  Timescale = 0
  UseExternalLibrary = quda
EndMonomial

BeginIntegrator 
  Type0 = 2MN
  IntegrationSteps0 = 100
  Tau = 1.0
  Lambda0 = 0.193
  NumberOfTimescales = 1
EndIntegrator

for pure gauge.

Thank you, we also see the problem, now try to identify the issue

Actually I found an issue with OPENMP threads, will upload the fixing asap",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,502,2021-08-30T13:36:58Z,2021-09-20T09:30:03Z,2022-01-28T18:41:48Z,MERGED,True,647,274,11,https://github.com/urbach,Split gauge update,39,[],https://github.com/etmc/tmLQCD/pull/502,https://github.com/pittlerf,32,https://github.com/etmc/tmLQCD/pull/502#issuecomment-919231745,some steps towards gauge update on GPUs,"Sure, I just do something like:
L=16
T=32

nrxprocs = 1
nryprocs = 1
nrzprocs = 1
ompnumthreads = 3

Measurements = 10000
StartCondition = hot

NSave = 500000
ThetaT = 1.0

UseEvenOdd = yes
ReversibilityCheck = no
ReversibilityCheckIntervall = 100
DebugLevel = 2

BeginMonomial GAUGE
  Type = Iwasaki
  beta = 1.9
  Timescale = 0
  UseExternalLibrary = quda
EndMonomial

BeginIntegrator 
  Type0 = 2MN
  IntegrationSteps0 = 100
  Tau = 1.0
  Lambda0 = 0.193
  NumberOfTimescales = 1
EndIntegrator

for pure gauge.

Thank you, we also see the problem, now try to identify the issue

Actually I found an issue with OPENMP threads, will upload the fixing asap

@kostrzewa I try to push the fixing, but seems that I do not have right to push here:
ERROR: Permission to etmc/tmLQCD.git denied to pittlerf.
fatal: Could not read from remote repository.
Please make sure you have the correct access rights
and the repository exists.
Can you add me writing permissions?
Thanks",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,502,2021-08-30T13:36:58Z,2021-09-20T09:30:03Z,2022-01-28T18:41:48Z,MERGED,True,647,274,11,https://github.com/urbach,Split gauge update,39,[],https://github.com/etmc/tmLQCD/pull/502,https://github.com/kostrzewa,33,https://github.com/etmc/tmLQCD/pull/502#issuecomment-919235760,some steps towards gauge update on GPUs,You should be able to push. How have you configured the remote?,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,502,2021-08-30T13:36:58Z,2021-09-20T09:30:03Z,2022-01-28T18:41:48Z,MERGED,True,647,274,11,https://github.com/urbach,Split gauge update,39,[],https://github.com/etmc/tmLQCD/pull/502,https://github.com/kostrzewa,34,https://github.com/etmc/tmLQCD/pull/502#issuecomment-919237613,some steps towards gauge update on GPUs,"Actually you are right, the base permission was ""read"" for some reason. You should be able to push now.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,502,2021-08-30T13:36:58Z,2021-09-20T09:30:03Z,2022-01-28T18:41:48Z,MERGED,True,647,274,11,https://github.com/urbach,Split gauge update,39,[],https://github.com/etmc/tmLQCD/pull/502,https://github.com/pittlerf,35,https://github.com/etmc/tmLQCD/pull/502#issuecomment-919238209,some steps towards gauge update on GPUs,"Actually you are right, the base permission was ""read"" for some reason. You should be able to push now.

thank you :)",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,502,2021-08-30T13:36:58Z,2021-09-20T09:30:03Z,2022-01-28T18:41:48Z,MERGED,True,647,274,11,https://github.com/urbach,Split gauge update,39,[],https://github.com/etmc/tmLQCD/pull/502,https://github.com/kostrzewa,36,https://github.com/etmc/tmLQCD/pull/502#issuecomment-919247829,some steps towards gauge update on GPUs,"Very nice, the last commit has done the trick. I have a few more instrumentation which I'd like to push if you don't mind and one small performance improvement.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,502,2021-08-30T13:36:58Z,2021-09-20T09:30:03Z,2022-01-28T18:41:48Z,MERGED,True,647,274,11,https://github.com/urbach,Split gauge update,39,[],https://github.com/etmc/tmLQCD/pull/502,https://github.com/pittlerf,37,https://github.com/etmc/tmLQCD/pull/502#issuecomment-919249948,some steps towards gauge update on GPUs,"Very nice, the last commit has done the trick. I have a few more instrumentation which I'd like to push if you don't mind and one small performance improvement.

of coarse, go ahead :)",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,502,2021-08-30T13:36:58Z,2021-09-20T09:30:03Z,2022-01-28T18:41:48Z,MERGED,True,647,274,11,https://github.com/urbach,Split gauge update,39,[],https://github.com/etmc/tmLQCD/pull/502,https://github.com/kostrzewa,38,https://github.com/etmc/tmLQCD/pull/502#issuecomment-919252501,some steps towards gauge update on GPUs,Thanks! It would be great if we could resolve the merge conflict and go over the remaining issues over the next few days.,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,502,2021-08-30T13:36:58Z,2021-09-20T09:30:03Z,2022-01-28T18:41:48Z,MERGED,True,647,274,11,https://github.com/urbach,Split gauge update,39,[],https://github.com/etmc/tmLQCD/pull/502,https://github.com/kostrzewa,39,https://github.com/etmc/tmLQCD/pull/502#issuecomment-919427809,some steps towards gauge update on GPUs,I think I've addressed the points in 6f579c8 and 7f61ee1.,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,502,2021-08-30T13:36:58Z,2021-09-20T09:30:03Z,2022-01-28T18:41:48Z,MERGED,True,647,274,11,https://github.com/urbach,Split gauge update,39,[],https://github.com/etmc/tmLQCD/pull/502,https://github.com/kostrzewa,40,https://github.com/etmc/tmLQCD/pull/502#issuecomment-919446531,some steps towards gauge update on GPUs,"I realised that the merge conflict was rather major so I went ahead and fixed it, it wasn't particularly clear...",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,502,2021-08-30T13:36:58Z,2021-09-20T09:30:03Z,2022-01-28T18:41:48Z,MERGED,True,647,274,11,https://github.com/urbach,Split gauge update,39,[],https://github.com/etmc/tmLQCD/pull/502,https://github.com/pittlerf,41,https://github.com/etmc/tmLQCD/pull/502#issuecomment-919768804,some steps towards gauge update on GPUs,"We added also an online checking tool, which can be used in debugging. Shall we remove the executable test_gauge_derivative then, or we keep it?",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,502,2021-08-30T13:36:58Z,2021-09-20T09:30:03Z,2022-01-28T18:41:48Z,MERGED,True,647,274,11,https://github.com/urbach,Split gauge update,39,[],https://github.com/etmc/tmLQCD/pull/502,https://github.com/kostrzewa,42,https://github.com/etmc/tmLQCD/pull/502#issuecomment-919770987,some steps towards gauge update on GPUs,"We added also an online checking tool, which can be used in debugging. Shall we remove the executable test_gauge_derivative then, or we keep it?

Probably better to remove it since it might break and then we need to take care of it.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,502,2021-08-30T13:36:58Z,2021-09-20T09:30:03Z,2022-01-28T18:41:48Z,MERGED,True,647,274,11,https://github.com/urbach,Split gauge update,39,[],https://github.com/etmc/tmLQCD/pull/502,https://github.com/kostrzewa,43,https://github.com/etmc/tmLQCD/pull/502#issuecomment-922264226,some steps towards gauge update on GPUs,"I've made some small adjustments and think that this can be merged. The gauge derivative regularly produces relative deviations in excess of 1e-10 on my machine, so I've increased the threshold. I don't think that the deviations that I see are worrisome, however as they occur only when the component in question is of a similar size to the threshold. I've made program termination dependent on g_strict_residual_check, which allows one to study the behaviour of the deviations on all lattice sites over mutliple trajectories.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,504,2021-09-13T07:08:20Z,2021-09-13T07:55:02Z,2021-09-13T07:55:02Z,MERGED,True,794,215,5,https://github.com/pittlerf,Testing gauge force in QUDA and tmLQCD Ferenc and Simone,16,[],https://github.com/etmc/tmLQCD/pull/504,https://github.com/pittlerf,1,https://github.com/etmc/tmLQCD/pull/504,,,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,505,2021-09-13T12:43:18Z,2021-09-15T09:50:08Z,2021-09-15T09:50:08Z,CLOSED,False,464,457,33,https://github.com/Marcogarofalo,adding in which monomial the timing is measured,2,[],https://github.com/etmc/tmLQCD/pull/505,https://github.com/Marcogarofalo,1,https://github.com/etmc/tmLQCD/pull/505,I introduce a global char * which is set to the working monomial in the update,I introduce a global char * which is set to the working monomial in the update,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,505,2021-09-13T12:43:18Z,2021-09-15T09:50:08Z,2021-09-15T09:50:08Z,CLOSED,False,464,457,33,https://github.com/Marcogarofalo,adding in which monomial the timing is measured,2,[],https://github.com/etmc/tmLQCD/pull/505,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/505#issuecomment-918155984,I introduce a global char * which is set to the working monomial in the update,"I would prefer not to have yet another global variable to take care of. I think it would be better to add arguments to tm_stopwatch_push, such that it can also print at some debug level (let's say >= 3).",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,505,2021-09-13T12:43:18Z,2021-09-15T09:50:08Z,2021-09-15T09:50:08Z,CLOSED,False,464,457,33,https://github.com/Marcogarofalo,adding in which monomial the timing is measured,2,[],https://github.com/etmc/tmLQCD/pull/505,https://github.com/Marcogarofalo,3,https://github.com/etmc/tmLQCD/pull/505#issuecomment-918160870,I introduce a global char * which is set to the working monomial in the update,"Then how tm_stopwatch_push should know the monomial? The other option that I can think of is to pass the monomial name to all the functions like sw_spinor_eo, sw_all, deriv_Sb, ...
Do you have something better?",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,505,2021-09-13T12:43:18Z,2021-09-15T09:50:08Z,2021-09-15T09:50:08Z,CLOSED,False,464,457,33,https://github.com/Marcogarofalo,adding in which monomial the timing is measured,2,[],https://github.com/etmc/tmLQCD/pull/505,https://github.com/kostrzewa,4,https://github.com/etmc/tmLQCD/pull/505#issuecomment-918166262,I introduce a global char * which is set to the working monomial in the update,"It doesn't need to. The only thing that's required is that inside the monomial functions, one calls:
tm_stopwatch_push(&g_timers, 0, 3, mnl->name, __func__);

which then prints something like
# monomial_name: Entering __func__ level: %d

In the analysis of the output, the timings can then be associated to the correct context by reading monomial_name and the level and the final output of:
tm_stopwatch_pop(&g_timers, 0, 1, mnl->name, __func__);

Anything at levels higher than these two outputs belongs to that context.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,505,2021-09-13T12:43:18Z,2021-09-15T09:50:08Z,2021-09-15T09:50:08Z,CLOSED,False,464,457,33,https://github.com/Marcogarofalo,adding in which monomial the timing is measured,2,[],https://github.com/etmc/tmLQCD/pull/505,https://github.com/kostrzewa,5,https://github.com/etmc/tmLQCD/pull/505#issuecomment-918173628,I introduce a global char * which is set to the working monomial in the update,"Another option is to add an explicit ""context"" information for tm_stopwatch_push. In other words, the g_timers struct contains another array of strings (with some good length each, up to 500 or so).
tm_stopwatch_push(&g_timers, ""context"");

which then stores ""context"" in g_timers.context[level]. This context could be, for example, mnl->name and can even be used recursively in the logic (if the argument is empty, use the context of the previous level).
tm_stopwatch_push(&g_timers, """")

would thus result (internally) in
g_timers.context[level] = g_timers.context[level-1];

And then you can even have the context output at every call.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,505,2021-09-13T12:43:18Z,2021-09-15T09:50:08Z,2021-09-15T09:50:08Z,CLOSED,False,464,457,33,https://github.com/Marcogarofalo,adding in which monomial the timing is measured,2,[],https://github.com/etmc/tmLQCD/pull/505,https://github.com/Marcogarofalo,6,https://github.com/etmc/tmLQCD/pull/505#issuecomment-918176637,I introduce a global char * which is set to the working monomial in the update,"ok, then in a function like
void deriv_Sb(const int ieo, spinor * const l, spinor * const k,
              hamiltonian_field_t * const hf, const double factor) 

I have to add
void deriv_Sb(const int ieo, spinor * const l, spinor * const k,
              hamiltonian_field_t * const hf, const double factor, const char* mnl_name )",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,505,2021-09-13T12:43:18Z,2021-09-15T09:50:08Z,2021-09-15T09:50:08Z,CLOSED,False,464,457,33,https://github.com/Marcogarofalo,adding in which monomial the timing is measured,2,[],https://github.com/etmc/tmLQCD/pull/505,https://github.com/kostrzewa,7,https://github.com/etmc/tmLQCD/pull/505#issuecomment-918190105,I introduce a global char * which is set to the working monomial in the update,"I have to add

No, it's not necessary. When you have:
Entering xxx in yyy, level: n
in the output, anything above this level is automatically within that context. In other words: the deriv_Sb used within the monomial function will automatically have level: n+1 and can be associated correctly at the analysis stage.
In addition, doing what I wrote above in #505 (comment) would even give you the context locally.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,505,2021-09-13T12:43:18Z,2021-09-15T09:50:08Z,2021-09-15T09:50:08Z,CLOSED,False,464,457,33,https://github.com/Marcogarofalo,adding in which monomial the timing is measured,2,[],https://github.com/etmc/tmLQCD/pull/505,https://github.com/kostrzewa,8,https://github.com/etmc/tmLQCD/pull/505#issuecomment-918194991,I introduce a global char * which is set to the working monomial in the update,"To be more concrete, you could have:
tm_stopwatch_push(&g_timers, mnl->name);
at the top of det_derivative, for example. Internally, this sets
timers->context[level] = ""name of the monomial"";
Then, when tm_stopwatch_push(&g_timers, """") is called with an empty context (for example, inside deriv_Sb), this instead sets
timers->context[level] = timers->context[level-1];
which can then be printed as part of the tm_stopwatch_pop inside of the function is question. This way all pops would be instrumented and one would only provide context when this makes sense from a design and/or logical pov.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,505,2021-09-13T12:43:18Z,2021-09-15T09:50:08Z,2021-09-15T09:50:08Z,CLOSED,False,464,457,33,https://github.com/Marcogarofalo,adding in which monomial the timing is measured,2,[],https://github.com/etmc/tmLQCD/pull/505,https://github.com/kostrzewa,9,https://github.com/etmc/tmLQCD/pull/505#issuecomment-919822379,I introduce a global char * which is set to the working monomial in the update,@Marcogarofalo can you push this branch to the etmc repo please?,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,506,2021-09-15T09:49:49Z,2021-09-23T11:43:01Z,2022-01-28T18:41:47Z,MERGED,True,47860,791,48,https://github.com/kostrzewa,fine tune the hierarchichal timing infrastructure,12,[],https://github.com/etmc/tmLQCD/pull/506,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/506,replaces #505,replaces #505,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,506,2021-09-15T09:49:49Z,2021-09-23T11:43:01Z,2022-01-28T18:41:47Z,MERGED,True,47860,791,48,https://github.com/kostrzewa,fine tune the hierarchichal timing infrastructure,12,[],https://github.com/etmc/tmLQCD/pull/506,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/506#issuecomment-922793215,replaces #505,"I'm working on resolving the conflicts and adjusting some of the output, I hope that's okay.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,506,2021-09-15T09:49:49Z,2021-09-23T11:43:01Z,2022-01-28T18:41:47Z,MERGED,True,47860,791,48,https://github.com/kostrzewa,fine tune the hierarchichal timing infrastructure,12,[],https://github.com/etmc/tmLQCD/pull/506,https://github.com/kostrzewa,3,https://github.com/etmc/tmLQCD/pull/506#issuecomment-924807738,replaces #505,"@Marcogarofalo after some thought and some exploration of the data.tree package I've made a change which may or may not be useful. It significantly worsens the ""human readability"" of the output but it allows the output to be fed into a tree-based data structure without any additional logic. In the analysis one can do:
raw_data <- system(paste(""grep \""Time for\"""",
                         args[1],
                         ""| grep level"",
                         ""| awk '{print $2 \"" \"" $5 \"" \"" $6 \"" \"" $9 \"" \"" $12}'""),
                   intern = TRUE)

data <- read.table(text = raw_data, stringsAsFactors = FALSE)
colnames(data) <- c(""prefix"", ""name"", ""time"", ""level"", ""pathString"")

data <- dplyr::mutate(data, pathString = sprintf(""HMC%s"", pathString)) %>%
        dplyr::group_by(pathString) %>%
        dplyr::summarise(time = sum(time),
                         prefix = unique(prefix),
                         name = unique(name),
                         level = unique(level)) %>%
        dplyr::ungroup()

t_tree <- data.tree::as.Node(data)

which produces the following kind of representation:
> print(t_tree, ""time"", ""prefix"")
                                           levelName         time   prefix
1   HMC                                                        NA         
2    --cloverdetlight:cloverdet_heatbath             0.276630200        :
3       --Qp                                        0.039110120        :
4       --random_energy0                            0.066529490        :
5       --sw_invert                                 0.069037080        :
6       --sw_term                                   0.101852300        :
7    --cloverdetratio1light:cloverdetratio_heatbath 34.091170000        :
8       --Qp_zero_pf                                0.031062650        :
9       --random_energy0                            0.069898270        :
10      --solve_degenerate                         33.826040000        :
11         --gamma5                                0.000388851        :
12         --invert_eo_degenerate_quda            33.825010000 TM_QUDA:
13             --invertQuda                       13.625890000 TM_QUDA:
14             --MG_Preconditioner_Setup          20.195500000 TM_QUDA:
15             --reorder_spinor_eo_fromQuda        0.001913765 TM_QUDA:
16             --reorder_spinor_eo_toQuda          0.001588084 TM_QUDA:
17      --sw_invert                                 0.063206370        :
18      --sw_term                                   0.100872100        :
19   --cloverdetratio2light:cloverdetratio_heatbath  2.513363000        :
20      --Qp_zero_pf                                0.036231330        :
21      --random_energy0                            0.067319410        :
22      --solve_degenerate                          2.242713000        :
23         --gamma5                                0.000419401        :
24         --invert_eo_degenerate_quda             2.241631000 TM_QUDA:
25             --invertQuda                        2.238565000 TM_QUDA:
26             --reorder_spinor_eo_fromQuda        0.002052576 TM_QUDA:
27             --reorder_spinor_eo_toQuda          0.000918682 TM_QUDA:
28      --sw_invert                                 0.064552320        :
29      --sw_term                                   0.102456200        :
30   --CLOVERNDTRLOG:clovernd_trlog_heatbath         0.127413100        :
31      --sw_term                                   0.102629100        :
32      --sw_trace_nd                               0.024746180        :
33   --CLOVERTRLOG:clover_trlog_heatbath             0.120279500        :
34      --sw_term                                   0.103729000        :
35      --sw_trace                                  0.013745540        :
36   --GAUGE:gauge_heatbath                          0.067569350        :
37   --ndcloverrat_0_3:init_ndrat_monomial           0.000018670        :
38   --ndcloverrat_0_3:ndrat_heatbath                2.065281000        :
39      --random_energy0                            0.135540100        :
40      --solve_mms_nd_plus                         1.748963000        :
41         --f_assign                              0.252822900        :
42         --solve_mms_nd                          1.496015000        :
43             --gamma5                            0.002436816        :
44             --invert_eo_quda_twoflavour_mshift  1.487874000 TM_QUDA:
45                --invertMultiShiftQuda          0.416139500 TM_QUDA:
46                --loadCloverQuda                0.021220480 TM_QUDA:
47                --loadGaugeQuda                 0.017785190 TM_QUDA:
48                --reorder_gauge_toQuda          0.010681870 TM_QUDA:
49                --reorder_spinor_eo_fromQuda    0.015871140 TM_QUDA:
50                --reorder_spinor_eo_toQuda      0.004953463 TM_QUDA:
51                --twoflavour_input_overhead     0.003285359 TM_QUDA:
52                --twoflavour_output_overhead    0.011988443 TM_QUDA:
53             --mul_r_gamma5                      0.004574722        :
54      --sw_invert_nd                              0.043876160        :
55      --sw_term                                   0.100460900        :
56   --ndcloverrat_4_6:init_ndrat_monomial           0.000009320        :
57   --ndcloverrat_4_6:ndrat_heatbath                2.265935000        :
58      --random_energy0                            0.132979700        :
59      --solve_mms_nd_plus                         1.955709000        :
60         --f_assign                              0.204246400        :
61         --solve_mms_nd                          1.748212000        :
62             --gamma5                            0.002139136        :
63             --invert_eo_quda_twoflavour_mshift  1.742732000 TM_QUDA:
64                --invertMultiShiftQuda          1.715788000 TM_QUDA:
65                --reorder_spinor_eo_fromQuda    0.012970324 TM_QUDA:
66                --reorder_spinor_eo_toQuda      0.003167139 TM_QUDA:
67                --twoflavour_input_overhead     0.001384784 TM_QUDA:
68                --twoflavour_output_overhead    0.005865898 TM_QUDA:
69             --mul_r_gamma5                      0.003186799        :
70      --sw_invert_nd                              0.043966710        :
71      --sw_term                                   0.108778100        :

which can in turn be rather easily plotted as a multi-level barplot (I'll prepare an actual example hopefully by the end of the day). The idea is to be able to plot something like:

What do you think?",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,506,2021-09-15T09:49:49Z,2021-09-23T11:43:01Z,2022-01-28T18:41:47Z,MERGED,True,47860,791,48,https://github.com/kostrzewa,fine tune the hierarchichal timing infrastructure,12,[],https://github.com/etmc/tmLQCD/pull/506,https://github.com/Marcogarofalo,4,https://github.com/etmc/tmLQCD/pull/506#issuecomment-924877649,replaces #505,"I should be able to produce your plots already because I had all the information in the structure I create in my script. However, your approach should solve the problem I had in examining logs of killed jobs and can easily print the tree in a readable format.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,506,2021-09-15T09:49:49Z,2021-09-23T11:43:01Z,2022-01-28T18:41:47Z,MERGED,True,47860,791,48,https://github.com/kostrzewa,fine tune the hierarchichal timing infrastructure,12,[],https://github.com/etmc/tmLQCD/pull/506,https://github.com/kostrzewa,5,https://github.com/etmc/tmLQCD/pull/506#issuecomment-925663563,replaces #505,"Thanks a lot for all the help @Marcogarofalo. Based on this and the ""new"" timing infrastructure, I've introduced the hmc_mk2 profile (profiling/hmc_mk2) which produces this kind of output: profile.pdf",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,506,2021-09-15T09:49:49Z,2021-09-23T11:43:01Z,2022-01-28T18:41:47Z,MERGED,True,47860,791,48,https://github.com/kostrzewa,fine tune the hierarchichal timing infrastructure,12,[],https://github.com/etmc/tmLQCD/pull/506,https://github.com/Marcogarofalo,6,https://github.com/etmc/tmLQCD/pull/506#issuecomment-925745354,replaces #505,I think we can remove profiling/hmc since it will not work with the current log.,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,506,2021-09-15T09:49:49Z,2021-09-23T11:43:01Z,2022-01-28T18:41:47Z,MERGED,True,47860,791,48,https://github.com/kostrzewa,fine tune the hierarchichal timing infrastructure,12,[],https://github.com/etmc/tmLQCD/pull/506,https://github.com/Marcogarofalo,7,https://github.com/etmc/tmLQCD/pull/506#issuecomment-933531333,replaces #505,"in the log there is no information on the gauges subfunctions, it look like:
# : Time for ndrat_derivative 1.016409e+01 s level: 1 proc_id: 0 /HMC/ndcloverrat1:ndrat_derivative
# : Time for gauge_derivative 2.770116e+00 s level: 1 proc_id: 0 /HMC/GAUGE:gauge_derivative
# : Time for update_gauge 4.501816e-01 s level: 1 proc_id: 0 /HMC/update_gauge


these with
# QUDA: QUDA 1.0.0 (git v0.9.0-4675-g16b06db2d-sm_80)

and tmLQCD
Version 5.2.0, commit 20e85af0400ad5f9d7da7aa150caf096b119add9",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,506,2021-09-15T09:49:49Z,2021-09-23T11:43:01Z,2022-01-28T18:41:47Z,MERGED,True,47860,791,48,https://github.com/kostrzewa,fine tune the hierarchichal timing infrastructure,12,[],https://github.com/etmc/tmLQCD/pull/506,https://github.com/kostrzewa,8,https://github.com/etmc/tmLQCD/pull/506#issuecomment-933584535,replaces #505,"If you had UseExternalLibrary = quda set in the GAUGE monomial, you should see something like:
# TM_QUDA: Time for reorder_gauge_toQuda 9.961213e-03 s level: 3 proc_id: 0 /HMC/GAUGE:gauge_derivative/compute_gauge_derivative_quda/reorder_gauge_toQuda
# TM_QUDA: Time for computeGaugeForceQuda 1.246274e-01 s level: 3 proc_id: 0 /HMC/GAUGE:gauge_derivative/compute_gauge_derivative_quda/computeGaugeForceQuda
# TM_QUDA: Time for reorder_mom_fromQuda 3.761868e-02 s level: 3 proc_id: 0 /HMC/GAUGE:gauge_derivative/compute_gauge_derivative_quda/reorder_mom_fromQuda
# TM_QUDA: Time for add_mom_to_derivative 2.790029e-03 s level: 3 proc_id: 0 /HMC/GAUGE:gauge_derivative/compute_gauge_derivative_quda/add_mom_to_derivative
# TM_QUDA: Time for compute_gauge_derivative_quda 1.016333e+00 s level: 2 proc_id: 0 /HMC/GAUGE:gauge_derivative/compute_gauge_derivative_quda
# : Time for gauge_derivative 1.016342e+00 s level: 1 proc_id: 0 /HMC/GAUGE:gauge_derivative
# : Time for update_gauge 5.516283e-02 s level: 1 proc_id: 0 /HMC/update_gauge
# TM_QUDA: Time for reorder_gauge_toQuda 8.106367e-03 s level: 3 proc_id: 0 /HMC/GAUGE:gauge_derivative/compute_gauge_derivative_quda/reorder_gauge_toQuda
# TM_QUDA: Time for computeGaugeForceQuda 1.143318e-01 s level: 3 proc_id: 0 /HMC/GAUGE:gauge_derivative/compute_gauge_derivative_quda/computeGaugeForceQuda
# TM_QUDA: Time for reorder_mom_fromQuda 3.010765e-02 s level: 3 proc_id: 0 /HMC/GAUGE:gauge_derivative/compute_gauge_derivative_quda/reorder_mom_fromQuda
# TM_QUDA: Time for add_mom_to_derivative 2.823760e-03 s level: 3 proc_id: 0 /HMC/GAUGE:gauge_derivative/compute_gauge_derivative_quda/add_mom_to_derivative
# TM_QUDA: Time for compute_gauge_derivative_quda 1.577096e-01 s level: 2 proc_id: 0 /HMC/GAUGE:gauge_derivative/compute_gauge_derivative_quda
# : Time for gauge_derivative 1.577177e-01 s level: 1 proc_id: 0 /HMC/GAUGE:gauge_derivative
# TM_QUDA: Time for reorder_gauge_toQuda 7.356934e-03 s level: 3 proc_id: 0 /HMC/GAUGE:gauge_derivative/compute_gauge_derivative_quda/reorder_gauge_toQuda
# TM_QUDA: Time for computeGaugeForceQuda 1.130398e-01 s level: 3 proc_id: 0 /HMC/GAUGE:gauge_derivative/compute_gauge_derivative_quda/computeGaugeForceQuda
# TM_QUDA: Time for reorder_mom_fromQuda 1.770647e-02 s level: 3 proc_id: 0 /HMC/GAUGE:gauge_derivative/compute_gauge_derivative_quda/reorder_mom_fromQuda
# TM_QUDA: Time for add_mom_to_derivative 2.842720e-03 s level: 3 proc_id: 0 /HMC/GAUGE:gauge_derivative/compute_gauge_derivative_quda/add_mom_to_derivative
# TM_QUDA: Time for compute_gauge_derivative_quda 1.431690e-01 s level: 2 proc_id: 0 /HMC/GAUGE:gauge_derivative/compute_gauge_derivative_quda
# : Time for gauge_derivative 1.431770e-01 s level: 1 proc_id: 0 /HMC/GAUGE:gauge_derivative

and so on.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,506,2021-09-15T09:49:49Z,2021-09-23T11:43:01Z,2022-01-28T18:41:47Z,MERGED,True,47860,791,48,https://github.com/kostrzewa,fine tune the hierarchichal timing infrastructure,12,[],https://github.com/etmc/tmLQCD/pull/506,https://github.com/kostrzewa,9,https://github.com/etmc/tmLQCD/pull/506#issuecomment-933585164,replaces #505,"I think we can remove profiling/hmc since it will not work with the current log.

I wanted to keep the option available to perhaps make it work with the current output as it is in principle more flexible than my implementation.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,506,2021-09-15T09:49:49Z,2021-09-23T11:43:01Z,2022-01-28T18:41:47Z,MERGED,True,47860,791,48,https://github.com/kostrzewa,fine tune the hierarchichal timing infrastructure,12,[],https://github.com/etmc/tmLQCD/pull/506,https://github.com/Marcogarofalo,10,https://github.com/etmc/tmLQCD/pull/506#issuecomment-933594222,replaces #505,"If you had UseExternalLibrary = quda set in the GAUGE monomial, you should see something like:

Sorry  I compile the version that support quda in the GAUGE monomial but I forgot to add it in the input. Should I rerun the benchmark?",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,506,2021-09-15T09:49:49Z,2021-09-23T11:43:01Z,2022-01-28T18:41:47Z,MERGED,True,47860,791,48,https://github.com/kostrzewa,fine tune the hierarchichal timing infrastructure,12,[],https://github.com/etmc/tmLQCD/pull/506,https://github.com/Marcogarofalo,11,https://github.com/etmc/tmLQCD/pull/506#issuecomment-933596346,replaces #505,"I think we can remove profiling/hmc since it will not work with the current log.

I wanted to keep the option available to perhaps make it work with the current output as it is in principle more flexible than my implementation.

ok, I will do the necesssary modifications.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,506,2021-09-15T09:49:49Z,2021-09-23T11:43:01Z,2022-01-28T18:41:47Z,MERGED,True,47860,791,48,https://github.com/kostrzewa,fine tune the hierarchichal timing infrastructure,12,[],https://github.com/etmc/tmLQCD/pull/506,https://github.com/kostrzewa,12,https://github.com/etmc/tmLQCD/pull/506#issuecomment-933598029,replaces #505,"ok, I will do the necesssary modifications.

I was thinking more in terms of ""let's keep them around if we perhaps need them"". If you see an urgent need, please go ahead, but don't feel obliged to invest time into this now.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,509,2021-12-06T19:12:50Z,,2021-12-06T19:12:50Z,OPEN,False,79,7,1,https://github.com/kostrzewa,attempt to modify logic for generating and refreshing the MG setup wh,1,[],https://github.com/etmc/tmLQCD/pull/509,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/509,ich takes into account tm_rho,ich takes into account tm_rho,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,516,2021-12-15T15:43:35Z,2022-05-24T22:08:21Z,2022-05-24T22:08:21Z,MERGED,True,135,63,5,https://github.com/Marcogarofalo,Quda work add actions wflow,10,[],https://github.com/etmc/tmLQCD/pull/516,https://github.com/Marcogarofalo,1,https://github.com/etmc/tmLQCD/pull/516,Wflow is working but the output goes to stdout,Wflow is working but the output goes to stdout,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,516,2021-12-15T15:43:35Z,2022-05-24T22:08:21Z,2022-05-24T22:08:21Z,MERGED,True,135,63,5,https://github.com/Marcogarofalo,Quda work add actions wflow,10,[],https://github.com/etmc/tmLQCD/pull/516,https://github.com/Marcogarofalo,2,https://github.com/etmc/tmLQCD/pull/516#issuecomment-994915844,Wflow is working but the output goes to stdout,"We do not know how to get in tmLQCD the variables like
QudaGaugeObservableParam param computed in the Wflow",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,516,2021-12-15T15:43:35Z,2022-05-24T22:08:21Z,2022-05-24T22:08:21Z,MERGED,True,135,63,5,https://github.com/Marcogarofalo,Quda work add actions wflow,10,[],https://github.com/etmc/tmLQCD/pull/516,https://github.com/Marcogarofalo,3,https://github.com/etmc/tmLQCD/pull/516#issuecomment-1007564806,Wflow is working but the output goes to stdout,"This version works only with
qcdcode/quda@5028c3a",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,516,2021-12-15T15:43:35Z,2022-05-24T22:08:21Z,2022-05-24T22:08:21Z,MERGED,True,135,63,5,https://github.com/Marcogarofalo,Quda work add actions wflow,10,[],https://github.com/etmc/tmLQCD/pull/516,https://github.com/kostrzewa,4,https://github.com/etmc/tmLQCD/pull/516#issuecomment-1007728986,Wflow is working but the output goes to stdout,"@Marcogarofalo thanks. Any changes to QUDA should be based on the develop branch though (which contains all of feature/ndeg-twisted-clover), just to make merging them easier.
Besides this, I think it would be better if the array of QudaGaugeObservableParam were created in tmLQCD (or any other external program using the lib) and passed to performWFlownStep (with the existing behaviour the default when one passes nullptr). In any case I doubt that Kate would accept the use of new and delete.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,516,2021-12-15T15:43:35Z,2022-05-24T22:08:21Z,2022-05-24T22:08:21Z,MERGED,True,135,63,5,https://github.com/Marcogarofalo,Quda work add actions wflow,10,[],https://github.com/etmc/tmLQCD/pull/516,https://github.com/kostrzewa,5,https://github.com/etmc/tmLQCD/pull/516#issuecomment-1007730784,Wflow is working but the output goes to stdout,"Ah, wait, I understand, sorry. Let's try it like this. I think, however, that newQudaGaugeParam should be called on all elements to make sure that any future changes don't break the initialisation.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,516,2021-12-15T15:43:35Z,2022-05-24T22:08:21Z,2022-05-24T22:08:21Z,MERGED,True,135,63,5,https://github.com/Marcogarofalo,Quda work add actions wflow,10,[],https://github.com/etmc/tmLQCD/pull/516,https://github.com/Marcogarofalo,6,https://github.com/etmc/tmLQCD/pull/516#issuecomment-1007755519,Wflow is working but the output goes to stdout,"@Marcogarofalo thanks. Any changes to QUDA should be based on the develop branch though (which contains all of feature/ndeg-twisted-clover), just to make merging them easier.

ok I will try

Besides this, I think it would be better if the array of QudaGaugeObservableParam were created in tmLQCD (or any other external program using the lib). In any case I doubt that Kate would accept the use of new and delete.

Since we could not implement a dofoult value for a parameter in c we add a function in quda performWFlownStep_param that is the one really doing the computation and the old one performWFlownStep
https://github.com/qcdcode/quda/blob/5028c3a8a3ea0655307339893084633de11c76ee/lib/interface_quda.cpp#L5597
is initializing a structure param and calling the other function performWFlownStep_param, so that we do not lose the backward compatibility
should we allocate the memory as we did in tmLQCD?
QudaGaugeObservableParam *param;
  param = (QudaGaugeObservableParam*) malloc(sizeof(QudaGaugeObservableParam) * (n_steps+1));
  for (int i=0;i<n_steps+1; i++){
    param[i] = newQudaGaugeObservableParam();   
    param[i].compute_plaquette = QUDA_BOOLEAN_TRUE;
    param[i].compute_qcharge = QUDA_BOOLEAN_TRUE; 
  }
  ...
  free(param)


Ah, wait, I understand, sorry. Let's try it like this. I think, however, that newQudaGaugeParam should be called on all elements to make sure that any future changes don't break the initialisation.

We add the initialization of the params with newQudaGaugeParam() in a following commit.
https://github.com/qcdcode/quda/blob/5028c3a8a3ea0655307339893084633de11c76ee/lib/interface_quda.cpp#L5602",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,516,2021-12-15T15:43:35Z,2022-05-24T22:08:21Z,2022-05-24T22:08:21Z,MERGED,True,135,63,5,https://github.com/Marcogarofalo,Quda work add actions wflow,10,[],https://github.com/etmc/tmLQCD/pull/516,https://github.com/kostrzewa,7,https://github.com/etmc/tmLQCD/pull/516#issuecomment-1007918623,Wflow is working but the output goes to stdout,"Since we could not implement a dofoult value for a parameter in c we add a function in quda performWFlownStep_param that is the one really doing the computation and the old one performWFlownStep

Yes, I agree. I also agree with the new and delete pairing. I had misinterpreted your intent.
Having said that, the gradient flow (and other gauge smearing functions) in QUDA are quite odd in that they perform the measurements only as informative output. I think your miniminal modification proposal is a good way to see if Kate would be willing to accept further changes to make the output independent of the verbosity setting.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,516,2021-12-15T15:43:35Z,2022-05-24T22:08:21Z,2022-05-24T22:08:21Z,MERGED,True,135,63,5,https://github.com/Marcogarofalo,Quda work add actions wflow,10,[],https://github.com/etmc/tmLQCD/pull/516,https://github.com/kostrzewa,8,https://github.com/etmc/tmLQCD/pull/516#issuecomment-1019915435,Wflow is working but the output goes to stdout,Does this now produce the same output as tmLQCD's gradient flow? (up to the difference in the topological charge at small flow times discussed in lattice/quda#959),True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,516,2021-12-15T15:43:35Z,2022-05-24T22:08:21Z,2022-05-24T22:08:21Z,MERGED,True,135,63,5,https://github.com/Marcogarofalo,Quda work add actions wflow,10,[],https://github.com/etmc/tmLQCD/pull/516,https://github.com/Marcogarofalo,9,https://github.com/etmc/tmLQCD/pull/516#issuecomment-1019943115,Wflow is working but the output goes to stdout,"Does this now produce the same output as tmLQCD's gradient flow? (up to the difference in the topological charge at small flow times discussed in lattice/quda#959)

Yes, also there is the addition of the QUDA output depending on its verbosity.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,516,2021-12-15T15:43:35Z,2022-05-24T22:08:21Z,2022-05-24T22:08:21Z,MERGED,True,135,63,5,https://github.com/Marcogarofalo,Quda work add actions wflow,10,[],https://github.com/etmc/tmLQCD/pull/516,https://github.com/kostrzewa,10,https://github.com/etmc/tmLQCD/pull/516#issuecomment-1019956859,Wflow is working but the output goes to stdout,"Perfect, thank you. I'll merge this in once the corresponding commit lands in QUDA. Alternatively, you can also add some guards to enable/disable this at the configuration stage so being able to compile does not depend on the QUDA-PR being merged.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,516,2021-12-15T15:43:35Z,2022-05-24T22:08:21Z,2022-05-24T22:08:21Z,MERGED,True,135,63,5,https://github.com/Marcogarofalo,Quda work add actions wflow,10,[],https://github.com/etmc/tmLQCD/pull/516,https://github.com/Marcogarofalo,11,https://github.com/etmc/tmLQCD/pull/516#issuecomment-1056874983,Wflow is working but the output goes to stdout,"I did not find I way to get the current verbosity of quda, that is why I add the function _setVerbosityQuda().
@kostrzewa @simone-romiti  do you have something better?",True,{'THUMBS_UP': ['https://github.com/kostrzewa']}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,516,2021-12-15T15:43:35Z,2022-05-24T22:08:21Z,2022-05-24T22:08:21Z,MERGED,True,135,63,5,https://github.com/Marcogarofalo,Quda work add actions wflow,10,[],https://github.com/etmc/tmLQCD/pull/516,https://github.com/simone-romiti,12,https://github.com/etmc/tmLQCD/pull/516#issuecomment-1057009446,Wflow is working but the output goes to stdout,"Maybe I misunderstood, but in quda/lib/util_quda.cpp you find the setVerbosity() and getVerbosity() functions. Is that what you're looking for?",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,516,2021-12-15T15:43:35Z,2022-05-24T22:08:21Z,2022-05-24T22:08:21Z,MERGED,True,135,63,5,https://github.com/Marcogarofalo,Quda work add actions wflow,10,[],https://github.com/etmc/tmLQCD/pull/516,https://github.com/kostrzewa,13,https://github.com/etmc/tmLQCD/pull/516#issuecomment-1057035605,Wflow is working but the output goes to stdout,"There's unfortunately no corresponding C interface function for getVerbosity(). Maybe this is something that we actually need to change in QUDA.
However, looking at our quda_interface.c, we set the general verbosity to QUDA_SUMMARIZE independently of the debug level. At this stage then, I think you can do what you do, although I would explicitly set QUDA_SILENT before the gradient flow if g_debug_level <= 2 and leave it at its default in all other cases.
Sorry, strike that, that was the case before quda_work_add_actions. I think what you're doing is fine.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,516,2021-12-15T15:43:35Z,2022-05-24T22:08:21Z,2022-05-24T22:08:21Z,MERGED,True,135,63,5,https://github.com/Marcogarofalo,Quda work add actions wflow,10,[],https://github.com/etmc/tmLQCD/pull/516,https://github.com/kostrzewa,14,https://github.com/etmc/tmLQCD/pull/516#issuecomment-1113420411,Wflow is working but the output goes to stdout,"@Marcogarofalo sorry for taking so long... I'm now testing this (against the current develop branch which includes your modifications and the subsequent updates by Kate, Dean and Evan).
I see the following issue:
# TM_QUDA: Called _loadGaugeQuda for gauge_id: 0.051000
# TM_QUDA: Theta boundary conditions will be applied to gauge field
# TM_QUDA: Time for reorder_gauge_toQuda 1.085192e-02 s level: 3 proc_id: 0 /HMC/gradient_flow_measurement/compute_WFlow_quda/reorder_gauge_toQuda
# TM_QUDA: Time for loadGaugeQuda 1.625766e-02 s level: 3 proc_id: 0 /HMC/gradient_flow_measurement/compute_WFlow_quda/loadGaugeQuda
performWFlowQuda: ERROR: Invalid field location (rank 1, host cassiopeia, lattice_field.cpp:145 in void quda::LatticeField::create(const quda::LatticeFieldParam&)())
performWFlowQuda:        last kernel called was (name=N4quda9GaugePlaqIdLi3EL21QudaReconstructType_s18EEE,volume=16x16x16x20,aux=GPU-offline,nParity=2,vol=81920stride=40960precision=8geometry=4Nc=3r=0002)
performWFlowQuda: ERROR: Invalid field location (rank 0, host cassiopeia, lattice_field.cpp:145 in void quda::LatticeField::create(const quda::LatticeFieldParam&)())
performWFlowQuda:        last kernel called was (name=N4quda9GaugePlaqIdLi3EL21QudaReconstructType_s18EEE,volume=16x16x16x20,aux=GPU-offline,nParity=2,vol=81920stride=40960precision=8geometry=4Nc=3r=0002)
--------------------------------------------------------------------------

did you encounter this by any chance? I'll investigate until the end of the day now.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,516,2021-12-15T15:43:35Z,2022-05-24T22:08:21Z,2022-05-24T22:08:21Z,MERGED,True,135,63,5,https://github.com/Marcogarofalo,Quda work add actions wflow,10,[],https://github.com/etmc/tmLQCD/pull/516,https://github.com/kostrzewa,15,https://github.com/etmc/tmLQCD/pull/516#issuecomment-1113580125,Wflow is working but the output goes to stdout,It appears to be a regression in QUDA. I'll git-bisect and submit an issue.,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,516,2021-12-15T15:43:35Z,2022-05-24T22:08:21Z,2022-05-24T22:08:21Z,MERGED,True,135,63,5,https://github.com/Marcogarofalo,Quda work add actions wflow,10,[],https://github.com/etmc/tmLQCD/pull/516,https://github.com/kostrzewa,16,https://github.com/etmc/tmLQCD/pull/516#issuecomment-1136477890,Wflow is working but the output goes to stdout,Works now thanks to dbc1e288315201f35f0069c60e4f936daad54d22 in QUDA.,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,518,2022-01-21T10:10:45Z,2022-01-21T11:55:55Z,2022-01-28T18:41:44Z,MERGED,True,39,0,4,https://github.com/kostrzewa,"expose 'QUDA_ENABLE_[DEVICE,PINNED]_MEMORY_POOL' via new parameters '",2,[],https://github.com/etmc/tmLQCD/pull/518,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/518,EnableDeviceMemoryPool' and 'EnablePinnedMemoryPool' and disable these by default to save device / host memory,EnableDeviceMemoryPool' and 'EnablePinnedMemoryPool' and disable these by default to save device / host memory,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,518,2022-01-21T10:10:45Z,2022-01-21T11:55:55Z,2022-01-28T18:41:44Z,MERGED,True,39,0,4,https://github.com/kostrzewa,"expose 'QUDA_ENABLE_[DEVICE,PINNED]_MEMORY_POOL' via new parameters '",2,[],https://github.com/etmc/tmLQCD/pull/518,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/518#issuecomment-1018371023,EnableDeviceMemoryPool' and 'EnablePinnedMemoryPool' and disable these by default to save device / host memory,@Marcogarofalo @pittlerf @sbacchio  FYI,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,519,2022-01-28T15:17:06Z,2022-02-23T15:28:08Z,2022-02-23T15:28:08Z,CLOSED,False,5,2,1,https://github.com/simone-romiti,Quda work add actions bug measurements,2,[],https://github.com/etmc/tmLQCD/pull/519,https://github.com/simone-romiti,1,https://github.com/etmc/tmLQCD/pull/519,"quda was not working with the following input (2kappaMu not specified)
BeginOperator CLOVER
  CSW = 1.76
  kappa = 0.15
  SolverPrecision = 1e-14
  MaxSolverIterations = 1000
  solver = mg
  UseEvenOdd = yes
  useexternalinverter = quda
  usesloppyprecision = single  
EndOperator

BeginMeasurement CORRELATORS
  MaxSolverIterations = 1000
  Frequency = 1
EndMeasurement","quda was not working with the following input (2kappaMu not specified)
BeginOperator CLOVER
  CSW = 1.76
  kappa = 0.15
  SolverPrecision = 1e-14
  MaxSolverIterations = 1000
  solver = mg
  UseEvenOdd = yes
  useexternalinverter = quda
  usesloppyprecision = single  
EndOperator

BeginMeasurement CORRELATORS
  MaxSolverIterations = 1000
  Frequency = 1
EndMeasurement",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,519,2022-01-28T15:17:06Z,2022-02-23T15:28:08Z,2022-02-23T15:28:08Z,CLOSED,False,5,2,1,https://github.com/simone-romiti,Quda work add actions bug measurements,2,[],https://github.com/etmc/tmLQCD/pull/519,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/519#issuecomment-1024509512,"quda was not working with the following input (2kappaMu not specified)
BeginOperator CLOVER
  CSW = 1.76
  kappa = 0.15
  SolverPrecision = 1e-14
  MaxSolverIterations = 1000
  solver = mg
  UseEvenOdd = yes
  useexternalinverter = quda
  usesloppyprecision = single  
EndOperator

BeginMeasurement CORRELATORS
  MaxSolverIterations = 1000
  Frequency = 1
EndMeasurement",Note that operator CLOVER with 2kappamu = 0.0 implies QUDA_TWIST_NO for the QUDA operator.,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,519,2022-01-28T15:17:06Z,2022-02-23T15:28:08Z,2022-02-23T15:28:08Z,CLOSED,False,5,2,1,https://github.com/simone-romiti,Quda work add actions bug measurements,2,[],https://github.com/etmc/tmLQCD/pull/519,https://github.com/Marcogarofalo,3,https://github.com/etmc/tmLQCD/pull/519#issuecomment-1024527741,"quda was not working with the following input (2kappaMu not specified)
BeginOperator CLOVER
  CSW = 1.76
  kappa = 0.15
  SolverPrecision = 1e-14
  MaxSolverIterations = 1000
  solver = mg
  UseEvenOdd = yes
  useexternalinverter = quda
  usesloppyprecision = single  
EndOperator

BeginMeasurement CORRELATORS
  MaxSolverIterations = 1000
  Frequency = 1
EndMeasurement","with QUDA_TWIST_NO quda is complaining
MG level 0 (GPU): ERROR: twist flavors do not match: 1 0 (rank 0, host lnode15.cluster.hiskp, color_spinor_field.cpp:707 in checkField())
MG level 0 (GPU):        last kernel called was (name=N4quda15CopyColorSpinorILi4ELi3ENS_11colorspinor11FloatNOrderIfLi4ELi3ELi4ELb0ELb0EEENS2_IdLi4ELi3ELi2ELb0ELb0EEESt5tupleIJRNS_16ColorSpinorFieldERKS6_19QudaFieldLocation_sPfPKdEEEE,volume=4x8x8x8,aux=GPU-offline,vol=2048,precision=8,order=2,Ns=4,Nc=3vol=2048,precision=4,order=4,Ns=4,Nc=3,PreserveBasis)

instead with QUDA_TWIST_SINGLET is working fine and the online measurements are the same of the host version.
Probably QUDA  is complaining because it is using an old MG setup with mu>0",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,519,2022-01-28T15:17:06Z,2022-02-23T15:28:08Z,2022-02-23T15:28:08Z,CLOSED,False,5,2,1,https://github.com/simone-romiti,Quda work add actions bug measurements,2,[],https://github.com/etmc/tmLQCD/pull/519,https://github.com/kostrzewa,4,https://github.com/etmc/tmLQCD/pull/519#issuecomment-1024553962,"quda was not working with the following input (2kappaMu not specified)
BeginOperator CLOVER
  CSW = 1.76
  kappa = 0.15
  SolverPrecision = 1e-14
  MaxSolverIterations = 1000
  solver = mg
  UseEvenOdd = yes
  useexternalinverter = quda
  usesloppyprecision = single  
EndOperator

BeginMeasurement CORRELATORS
  MaxSolverIterations = 1000
  Frequency = 1
EndMeasurement","with QUDA_TWIST_NO quda is complaining
Probably QUDA is complaining because it is using an old MG setup with mu>0

okay, but then we need to separate the cases:

pure Wilson clover HMC with Wilson clover online measurements
twisted mass clover HMC with twisted mass clover measurements

Any other combination does not make sense, although it is possible from the point of view of parameters.
Ideally, the MG setup would be forced to be reset when the operator type changes between HMC and online measurement (i.e., when we're running twisted clover HMC and perform a Wilson clover measurement or vice versa).
What I observed, however, is that twisted clover HMC + twisted clover online measurements don't work with the MG, is that correct?",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,519,2022-01-28T15:17:06Z,2022-02-23T15:28:08Z,2022-02-23T15:28:08Z,CLOSED,False,5,2,1,https://github.com/simone-romiti,Quda work add actions bug measurements,2,[],https://github.com/etmc/tmLQCD/pull/519,https://github.com/Marcogarofalo,5,https://github.com/etmc/tmLQCD/pull/519#issuecomment-1024582406,"quda was not working with the following input (2kappaMu not specified)
BeginOperator CLOVER
  CSW = 1.76
  kappa = 0.15
  SolverPrecision = 1e-14
  MaxSolverIterations = 1000
  solver = mg
  UseEvenOdd = yes
  useexternalinverter = quda
  usesloppyprecision = single  
EndOperator

BeginMeasurement CORRELATORS
  MaxSolverIterations = 1000
  Frequency = 1
EndMeasurement","What I observed, however, is that twisted clover HMC + twisted clover online measurements don't work with the MG, is that correct?

I did not see any problem with this combination, more specific
BeginOperator CLOVER
  CSW = 1.76
  kappa = 0.15
  2kappamu = 0.0015846837
  SolverPrecision = 1e-14
  MaxSolverIterations = 1000
  solver = mg
  UseEvenOdd = yes
  useexternalinverter = quda
  usesloppyprecision = single
EndOperator

BeginMeasurement CORRELATORS
  MaxSolverIterations = 1000
  Frequency = 1
EndMeasurement



BeginMonomial CLOVERDET
  Timescale = 1
  kappa = 0.15
  2KappaMu = 0.0015846837
  CSW = 1.74
  rho = 0.09353509
  MaxSolverIterations = 1000
  AcceptancePrecision =  1.e-19
  ForcePrecision = 1.e-15
  Name = cloverdetlight
  solver = mg
  useexternalinverter = quda
  usesloppyprecision = single
EndMonomial

BeginMonomial CLOVERDETRATIO
  Timescale = 1
  kappa = 0.15
  2KappaMu = 0.0015846837
  rho = 0.01039279
  rho2 = 0.09353509
  CSW = 1.74
  MaxSolverIterations = 1000
  AcceptancePrecision =  1.e-19
  ForcePrecision = 1.e-16
  Name = cloverdetratio1light
  solver = mg
  useexternalinverter = quda
  usesloppyprecision = single
EndMonomial",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,519,2022-01-28T15:17:06Z,2022-02-23T15:28:08Z,2022-02-23T15:28:08Z,CLOSED,False,5,2,1,https://github.com/simone-romiti,Quda work add actions bug measurements,2,[],https://github.com/etmc/tmLQCD/pull/519,https://github.com/kostrzewa,6,https://github.com/etmc/tmLQCD/pull/519#issuecomment-1024590744,"quda was not working with the following input (2kappaMu not specified)
BeginOperator CLOVER
  CSW = 1.76
  kappa = 0.15
  SolverPrecision = 1e-14
  MaxSolverIterations = 1000
  solver = mg
  UseEvenOdd = yes
  useexternalinverter = quda
  usesloppyprecision = single  
EndOperator

BeginMeasurement CORRELATORS
  MaxSolverIterations = 1000
  Frequency = 1
EndMeasurement","I did not see any problem with this combination, more specific

The residual check after the online measurement comes out correctly?
[...]
# Inversion done in N iterations, squared residue = 3.419632e+04!
# Inversion done in X sec. 
# : Time for correlators_measurement X s level: 1 proc_id: 0 /HMC/correlators_measurement
[...]",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,519,2022-01-28T15:17:06Z,2022-02-23T15:28:08Z,2022-02-23T15:28:08Z,CLOSED,False,5,2,1,https://github.com/simone-romiti,Quda work add actions bug measurements,2,[],https://github.com/etmc/tmLQCD/pull/519,https://github.com/kostrzewa,7,https://github.com/etmc/tmLQCD/pull/519#issuecomment-1024591535,"quda was not working with the following input (2kappaMu not specified)
BeginOperator CLOVER
  CSW = 1.76
  kappa = 0.15
  SolverPrecision = 1e-14
  MaxSolverIterations = 1000
  solver = mg
  UseEvenOdd = yes
  useexternalinverter = quda
  usesloppyprecision = single  
EndOperator

BeginMeasurement CORRELATORS
  MaxSolverIterations = 1000
  Frequency = 1
EndMeasurement",About your input file: make sure that you have the same value of csw everywhere. I think the setup will always be rebuilt when you don't.,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,521,2022-02-06T08:53:32Z,2022-02-06T15:57:19Z,2022-02-07T09:28:03Z,MERGED,True,66,17,7,https://github.com/kostrzewa,re-expose refinenement precision,1,[],https://github.com/etmc/tmLQCD/pull/521,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/521,"Add back support for writing something like
BeginMonomial NDCLOVERRAT
  Timescale = 1
  kappa = 0.1400645
  CSW = 1.74
  AcceptancePrecision =  1e-21
  ForcePrecision = 1e-16
  StildeMin = 0.0000376
  StildeMax = 4.7
  MaxSolverIterations = 500
  Name = ndcloverrat_0_3
  DegreeOfRational = 10
  Cmin = 0
  Cmax = 3
  ComputeEVFreq = 0
  2Kappamubar = 0.0394421632
  2Kappaepsbar = 0.0426076209
  AddTrLog = yes
  UseExternalInverter = quda
  UseSloppyPrecision = single
  RefinementPrecision = half    # <- refinement precision                                                                                                                                                                                                                                                
  solver = cgmmsnd
EndMonomial

which allows the multi-shift solver to run up to single precision and then refines any unconverged shifts using double-half mixed CG, leading to another 20-25% improvement in time to solution for those monomials.","Add back support for writing something like
BeginMonomial NDCLOVERRAT
  Timescale = 1
  kappa = 0.1400645
  CSW = 1.74
  AcceptancePrecision =  1e-21
  ForcePrecision = 1e-16
  StildeMin = 0.0000376
  StildeMax = 4.7
  MaxSolverIterations = 500
  Name = ndcloverrat_0_3
  DegreeOfRational = 10
  Cmin = 0
  Cmax = 3
  ComputeEVFreq = 0
  2Kappamubar = 0.0394421632
  2Kappaepsbar = 0.0426076209
  AddTrLog = yes
  UseExternalInverter = quda
  UseSloppyPrecision = single
  RefinementPrecision = half    # <- refinement precision                                                                                                                                                                                                                                                
  solver = cgmmsnd
EndMonomial

which allows the multi-shift solver to run up to single precision and then refines any unconverged shifts using double-half mixed CG, leading to another 20-25% improvement in time to solution for those monomials.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,521,2022-02-06T08:53:32Z,2022-02-06T15:57:19Z,2022-02-07T09:28:03Z,MERGED,True,66,17,7,https://github.com/kostrzewa,re-expose refinenement precision,1,[],https://github.com/etmc/tmLQCD/pull/521,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/521#issuecomment-1030779728,"Add back support for writing something like
BeginMonomial NDCLOVERRAT
  Timescale = 1
  kappa = 0.1400645
  CSW = 1.74
  AcceptancePrecision =  1e-21
  ForcePrecision = 1e-16
  StildeMin = 0.0000376
  StildeMax = 4.7
  MaxSolverIterations = 500
  Name = ndcloverrat_0_3
  DegreeOfRational = 10
  Cmin = 0
  Cmax = 3
  ComputeEVFreq = 0
  2Kappamubar = 0.0394421632
  2Kappaepsbar = 0.0426076209
  AddTrLog = yes
  UseExternalInverter = quda
  UseSloppyPrecision = single
  RefinementPrecision = half    # <- refinement precision                                                                                                                                                                                                                                                
  solver = cgmmsnd
EndMonomial

which allows the multi-shift solver to run up to single precision and then refines any unconverged shifts using double-half mixed CG, leading to another 20-25% improvement in time to solution for those monomials.",@simone-romiti can you give this a test run to see if I didn't miss anything?,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,521,2022-02-06T08:53:32Z,2022-02-06T15:57:19Z,2022-02-07T09:28:03Z,MERGED,True,66,17,7,https://github.com/kostrzewa,re-expose refinenement precision,1,[],https://github.com/etmc/tmLQCD/pull/521,https://github.com/kostrzewa,3,https://github.com/etmc/tmLQCD/pull/521#issuecomment-1031217016,"Add back support for writing something like
BeginMonomial NDCLOVERRAT
  Timescale = 1
  kappa = 0.1400645
  CSW = 1.74
  AcceptancePrecision =  1e-21
  ForcePrecision = 1e-16
  StildeMin = 0.0000376
  StildeMax = 4.7
  MaxSolverIterations = 500
  Name = ndcloverrat_0_3
  DegreeOfRational = 10
  Cmin = 0
  Cmax = 3
  ComputeEVFreq = 0
  2Kappamubar = 0.0394421632
  2Kappaepsbar = 0.0426076209
  AddTrLog = yes
  UseExternalInverter = quda
  UseSloppyPrecision = single
  RefinementPrecision = half    # <- refinement precision                                                                                                                                                                                                                                                
  solver = cgmmsnd
EndMonomial

which allows the multi-shift solver to run up to single precision and then refines any unconverged shifts using double-half mixed CG, leading to another 20-25% improvement in time to solution for those monomials.",@simone-romiti can you explain which parts of this you tested before merging? Did you try different combinations of sloppy and reconstruct precisions?,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,521,2022-02-06T08:53:32Z,2022-02-06T15:57:19Z,2022-02-07T09:28:03Z,MERGED,True,66,17,7,https://github.com/kostrzewa,re-expose refinenement precision,1,[],https://github.com/etmc/tmLQCD/pull/521,https://github.com/simone-romiti,4,https://github.com/etmc/tmLQCD/pull/521#issuecomment-1031233878,"Add back support for writing something like
BeginMonomial NDCLOVERRAT
  Timescale = 1
  kappa = 0.1400645
  CSW = 1.74
  AcceptancePrecision =  1e-21
  ForcePrecision = 1e-16
  StildeMin = 0.0000376
  StildeMax = 4.7
  MaxSolverIterations = 500
  Name = ndcloverrat_0_3
  DegreeOfRational = 10
  Cmin = 0
  Cmax = 3
  ComputeEVFreq = 0
  2Kappamubar = 0.0394421632
  2Kappaepsbar = 0.0426076209
  AddTrLog = yes
  UseExternalInverter = quda
  UseSloppyPrecision = single
  RefinementPrecision = half    # <- refinement precision                                                                                                                                                                                                                                                
  solver = cgmmsnd
EndMonomial

which allows the multi-shift solver to run up to single precision and then refines any unconverged shifts using double-half mixed CG, leading to another 20-25% improvement in time to solution for those monomials.","I tried the 9 combinations with A, B = double,single,half in the input file:

...
UseSloppyPrecision = A
RefinementPrecision = B    # <- refinement precision
...",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,521,2022-02-06T08:53:32Z,2022-02-06T15:57:19Z,2022-02-07T09:28:03Z,MERGED,True,66,17,7,https://github.com/kostrzewa,re-expose refinenement precision,1,[],https://github.com/etmc/tmLQCD/pull/521,https://github.com/kostrzewa,5,https://github.com/etmc/tmLQCD/pull/521#issuecomment-1031249415,"Add back support for writing something like
BeginMonomial NDCLOVERRAT
  Timescale = 1
  kappa = 0.1400645
  CSW = 1.74
  AcceptancePrecision =  1e-21
  ForcePrecision = 1e-16
  StildeMin = 0.0000376
  StildeMax = 4.7
  MaxSolverIterations = 500
  Name = ndcloverrat_0_3
  DegreeOfRational = 10
  Cmin = 0
  Cmax = 3
  ComputeEVFreq = 0
  2Kappamubar = 0.0394421632
  2Kappaepsbar = 0.0426076209
  AddTrLog = yes
  UseExternalInverter = quda
  UseSloppyPrecision = single
  RefinementPrecision = half    # <- refinement precision                                                                                                                                                                                                                                                
  solver = cgmmsnd
EndMonomial

which allows the multi-shift solver to run up to single precision and then refines any unconverged shifts using double-half mixed CG, leading to another 20-25% improvement in time to solution for those monomials.","Perfect, thank you!",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,522,2022-02-08T13:24:31Z,2022-02-08T13:31:41Z,2022-02-08T17:24:40Z,MERGED,True,1,0,1,https://github.com/sunpho84,Ensure gauge_id member is initialized when the gauge_status is created,2,[],https://github.com/etmc/tmLQCD/pull/522,https://github.com/sunpho84,1,https://github.com/etmc/tmLQCD/pull/522,"I'm in the process o fixing a nasty segmentation fault that arises in random places around. With the help of @Marcogarofalo
I've managed to run the code under valgrind, and I'm proceeding to fix each complain in turn, this is the first one
==20258== Use of uninitialised value of size 8
==20258==    at 0xBD369EC: __printf_fp_l (in /usr/lib64/power9/libc-2.28.so)
==20258==    by 0x1FFF007AAF: ???
==20258==    by 0xBD32623: printf_positional (in /usr/lib64/power9/libc-2.28.so)
==20258==    by 0xBD33BDF: vfprintf@@GLIBC_2.17 (in /usr/lib64/power9/libc-2.28.so)
==20258==    by 0x10045397: vprintf (stdio.h:41)
==20258==    by 0x10045397: tm_debug_printf (tm_debug_printf.c:35)
==20258==    by 0x100481F7: _loadGaugeQuda (quda_interface.c:565)
==20258==    by 0x1004BDB3: invert_eo_degenerate_quda (quda_interface.c:2062)
==20258==    by 0x1013FB13: solve_degenerate (monomial_solve.c:127)
==20258==    by 0x100775A7: cloverdetratio_heatbath (cloverdetratio_monomial.c:287)
==20258==    by 0x100366A3: update_tm (update_tm.c:130)
==20258==    by 0x1000758F: main (hmc_tm.c:402)
==20258==  Uninitialised value was created by a stack allocation
==20258==    at 0x10150A18: init_global_states (init_global_states.c:25)

My understanding is that the gauge_id is not set to zero right where it should (at the creation of the state), but a complicated mechanism is in place.  The gauge_id is referred in several places (some of clearly harmless, some of which possibly harmful)","I'm in the process o fixing a nasty segmentation fault that arises in random places around. With the help of @Marcogarofalo
I've managed to run the code under valgrind, and I'm proceeding to fix each complain in turn, this is the first one
==20258== Use of uninitialised value of size 8
==20258==    at 0xBD369EC: __printf_fp_l (in /usr/lib64/power9/libc-2.28.so)
==20258==    by 0x1FFF007AAF: ???
==20258==    by 0xBD32623: printf_positional (in /usr/lib64/power9/libc-2.28.so)
==20258==    by 0xBD33BDF: vfprintf@@GLIBC_2.17 (in /usr/lib64/power9/libc-2.28.so)
==20258==    by 0x10045397: vprintf (stdio.h:41)
==20258==    by 0x10045397: tm_debug_printf (tm_debug_printf.c:35)
==20258==    by 0x100481F7: _loadGaugeQuda (quda_interface.c:565)
==20258==    by 0x1004BDB3: invert_eo_degenerate_quda (quda_interface.c:2062)
==20258==    by 0x1013FB13: solve_degenerate (monomial_solve.c:127)
==20258==    by 0x100775A7: cloverdetratio_heatbath (cloverdetratio_monomial.c:287)
==20258==    by 0x100366A3: update_tm (update_tm.c:130)
==20258==    by 0x1000758F: main (hmc_tm.c:402)
==20258==  Uninitialised value was created by a stack allocation
==20258==    at 0x10150A18: init_global_states (init_global_states.c:25)

My understanding is that the gauge_id is not set to zero right where it should (at the creation of the state), but a complicated mechanism is in place.  The gauge_id is referred in several places (some of clearly harmless, some of which possibly harmful)",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,522,2022-02-08T13:24:31Z,2022-02-08T13:31:41Z,2022-02-08T17:24:40Z,MERGED,True,1,0,1,https://github.com/sunpho84,Ensure gauge_id member is initialized when the gauge_status is created,2,[],https://github.com/etmc/tmLQCD/pull/522,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/522#issuecomment-1032612575,"I'm in the process o fixing a nasty segmentation fault that arises in random places around. With the help of @Marcogarofalo
I've managed to run the code under valgrind, and I'm proceeding to fix each complain in turn, this is the first one
==20258== Use of uninitialised value of size 8
==20258==    at 0xBD369EC: __printf_fp_l (in /usr/lib64/power9/libc-2.28.so)
==20258==    by 0x1FFF007AAF: ???
==20258==    by 0xBD32623: printf_positional (in /usr/lib64/power9/libc-2.28.so)
==20258==    by 0xBD33BDF: vfprintf@@GLIBC_2.17 (in /usr/lib64/power9/libc-2.28.so)
==20258==    by 0x10045397: vprintf (stdio.h:41)
==20258==    by 0x10045397: tm_debug_printf (tm_debug_printf.c:35)
==20258==    by 0x100481F7: _loadGaugeQuda (quda_interface.c:565)
==20258==    by 0x1004BDB3: invert_eo_degenerate_quda (quda_interface.c:2062)
==20258==    by 0x1013FB13: solve_degenerate (monomial_solve.c:127)
==20258==    by 0x100775A7: cloverdetratio_heatbath (cloverdetratio_monomial.c:287)
==20258==    by 0x100366A3: update_tm (update_tm.c:130)
==20258==    by 0x1000758F: main (hmc_tm.c:402)
==20258==  Uninitialised value was created by a stack allocation
==20258==    at 0x10150A18: init_global_states (init_global_states.c:25)

My understanding is that the gauge_id is not set to zero right where it should (at the creation of the state), but a complicated mechanism is in place.  The gauge_id is referred in several places (some of clearly harmless, some of which possibly harmful)","Thanks, I agree that this was clearly a bug.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,522,2022-02-08T13:24:31Z,2022-02-08T13:31:41Z,2022-02-08T17:24:40Z,MERGED,True,1,0,1,https://github.com/sunpho84,Ensure gauge_id member is initialized when the gauge_status is created,2,[],https://github.com/etmc/tmLQCD/pull/522,https://github.com/kostrzewa,3,https://github.com/etmc/tmLQCD/pull/522#issuecomment-1032632336,"I'm in the process o fixing a nasty segmentation fault that arises in random places around. With the help of @Marcogarofalo
I've managed to run the code under valgrind, and I'm proceeding to fix each complain in turn, this is the first one
==20258== Use of uninitialised value of size 8
==20258==    at 0xBD369EC: __printf_fp_l (in /usr/lib64/power9/libc-2.28.so)
==20258==    by 0x1FFF007AAF: ???
==20258==    by 0xBD32623: printf_positional (in /usr/lib64/power9/libc-2.28.so)
==20258==    by 0xBD33BDF: vfprintf@@GLIBC_2.17 (in /usr/lib64/power9/libc-2.28.so)
==20258==    by 0x10045397: vprintf (stdio.h:41)
==20258==    by 0x10045397: tm_debug_printf (tm_debug_printf.c:35)
==20258==    by 0x100481F7: _loadGaugeQuda (quda_interface.c:565)
==20258==    by 0x1004BDB3: invert_eo_degenerate_quda (quda_interface.c:2062)
==20258==    by 0x1013FB13: solve_degenerate (monomial_solve.c:127)
==20258==    by 0x100775A7: cloverdetratio_heatbath (cloverdetratio_monomial.c:287)
==20258==    by 0x100366A3: update_tm (update_tm.c:130)
==20258==    by 0x1000758F: main (hmc_tm.c:402)
==20258==  Uninitialised value was created by a stack allocation
==20258==    at 0x10150A18: init_global_states (init_global_states.c:25)

My understanding is that the gauge_id is not set to zero right where it should (at the creation of the state), but a complicated mechanism is in place.  The gauge_id is referred in several places (some of clearly harmless, some of which possibly harmful)","Looking back, I think the fact that gauge_id was not set was ""by design"". The point being that if loaded == 0, none of the other struct members may contain valid values.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,522,2022-02-08T13:24:31Z,2022-02-08T13:31:41Z,2022-02-08T17:24:40Z,MERGED,True,1,0,1,https://github.com/sunpho84,Ensure gauge_id member is initialized when the gauge_status is created,2,[],https://github.com/etmc/tmLQCD/pull/522,https://github.com/kostrzewa,4,https://github.com/etmc/tmLQCD/pull/522#issuecomment-1032636370,"I'm in the process o fixing a nasty segmentation fault that arises in random places around. With the help of @Marcogarofalo
I've managed to run the code under valgrind, and I'm proceeding to fix each complain in turn, this is the first one
==20258== Use of uninitialised value of size 8
==20258==    at 0xBD369EC: __printf_fp_l (in /usr/lib64/power9/libc-2.28.so)
==20258==    by 0x1FFF007AAF: ???
==20258==    by 0xBD32623: printf_positional (in /usr/lib64/power9/libc-2.28.so)
==20258==    by 0xBD33BDF: vfprintf@@GLIBC_2.17 (in /usr/lib64/power9/libc-2.28.so)
==20258==    by 0x10045397: vprintf (stdio.h:41)
==20258==    by 0x10045397: tm_debug_printf (tm_debug_printf.c:35)
==20258==    by 0x100481F7: _loadGaugeQuda (quda_interface.c:565)
==20258==    by 0x1004BDB3: invert_eo_degenerate_quda (quda_interface.c:2062)
==20258==    by 0x1013FB13: solve_degenerate (monomial_solve.c:127)
==20258==    by 0x100775A7: cloverdetratio_heatbath (cloverdetratio_monomial.c:287)
==20258==    by 0x100366A3: update_tm (update_tm.c:130)
==20258==    by 0x1000758F: main (hmc_tm.c:402)
==20258==  Uninitialised value was created by a stack allocation
==20258==    at 0x10150A18: init_global_states (init_global_states.c:25)

My understanding is that the gauge_id is not set to zero right where it should (at the creation of the state), but a complicated mechanism is in place.  The gauge_id is referred in several places (some of clearly harmless, some of which possibly harmful)",The same applies to tm_CloverState_t and tm_CloverInverseState_t. I would actually argue that what was pulled in here should be reverted.,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,522,2022-02-08T13:24:31Z,2022-02-08T13:31:41Z,2022-02-08T17:24:40Z,MERGED,True,1,0,1,https://github.com/sunpho84,Ensure gauge_id member is initialized when the gauge_status is created,2,[],https://github.com/etmc/tmLQCD/pull/522,https://github.com/kostrzewa,5,https://github.com/etmc/tmLQCD/pull/522#issuecomment-1032637485,"I'm in the process o fixing a nasty segmentation fault that arises in random places around. With the help of @Marcogarofalo
I've managed to run the code under valgrind, and I'm proceeding to fix each complain in turn, this is the first one
==20258== Use of uninitialised value of size 8
==20258==    at 0xBD369EC: __printf_fp_l (in /usr/lib64/power9/libc-2.28.so)
==20258==    by 0x1FFF007AAF: ???
==20258==    by 0xBD32623: printf_positional (in /usr/lib64/power9/libc-2.28.so)
==20258==    by 0xBD33BDF: vfprintf@@GLIBC_2.17 (in /usr/lib64/power9/libc-2.28.so)
==20258==    by 0x10045397: vprintf (stdio.h:41)
==20258==    by 0x10045397: tm_debug_printf (tm_debug_printf.c:35)
==20258==    by 0x100481F7: _loadGaugeQuda (quda_interface.c:565)
==20258==    by 0x1004BDB3: invert_eo_degenerate_quda (quda_interface.c:2062)
==20258==    by 0x1013FB13: solve_degenerate (monomial_solve.c:127)
==20258==    by 0x100775A7: cloverdetratio_heatbath (cloverdetratio_monomial.c:287)
==20258==    by 0x100366A3: update_tm (update_tm.c:130)
==20258==    by 0x1000758F: main (hmc_tm.c:402)
==20258==  Uninitialised value was created by a stack allocation
==20258==    at 0x10150A18: init_global_states (init_global_states.c:25)

My understanding is that the gauge_id is not set to zero right where it should (at the creation of the state), but a complicated mechanism is in place.  The gauge_id is referred in several places (some of clearly harmless, some of which possibly harmful)","Or instead, the default value should be some large negative number, because it is of course correct that _loadGaugeQuda reads this value and might read it before it has been initialised.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,522,2022-02-08T13:24:31Z,2022-02-08T13:31:41Z,2022-02-08T17:24:40Z,MERGED,True,1,0,1,https://github.com/sunpho84,Ensure gauge_id member is initialized when the gauge_status is created,2,[],https://github.com/etmc/tmLQCD/pull/522,https://github.com/kostrzewa,6,https://github.com/etmc/tmLQCD/pull/522#issuecomment-1032640988,"I'm in the process o fixing a nasty segmentation fault that arises in random places around. With the help of @Marcogarofalo
I've managed to run the code under valgrind, and I'm proceeding to fix each complain in turn, this is the first one
==20258== Use of uninitialised value of size 8
==20258==    at 0xBD369EC: __printf_fp_l (in /usr/lib64/power9/libc-2.28.so)
==20258==    by 0x1FFF007AAF: ???
==20258==    by 0xBD32623: printf_positional (in /usr/lib64/power9/libc-2.28.so)
==20258==    by 0xBD33BDF: vfprintf@@GLIBC_2.17 (in /usr/lib64/power9/libc-2.28.so)
==20258==    by 0x10045397: vprintf (stdio.h:41)
==20258==    by 0x10045397: tm_debug_printf (tm_debug_printf.c:35)
==20258==    by 0x100481F7: _loadGaugeQuda (quda_interface.c:565)
==20258==    by 0x1004BDB3: invert_eo_degenerate_quda (quda_interface.c:2062)
==20258==    by 0x1013FB13: solve_degenerate (monomial_solve.c:127)
==20258==    by 0x100775A7: cloverdetratio_heatbath (cloverdetratio_monomial.c:287)
==20258==    by 0x100366A3: update_tm (update_tm.c:130)
==20258==    by 0x1000758F: main (hmc_tm.c:402)
==20258==  Uninitialised value was created by a stack allocation
==20258==    at 0x10150A18: init_global_states (init_global_states.c:25)

My understanding is that the gauge_id is not set to zero right where it should (at the creation of the state), but a complicated mechanism is in place.  The gauge_id is referred in several places (some of clearly harmless, some of which possibly harmful)",The issue (in the case of the HMC) is the fact that update_tm_gauge_state is not called after random_gauge_field or after unit_g_gauge_field. The solution would be to modify these functions in start.c to call update_tm_gauge_state.,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,522,2022-02-08T13:24:31Z,2022-02-08T13:31:41Z,2022-02-08T17:24:40Z,MERGED,True,1,0,1,https://github.com/sunpho84,Ensure gauge_id member is initialized when the gauge_status is created,2,[],https://github.com/etmc/tmLQCD/pull/522,https://github.com/kostrzewa,7,https://github.com/etmc/tmLQCD/pull/522#issuecomment-1032641407,"I'm in the process o fixing a nasty segmentation fault that arises in random places around. With the help of @Marcogarofalo
I've managed to run the code under valgrind, and I'm proceeding to fix each complain in turn, this is the first one
==20258== Use of uninitialised value of size 8
==20258==    at 0xBD369EC: __printf_fp_l (in /usr/lib64/power9/libc-2.28.so)
==20258==    by 0x1FFF007AAF: ???
==20258==    by 0xBD32623: printf_positional (in /usr/lib64/power9/libc-2.28.so)
==20258==    by 0xBD33BDF: vfprintf@@GLIBC_2.17 (in /usr/lib64/power9/libc-2.28.so)
==20258==    by 0x10045397: vprintf (stdio.h:41)
==20258==    by 0x10045397: tm_debug_printf (tm_debug_printf.c:35)
==20258==    by 0x100481F7: _loadGaugeQuda (quda_interface.c:565)
==20258==    by 0x1004BDB3: invert_eo_degenerate_quda (quda_interface.c:2062)
==20258==    by 0x1013FB13: solve_degenerate (monomial_solve.c:127)
==20258==    by 0x100775A7: cloverdetratio_heatbath (cloverdetratio_monomial.c:287)
==20258==    by 0x100366A3: update_tm (update_tm.c:130)
==20258==    by 0x1000758F: main (hmc_tm.c:402)
==20258==  Uninitialised value was created by a stack allocation
==20258==    at 0x10150A18: init_global_states (init_global_states.c:25)

My understanding is that the gauge_id is not set to zero right where it should (at the creation of the state), but a complicated mechanism is in place.  The gauge_id is referred in several places (some of clearly harmless, some of which possibly harmful)",There may be other oversights in the logic and it's good that other people are looking at this now.,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,522,2022-02-08T13:24:31Z,2022-02-08T13:31:41Z,2022-02-08T17:24:40Z,MERGED,True,1,0,1,https://github.com/sunpho84,Ensure gauge_id member is initialized when the gauge_status is created,2,[],https://github.com/etmc/tmLQCD/pull/522,https://github.com/sunpho84,8,https://github.com/etmc/tmLQCD/pull/522#issuecomment-1032644465,"I'm in the process o fixing a nasty segmentation fault that arises in random places around. With the help of @Marcogarofalo
I've managed to run the code under valgrind, and I'm proceeding to fix each complain in turn, this is the first one
==20258== Use of uninitialised value of size 8
==20258==    at 0xBD369EC: __printf_fp_l (in /usr/lib64/power9/libc-2.28.so)
==20258==    by 0x1FFF007AAF: ???
==20258==    by 0xBD32623: printf_positional (in /usr/lib64/power9/libc-2.28.so)
==20258==    by 0xBD33BDF: vfprintf@@GLIBC_2.17 (in /usr/lib64/power9/libc-2.28.so)
==20258==    by 0x10045397: vprintf (stdio.h:41)
==20258==    by 0x10045397: tm_debug_printf (tm_debug_printf.c:35)
==20258==    by 0x100481F7: _loadGaugeQuda (quda_interface.c:565)
==20258==    by 0x1004BDB3: invert_eo_degenerate_quda (quda_interface.c:2062)
==20258==    by 0x1013FB13: solve_degenerate (monomial_solve.c:127)
==20258==    by 0x100775A7: cloverdetratio_heatbath (cloverdetratio_monomial.c:287)
==20258==    by 0x100366A3: update_tm (update_tm.c:130)
==20258==    by 0x1000758F: main (hmc_tm.c:402)
==20258==  Uninitialised value was created by a stack allocation
==20258==    at 0x10150A18: init_global_states (init_global_states.c:25)

My understanding is that the gauge_id is not set to zero right where it should (at the creation of the state), but a complicated mechanism is in place.  The gauge_id is referred in several places (some of clearly harmless, some of which possibly harmful)","this is another occurrence where the gauge_id is referred
# TM_QUDA: Called _loadGaugeQuda for gauge_id: 0.000000
# TM_QUDA: Theta boundary conditions will be applied to gauge field
==20258== Conditional jump or move depends on uninitialised value(s)
==20258==    at 0x1004843C: check_quda_gauge_state (quda_types.h:192)
==20258==    by 0x1004843C: _loadGaugeQuda (quda_interface.c:581)
==20258==    by 0x1004BDB3: invert_eo_degenerate_quda (quda_interface.c:2062)
==20258==    by 0x1013FB13: solve_degenerate (monomial_solve.c:127)
==20258==    by 0x100775A7: cloverdetratio_heatbath (cloverdetratio_monomial.c:287)
==20258==    by 0x100366A3: update_tm (update_tm.c:130)
==20258==    by 0x1000758F: main (hmc_tm.c:402)
==20258==  Uninitialised value was created by a stack allocation
==20258==    at 0x10150A18: init_global_states (init_global_states.c:25)

which points to

  
    
      tmLQCD/quda_types.h
    
    
         Line 193
      in
      23003f1
    
  
  
    

        
          
           (fabs(quda_gauge_state->gauge_id - gauge_id) < 2*DBL_EPSILON) );",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,522,2022-02-08T13:24:31Z,2022-02-08T13:31:41Z,2022-02-08T17:24:40Z,MERGED,True,1,0,1,https://github.com/sunpho84,Ensure gauge_id member is initialized when the gauge_status is created,2,[],https://github.com/etmc/tmLQCD/pull/522,https://github.com/sunpho84,9,https://github.com/etmc/tmLQCD/pull/522#issuecomment-1032644862,"I'm in the process o fixing a nasty segmentation fault that arises in random places around. With the help of @Marcogarofalo
I've managed to run the code under valgrind, and I'm proceeding to fix each complain in turn, this is the first one
==20258== Use of uninitialised value of size 8
==20258==    at 0xBD369EC: __printf_fp_l (in /usr/lib64/power9/libc-2.28.so)
==20258==    by 0x1FFF007AAF: ???
==20258==    by 0xBD32623: printf_positional (in /usr/lib64/power9/libc-2.28.so)
==20258==    by 0xBD33BDF: vfprintf@@GLIBC_2.17 (in /usr/lib64/power9/libc-2.28.so)
==20258==    by 0x10045397: vprintf (stdio.h:41)
==20258==    by 0x10045397: tm_debug_printf (tm_debug_printf.c:35)
==20258==    by 0x100481F7: _loadGaugeQuda (quda_interface.c:565)
==20258==    by 0x1004BDB3: invert_eo_degenerate_quda (quda_interface.c:2062)
==20258==    by 0x1013FB13: solve_degenerate (monomial_solve.c:127)
==20258==    by 0x100775A7: cloverdetratio_heatbath (cloverdetratio_monomial.c:287)
==20258==    by 0x100366A3: update_tm (update_tm.c:130)
==20258==    by 0x1000758F: main (hmc_tm.c:402)
==20258==  Uninitialised value was created by a stack allocation
==20258==    at 0x10150A18: init_global_states (init_global_states.c:25)

My understanding is that the gauge_id is not set to zero right where it should (at the creation of the state), but a complicated mechanism is in place.  The gauge_id is referred in several places (some of clearly harmless, some of which possibly harmful)",of course this complaint by valgrind was occurring before the fix,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,522,2022-02-08T13:24:31Z,2022-02-08T13:31:41Z,2022-02-08T17:24:40Z,MERGED,True,1,0,1,https://github.com/sunpho84,Ensure gauge_id member is initialized when the gauge_status is created,2,[],https://github.com/etmc/tmLQCD/pull/522,https://github.com/kostrzewa,10,https://github.com/etmc/tmLQCD/pull/522#issuecomment-1032653542,"I'm in the process o fixing a nasty segmentation fault that arises in random places around. With the help of @Marcogarofalo
I've managed to run the code under valgrind, and I'm proceeding to fix each complain in turn, this is the first one
==20258== Use of uninitialised value of size 8
==20258==    at 0xBD369EC: __printf_fp_l (in /usr/lib64/power9/libc-2.28.so)
==20258==    by 0x1FFF007AAF: ???
==20258==    by 0xBD32623: printf_positional (in /usr/lib64/power9/libc-2.28.so)
==20258==    by 0xBD33BDF: vfprintf@@GLIBC_2.17 (in /usr/lib64/power9/libc-2.28.so)
==20258==    by 0x10045397: vprintf (stdio.h:41)
==20258==    by 0x10045397: tm_debug_printf (tm_debug_printf.c:35)
==20258==    by 0x100481F7: _loadGaugeQuda (quda_interface.c:565)
==20258==    by 0x1004BDB3: invert_eo_degenerate_quda (quda_interface.c:2062)
==20258==    by 0x1013FB13: solve_degenerate (monomial_solve.c:127)
==20258==    by 0x100775A7: cloverdetratio_heatbath (cloverdetratio_monomial.c:287)
==20258==    by 0x100366A3: update_tm (update_tm.c:130)
==20258==    by 0x1000758F: main (hmc_tm.c:402)
==20258==  Uninitialised value was created by a stack allocation
==20258==    at 0x10150A18: init_global_states (init_global_states.c:25)

My understanding is that the gauge_id is not set to zero right where it should (at the creation of the state), but a complicated mechanism is in place.  The gauge_id is referred in several places (some of clearly harmless, some of which possibly harmful)","I think we can safely set various things to large negative numbers by default (so that they are never uninitialised) and beyond that, whenever the state is modified, we must call update_tm_*_state.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,522,2022-02-08T13:24:31Z,2022-02-08T13:31:41Z,2022-02-08T17:24:40Z,MERGED,True,1,0,1,https://github.com/sunpho84,Ensure gauge_id member is initialized when the gauge_status is created,2,[],https://github.com/etmc/tmLQCD/pull/522,https://github.com/Marcogarofalo,11,https://github.com/etmc/tmLQCD/pull/522#issuecomment-1032655433,"I'm in the process o fixing a nasty segmentation fault that arises in random places around. With the help of @Marcogarofalo
I've managed to run the code under valgrind, and I'm proceeding to fix each complain in turn, this is the first one
==20258== Use of uninitialised value of size 8
==20258==    at 0xBD369EC: __printf_fp_l (in /usr/lib64/power9/libc-2.28.so)
==20258==    by 0x1FFF007AAF: ???
==20258==    by 0xBD32623: printf_positional (in /usr/lib64/power9/libc-2.28.so)
==20258==    by 0xBD33BDF: vfprintf@@GLIBC_2.17 (in /usr/lib64/power9/libc-2.28.so)
==20258==    by 0x10045397: vprintf (stdio.h:41)
==20258==    by 0x10045397: tm_debug_printf (tm_debug_printf.c:35)
==20258==    by 0x100481F7: _loadGaugeQuda (quda_interface.c:565)
==20258==    by 0x1004BDB3: invert_eo_degenerate_quda (quda_interface.c:2062)
==20258==    by 0x1013FB13: solve_degenerate (monomial_solve.c:127)
==20258==    by 0x100775A7: cloverdetratio_heatbath (cloverdetratio_monomial.c:287)
==20258==    by 0x100366A3: update_tm (update_tm.c:130)
==20258==    by 0x1000758F: main (hmc_tm.c:402)
==20258==  Uninitialised value was created by a stack allocation
==20258==    at 0x10150A18: init_global_states (init_global_states.c:25)

My understanding is that the gauge_id is not set to zero right where it should (at the creation of the state), but a complicated mechanism is in place.  The gauge_id is referred in several places (some of clearly harmless, some of which possibly harmful)","why large negative, -1 is not enough?
since quda_gauge_state starts with gauge_id=-1 why not the same for gauge_param.gauge_id
static inline void reset_quda_gauge_state(tm_QudaGaugeState_t * const quda_gauge_state){
  quda_gauge_state->gauge_id = -1;
  quda_gauge_state->loaded = 0;
}",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,522,2022-02-08T13:24:31Z,2022-02-08T13:31:41Z,2022-02-08T17:24:40Z,MERGED,True,1,0,1,https://github.com/sunpho84,Ensure gauge_id member is initialized when the gauge_status is created,2,[],https://github.com/etmc/tmLQCD/pull/522,https://github.com/kostrzewa,12,https://github.com/etmc/tmLQCD/pull/522#issuecomment-1032845068,"I'm in the process o fixing a nasty segmentation fault that arises in random places around. With the help of @Marcogarofalo
I've managed to run the code under valgrind, and I'm proceeding to fix each complain in turn, this is the first one
==20258== Use of uninitialised value of size 8
==20258==    at 0xBD369EC: __printf_fp_l (in /usr/lib64/power9/libc-2.28.so)
==20258==    by 0x1FFF007AAF: ???
==20258==    by 0xBD32623: printf_positional (in /usr/lib64/power9/libc-2.28.so)
==20258==    by 0xBD33BDF: vfprintf@@GLIBC_2.17 (in /usr/lib64/power9/libc-2.28.so)
==20258==    by 0x10045397: vprintf (stdio.h:41)
==20258==    by 0x10045397: tm_debug_printf (tm_debug_printf.c:35)
==20258==    by 0x100481F7: _loadGaugeQuda (quda_interface.c:565)
==20258==    by 0x1004BDB3: invert_eo_degenerate_quda (quda_interface.c:2062)
==20258==    by 0x1013FB13: solve_degenerate (monomial_solve.c:127)
==20258==    by 0x100775A7: cloverdetratio_heatbath (cloverdetratio_monomial.c:287)
==20258==    by 0x100366A3: update_tm (update_tm.c:130)
==20258==    by 0x1000758F: main (hmc_tm.c:402)
==20258==  Uninitialised value was created by a stack allocation
==20258==    at 0x10150A18: init_global_states (init_global_states.c:25)

My understanding is that the gauge_id is not set to zero right where it should (at the creation of the state), but a complicated mechanism is in place.  The gauge_id is referred in several places (some of clearly harmless, some of which possibly harmful)","@Marcogarofalo sure. I wanted to use a large negative number because then it's clear that the thresholds are exceeded. The whole ""state tracking"" is quite fragile unfortunately...",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,522,2022-02-08T13:24:31Z,2022-02-08T13:31:41Z,2022-02-08T17:24:40Z,MERGED,True,1,0,1,https://github.com/sunpho84,Ensure gauge_id member is initialized when the gauge_status is created,2,[],https://github.com/etmc/tmLQCD/pull/522,https://github.com/kostrzewa,13,https://github.com/etmc/tmLQCD/pull/522#issuecomment-1032867519,"I'm in the process o fixing a nasty segmentation fault that arises in random places around. With the help of @Marcogarofalo
I've managed to run the code under valgrind, and I'm proceeding to fix each complain in turn, this is the first one
==20258== Use of uninitialised value of size 8
==20258==    at 0xBD369EC: __printf_fp_l (in /usr/lib64/power9/libc-2.28.so)
==20258==    by 0x1FFF007AAF: ???
==20258==    by 0xBD32623: printf_positional (in /usr/lib64/power9/libc-2.28.so)
==20258==    by 0xBD33BDF: vfprintf@@GLIBC_2.17 (in /usr/lib64/power9/libc-2.28.so)
==20258==    by 0x10045397: vprintf (stdio.h:41)
==20258==    by 0x10045397: tm_debug_printf (tm_debug_printf.c:35)
==20258==    by 0x100481F7: _loadGaugeQuda (quda_interface.c:565)
==20258==    by 0x1004BDB3: invert_eo_degenerate_quda (quda_interface.c:2062)
==20258==    by 0x1013FB13: solve_degenerate (monomial_solve.c:127)
==20258==    by 0x100775A7: cloverdetratio_heatbath (cloverdetratio_monomial.c:287)
==20258==    by 0x100366A3: update_tm (update_tm.c:130)
==20258==    by 0x1000758F: main (hmc_tm.c:402)
==20258==  Uninitialised value was created by a stack allocation
==20258==    at 0x10150A18: init_global_states (init_global_states.c:25)

My understanding is that the gauge_id is not set to zero right where it should (at the creation of the state), but a complicated mechanism is in place.  The gauge_id is referred in several places (some of clearly harmless, some of which possibly harmful)",Please let me know what you think of the proposal in #523,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,522,2022-02-08T13:24:31Z,2022-02-08T13:31:41Z,2022-02-08T17:24:40Z,MERGED,True,1,0,1,https://github.com/sunpho84,Ensure gauge_id member is initialized when the gauge_status is created,2,[],https://github.com/etmc/tmLQCD/pull/522,https://github.com/sunpho84,14,https://github.com/etmc/tmLQCD/pull/522#issuecomment-1032869950,"I'm in the process o fixing a nasty segmentation fault that arises in random places around. With the help of @Marcogarofalo
I've managed to run the code under valgrind, and I'm proceeding to fix each complain in turn, this is the first one
==20258== Use of uninitialised value of size 8
==20258==    at 0xBD369EC: __printf_fp_l (in /usr/lib64/power9/libc-2.28.so)
==20258==    by 0x1FFF007AAF: ???
==20258==    by 0xBD32623: printf_positional (in /usr/lib64/power9/libc-2.28.so)
==20258==    by 0xBD33BDF: vfprintf@@GLIBC_2.17 (in /usr/lib64/power9/libc-2.28.so)
==20258==    by 0x10045397: vprintf (stdio.h:41)
==20258==    by 0x10045397: tm_debug_printf (tm_debug_printf.c:35)
==20258==    by 0x100481F7: _loadGaugeQuda (quda_interface.c:565)
==20258==    by 0x1004BDB3: invert_eo_degenerate_quda (quda_interface.c:2062)
==20258==    by 0x1013FB13: solve_degenerate (monomial_solve.c:127)
==20258==    by 0x100775A7: cloverdetratio_heatbath (cloverdetratio_monomial.c:287)
==20258==    by 0x100366A3: update_tm (update_tm.c:130)
==20258==    by 0x1000758F: main (hmc_tm.c:402)
==20258==  Uninitialised value was created by a stack allocation
==20258==    at 0x10150A18: init_global_states (init_global_states.c:25)

My understanding is that the gauge_id is not set to zero right where it should (at the creation of the state), but a complicated mechanism is in place.  The gauge_id is referred in several places (some of clearly harmless, some of which possibly harmful)","Yeah it makes sense, as long as one keep memory of updating the status where needed.
The large negative number can be probably better understood",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,523,2022-02-08T17:20:08Z,2022-02-10T18:14:04Z,2022-02-10T18:14:04Z,MERGED,True,17,3,3,https://github.com/kostrzewa,call tm_update_gauge_id also from random_gauge_field and unit_g_gauge_field,2,[],https://github.com/etmc/tmLQCD/pull/523,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/523,This is a compantion PR to #522,This is a compantion PR to #522,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,524,2022-02-10T18:48:03Z,2022-02-11T15:56:26Z,2022-02-11T15:56:27Z,MERGED,True,0,16,2,https://github.com/kostrzewa,mg_eig_preserve_deflation does not need to guarded any more,1,[],https://github.com/etmc/tmLQCD/pull/524,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/524,"mg_eig_preserve_deflation is now supported even in QUDA-1.1.x, no need to guard it with TM_QUDA_EXPERIMENTAL","mg_eig_preserve_deflation is now supported even in QUDA-1.1.x, no need to guard it with TM_QUDA_EXPERIMENTAL",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,525,2022-02-17T11:03:32Z,2022-02-17T18:17:09Z,2022-04-27T10:04:50Z,MERGED,True,138,23,3,https://github.com/kostrzewa,partial workaround for some of the precision mismatch problems in QUDA interface,4,[],https://github.com/etmc/tmLQCD/pull/525,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/525,"We were not tracking the precisions of the gauge and clover fields present on the device and hence these were bound to lead to mismatches when switching from one monomial employing an operator and solver with a particular set of precisions to another monomial employing a different set of precisions (for cuda_prec, cuda_prec_sloppy, cuda_prec_refinement_sloppy, cuda_prec_precondition and cuda_prec_eigensolver and the corresponding ones for clover_quda_*.
Unfortunately, this does not fully ""solve"" #517, but it does raise a new type of error there which might help resolve that too in the end.
The set of changes here has a drawback of course: the gauge and clover fields are reloaded much more frequently instead of just causing the missing precision to be instantiated from the existing double precision field on the device. Not sure how bad the additional overhead is compared to the time spent in a trajectory.
It is especially a complete waste of time to call reorder_gauge_toQuda so frequently because this should really only be called when g_gauge_field or any of the theta angles have actually changed. freeGaugeQuda() and loadGaugeQuda(..) do have to be called, however (at least for now, since that is our mechanism for ensuring that the field is up to date).","We were not tracking the precisions of the gauge and clover fields present on the device and hence these were bound to lead to mismatches when switching from one monomial employing an operator and solver with a particular set of precisions to another monomial employing a different set of precisions (for cuda_prec, cuda_prec_sloppy, cuda_prec_refinement_sloppy, cuda_prec_precondition and cuda_prec_eigensolver and the corresponding ones for clover_quda_*.
Unfortunately, this does not fully ""solve"" #517, but it does raise a new type of error there which might help resolve that too in the end.
The set of changes here has a drawback of course: the gauge and clover fields are reloaded much more frequently instead of just causing the missing precision to be instantiated from the existing double precision field on the device. Not sure how bad the additional overhead is compared to the time spent in a trajectory.
It is especially a complete waste of time to call reorder_gauge_toQuda so frequently because this should really only be called when g_gauge_field or any of the theta angles have actually changed. freeGaugeQuda() and loadGaugeQuda(..) do have to be called, however (at least for now, since that is our mechanism for ensuring that the field is up to date).",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,525,2022-02-17T11:03:32Z,2022-02-17T18:17:09Z,2022-04-27T10:04:50Z,MERGED,True,138,23,3,https://github.com/kostrzewa,partial workaround for some of the precision mismatch problems in QUDA interface,4,[],https://github.com/etmc/tmLQCD/pull/525,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/525#issuecomment-1042860943,"We were not tracking the precisions of the gauge and clover fields present on the device and hence these were bound to lead to mismatches when switching from one monomial employing an operator and solver with a particular set of precisions to another monomial employing a different set of precisions (for cuda_prec, cuda_prec_sloppy, cuda_prec_refinement_sloppy, cuda_prec_precondition and cuda_prec_eigensolver and the corresponding ones for clover_quda_*.
Unfortunately, this does not fully ""solve"" #517, but it does raise a new type of error there which might help resolve that too in the end.
The set of changes here has a drawback of course: the gauge and clover fields are reloaded much more frequently instead of just causing the missing precision to be instantiated from the existing double precision field on the device. Not sure how bad the additional overhead is compared to the time spent in a trajectory.
It is especially a complete waste of time to call reorder_gauge_toQuda so frequently because this should really only be called when g_gauge_field or any of the theta angles have actually changed. freeGaugeQuda() and loadGaugeQuda(..) do have to be called, however (at least for now, since that is our mechanism for ensuring that the field is up to date).",Do not merge yet. I'm afraid there are other issues left...,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,525,2022-02-17T11:03:32Z,2022-02-17T18:17:09Z,2022-04-27T10:04:50Z,MERGED,True,138,23,3,https://github.com/kostrzewa,partial workaround for some of the precision mismatch problems in QUDA interface,4,[],https://github.com/etmc/tmLQCD/pull/525,https://github.com/kostrzewa,3,https://github.com/etmc/tmLQCD/pull/525#issuecomment-1042992160,"We were not tracking the precisions of the gauge and clover fields present on the device and hence these were bound to lead to mismatches when switching from one monomial employing an operator and solver with a particular set of precisions to another monomial employing a different set of precisions (for cuda_prec, cuda_prec_sloppy, cuda_prec_refinement_sloppy, cuda_prec_precondition and cuda_prec_eigensolver and the corresponding ones for clover_quda_*.
Unfortunately, this does not fully ""solve"" #517, but it does raise a new type of error there which might help resolve that too in the end.
The set of changes here has a drawback of course: the gauge and clover fields are reloaded much more frequently instead of just causing the missing precision to be instantiated from the existing double precision field on the device. Not sure how bad the additional overhead is compared to the time spent in a trajectory.
It is especially a complete waste of time to call reorder_gauge_toQuda so frequently because this should really only be called when g_gauge_field or any of the theta angles have actually changed. freeGaugeQuda() and loadGaugeQuda(..) do have to be called, however (at least for now, since that is our mechanism for ensuring that the field is up to date).","6c040df resolves #517 and solidifies the precision mismatch fix
The problem was that the MG Setup (in particular I guess the coarse operators) seem to have an internal memory of the gauge field device pointers (rather than an abstract reference which I would expect to update with the gauge field on the device).
When we call freeGaugeQuda() in the HMC, we are left with dangling pointers in the MG and this is what causes the crazy ""volume mismatches"". At the same time, the current gauge and clover fields must be consistent with the precisions in the MG Setup and this leads to the precision mismatches.
I'm not happy with this because it induces lots of MG Setup updates, but these are not THAT expensive. I think this is ready to test now.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,525,2022-02-17T11:03:32Z,2022-02-17T18:17:09Z,2022-04-27T10:04:50Z,MERGED,True,138,23,3,https://github.com/kostrzewa,partial workaround for some of the precision mismatch problems in QUDA interface,4,[],https://github.com/etmc/tmLQCD/pull/525,https://github.com/Marcogarofalo,4,https://github.com/etmc/tmLQCD/pull/525#issuecomment-1043184405,"We were not tracking the precisions of the gauge and clover fields present on the device and hence these were bound to lead to mismatches when switching from one monomial employing an operator and solver with a particular set of precisions to another monomial employing a different set of precisions (for cuda_prec, cuda_prec_sloppy, cuda_prec_refinement_sloppy, cuda_prec_precondition and cuda_prec_eigensolver and the corresponding ones for clover_quda_*.
Unfortunately, this does not fully ""solve"" #517, but it does raise a new type of error there which might help resolve that too in the end.
The set of changes here has a drawback of course: the gauge and clover fields are reloaded much more frequently instead of just causing the missing precision to be instantiated from the existing double precision field on the device. Not sure how bad the additional overhead is compared to the time spent in a trajectory.
It is especially a complete waste of time to call reorder_gauge_toQuda so frequently because this should really only be called when g_gauge_field or any of the theta angles have actually changed. freeGaugeQuda() and loadGaugeQuda(..) do have to be called, however (at least for now, since that is our mechanism for ensuring that the field is up to date).","I'm not happy with this because it induces lots of MG Setup updates, but these are not THAT expensive. I think this is ready to test now.

but it works. Also all the valgrind messages disappear. Thanks",True,{'HOORAY': ['https://github.com/kostrzewa']}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,525,2022-02-17T11:03:32Z,2022-02-17T18:17:09Z,2022-04-27T10:04:50Z,MERGED,True,138,23,3,https://github.com/kostrzewa,partial workaround for some of the precision mismatch problems in QUDA interface,4,[],https://github.com/etmc/tmLQCD/pull/525,https://github.com/kostrzewa,5,https://github.com/etmc/tmLQCD/pull/525#issuecomment-1043241034,"We were not tracking the precisions of the gauge and clover fields present on the device and hence these were bound to lead to mismatches when switching from one monomial employing an operator and solver with a particular set of precisions to another monomial employing a different set of precisions (for cuda_prec, cuda_prec_sloppy, cuda_prec_refinement_sloppy, cuda_prec_precondition and cuda_prec_eigensolver and the corresponding ones for clover_quda_*.
Unfortunately, this does not fully ""solve"" #517, but it does raise a new type of error there which might help resolve that too in the end.
The set of changes here has a drawback of course: the gauge and clover fields are reloaded much more frequently instead of just causing the missing precision to be instantiated from the existing double precision field on the device. Not sure how bad the additional overhead is compared to the time spent in a trajectory.
It is especially a complete waste of time to call reorder_gauge_toQuda so frequently because this should really only be called when g_gauge_field or any of the theta angles have actually changed. freeGaugeQuda() and loadGaugeQuda(..) do have to be called, however (at least for now, since that is our mechanism for ensuring that the field is up to date).","but it works. Also all the valgrind messages disappear. Thanks

Thanks for the test! It would be interesting to see how a profile with this code compares to the profiles that you generated a while ago.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,525,2022-02-17T11:03:32Z,2022-02-17T18:17:09Z,2022-04-27T10:04:50Z,MERGED,True,138,23,3,https://github.com/kostrzewa,partial workaround for some of the precision mismatch problems in QUDA interface,4,[],https://github.com/etmc/tmLQCD/pull/525,https://github.com/kostrzewa,6,https://github.com/etmc/tmLQCD/pull/525#issuecomment-1043273636,"We were not tracking the precisions of the gauge and clover fields present on the device and hence these were bound to lead to mismatches when switching from one monomial employing an operator and solver with a particular set of precisions to another monomial employing a different set of precisions (for cuda_prec, cuda_prec_sloppy, cuda_prec_refinement_sloppy, cuda_prec_precondition and cuda_prec_eigensolver and the corresponding ones for clover_quda_*.
Unfortunately, this does not fully ""solve"" #517, but it does raise a new type of error there which might help resolve that too in the end.
The set of changes here has a drawback of course: the gauge and clover fields are reloaded much more frequently instead of just causing the missing precision to be instantiated from the existing double precision field on the device. Not sure how bad the additional overhead is compared to the time spent in a trajectory.
It is especially a complete waste of time to call reorder_gauge_toQuda so frequently because this should really only be called when g_gauge_field or any of the theta angles have actually changed. freeGaugeQuda() and loadGaugeQuda(..) do have to be called, however (at least for now, since that is our mechanism for ensuring that the field is up to date).","Thanks for all the tests, valgrind runs and tentative workarounds @sunpho84 @simone-romiti @Marcogarofalo @pittlerf  Without the hints from these I would not have been able to fix this...",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,528,2022-02-23T11:30:19Z,2022-02-23T15:18:10Z,2022-03-17T18:49:30Z,MERGED,True,13,1,1,https://github.com/kostrzewa,fix online meaurements with QUDA when running the HMC,1,[],https://github.com/etmc/tmLQCD/pull/528,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/528,always set inv_param.dagger to make sure that we don't accidentally re-use the parameter from the previous solve,always set inv_param.dagger to make sure that we don't accidentally re-use the parameter from the previous solve,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,528,2022-02-23T11:30:19Z,2022-02-23T15:18:10Z,2022-03-17T18:49:30Z,MERGED,True,13,1,1,https://github.com/kostrzewa,fix online meaurements with QUDA when running the HMC,1,[],https://github.com/etmc/tmLQCD/pull/528,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/528#issuecomment-1048690109,always set inv_param.dagger to make sure that we don't accidentally re-use the parameter from the previous solve,Would appreciate a test of this.,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,528,2022-02-23T11:30:19Z,2022-02-23T15:18:10Z,2022-03-17T18:49:30Z,MERGED,True,13,1,1,https://github.com/kostrzewa,fix online meaurements with QUDA when running the HMC,1,[],https://github.com/etmc/tmLQCD/pull/528,https://github.com/Marcogarofalo,3,https://github.com/etmc/tmLQCD/pull/528#issuecomment-1048816121,always set inv_param.dagger to make sure that we don't accidentally re-use the parameter from the previous solve,"It works
/qbigwork/garofalo/test_tmLQCD_QUDA/online_meas$ grep residue slurm-86651.out
# Inversion done in 27 iterations, squared residue = 3.327151e-14!
# Inversion done in 24 iterations, squared residue = 2.201307e-14!",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,529,2022-02-23T19:02:10Z,2022-03-01T22:43:54Z,2022-03-17T18:49:29Z,MERGED,True,35,65,4,https://github.com/kostrzewa,change mechanism by which QUDA MG state's dependence on state of gauge (and clover) field is tracked,2,[],https://github.com/etmc/tmLQCD/pull/529,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/529,"This fixes one more bug due to which yet another instance of a dangling pointer in the MG Setup is resolved. This re-appared due to fixing another part of the logic through 221bf09).
As a nice side effect, it reduces the number of Setup updates that should occur during the HMC (the setup will only be updated when necessary).","This fixes one more bug due to which yet another instance of a dangling pointer in the MG Setup is resolved. This re-appared due to fixing another part of the logic through 221bf09).
As a nice side effect, it reduces the number of Setup updates that should occur during the HMC (the setup will only be updated when necessary).",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,529,2022-02-23T19:02:10Z,2022-03-01T22:43:54Z,2022-03-17T18:49:29Z,MERGED,True,35,65,4,https://github.com/kostrzewa,change mechanism by which QUDA MG state's dependence on state of gauge (and clover) field is tracked,2,[],https://github.com/etmc/tmLQCD/pull/529,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/529#issuecomment-1049113231,"This fixes one more bug due to which yet another instance of a dangling pointer in the MG Setup is resolved. This re-appared due to fixing another part of the logic through 221bf09).
As a nice side effect, it reduces the number of Setup updates that should occur during the HMC (the setup will only be updated when necessary).",@marcuspetschlies could you please test if this keeps the setup reuse as with 221bf09 ?(the setup should only be updated when necessary),True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,529,2022-02-23T19:02:10Z,2022-03-01T22:43:54Z,2022-03-17T18:49:29Z,MERGED,True,35,65,4,https://github.com/kostrzewa,change mechanism by which QUDA MG state's dependence on state of gauge (and clover) field is tracked,2,[],https://github.com/etmc/tmLQCD/pull/529,https://github.com/Marcogarofalo,3,https://github.com/etmc/tmLQCD/pull/529#issuecomment-1049923828,"This fixes one more bug due to which yet another instance of a dangling pointer in the MG Setup is resolved. This re-appared due to fixing another part of the logic through 221bf09).
As a nice side effect, it reduces the number of Setup updates that should occur during the HMC (the setup will only be updated when necessary).","Hi, I observe that with this commit it is necessary to add
BeginOperator CLOVER
  ...
  usesloppyprecision = single
EndOperator

when useexternalinverter = quda is set. while before it was working without specifying the precision",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,529,2022-02-23T19:02:10Z,2022-03-01T22:43:54Z,2022-03-17T18:49:29Z,MERGED,True,35,65,4,https://github.com/kostrzewa,change mechanism by which QUDA MG state's dependence on state of gauge (and clover) field is tracked,2,[],https://github.com/etmc/tmLQCD/pull/529,https://github.com/kostrzewa,4,https://github.com/etmc/tmLQCD/pull/529#issuecomment-1049932830,"This fixes one more bug due to which yet another instance of a dangling pointer in the MG Setup is resolved. This re-appared due to fixing another part of the logic through 221bf09).
As a nice side effect, it reduces the number of Setup updates that should occur during the HMC (the setup will only be updated when necessary).","Hi, I observe that with this commit it is necessary to add

can you elaborate on what you mean with ""necessary"" ? The MG should also work fully in double precision (albeit inefficiently).",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,529,2022-02-23T19:02:10Z,2022-03-01T22:43:54Z,2022-03-17T18:49:29Z,MERGED,True,35,65,4,https://github.com/kostrzewa,change mechanism by which QUDA MG state's dependence on state of gauge (and clover) field is tracked,2,[],https://github.com/etmc/tmLQCD/pull/529,https://github.com/Marcogarofalo,5,https://github.com/etmc/tmLQCD/pull/529#issuecomment-1049959620,"This fixes one more bug due to which yet another instance of a dangling pointer in the MG Setup is resolved. This re-appared due to fixing another part of the logic through 221bf09).
As a nice side effect, it reduces the number of Setup updates that should occur during the HMC (the setup will only be updated when necessary).","Nothing sorry, I was convinced that by default  usesloppyprecision = single, instead, I guess it is double=8. With double precision, it produces the error
# TM_QUDA: Time for loadCloverQuda 4.007330e-04 s level: 3 proc_id: 0 /HMC/correlators_measurement/invert_eo_quda/loadCloverQuda
# TM_QUDA: mu = 0.001200000000, kappa = 0.140065000000, csw = 1.740000000000
# TM_QUDA: using MG solver to invert operator with 2kappamu = 0.000336156000
# TM_QUDA: MG level 0, extent of (xyzt) dim 0: 8
# TM_QUDA: MG aggregation size set to: 1
# TM_QUDA: MG level 0, extent of (xyzt) dim 1: 8
# TM_QUDA: MG aggregation size set to: 2
# TM_QUDA: MG level 0, extent of (xyzt) dim 2: 8
# TM_QUDA: MG aggregation size set to: 2
# TM_QUDA: MG level 0, extent of (xyzt) dim 3: 4
# TM_QUDA: MG aggregation size set to: 2
# TM_QUDA: MG setting coarse mu scaling factor on level 0 to 1.000000
# TM_QUDA: MG setting coarse mu scaling factor on level 1 to 1.000000
# TM_QUDA: Destroying MG Preconditioner Setup
# TM_QUDA: Performing MG Preconditioner Setup for gauge_id: 6.001000
# TM_QUDA: Generating MG Setup with mu = 0.001199994860 instead of 0.001200000000
MG level 0 (GPU): ERROR: Precisions 4 8 do not match (/qbigwork/garofalo/quda/lib/coarse_op.cu:165 in calculateY())
 (rank 0, host lnode15.cluster.hiskp, lattice_field.h:795 in Precision_())

I notice this because I forgot to add  usesloppyprecision = single, I am not sure whether this should be addressed, maybe it is not relevant for physical applications",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,529,2022-02-23T19:02:10Z,2022-03-01T22:43:54Z,2022-03-17T18:49:29Z,MERGED,True,35,65,4,https://github.com/kostrzewa,change mechanism by which QUDA MG state's dependence on state of gauge (and clover) field is tracked,2,[],https://github.com/etmc/tmLQCD/pull/529,https://github.com/kostrzewa,6,https://github.com/etmc/tmLQCD/pull/529#issuecomment-1049969856,"This fixes one more bug due to which yet another instance of a dangling pointer in the MG Setup is resolved. This re-appared due to fixing another part of the logic through 221bf09).
As a nice side effect, it reduces the number of Setup updates that should occur during the HMC (the setup will only be updated when necessary).","I notice this because I forgot to add usesloppyprecision = single, I am not sure whether this should be addressed, maybe it is not relevant for physical applications

It's certainly a bug and may indicate that we are setting some of the precisions incorrectly. Thanks. I've created a new issue to track this --> #530",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,529,2022-02-23T19:02:10Z,2022-03-01T22:43:54Z,2022-03-17T18:49:29Z,MERGED,True,35,65,4,https://github.com/kostrzewa,change mechanism by which QUDA MG state's dependence on state of gauge (and clover) field is tracked,2,[],https://github.com/etmc/tmLQCD/pull/529,https://github.com/kostrzewa,7,https://github.com/etmc/tmLQCD/pull/529#issuecomment-1055938131,"This fixes one more bug due to which yet another instance of a dangling pointer in the MG Setup is resolved. This re-appared due to fixing another part of the logic through 221bf09).
As a nice side effect, it reduces the number of Setup updates that should occur during the HMC (the setup will only be updated when necessary).",@Finkenrath this will reduce the number of MG updates in the HMC compared to 221bf09,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,531,2022-03-03T17:25:12Z,2022-03-07T12:39:03Z,2022-03-07T12:39:04Z,MERGED,True,62,10,5,https://github.com/simone-romiti,Check monomials convergence,2,[],https://github.com/etmc/tmLQCD/pull/531,https://github.com/simone-romiti,1,https://github.com/etmc/tmLQCD/pull/531,"Reply to the issue #526 .
I added a global parameter BarrierMonomialsConvergence to be specified in the input file as ""yes"" or ""no"". The default is ""no"". The corresponding variable is g_barrier_monomials_convergence (==1 for ""yes"" and ==0 for ""no"").
If set to ""yes"" the convergence is checked for each monomial. When the returned number of iterations equals -1 , the program is aborted.
For reference: this is implemented with a conditional statement for each solve_*() function in tmLQCD/solver/monomial_solve.c which calls fatal_error() if the solver didn't converge and if g_barrier_monomials_convergence=1","Reply to the issue #526 .
I added a global parameter BarrierMonomialsConvergence to be specified in the input file as ""yes"" or ""no"". The default is ""no"". The corresponding variable is g_barrier_monomials_convergence (==1 for ""yes"" and ==0 for ""no"").
If set to ""yes"" the convergence is checked for each monomial. When the returned number of iterations equals -1 , the program is aborted.
For reference: this is implemented with a conditional statement for each solve_*() function in tmLQCD/solver/monomial_solve.c which calls fatal_error() if the solver didn't converge and if g_barrier_monomials_convergence=1",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,531,2022-03-03T17:25:12Z,2022-03-07T12:39:03Z,2022-03-07T12:39:04Z,MERGED,True,62,10,5,https://github.com/simone-romiti,Check monomials convergence,2,[],https://github.com/etmc/tmLQCD/pull/531,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/531#issuecomment-1060597080,"Reply to the issue #526 .
I added a global parameter BarrierMonomialsConvergence to be specified in the input file as ""yes"" or ""no"". The default is ""no"". The corresponding variable is g_barrier_monomials_convergence (==1 for ""yes"" and ==0 for ""no"").
If set to ""yes"" the convergence is checked for each monomial. When the returned number of iterations equals -1 , the program is aborted.
For reference: this is implemented with a conditional statement for each solve_*() function in tmLQCD/solver/monomial_solve.c which calls fatal_error() if the solver didn't converge and if g_barrier_monomials_convergence=1",Thanks! (note that I've changed the target branch). Could you also add a description of this option to the TeX-documentation?,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,531,2022-03-03T17:25:12Z,2022-03-07T12:39:03Z,2022-03-07T12:39:04Z,MERGED,True,62,10,5,https://github.com/simone-romiti,Check monomials convergence,2,[],https://github.com/etmc/tmLQCD/pull/531,https://github.com/simone-romiti,3,https://github.com/etmc/tmLQCD/pull/531#issuecomment-1060616805,"Reply to the issue #526 .
I added a global parameter BarrierMonomialsConvergence to be specified in the input file as ""yes"" or ""no"". The default is ""no"". The corresponding variable is g_barrier_monomials_convergence (==1 for ""yes"" and ==0 for ""no"").
If set to ""yes"" the convergence is checked for each monomial. When the returned number of iterations equals -1 , the program is aborted.
For reference: this is implemented with a conditional statement for each solve_*() function in tmLQCD/solver/monomial_solve.c which calls fatal_error() if the solver didn't converge and if g_barrier_monomials_convergence=1",Done! Please check if the explanation is clear enough.,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,533,2022-03-07T21:17:13Z,2022-03-08T10:17:34Z,2022-03-17T18:49:27Z,MERGED,True,17,4,2,https://github.com/kostrzewa,treat setup updates and refreshes differently from the point of view ,2,[],https://github.com/etmc/tmLQCD/pull/533,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/533,"tm_QudaMGSetupState_t
This should fix #532","tm_QudaMGSetupState_t
This should fix #532",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,533,2022-03-07T21:17:13Z,2022-03-08T10:17:34Z,2022-03-17T18:49:27Z,MERGED,True,17,4,2,https://github.com/kostrzewa,treat setup updates and refreshes differently from the point of view ,2,[],https://github.com/etmc/tmLQCD/pull/533,https://github.com/Marcogarofalo,2,https://github.com/etmc/tmLQCD/pull/533#issuecomment-1061182050,"tm_QudaMGSetupState_t
This should fix #532","Thank you, I am trying it on marconi100.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,534,2022-03-09T13:59:52Z,2022-03-10T09:39:33Z,2022-03-17T18:49:38Z,MERGED,True,3,1,1,https://github.com/Marcogarofalo,tables position within same section + caption,1,[],https://github.com/etmc/tmLQCD/pull/534,https://github.com/Marcogarofalo,1,https://github.com/etmc/tmLQCD/pull/534,"I found confusing in the profile tool the position of the tables

so I did two things:

Force the table to be placed in the same subsection;
Add a caption to the table.

the result is now the following","I found confusing in the profile tool the position of the tables

so I did two things:

Force the table to be placed in the same subsection;
Add a caption to the table.

the result is now the following",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,534,2022-03-09T13:59:52Z,2022-03-10T09:39:33Z,2022-03-17T18:49:38Z,MERGED,True,3,1,1,https://github.com/Marcogarofalo,tables position within same section + caption,1,[],https://github.com/etmc/tmLQCD/pull/534,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/534#issuecomment-1063854990,"I found confusing in the profile tool the position of the tables

so I did two things:

Force the table to be placed in the same subsection;
Add a caption to the table.

the result is now the following","looks good, thanks. I left it flexible because the size of the table can vary a lot, but I agree that this is better in any case",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,535,2022-03-10T19:27:44Z,2022-03-11T09:12:18Z,2022-03-17T18:49:37Z,MERGED,True,2,2,1,https://github.com/Marcogarofalo,print message only if g_proc_id==0,1,[],https://github.com/etmc/tmLQCD/pull/535,https://github.com/Marcogarofalo,1,https://github.com/etmc/tmLQCD/pull/535,,,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,535,2022-03-10T19:27:44Z,2022-03-11T09:12:18Z,2022-03-17T18:49:37Z,MERGED,True,2,2,1,https://github.com/Marcogarofalo,print message only if g_proc_id==0,1,[],https://github.com/etmc/tmLQCD/pull/535,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/535#issuecomment-1064918417,,"thanks, I missed that!",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,535,2022-03-10T19:27:44Z,2022-03-11T09:12:18Z,2022-03-17T18:49:37Z,MERGED,True,2,2,1,https://github.com/Marcogarofalo,print message only if g_proc_id==0,1,[],https://github.com/etmc/tmLQCD/pull/535,https://github.com/simone-romiti,3,https://github.com/etmc/tmLQCD/pull/535#issuecomment-1064920159,,Thank you Marco!,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,536,2022-03-13T15:59:21Z,2022-03-22T09:58:42Z,2022-04-27T10:04:48Z,MERGED,True,62,8,2,https://github.com/simone-romiti,Quda regenerate mg setup,11,[],https://github.com/etmc/tmLQCD/pull/536,https://github.com/simone-romiti,1,https://github.com/etmc/tmLQCD/pull/536,"Reply to the issue #527 .
Edits
I edited the quda_interface.c file as follows:

I created a function void forceRegenerateMGSetupQuda(const CompressionType compression) which regenerates the MG setup.

At the beginning _loadGaugeQuda() is called. For how it is implemented now, maybe it's redundant because this function is always called after one call of that function.
In order to destroy the MG setup, the same MG-related functions called in _endQuda() are used.
In order to regenerate the MG setup, the same MG-related functions called in _initQuda() are used.


This function is called inside each invert_*() function defined in that file, whenever one's using the MG and the latter didn't converge.
Any time the MG doesn't converge, the inversion is done one more time in order to check for possible instabilities. This is implemented through a global variable updated as the MG doesn't converge.

Note
We can think about adding a global parameter, to be specified in the input file, which limits the number of regenerations of the MG setup. Now the latter is implicitly set to 1.","Reply to the issue #527 .
Edits
I edited the quda_interface.c file as follows:

I created a function void forceRegenerateMGSetupQuda(const CompressionType compression) which regenerates the MG setup.

At the beginning _loadGaugeQuda() is called. For how it is implemented now, maybe it's redundant because this function is always called after one call of that function.
In order to destroy the MG setup, the same MG-related functions called in _endQuda() are used.
In order to regenerate the MG setup, the same MG-related functions called in _initQuda() are used.


This function is called inside each invert_*() function defined in that file, whenever one's using the MG and the latter didn't converge.
Any time the MG doesn't converge, the inversion is done one more time in order to check for possible instabilities. This is implemented through a global variable updated as the MG doesn't converge.

Note
We can think about adding a global parameter, to be specified in the input file, which limits the number of regenerations of the MG setup. Now the latter is implicitly set to 1.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,536,2022-03-13T15:59:21Z,2022-03-22T09:58:42Z,2022-04-27T10:04:48Z,MERGED,True,62,8,2,https://github.com/simone-romiti,Quda regenerate mg setup,11,[],https://github.com/etmc/tmLQCD/pull/536,https://github.com/Marcogarofalo,2,https://github.com/etmc/tmLQCD/pull/536#issuecomment-1066611557,"Reply to the issue #527 .
Edits
I edited the quda_interface.c file as follows:

I created a function void forceRegenerateMGSetupQuda(const CompressionType compression) which regenerates the MG setup.

At the beginning _loadGaugeQuda() is called. For how it is implemented now, maybe it's redundant because this function is always called after one call of that function.
In order to destroy the MG setup, the same MG-related functions called in _endQuda() are used.
In order to regenerate the MG setup, the same MG-related functions called in _initQuda() are used.


This function is called inside each invert_*() function defined in that file, whenever one's using the MG and the latter didn't converge.
Any time the MG doesn't converge, the inversion is done one more time in order to check for possible instabilities. This is implemented through a global variable updated as the MG doesn't converge.

Note
We can think about adding a global parameter, to be specified in the input file, which limits the number of regenerations of the MG setup. Now the latter is implicitly set to 1.",Maybe you want to merge this to quda_work_add_action instead of master branch,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,536,2022-03-13T15:59:21Z,2022-03-22T09:58:42Z,2022-04-27T10:04:48Z,MERGED,True,62,8,2,https://github.com/simone-romiti,Quda regenerate mg setup,11,[],https://github.com/etmc/tmLQCD/pull/536,https://github.com/simone-romiti,3,https://github.com/etmc/tmLQCD/pull/536#issuecomment-1066618027,"Reply to the issue #527 .
Edits
I edited the quda_interface.c file as follows:

I created a function void forceRegenerateMGSetupQuda(const CompressionType compression) which regenerates the MG setup.

At the beginning _loadGaugeQuda() is called. For how it is implemented now, maybe it's redundant because this function is always called after one call of that function.
In order to destroy the MG setup, the same MG-related functions called in _endQuda() are used.
In order to regenerate the MG setup, the same MG-related functions called in _initQuda() are used.


This function is called inside each invert_*() function defined in that file, whenever one's using the MG and the latter didn't converge.
Any time the MG doesn't converge, the inversion is done one more time in order to check for possible instabilities. This is implemented through a global variable updated as the MG doesn't converge.

Note
We can think about adding a global parameter, to be specified in the input file, which limits the number of regenerations of the MG setup. Now the latter is implicitly set to 1.","Maybe you want to merge this to quda_work_add_action instead of master branch

Yes, thanks",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,536,2022-03-13T15:59:21Z,2022-03-22T09:58:42Z,2022-04-27T10:04:48Z,MERGED,True,62,8,2,https://github.com/simone-romiti,Quda regenerate mg setup,11,[],https://github.com/etmc/tmLQCD/pull/536,https://github.com/kostrzewa,4,https://github.com/etmc/tmLQCD/pull/536#issuecomment-1067278322,"Reply to the issue #527 .
Edits
I edited the quda_interface.c file as follows:

I created a function void forceRegenerateMGSetupQuda(const CompressionType compression) which regenerates the MG setup.

At the beginning _loadGaugeQuda() is called. For how it is implemented now, maybe it's redundant because this function is always called after one call of that function.
In order to destroy the MG setup, the same MG-related functions called in _endQuda() are used.
In order to regenerate the MG setup, the same MG-related functions called in _initQuda() are used.


This function is called inside each invert_*() function defined in that file, whenever one's using the MG and the latter didn't converge.
Any time the MG doesn't converge, the inversion is done one more time in order to check for possible instabilities. This is implemented through a global variable updated as the MG doesn't converge.

Note
We can think about adding a global parameter, to be specified in the input file, which limits the number of regenerations of the MG setup. Now the latter is implicitly set to 1.","Thanks. I've cleaned things up a bit and added a local static variable to break out of the recursion. This seems to work as expected now. I've explicitly let an MG setup deteriorate by not evolving it with the gauge field and as the number of iterations begins to increase, the mechanism is triggered. The first time around, it is able to save the run. At the second occurence it fails and the program terminates:
GCR: Convergence at 48 iterations, L2 relative residual: iterated = 2.507958e-10, true = 2.507958e-10 (requested = 3.162278e-10)
GCR: Convergence at 52 iterations, L2 relative residual: iterated = 2.348466e-10, true = 2.348466e-10 (requested = 3.162278e-10)
GCR: Convergence at 52 iterations, L2 relative residual: iterated = 2.990532e-10, true = 2.990532e-10 (requested = 3.162278e-10)
GCR: Convergence at 59 iterations, L2 relative residual: iterated = 2.469045e-10, true = 2.469045e-10 (requested = 3.162278e-10)
GCR: Convergence at 67 iterations, L2 relative residual: iterated = 2.912129e-10, true = 2.912129e-10 (requested = 3.162278e-10)
GCR: Convergence at 75 iterations, L2 relative residual: iterated = 2.611657e-10, true = 2.611657e-10 (requested = 3.162278e-10)
GCR: Convergence at 96 iterations, L2 relative residual: iterated = 2.987194e-10, true = 2.987194e-10 (requested = 3.162278e-10)
GCR: Convergence at 110 iterations, L2 relative residual: iterated = 2.938478e-10, true = 2.938478e-10 (requested = 3.162278e-10)
GCR: Convergence at 147 iterations, L2 relative residual: iterated = 3.078089e-10, true = 3.078089e-10 (requested = 3.162278e-10)
GCR: Convergence at 169 iterations, L2 relative residual: iterated = 2.863158e-10, true = 2.863158e-10 (requested = 3.162278e-10)
GCR: Convergence at 126 iterations, L2 relative residual: iterated = 3.055091e-10, true = 3.055091e-10 (requested = 3.162278e-10)
GCR: Convergence at 151 iterations, L2 relative residual: iterated = 2.725082e-10, true = 2.725082e-10 (requested = 3.162278e-10)
GCR: Convergence at 161 iterations, L2 relative residual: iterated = 2.883943e-10, true = 2.883943e-10 (requested = 3.162278e-10)
GCR: Convergence at 207 iterations, L2 relative residual: iterated = 3.118657e-10, true = 3.118657e-10 (requested = 3.162278e-10)
### -> setup is regenerated here
GCR: Convergence at 34 iterations, L2 relative residual: iterated = 2.830836e-10, true = 2.830836e-10 (requested = 3.162278e-10)
GCR: Convergence at 37 iterations, L2 relative residual: iterated = 1.898408e-10, true = 1.898408e-10 (requested = 3.162278e-10)
GCR: Convergence at 28 iterations, L2 relative residual: iterated = 2.033467e-10, true = 2.033467e-10 (requested = 3.162278e-10)
GCR: Convergence at 29 iterations, L2 relative residual: iterated = 2.099869e-10, true = 2.099869e-10 (requested = 3.162278e-10)
### -> no convergence possible any more
GCR: Convergence at 300 iterations, L2 relative residual: iterated = 3.994108e-02, true = 3.994108e-02 (requested = 3.162278e-10)
GCR: Convergence at 300 iterations, L2 relative residual: iterated = 6.097005e-01, true = 6.097005e-01 (requested = 3.162278e-10)
GCR: Convergence at 300 iterations, L2 relative residual: iterated = 1.555925e-01, true = 1.555925e-01 (requested = 3.162278e-10)
GCR: Convergence at 300 iterations, L2 relative residual: iterated = 8.021428e-01, true = 8.021428e-01 (requested = 3.162278e-10)
### program terminates

The fact that the solves just after the setup regeneration work and the next four solves fail suggests to me that there is still a bit of a logic problem present. To be fair, however, this was a run with two monomials using the MG and we know that it's problematic when these have very different rho values.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,536,2022-03-13T15:59:21Z,2022-03-22T09:58:42Z,2022-04-27T10:04:48Z,MERGED,True,62,8,2,https://github.com/simone-romiti,Quda regenerate mg setup,11,[],https://github.com/etmc/tmLQCD/pull/536,https://github.com/kostrzewa,5,https://github.com/etmc/tmLQCD/pull/536#issuecomment-1071367326,"Reply to the issue #527 .
Edits
I edited the quda_interface.c file as follows:

I created a function void forceRegenerateMGSetupQuda(const CompressionType compression) which regenerates the MG setup.

At the beginning _loadGaugeQuda() is called. For how it is implemented now, maybe it's redundant because this function is always called after one call of that function.
In order to destroy the MG setup, the same MG-related functions called in _endQuda() are used.
In order to regenerate the MG setup, the same MG-related functions called in _initQuda() are used.


This function is called inside each invert_*() function defined in that file, whenever one's using the MG and the latter didn't converge.
Any time the MG doesn't converge, the inversion is done one more time in order to check for possible instabilities. This is implemented through a global variable updated as the MG doesn't converge.

Note
We can think about adding a global parameter, to be specified in the input file, which limits the number of regenerations of the MG setup. Now the latter is implicitly set to 1.","Okay, I fixed the issue that existed with at the end of my test there.
I've also replaced resetting the setup with refreshing it instead, which should be sufficient to make the MG work properly when it deteriorates. We'll see. Refreshing is much faster than resetting, of course.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,536,2022-03-13T15:59:21Z,2022-03-22T09:58:42Z,2022-04-27T10:04:48Z,MERGED,True,62,8,2,https://github.com/simone-romiti,Quda regenerate mg setup,11,[],https://github.com/etmc/tmLQCD/pull/536,https://github.com/kostrzewa,6,https://github.com/etmc/tmLQCD/pull/536#issuecomment-1072409296,"Reply to the issue #527 .
Edits
I edited the quda_interface.c file as follows:

I created a function void forceRegenerateMGSetupQuda(const CompressionType compression) which regenerates the MG setup.

At the beginning _loadGaugeQuda() is called. For how it is implemented now, maybe it's redundant because this function is always called after one call of that function.
In order to destroy the MG setup, the same MG-related functions called in _endQuda() are used.
In order to regenerate the MG setup, the same MG-related functions called in _initQuda() are used.


This function is called inside each invert_*() function defined in that file, whenever one's using the MG and the latter didn't converge.
Any time the MG doesn't converge, the inversion is done one more time in order to check for possible instabilities. This is implemented through a global variable updated as the MG doesn't converge.

Note
We can think about adding a global parameter, to be specified in the input file, which limits the number of regenerations of the MG setup. Now the latter is implicitly set to 1.",@simone-romiti will you be able to run some tests of this? I don't know if I caught all possible ways this can go wrong...,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,536,2022-03-13T15:59:21Z,2022-03-22T09:58:42Z,2022-04-27T10:04:48Z,MERGED,True,62,8,2,https://github.com/simone-romiti,Quda regenerate mg setup,11,[],https://github.com/etmc/tmLQCD/pull/536,https://github.com/simone-romiti,7,https://github.com/etmc/tmLQCD/pull/536#issuecomment-1074455940,"Reply to the issue #527 .
Edits
I edited the quda_interface.c file as follows:

I created a function void forceRegenerateMGSetupQuda(const CompressionType compression) which regenerates the MG setup.

At the beginning _loadGaugeQuda() is called. For how it is implemented now, maybe it's redundant because this function is always called after one call of that function.
In order to destroy the MG setup, the same MG-related functions called in _endQuda() are used.
In order to regenerate the MG setup, the same MG-related functions called in _initQuda() are used.


This function is called inside each invert_*() function defined in that file, whenever one's using the MG and the latter didn't converge.
Any time the MG doesn't converge, the inversion is done one more time in order to check for possible instabilities. This is implemented through a global variable updated as the MG doesn't converge.

Note
We can think about adding a global parameter, to be specified in the input file, which limits the number of regenerations of the MG setup. Now the latter is implicitly set to 1.","I've tested your solution and it works as expected also for me.
For reference, I did it with the help of ad hoc static int variables here and there as follows:

I forced the non-convergence editing the line 
  
    
      tmLQCD/quda_interface.c
    
    
         Line 2190
      in
      b061909
    
  
  
    

        
          
           if (iterations >= max_iter) { 
        
    
  

 in order to check that the regeneration of the MG is done only once. Namely, the program doesn't enter this scope twice: 
  
    
      tmLQCD/quda_interface.c
    
    
         Line 2198
      in
      b061909
    
  
  
    

        
          
           if( quda_mg_setup_was_force_refreshed == 0 ){ 
        
    
  

 .
I did also a separate test where I forced the non-convergence after the first failure of the MG and consequent regeneration of the MG, editing the line 
  
    
      tmLQCD/quda_interface.c
    
    
         Line 2208
      in
      b061909
    
  
  
    

        
          
           if (ret_value >= max_iter) { 
        
    
  

 . The program aborts correctly.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,537,2022-03-24T19:50:25Z,,2022-04-25T10:21:23Z,OPEN,False,1136,7,9,https://github.com/kostrzewa,"automatic tuning of (QUDA)-MG parameters [WIP, DO NOT MERGE]",11,['DO NOT MERGE'],https://github.com/etmc/tmLQCD/pull/537,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/537,started work on a simple algorithm to automatically tune the (QUDA)-MG parameters which can be tuned without rebuilding the setup,started work on a simple algorithm to automatically tune the (QUDA)-MG parameters which can be tuned without rebuilding the setup,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,537,2022-03-24T19:50:25Z,,2022-04-25T10:21:23Z,OPEN,False,1136,7,9,https://github.com/kostrzewa,"automatic tuning of (QUDA)-MG parameters [WIP, DO NOT MERGE]",11,['DO NOT MERGE'],https://github.com/etmc/tmLQCD/pull/537,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/537#issuecomment-1078082800,started work on a simple algorithm to automatically tune the (QUDA)-MG parameters which can be tuned without rebuilding the setup,"The preliminary idea for the input is as follows but this has to be fine-tuned depending how the algorithm will turn out in the end:
BeginExternalInverter QUDA
  Pipeline = 24
  gcrNkrylov = 24
  MGNumberOfLevels = 3
  MGNumberOfVectors = 24, 32
  MGSetupSolver = cg
  MGSetup2KappaMu = 0.000224102400
  MGVerbosity = summarize, silent, silent
  MGSetupSolverTolerance = 5e-7, 5e-7
  MGSetupMaxSolverIterations = 1500, 1500
  MGCoarseSolverType = gcr, gcr, cagcr
  MGSmootherType = cagcr, cagcr, cagcr
  MGBlockSizesX = 4,3
  MGBlockSizesY = 4,3
  MGBlockSizesZ = 3,2
  MGBlockSizesT = 4,2
  
  MGCoarseMuFactor = 1.0, 1.0, 20.0
  MGCoarseMaxSolverIterations = 50, 50, 50
  MgCoarseSolverTolerance = 0.1, 0.1, 0.1
  MGSmootherPostIterations = 2, 2, 2
  MGSmootherPreIterations = 0, 0, 0
  MGSmootherTolerance = 0.1, 0.1, 0.1
  MGOverUnderRelaxationFactor = 0.85, 0.85, 0.85
  
EndExternalInverter

BeginTuneMGParams QUDA
  MGCoarseMuFactorSteps = 10, 10, 10
  MGCoarseMuFactorDelta = 0.1, 0.2, 5

  MGCoarseMaxSolverIterationsSteps = 10, 10, 10
  MGCoarseMaxSolverIterationsDelta = -5, -5, -5

  MGCoarseSolverToleranceSteps = 10, 10, 10
  MGCoarseSolverToleranceDelta = 0.05, 0.05, 0.05

  MGSmootherPreIterationsSteps = 4, 4, 4
  MGSmootherPreIterationsDelta = 1, 1, 1

  MGSmootherPostIterationsSteps = 4, 4, 4
  MGSmootherPostIterationsDelta = 1, 1, 1

  MGSmootherToleranceSteps = 4, 4, 4
  MGSmootherToleranceDelta = 0.1, 0.1, 0.1

  MGOverUnderRelaxationFactorSteps = 4, 4, 4
  MGOverUnderRelaxationFactorDelta = 0.05, 0.05, 0.05

  MGTuningIterations = 1000

  # when in a particular tuning step the improvement is less than 1%, we
  # move on to the next parameter to be tuned
  MGTuningTolerance = 0.99
EndTuneMGParams


There may be some adaptive process added to dynamically reduce the search space if certain parameter changes don't affect the tts.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,537,2022-03-24T19:50:25Z,,2022-04-25T10:21:23Z,OPEN,False,1136,7,9,https://github.com/kostrzewa,"automatic tuning of (QUDA)-MG parameters [WIP, DO NOT MERGE]",11,['DO NOT MERGE'],https://github.com/etmc/tmLQCD/pull/537,https://github.com/kostrzewa,3,https://github.com/etmc/tmLQCD/pull/537#issuecomment-1079357328,started work on a simple algorithm to automatically tune the (QUDA)-MG parameters which can be tuned without rebuilding the setup,"I will probably change the input format such that one doesn't specify min/max and a number of steps but a ""delta"" for each parameter and level and a number of steps that this delta should be applied for
The current ""algorithm"" (I use the word very cautiously) can start with a completely useless setup which doesn't converge and finds something which does. Unfortunately, it doesn't yet find a better minimum than I can find by hand. However, I've tested this only on small lattices (16c32 and 24c48, albeit at the physical point) and I suspect that it will work better on larger lattices.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,537,2022-03-24T19:50:25Z,,2022-04-25T10:21:23Z,OPEN,False,1136,7,9,https://github.com/kostrzewa,"automatic tuning of (QUDA)-MG parameters [WIP, DO NOT MERGE]",11,['DO NOT MERGE'],https://github.com/etmc/tmLQCD/pull/537,https://github.com/kostrzewa,4,https://github.com/etmc/tmLQCD/pull/537#issuecomment-1079900315,started work on a simple algorithm to automatically tune the (QUDA)-MG parameters which can be tuned without rebuilding the setup,"Funnily enough, this actually works and seems to find parameter sets that I would have never considered. For example, on cA211.12.48, this is a parameter set that it evolves to:
QUDA-MG param tuner: BEST SET OF PARAMETERS
-------------------------------------------
             mg_mu_factor: (1.000000, 3.000000, 27.000000)
 mg_coarse_solver_maxiter: (20, 10, 50)
     mg_coarse_solver_tol: (0.200000, 0.400000, 0.200000)
               mg_nu_post: (6, 6, 8)
                mg_nu_pre: (0, 4, 2)
          mg_smoother_tol: (0.200000, 0.200000, 0.100000)
                 mg_omega: (0.950000, 1.050000, 0.850000)
Timing: 1.989135, Iters: 51
-------------------------------------------",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,538,2022-04-06T06:31:53Z,2022-04-06T16:04:42Z,2022-04-27T10:04:53Z,MERGED,True,1,1,1,https://github.com/Finkenrath,Fixed overflow in printout of rectan-term to output.data (appears for,1,[],https://github.com/etmc/tmLQCD/pull/538,https://github.com/Finkenrath,1,https://github.com/etmc/tmLQCD/pull/538,"Normalisation factor for rectangular term is not converted before division. Leads to an overflow, when lattice is of size 112x112x112x224.","Normalisation factor for rectangular term is not converted before division. Leads to an overflow, when lattice is of size 112x112x112x224.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,538,2022-04-06T06:31:53Z,2022-04-06T16:04:42Z,2022-04-27T10:04:53Z,MERGED,True,1,1,1,https://github.com/Finkenrath,Fixed overflow in printout of rectan-term to output.data (appears for,1,[],https://github.com/etmc/tmLQCD/pull/538,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/538#issuecomment-1090443510,"Normalisation factor for rectangular term is not converted before division. Leads to an overflow, when lattice is of size 112x112x112x224.",thanks!,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,539,2022-04-13T15:27:34Z,2022-04-25T10:17:35Z,2022-04-27T10:04:47Z,MERGED,True,41,10,7,https://github.com/simone-romiti,nstore_counter not hidden,2,[],https://github.com/etmc/tmLQCD/pull/539,https://github.com/simone-romiti,1,https://github.com/etmc/tmLQCD/pull/539,"Please see d197c0c.
I tested this in a simple case and works as expected.","Please see d197c0c.
I tested this in a simple case and works as expected.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,541,2022-05-19T13:33:33Z,2022-05-20T06:12:39Z,2022-05-20T16:38:18Z,MERGED,True,36,67,1,https://github.com/simone-romiti,specify quda backend,4,[],https://github.com/etmc/tmLQCD/pull/541,https://github.com/simone-romiti,1,https://github.com/etmc/tmLQCD/pull/541,in progress: changes to configure.in so that we can support both cuda and hip backends for quda.,in progress: changes to configure.in so that we can support both cuda and hip backends for quda.,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,541,2022-05-19T13:33:33Z,2022-05-20T06:12:39Z,2022-05-20T16:38:18Z,MERGED,True,36,67,1,https://github.com/simone-romiti,specify quda backend,4,[],https://github.com/etmc/tmLQCD/pull/541,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/541#issuecomment-1133037097,in progress: changes to configure.in so that we can support both cuda and hip backends for quda.,"I merged #542 after being told:

I've done a test linking with CUDA on marconi100 and run a successful job.

At what time does it complain about libcublas missing?",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,541,2022-05-19T13:33:33Z,2022-05-20T06:12:39Z,2022-05-20T16:38:18Z,MERGED,True,36,67,1,https://github.com/simone-romiti,specify quda backend,4,[],https://github.com/etmc/tmLQCD/pull/541,https://github.com/simone-romiti,3,https://github.com/etmc/tmLQCD/pull/541#issuecomment-1133075272,in progress: changes to configure.in so that we can support both cuda and hip backends for quda.,"It complains for libblas. If I simply launch the hmc_tm executable I get:
/m100_work/INF22_lqcd123_0/romiti/tmLQCD/build/hmc_tm: error while loading shared libraries: libblas.so: cannot open shared object file: No such file or directory
But, oddly, if I launch the hmc with the example in /m100_work/INF22_lqcd123_0/romiti/runs/test_1 it works. There I do:
./salloc.sh and when I'm the node I run ./do_run.sh",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,541,2022-05-19T13:33:33Z,2022-05-20T06:12:39Z,2022-05-20T16:38:18Z,MERGED,True,36,67,1,https://github.com/simone-romiti,specify quda backend,4,[],https://github.com/etmc/tmLQCD/pull/541,https://github.com/kostrzewa,4,https://github.com/etmc/tmLQCD/pull/541#issuecomment-1133106045,in progress: changes to configure.in so that we can support both cuda and hip backends for quda.,"Do you do
module load gnu/8.4.0  blas/3.8.0--gnu--8.4.0  spectrum_mpi lapack/3.9.0--gnu--8.4.0

when running interactively?",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,541,2022-05-19T13:33:33Z,2022-05-20T06:12:39Z,2022-05-20T16:38:18Z,MERGED,True,36,67,1,https://github.com/simone-romiti,specify quda backend,4,[],https://github.com/etmc/tmLQCD/pull/541,https://github.com/kostrzewa,5,https://github.com/etmc/tmLQCD/pull/541#issuecomment-1133107024,in progress: changes to configure.in so that we can support both cuda and hip backends for quda.,note that it complains about libblas and not libcublas,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,542,2022-05-19T16:13:10Z,2022-05-20T06:12:21Z,2022-05-20T06:12:21Z,MERGED,True,32,100,1,https://github.com/kostrzewa,move checking for CUDA or HIP libraries outside of the QUDA config block,2,[],https://github.com/etmc/tmLQCD/pull/542,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/542,This seems to work for me to link QUDA with CUDA. I haven't tried QUDA with HIP yet.,This seems to work for me to link QUDA with CUDA. I haven't tried QUDA with HIP yet.,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,542,2022-05-19T16:13:10Z,2022-05-20T06:12:21Z,2022-05-20T06:12:21Z,MERGED,True,32,100,1,https://github.com/kostrzewa,move checking for CUDA or HIP libraries outside of the QUDA config block,2,[],https://github.com/etmc/tmLQCD/pull/542,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/542#issuecomment-1132014757,This seems to work for me to link QUDA with CUDA. I haven't tried QUDA with HIP yet.,"I've updated https://notes.desy.de/HJyYWNj1Rb-G7-ojjqDNWQ?view#Compiling-tmLQCD and with this, I can compile and link a version of hmc_tm which at least starts up. It then fails for yet unknown reasons with segfaults in MPI functions -> #jsc-amd-mpi channel in the Hackathon JuChat",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,542,2022-05-19T16:13:10Z,2022-05-20T06:12:21Z,2022-05-20T06:12:21Z,MERGED,True,32,100,1,https://github.com/kostrzewa,move checking for CUDA or HIP libraries outside of the QUDA config block,2,[],https://github.com/etmc/tmLQCD/pull/542,https://github.com/kostrzewa,3,https://github.com/etmc/tmLQCD/pull/542#issuecomment-1132029335,This seems to work for me to link QUDA with CUDA. I haven't tried QUDA with HIP yet.,See /p/project/fssh/kostrzewa2/build/dc-mi200/stage_2022/gcc_11_2_0/openmpi_4_1_2/tmLQCD.quda_work_add_actions_different_backends if you can acces it.,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,542,2022-05-19T16:13:10Z,2022-05-20T06:12:21Z,2022-05-20T06:12:21Z,MERGED,True,32,100,1,https://github.com/kostrzewa,move checking for CUDA or HIP libraries outside of the QUDA config block,2,[],https://github.com/etmc/tmLQCD/pull/542,https://github.com/simone-romiti,4,https://github.com/etmc/tmLQCD/pull/542#issuecomment-1132159178,This seems to work for me to link QUDA with CUDA. I haven't tried QUDA with HIP yet.,I've done a test linking with CUDA on marconi100 and run a successful job.,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,542,2022-05-19T16:13:10Z,2022-05-20T06:12:21Z,2022-05-20T06:12:21Z,MERGED,True,32,100,1,https://github.com/kostrzewa,move checking for CUDA or HIP libraries outside of the QUDA config block,2,[],https://github.com/etmc/tmLQCD/pull/542,https://github.com/kostrzewa,5,https://github.com/etmc/tmLQCD/pull/542#issuecomment-1132512181,This seems to work for me to link QUDA with CUDA. I haven't tried QUDA with HIP yet.,"Perfect, thanks. I can also confirm that it works on dc-mi200",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,543,2022-05-27T12:56:45Z,,2022-05-27T15:42:25Z,OPEN,False,19,25530,43,https://github.com/kostrzewa,remove legacy GPU support,1,[],https://github.com/etmc/tmLQCD/pull/543,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/543,"The presence of both legacy GPU code and the QUDA interface is confusing, especially since the former is completely unmaintained. This PR removes the legacy code completely.","The presence of both legacy GPU code and the QUDA interface is confusing, especially since the former is completely unmaintained. This PR removes the legacy code completely.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,543,2022-05-27T12:56:45Z,,2022-05-27T15:42:25Z,OPEN,False,19,25530,43,https://github.com/kostrzewa,remove legacy GPU support,1,[],https://github.com/etmc/tmLQCD/pull/543,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/543#issuecomment-1139631225,"The presence of both legacy GPU code and the QUDA interface is confusing, especially since the former is completely unmaintained. This PR removes the legacy code completely.","@Marcogarofalo @simone-romiti I think I got all remnants of the legacy GPU code, it would be great if you could take a look, however.
@urbach Do you agree with the complete removal of the legacy GPU code?",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,543,2022-05-27T12:56:45Z,,2022-05-27T15:42:25Z,OPEN,False,19,25530,43,https://github.com/kostrzewa,remove legacy GPU support,1,[],https://github.com/etmc/tmLQCD/pull/543,https://github.com/urbach,3,https://github.com/etmc/tmLQCD/pull/543#issuecomment-1139735396,"The presence of both legacy GPU code and the QUDA interface is confusing, especially since the former is completely unmaintained. This PR removes the legacy code completely.","@Marcogarofalo @simone-romiti I think I got all remnants of the legacy GPU code, it would be great if you could take a look, however.

 @urbach Do you agree with the complete removal of the legacy GPU code?
definitly!",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,544,2022-06-03T06:12:40Z,,2022-06-03T14:26:36Z,OPEN,False,4,3,1,https://github.com/kostrzewa,change logic for setting MG param coarse_grid_solution_type,2,[],https://github.com/etmc/tmLQCD/pull/544,https://github.com/kostrzewa,1,https://github.com/etmc/tmLQCD/pull/544,"When I was adding the HMC additions, I accidentally messed up the logic for coarse_grid_solution_type and was injecting a full field on all intermediate and coarse levels 
This PR significantly improves MG performance (4 Booster nodes, 64c128 lattice, physical point) and will also restore analysis performance to previous levels:
old
GCR: Convergence at 53 iterations, L2 relative residual: iterated = 7.315033e-10, true = 7.315033e-10 (requested = 1.000000e-09)
# TM_QUDA: Time for invertQuda 1.596819e+01 s level: 3 proc_id: 0 /HMC/correlators_measurement/invert_eo_quda/invertQuda
# TM_QUDA: Done: 53 iter / 15.7261 secs = 25234.6 Gflops
# TM_QUDA: Time for reorder_spinor_fromQuda 6.752734e-02 s level: 3 proc_id: 0 /HMC/correlators_measurement/invert_eo_quda/reorder_spinor_fromQuda
# TM_QUDA: Time for invert_eo_quda 2.134693e+01 s level: 2 proc_id: 0 /HMC/correlators_measurement/invert_eo_quda
# Inversion done in 53 iterations, squared residue = 9.589332e-13!

new
# TM_QUDA: Time for invertQuda 3.727005e+00 s level: 3 proc_id: 0 /HMC/correlators_measurement/invert_eo_quda/invertQuda
# TM_QUDA: Done: 33 iter / 3.47978 secs = 24770.2 Gflops
# TM_QUDA: Time for reorder_spinor_fromQuda 7.029620e-02 s level: 3 proc_id: 0 /HMC/correlators_measurement/invert_eo_quda/reorder_spinor_fromQuda
# TM_QUDA: Time for invert_eo_quda 3.914286e+00 s level: 2 proc_id: 0 /HMC/correlators_measurement/invert_eo_quda
# Inversion done in 33 iterations, squared residue = 1.686466e-12!

Just need to make sure that it doesn't break anything, but this will help us quite a bit...","When I was adding the HMC additions, I accidentally messed up the logic for coarse_grid_solution_type and was injecting a full field on all intermediate and coarse levels 
This PR significantly improves MG performance (4 Booster nodes, 64c128 lattice, physical point) and will also restore analysis performance to previous levels:
old
GCR: Convergence at 53 iterations, L2 relative residual: iterated = 7.315033e-10, true = 7.315033e-10 (requested = 1.000000e-09)
# TM_QUDA: Time for invertQuda 1.596819e+01 s level: 3 proc_id: 0 /HMC/correlators_measurement/invert_eo_quda/invertQuda
# TM_QUDA: Done: 53 iter / 15.7261 secs = 25234.6 Gflops
# TM_QUDA: Time for reorder_spinor_fromQuda 6.752734e-02 s level: 3 proc_id: 0 /HMC/correlators_measurement/invert_eo_quda/reorder_spinor_fromQuda
# TM_QUDA: Time for invert_eo_quda 2.134693e+01 s level: 2 proc_id: 0 /HMC/correlators_measurement/invert_eo_quda
# Inversion done in 53 iterations, squared residue = 9.589332e-13!

new
# TM_QUDA: Time for invertQuda 3.727005e+00 s level: 3 proc_id: 0 /HMC/correlators_measurement/invert_eo_quda/invertQuda
# TM_QUDA: Done: 33 iter / 3.47978 secs = 24770.2 Gflops
# TM_QUDA: Time for reorder_spinor_fromQuda 7.029620e-02 s level: 3 proc_id: 0 /HMC/correlators_measurement/invert_eo_quda/reorder_spinor_fromQuda
# TM_QUDA: Time for invert_eo_quda 3.914286e+00 s level: 2 proc_id: 0 /HMC/correlators_measurement/invert_eo_quda
# Inversion done in 33 iterations, squared residue = 1.686466e-12!

Just need to make sure that it doesn't break anything, but this will help us quite a bit...",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,544,2022-06-03T06:12:40Z,,2022-06-03T14:26:36Z,OPEN,False,4,3,1,https://github.com/kostrzewa,change logic for setting MG param coarse_grid_solution_type,2,[],https://github.com/etmc/tmLQCD/pull/544,https://github.com/kostrzewa,2,https://github.com/etmc/tmLQCD/pull/544#issuecomment-1145623757,"When I was adding the HMC additions, I accidentally messed up the logic for coarse_grid_solution_type and was injecting a full field on all intermediate and coarse levels 
This PR significantly improves MG performance (4 Booster nodes, 64c128 lattice, physical point) and will also restore analysis performance to previous levels:
old
GCR: Convergence at 53 iterations, L2 relative residual: iterated = 7.315033e-10, true = 7.315033e-10 (requested = 1.000000e-09)
# TM_QUDA: Time for invertQuda 1.596819e+01 s level: 3 proc_id: 0 /HMC/correlators_measurement/invert_eo_quda/invertQuda
# TM_QUDA: Done: 53 iter / 15.7261 secs = 25234.6 Gflops
# TM_QUDA: Time for reorder_spinor_fromQuda 6.752734e-02 s level: 3 proc_id: 0 /HMC/correlators_measurement/invert_eo_quda/reorder_spinor_fromQuda
# TM_QUDA: Time for invert_eo_quda 2.134693e+01 s level: 2 proc_id: 0 /HMC/correlators_measurement/invert_eo_quda
# Inversion done in 53 iterations, squared residue = 9.589332e-13!

new
# TM_QUDA: Time for invertQuda 3.727005e+00 s level: 3 proc_id: 0 /HMC/correlators_measurement/invert_eo_quda/invertQuda
# TM_QUDA: Done: 33 iter / 3.47978 secs = 24770.2 Gflops
# TM_QUDA: Time for reorder_spinor_fromQuda 7.029620e-02 s level: 3 proc_id: 0 /HMC/correlators_measurement/invert_eo_quda/reorder_spinor_fromQuda
# TM_QUDA: Time for invert_eo_quda 3.914286e+00 s level: 2 proc_id: 0 /HMC/correlators_measurement/invert_eo_quda
# Inversion done in 33 iterations, squared residue = 1.686466e-12!

Just need to make sure that it doesn't break anything, but this will help us quite a bit...","One problem that this still has (and in fact exacerbates) is an excessive iteration count for the heatbath of determinant ratios with larger mass shifts. This is of course completely unreasonable and will have to be fixed somehow... The code with full field injection behaves more benignly in this regard with the iteration count only going up to about 60 or so instead of over 350...
cloverdetratio3light
# TM_QUDA: Reusing MG Preconditioner Setup for gauge_id: 4.000000
# TM_QUDA: Time for reorder_spinor_eo_toQuda 2.656285e-02 s level: 4 proc_id: 0 /HMC/cloverdetratio3light:cloverdetratio_heatbath/solve_deg
enerate/invert_eo_degenerate_quda/reorder_spinor_eo_toQuda
GCR: Convergence at 33 iterations, L2 relative residual: iterated = 2.850317e-11, true = 2.850317e-11 (requested = 3.162278e-11)
# TM_QUDA: Time for invertQuda 3.041126e+00 s level: 4 proc_id: 0 /HMC/cloverdetratio3light:cloverdetratio_heatbath/solve_degenerate/invert
_eo_degenerate_quda/invertQuda
# TM_QUDA: Time for reorder_spinor_eo_fromQuda 3.097843e-02 s level: 4 proc_id: 0 /HMC/cloverdetratio3light:cloverdetratio_heatbath/solve_d
egenerate/invert_eo_degenerate_quda/reorder_spinor_eo_fromQuda
# TM_QUDA: QpQm solve done: 33 iter / 2.90188 secs = 23224.8 Gflops
# TM_QUDA: Time for invert_eo_degenerate_quda 3.098766e+00 s level: 3 proc_id: 0 /HMC/cloverdetratio3light:cloverdetratio_heatbath/solve_de
generate/invert_eo_degenerate_quda
# : Time for solve_degenerate 3.113027e+00 s level: 2 proc_id: 0 /HMC/cloverdetratio3light:cloverdetratio_heatbath/solve_degenerate
# : Time for cloverdetratio_heatbath 6.547380e+00 s level: 1 proc_id: 0 /HMC/cloverdetratio3light:cloverdetratio_heatbath


cloverdetratio2light
# TM_QUDA: Time for MG_Preconditioner_Setup_Update 5.104773e+00 s level: 4 proc_id: 0 /HMC/cloverdetratio2light:cloverdetratio_heatbath/sol
ve_degenerate/invert_eo_degenerate_quda/MG_Preconditioner_Setup_Update
# TM_QUDA: Time for reorder_spinor_eo_toQuda 2.470451e-02 s level: 4 proc_id: 0 /HMC/cloverdetratio2light:cloverdetratio_heatbath/solve_deg
enerate/invert_eo_degenerate_quda/reorder_spinor_eo_toQuda
GCR: Convergence at 358 iterations, L2 relative residual: iterated = 3.082474e-11, true = 3.082474e-11 (requested = 3.162278e-11)
# TM_QUDA: Time for invertQuda 7.751718e+01 s level: 4 proc_id: 0 /HMC/cloverdetratio2light:cloverdetratio_heatbath/solve_degenerate/invert
_eo_degenerate_quda/invertQuda
# TM_QUDA: Time for reorder_spinor_eo_fromQuda 3.110367e-02 s level: 4 proc_id: 0 /HMC/cloverdetratio2light:cloverdetratio_heatbath/solve_d
egenerate/invert_eo_degenerate_quda/reorder_spinor_eo_fromQuda
# TM_QUDA: QpQm solve done: 358 iter / 77.3822 secs = 23896.5 Gflops
# TM_QUDA: Time for invert_eo_degenerate_quda 8.297669e+01 s level: 3 proc_id: 0 /HMC/cloverdetratio2light:cloverdetratio_heatbath/solve_de
generate/invert_eo_degenerate_quda
# : Time for solve_degenerate 8.299070e+01 s level: 2 proc_id: 0 /HMC/cloverdetratio2light:cloverdetratio_heatbath/solve_degenerate
# : Time for cloverdetratio_heatbath 8.642201e+01 s level: 1 proc_id: 0 /HMC/cloverdetratio2light:cloverdetratio_heatbath

This increase to over 80 seconds spent in the heatbath of this heavier monomial does not negate the gain from the derivative, however. Still, fixing this will be a nice optimisation!",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,544,2022-06-03T06:12:40Z,,2022-06-03T14:26:36Z,OPEN,False,4,3,1,https://github.com/kostrzewa,change logic for setting MG param coarse_grid_solution_type,2,[],https://github.com/etmc/tmLQCD/pull/544,https://github.com/kostrzewa,3,https://github.com/etmc/tmLQCD/pull/544#issuecomment-1145627228,"When I was adding the HMC additions, I accidentally messed up the logic for coarse_grid_solution_type and was injecting a full field on all intermediate and coarse levels 
This PR significantly improves MG performance (4 Booster nodes, 64c128 lattice, physical point) and will also restore analysis performance to previous levels:
old
GCR: Convergence at 53 iterations, L2 relative residual: iterated = 7.315033e-10, true = 7.315033e-10 (requested = 1.000000e-09)
# TM_QUDA: Time for invertQuda 1.596819e+01 s level: 3 proc_id: 0 /HMC/correlators_measurement/invert_eo_quda/invertQuda
# TM_QUDA: Done: 53 iter / 15.7261 secs = 25234.6 Gflops
# TM_QUDA: Time for reorder_spinor_fromQuda 6.752734e-02 s level: 3 proc_id: 0 /HMC/correlators_measurement/invert_eo_quda/reorder_spinor_fromQuda
# TM_QUDA: Time for invert_eo_quda 2.134693e+01 s level: 2 proc_id: 0 /HMC/correlators_measurement/invert_eo_quda
# Inversion done in 53 iterations, squared residue = 9.589332e-13!

new
# TM_QUDA: Time for invertQuda 3.727005e+00 s level: 3 proc_id: 0 /HMC/correlators_measurement/invert_eo_quda/invertQuda
# TM_QUDA: Done: 33 iter / 3.47978 secs = 24770.2 Gflops
# TM_QUDA: Time for reorder_spinor_fromQuda 7.029620e-02 s level: 3 proc_id: 0 /HMC/correlators_measurement/invert_eo_quda/reorder_spinor_fromQuda
# TM_QUDA: Time for invert_eo_quda 3.914286e+00 s level: 2 proc_id: 0 /HMC/correlators_measurement/invert_eo_quda
# Inversion done in 33 iterations, squared residue = 1.686466e-12!

Just need to make sure that it doesn't break anything, but this will help us quite a bit...","@marcuspetschlies if you remember when you were testing analysis workloads with the quda_work_add_actions branch you were finding crazy slow behaviour of the MG compared to the quda_work branch. We suspected an issue in QUDA (and there were also a couple of issues there), but THIS was the actual and main reason...",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,544,2022-06-03T06:12:40Z,,2022-06-03T14:26:36Z,OPEN,False,4,3,1,https://github.com/kostrzewa,change logic for setting MG param coarse_grid_solution_type,2,[],https://github.com/etmc/tmLQCD/pull/544,https://github.com/Finkenrath,4,https://github.com/etmc/tmLQCD/pull/544#issuecomment-1145639036,"When I was adding the HMC additions, I accidentally messed up the logic for coarse_grid_solution_type and was injecting a full field on all intermediate and coarse levels 
This PR significantly improves MG performance (4 Booster nodes, 64c128 lattice, physical point) and will also restore analysis performance to previous levels:
old
GCR: Convergence at 53 iterations, L2 relative residual: iterated = 7.315033e-10, true = 7.315033e-10 (requested = 1.000000e-09)
# TM_QUDA: Time for invertQuda 1.596819e+01 s level: 3 proc_id: 0 /HMC/correlators_measurement/invert_eo_quda/invertQuda
# TM_QUDA: Done: 53 iter / 15.7261 secs = 25234.6 Gflops
# TM_QUDA: Time for reorder_spinor_fromQuda 6.752734e-02 s level: 3 proc_id: 0 /HMC/correlators_measurement/invert_eo_quda/reorder_spinor_fromQuda
# TM_QUDA: Time for invert_eo_quda 2.134693e+01 s level: 2 proc_id: 0 /HMC/correlators_measurement/invert_eo_quda
# Inversion done in 53 iterations, squared residue = 9.589332e-13!

new
# TM_QUDA: Time for invertQuda 3.727005e+00 s level: 3 proc_id: 0 /HMC/correlators_measurement/invert_eo_quda/invertQuda
# TM_QUDA: Done: 33 iter / 3.47978 secs = 24770.2 Gflops
# TM_QUDA: Time for reorder_spinor_fromQuda 7.029620e-02 s level: 3 proc_id: 0 /HMC/correlators_measurement/invert_eo_quda/reorder_spinor_fromQuda
# TM_QUDA: Time for invert_eo_quda 3.914286e+00 s level: 2 proc_id: 0 /HMC/correlators_measurement/invert_eo_quda
# Inversion done in 33 iterations, squared residue = 1.686466e-12!

Just need to make sure that it doesn't break anything, but this will help us quite a bit...","Ok, that looks good. I will try to check it (need to re-compile QUDA for that).
The heatbath problem seems that this indicates that the rho-shifts are not linear. However in case of DDalphaAMG one looses also performance/increase of iteration count if the shifts are too large, but much later rho ~ 0.1.",True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,544,2022-06-03T06:12:40Z,,2022-06-03T14:26:36Z,OPEN,False,4,3,1,https://github.com/kostrzewa,change logic for setting MG param coarse_grid_solution_type,2,[],https://github.com/etmc/tmLQCD/pull/544,https://github.com/kostrzewa,5,https://github.com/etmc/tmLQCD/pull/544#issuecomment-1145763973,"When I was adding the HMC additions, I accidentally messed up the logic for coarse_grid_solution_type and was injecting a full field on all intermediate and coarse levels 
This PR significantly improves MG performance (4 Booster nodes, 64c128 lattice, physical point) and will also restore analysis performance to previous levels:
old
GCR: Convergence at 53 iterations, L2 relative residual: iterated = 7.315033e-10, true = 7.315033e-10 (requested = 1.000000e-09)
# TM_QUDA: Time for invertQuda 1.596819e+01 s level: 3 proc_id: 0 /HMC/correlators_measurement/invert_eo_quda/invertQuda
# TM_QUDA: Done: 53 iter / 15.7261 secs = 25234.6 Gflops
# TM_QUDA: Time for reorder_spinor_fromQuda 6.752734e-02 s level: 3 proc_id: 0 /HMC/correlators_measurement/invert_eo_quda/reorder_spinor_fromQuda
# TM_QUDA: Time for invert_eo_quda 2.134693e+01 s level: 2 proc_id: 0 /HMC/correlators_measurement/invert_eo_quda
# Inversion done in 53 iterations, squared residue = 9.589332e-13!

new
# TM_QUDA: Time for invertQuda 3.727005e+00 s level: 3 proc_id: 0 /HMC/correlators_measurement/invert_eo_quda/invertQuda
# TM_QUDA: Done: 33 iter / 3.47978 secs = 24770.2 Gflops
# TM_QUDA: Time for reorder_spinor_fromQuda 7.029620e-02 s level: 3 proc_id: 0 /HMC/correlators_measurement/invert_eo_quda/reorder_spinor_fromQuda
# TM_QUDA: Time for invert_eo_quda 3.914286e+00 s level: 2 proc_id: 0 /HMC/correlators_measurement/invert_eo_quda
# Inversion done in 33 iterations, squared residue = 1.686466e-12!

Just need to make sure that it doesn't break anything, but this will help us quite a bit...",There's another problem though: somewhere between QUDA commit a1121d4597e60183021c70fc678c5bdfa1c0db8c and 9bae409b742765563b28939e93fa5c43b03da20b the cost for the setup update has increased by a factor of 10! This almost negates all gains from this PR (at least in the HMC).,True,{}
etmc/tmLQCD,https://github.com/etmc/tmLQCD,544,2022-06-03T06:12:40Z,,2022-06-03T14:26:36Z,OPEN,False,4,3,1,https://github.com/kostrzewa,change logic for setting MG param coarse_grid_solution_type,2,[],https://github.com/etmc/tmLQCD/pull/544,https://github.com/kostrzewa,6,https://github.com/etmc/tmLQCD/pull/544#issuecomment-1146020009,"When I was adding the HMC additions, I accidentally messed up the logic for coarse_grid_solution_type and was injecting a full field on all intermediate and coarse levels 
This PR significantly improves MG performance (4 Booster nodes, 64c128 lattice, physical point) and will also restore analysis performance to previous levels:
old
GCR: Convergence at 53 iterations, L2 relative residual: iterated = 7.315033e-10, true = 7.315033e-10 (requested = 1.000000e-09)
# TM_QUDA: Time for invertQuda 1.596819e+01 s level: 3 proc_id: 0 /HMC/correlators_measurement/invert_eo_quda/invertQuda
# TM_QUDA: Done: 53 iter / 15.7261 secs = 25234.6 Gflops
# TM_QUDA: Time for reorder_spinor_fromQuda 6.752734e-02 s level: 3 proc_id: 0 /HMC/correlators_measurement/invert_eo_quda/reorder_spinor_fromQuda
# TM_QUDA: Time for invert_eo_quda 2.134693e+01 s level: 2 proc_id: 0 /HMC/correlators_measurement/invert_eo_quda
# Inversion done in 53 iterations, squared residue = 9.589332e-13!

new
# TM_QUDA: Time for invertQuda 3.727005e+00 s level: 3 proc_id: 0 /HMC/correlators_measurement/invert_eo_quda/invertQuda
# TM_QUDA: Done: 33 iter / 3.47978 secs = 24770.2 Gflops
# TM_QUDA: Time for reorder_spinor_fromQuda 7.029620e-02 s level: 3 proc_id: 0 /HMC/correlators_measurement/invert_eo_quda/reorder_spinor_fromQuda
# TM_QUDA: Time for invert_eo_quda 3.914286e+00 s level: 2 proc_id: 0 /HMC/correlators_measurement/invert_eo_quda
# Inversion done in 33 iterations, squared residue = 1.686466e-12!

Just need to make sure that it doesn't break anything, but this will help us quite a bit...","@Finkenrath when you test, use QUDA commit 227ff8c8bdeec565aa82ba307d1a2539c8bb8664, it does not suffer from the performance regression in the setup update (and refresh) noted in the previous commit, yet it contains everything to be compatible with this branch of tmLQCD.",True,{}
