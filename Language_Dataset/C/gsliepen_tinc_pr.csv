gsliepen/tinc,https://github.com/gsliepen/tinc,107,2016-03-08T07:31:13Z,2016-03-08T07:34:33Z,2016-03-08T07:34:33Z,MERGED,True,6,6,1,https://github.com/aflyhorse,Just some proofreading,1,[],https://github.com/gsliepen/tinc/pull/107,https://github.com/aflyhorse,1,https://github.com/gsliepen/tinc/pull/107,,,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,111,2016-04-27T20:00:38Z,2016-04-30T18:16:52Z,2016-04-30T18:16:52Z,CLOSED,False,66,82,6,https://github.com/thorkill,Proposal for fixing long wait time when autoconnect=yes and only few nodes have defined address,6,[],https://github.com/gsliepen/tinc/pull/111,https://github.com/thorkill,1,https://github.com/gsliepen/tinc/pull/111,"When AutoConnect is enabled tinc tries to connect to other nodes picking them at random.
This may be sane default behavior but it may take ages if only few nodes have
defined Address in thier config.
Proposed solution to this problem:

Filter out nodes without known address in periodic_handler
I have added new node->status.has_known_address bool","When AutoConnect is enabled tinc tries to connect to other nodes picking them at random.
This may be sane default behavior but it may take ages if only few nodes have
defined Address in thier config.
Proposed solution to this problem:

Filter out nodes without known address in periodic_handler
I have added new node->status.has_known_address bool",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,111,2016-04-27T20:00:38Z,2016-04-30T18:16:52Z,2016-04-30T18:16:52Z,CLOSED,False,66,82,6,https://github.com/thorkill,Proposal for fixing long wait time when autoconnect=yes and only few nodes have defined address,6,[],https://github.com/gsliepen/tinc/pull/111,https://github.com/gsliepen,2,https://github.com/gsliepen/tinc/pull/111#issuecomment-215984872,"When AutoConnect is enabled tinc tries to connect to other nodes picking them at random.
This may be sane default behavior but it may take ages if only few nodes have
defined Address in thier config.
Proposed solution to this problem:

Filter out nodes without known address in periodic_handler
I have added new node->status.has_known_address bool",I implemented your approach in the 1.1 branch.,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,116,2016-05-09T22:54:24Z,2016-05-12T09:23:17Z,2016-05-12T09:23:17Z,CLOSED,False,4,3,2,https://github.com/thorkill,Allow PKT_PROBE in sptps_send_record,3,[],https://github.com/gsliepen/tinc/pull/116,https://github.com/thorkill,1,https://github.com/gsliepen/tinc/pull/116,"sptps_send_record prevented PKT_PROBE to be send in send_sptps_packet.
This occurred mostly when data was on ""the wire"" for some subnet.
route() would then trigger try_tx/try_udp which would be dropped by
sptps_send_record producing annoying amount of ""Handshake phase
not finished yet"" log messages.","sptps_send_record prevented PKT_PROBE to be send in send_sptps_packet.
This occurred mostly when data was on ""the wire"" for some subnet.
route() would then trigger try_tx/try_udp which would be dropped by
sptps_send_record producing annoying amount of ""Handshake phase
not finished yet"" log messages.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,116,2016-05-09T22:54:24Z,2016-05-12T09:23:17Z,2016-05-12T09:23:17Z,CLOSED,False,4,3,2,https://github.com/thorkill,Allow PKT_PROBE in sptps_send_record,3,[],https://github.com/gsliepen/tinc/pull/116,https://github.com/gsliepen,2,https://github.com/gsliepen/tinc/pull/116#issuecomment-218704670,"sptps_send_record prevented PKT_PROBE to be send in send_sptps_packet.
This occurred mostly when data was on ""the wire"" for some subnet.
route() would then trigger try_tx/try_udp which would be dropped by
sptps_send_record producing annoying amount of ""Handshake phase
not finished yet"" log messages.",Cherry-picked rather than merged :),True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,117,2016-05-10T09:46:25Z,2021-07-18T18:47:02Z,2021-07-18T18:47:02Z,CLOSED,False,5,2,1,https://github.com/thorkill,Prevent receive_tcppacket_sptps from forwarding data when in handshake,1,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/117,https://github.com/thorkill,1,https://github.com/gsliepen/tinc/pull/117,"Prevent receive_tcppacket_sptps from forwarding data to another nodes when we are in handshake phase with those nodes
Forwarding data to node which does not have vaildkey yet would destroy the running handshake.","Prevent receive_tcppacket_sptps from forwarding data to another nodes when we are in handshake phase with those nodes
Forwarding data to node which does not have vaildkey yet would destroy the running handshake.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,117,2016-05-10T09:46:25Z,2021-07-18T18:47:02Z,2021-07-18T18:47:02Z,CLOSED,False,5,2,1,https://github.com/thorkill,Prevent receive_tcppacket_sptps from forwarding data when in handshake,1,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/117,https://github.com/splitice,2,https://github.com/gsliepen/tinc/pull/117#issuecomment-878723832,"Prevent receive_tcppacket_sptps from forwarding data to another nodes when we are in handshake phase with those nodes
Forwarding data to node which does not have vaildkey yet would destroy the running handshake.","@gsliepen I think this is worth a review. Easy enough to make merge.
It looks sane enough.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,117,2016-05-10T09:46:25Z,2021-07-18T18:47:02Z,2021-07-18T18:47:02Z,CLOSED,False,5,2,1,https://github.com/thorkill,Prevent receive_tcppacket_sptps from forwarding data when in handshake,1,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/117,https://github.com/gsliepen,3,https://github.com/gsliepen/tinc/pull/117#issuecomment-882100893,"Prevent receive_tcppacket_sptps from forwarding data to another nodes when we are in handshake phase with those nodes
Forwarding data to node which does not have vaildkey yet would destroy the running handshake.",Fixed by commit 2c9126a.,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,119,2016-05-21T21:31:28Z,2016-05-21T23:32:06Z,2016-05-21T23:32:06Z,MERGED,True,8,1,1,https://github.com/seanmcveigh,check for daemon pid existence before trying to connect to the contro…,2,[],https://github.com/gsliepen/tinc/pull/119,https://github.com/seanmcveigh,1,https://github.com/gsliepen/tinc/pull/119,"…l socket, and clean up stale files otherwise.","…l socket, and clean up stale files otherwise.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,120,2016-07-14T18:18:37Z,2016-07-14T18:26:09Z,2016-07-14T18:26:10Z,MERGED,True,1,1,1,https://github.com/dechamps,Fix error handling when setting up the UDP socket,1,[],https://github.com/gsliepen/tinc/pull/120,https://github.com/dechamps,1,https://github.com/gsliepen/tinc/pull/120,"Due to this typo, if tinc managed to set up the TCP socket but not the UDP socket, it would continue anyway.
The regression was introduced in 6bc5d62.","Due to this typo, if tinc managed to set up the TCP socket but not the UDP socket, it would continue anyway.
The regression was introduced in 6bc5d62.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,124,2016-10-11T11:32:55Z,2016-10-11T15:27:20Z,2016-10-11T18:39:21Z,MERGED,True,5,4,1,https://github.com/VittGam,"fsck: Fix ed25519 public key reading, and fclose usage.",1,[],https://github.com/gsliepen/tinc/pull/124,https://github.com/VittGam,1,https://github.com/gsliepen/tinc/pull/124,"Hello,
This patch fixes two problems with tinc fsck: a wrong conditional clause preventing the validation of ed25519 public keys in ""raw"" form; and the usage of fclose on NULL pointers when the file couldn't be opened.
Cheers,
Vittorio","Hello,
This patch fixes two problems with tinc fsck: a wrong conditional clause preventing the validation of ed25519 public keys in ""raw"" form; and the usage of fclose on NULL pointers when the file couldn't be opened.
Cheers,
Vittorio",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,125,2016-10-11T18:32:20Z,2016-10-11T18:57:34Z,2016-10-12T12:05:07Z,MERGED,True,7,5,1,https://github.com/VittGam,tincctl: Avoid falling back to 1024 bits RSA key generation when an invalid key size is specified.,1,[],https://github.com/gsliepen/tinc/pull/125,https://github.com/VittGam,1,https://github.com/gsliepen/tinc/pull/125,"Also warn the user if a key smaller than 2048 bits is being generated.
Cheers,
Vittorio","Also warn the user if a key smaller than 2048 bits is being generated.
Cheers,
Vittorio",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,126,2016-10-12T12:22:31Z,2017-03-20T21:40:12Z,2017-03-20T21:40:12Z,CLOSED,False,9,2,1,https://github.com/VittGam,[1.1] route: Support ToS/DiffServ priority inheritance when routing IPv6 packets.,1,[],https://github.com/gsliepen/tinc/pull/126,https://github.com/VittGam,1,https://github.com/gsliepen/tinc/pull/126,"This is the patch for tinc 1.1.
Cheers,
Vittorio","This is the patch for tinc 1.1.
Cheers,
Vittorio",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,126,2016-10-12T12:22:31Z,2017-03-20T21:40:12Z,2017-03-20T21:40:12Z,CLOSED,False,9,2,1,https://github.com/VittGam,[1.1] route: Support ToS/DiffServ priority inheritance when routing IPv6 packets.,1,[],https://github.com/gsliepen/tinc/pull/126,https://github.com/gsliepen,2,https://github.com/gsliepen/tinc/pull/126#issuecomment-287906823,"This is the patch for tinc 1.1.
Cheers,
Vittorio","Merged, thanks!",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,127,2016-10-12T12:22:35Z,2017-03-21T20:48:47Z,2017-03-21T20:48:47Z,MERGED,True,9,2,1,https://github.com/VittGam,[1.0] route: Support ToS/DiffServ priority inheritance when routing IPv6 packets.,1,[],https://github.com/gsliepen/tinc/pull/127,https://github.com/VittGam,1,https://github.com/gsliepen/tinc/pull/127,"This is the patch for tinc 1.0.
Cheers,
Vittorio","This is the patch for tinc 1.0.
Cheers,
Vittorio",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,130,2016-10-31T20:10:20Z,2016-10-31T21:31:10Z,2016-10-31T21:31:10Z,MERGED,True,0,1,1,https://github.com/bouttier,Remove ExecStop in tinc@.service,1,[],https://github.com/gsliepen/tinc/pull/130,https://github.com/bouttier,1,https://github.com/gsliepen/tinc/pull/130,"This avoid tinc to receive SIGTERM twice (through ExecStop and through systemd
directly) which prevented tinc-down script to be executed.
An other possibility is to KillMode=none, but this cause systemd to think tinc is terminated when the ExecStop end which is false. Let systemd send the SIGTERM is better as systemd willl directly observe the tinc processus status in order to know if it has completed.","This avoid tinc to receive SIGTERM twice (through ExecStop and through systemd
directly) which prevented tinc-down script to be executed.
An other possibility is to KillMode=none, but this cause systemd to think tinc is terminated when the ExecStop end which is false. Let systemd send the SIGTERM is better as systemd willl directly observe the tinc processus status in order to know if it has completed.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,134,2016-11-17T10:13:07Z,2021-06-30T17:41:39Z,2021-06-30T17:41:39Z,CLOSED,False,5,24,3,https://github.com/fkooman,simplify systemd unit file,1,[],https://github.com/gsliepen/tinc/pull/134,https://github.com/fkooman,1,https://github.com/gsliepen/tinc/pull/134,PR for issue #133.,PR for issue #133.,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,134,2016-11-17T10:13:07Z,2021-06-30T17:41:39Z,2021-06-30T17:41:39Z,CLOSED,False,5,24,3,https://github.com/fkooman,simplify systemd unit file,1,[],https://github.com/gsliepen/tinc/pull/134,https://github.com/aflyhorse,2,https://github.com/gsliepen/tinc/pull/134#issuecomment-262159574,PR for issue #133.,"IMHO, the original ""tinc.service"" seems to act as a general all-in-one switch for all other ""tinc@"" services.
I'm not sure if removing is proper.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,134,2016-11-17T10:13:07Z,2021-06-30T17:41:39Z,2021-06-30T17:41:39Z,CLOSED,False,5,24,3,https://github.com/fkooman,simplify systemd unit file,1,[],https://github.com/gsliepen/tinc/pull/134,https://github.com/fkooman,3,https://github.com/gsliepen/tinc/pull/134#issuecomment-262234939,PR for issue #133.,"Ah, if that is a feature that is being used then that makes sense... It seems it is based on the Debian OpenVPN systemd unit.
Do you have any idea how to fix the issue on CentOS where the current service file does not wait for the network to be up to start? https://bugzilla.redhat.com/show_bug.cgi?id=1394512.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,134,2016-11-17T10:13:07Z,2021-06-30T17:41:39Z,2021-06-30T17:41:39Z,CLOSED,False,5,24,3,https://github.com/fkooman,simplify systemd unit file,1,[],https://github.com/gsliepen/tinc/pull/134,https://github.com/aflyhorse,4,https://github.com/gsliepen/tinc/pull/134#issuecomment-263772505,PR for issue #133.,"I thought After=network-online.target should work, although it is not so graceful. On the other side, tweaks must be made in actual C/C++ code, to make it more friendly to network freak.

If you are a developer, instead of wondering what to do about network.target, please just fix your program to be friendly to dynamically changing network configuration. That way you will make your users happy because things just start to work, and you will get fewer bug reports as your stuff is just rock solid.

source: https://www.freedesktop.org/wiki/Software/systemd/NetworkTarget/",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,134,2016-11-17T10:13:07Z,2021-06-30T17:41:39Z,2021-06-30T17:41:39Z,CLOSED,False,5,24,3,https://github.com/fkooman,simplify systemd unit file,1,[],https://github.com/gsliepen/tinc/pull/134,https://github.com/heroxbd,5,https://github.com/gsliepen/tinc/pull/134#issuecomment-362495568,PR for issue #133.,"Shall we close this PR?
BTW, greetings @aflyhorse !",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,134,2016-11-17T10:13:07Z,2021-06-30T17:41:39Z,2021-06-30T17:41:39Z,CLOSED,False,5,24,3,https://github.com/fkooman,simplify systemd unit file,1,[],https://github.com/gsliepen/tinc/pull/134,https://github.com/aflyhorse,6,https://github.com/gsliepen/tinc/pull/134#issuecomment-362503649,PR for issue #133.,"I'm suffering from that tinc@xxx.service doesn't start automatically in CentOS 7.x. It's working nice in Fedora 25+ however, so it might be another problem. Seems the distro files have be rewritten, @fkooman are you still interested in the PR?
BTW, Greetings @heroxbd , thank you for introducing tinc to me. I've been using it to bypass numerous firewalls and routers.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,134,2016-11-17T10:13:07Z,2021-06-30T17:41:39Z,2021-06-30T17:41:39Z,CLOSED,False,5,24,3,https://github.com/fkooman,simplify systemd unit file,1,[],https://github.com/gsliepen/tinc/pull/134,https://github.com/tomberek,7,https://github.com/gsliepen/tinc/pull/134#issuecomment-404020057,PR for issue #133.,Close?,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,134,2016-11-17T10:13:07Z,2021-06-30T17:41:39Z,2021-06-30T17:41:39Z,CLOSED,False,5,24,3,https://github.com/fkooman,simplify systemd unit file,1,[],https://github.com/gsliepen/tinc/pull/134,https://github.com/fkooman,8,https://github.com/gsliepen/tinc/pull/134#issuecomment-404063632,PR for issue #133.,"I'm currentl not using tinc, so maybe it is better if someone else took over, or indeed close the PR.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,134,2016-11-17T10:13:07Z,2021-06-30T17:41:39Z,2021-06-30T17:41:39Z,CLOSED,False,5,24,3,https://github.com/fkooman,simplify systemd unit file,1,[],https://github.com/gsliepen/tinc/pull/134,https://github.com/aflyhorse,9,https://github.com/gsliepen/tinc/pull/134#issuecomment-404067898,PR for issue #133.,The problem in CentOS 7.x has already fixed. I suggest keep the current status and close this PR.,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,134,2016-11-17T10:13:07Z,2021-06-30T17:41:39Z,2021-06-30T17:41:39Z,CLOSED,False,5,24,3,https://github.com/fkooman,simplify systemd unit file,1,[],https://github.com/gsliepen/tinc/pull/134,https://github.com/fangfufu,10,https://github.com/gsliepen/tinc/pull/134#issuecomment-871603124,PR for issue #133.,"Closing the PR, as per suggestion by @tomberek and @aflyhorse , and also @fkooman no longer uses tinc.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,136,2016-12-03T23:26:51Z,2017-03-20T21:34:57Z,2020-12-29T17:55:04Z,MERGED,True,21,10,2,https://github.com/dechamps,Fix bugs related to Windows nodes waking up from sleep,2,[],https://github.com/gsliepen/tinc/pull/136,https://github.com/dechamps,1,https://github.com/gsliepen/tinc/pull/136,"On Windows, I have noticed that tinc 1.1 sometimes has difficulties resuming operation after the computer wakes up from sleep. The issues were easy to reproduce, and I found two bugs that explain the problems.","On Windows, I have noticed that tinc 1.1 sometimes has difficulties resuming operation after the computer wakes up from sleep. The issues were easy to reproduce, and I found two bugs that explain the problems.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,136,2016-12-03T23:26:51Z,2017-03-20T21:34:57Z,2020-12-29T17:55:04Z,MERGED,True,21,10,2,https://github.com/dechamps,Fix bugs related to Windows nodes waking up from sleep,2,[],https://github.com/gsliepen/tinc/pull/136,https://github.com/igel-kun,2,https://github.com/gsliepen/tinc/pull/136#issuecomment-752183123,"On Windows, I have noticed that tinc 1.1 sometimes has difficulties resuming operation after the computer wakes up from sleep. The issues were easy to reproduce, and I found two bugs that explain the problems.","Sorry for the necro, but tinc-1.1pre17 still has problems waking properly from suspend.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,137,2016-12-04T14:58:26Z,2017-03-20T21:30:41Z,2017-03-20T21:30:41Z,CLOSED,False,2,1,1,https://github.com/dechamps,Fix broken Windows build,1,[],https://github.com/gsliepen/tinc/pull/137,https://github.com/dechamps,1,https://github.com/gsliepen/tinc/pull/137,"The regression was introduced in commit 4314df6.
  CC       tincctl.o
tincctl.c: In function ‘connect_tincd’:
tincctl.c:724:21: warning: implicit declaration of function ‘kill’ [-Wimplicit-function-declaration]
  if ((pid == 0) || (kill(pid, 0) && (errno == ESRCH))) {
        	     ^~~~
  CCLD     tinc.exe
tincctl.o: In function `connect_tincd':
/home/e-t172/dev/tinc/src/tincctl.c:724: undefined reference to `kill'
collect2: error: ld returned 1 exit status
Makefile:830: recipe for target 'tinc.exe' failed","The regression was introduced in commit 4314df6.
  CC       tincctl.o
tincctl.c: In function ‘connect_tincd’:
tincctl.c:724:21: warning: implicit declaration of function ‘kill’ [-Wimplicit-function-declaration]
  if ((pid == 0) || (kill(pid, 0) && (errno == ESRCH))) {
        	     ^~~~
  CCLD     tinc.exe
tincctl.o: In function `connect_tincd':
/home/e-t172/dev/tinc/src/tincctl.c:724: undefined reference to `kill'
collect2: error: ld returned 1 exit status
Makefile:830: recipe for target 'tinc.exe' failed",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,137,2016-12-04T14:58:26Z,2017-03-20T21:30:41Z,2017-03-20T21:30:41Z,CLOSED,False,2,1,1,https://github.com/dechamps,Fix broken Windows build,1,[],https://github.com/gsliepen/tinc/pull/137,https://github.com/gsliepen,2,https://github.com/gsliepen/tinc/pull/137#issuecomment-287904422,"The regression was introduced in commit 4314df6.
  CC       tincctl.o
tincctl.c: In function ‘connect_tincd’:
tincctl.c:724:21: warning: implicit declaration of function ‘kill’ [-Wimplicit-function-declaration]
  if ((pid == 0) || (kill(pid, 0) && (errno == ESRCH))) {
        	     ^~~~
  CCLD     tinc.exe
tincctl.o: In function `connect_tincd':
/home/e-t172/dev/tinc/src/tincctl.c:724: undefined reference to `kill'
collect2: error: ld returned 1 exit status
Makefile:830: recipe for target 'tinc.exe' failed","Ugh, I just fixed this myself while your patch has been lying around here since forever. Sorry for not applying it earlier!",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,139,2016-12-18T17:16:01Z,2016-12-21T13:47:43Z,2016-12-21T13:47:43Z,MERGED,True,56,65,2,https://github.com/dechamps,Fix local discovery regressions,4,[],https://github.com/gsliepen/tinc/pull/139,https://github.com/dechamps,1,https://github.com/gsliepen/tinc/pull/139,"Commit ab13c14 broke local discovery by preventing local node addresses from being set. The fix is in this pull request, as well as other small improvements I've made along the way.","Commit ab13c14 broke local discovery by preventing local node addresses from being set. The fix is in this pull request, as well as other small improvements I've made along the way.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,141,2017-03-01T14:08:44Z,2017-03-01T21:33:42Z,2017-03-01T21:33:42Z,MERGED,True,141,0,7,https://github.com/pacien,Add fd_device,1,[],https://github.com/gsliepen/tinc/pull/141,https://github.com/pacien,1,https://github.com/gsliepen/tinc/pull/141,"For Android stuff.
Tested with Android 5.1.1 VPN API.","For Android stuff.
Tested with Android 5.1.1 VPN API.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,141,2017-03-01T14:08:44Z,2017-03-01T21:33:42Z,2017-03-01T21:33:42Z,MERGED,True,141,0,7,https://github.com/pacien,Add fd_device,1,[],https://github.com/gsliepen/tinc/pull/141,https://github.com/gsliepen,2,https://github.com/gsliepen/tinc/pull/141#issuecomment-283409801,"For Android stuff.
Tested with Android 5.1.1 VPN API.","I think you missed something in your commit; I get some errors trying to compile it:
fd_device.c: In function ‘get_ip_ethertype’:
fd_device.c:74:10: error: ‘ETHERTYPE_MAX’ undeclared (first use in this function)
   return ETHERTYPE_MAX;

Also, it might be nice if you could rebase your work onto the latest commit on the 1.1 branch.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,141,2017-03-01T14:08:44Z,2017-03-01T21:33:42Z,2017-03-01T21:33:42Z,MERGED,True,141,0,7,https://github.com/pacien,Add fd_device,1,[],https://github.com/gsliepen/tinc/pull/141,https://github.com/pacien,3,https://github.com/gsliepen/tinc/pull/141#issuecomment-283463390,"For Android stuff.
Tested with Android 5.1.1 VPN API.","Thank you for your feedback.
ETHERTYPE_MAX is apparently defined only on Android and some BSD.
I replaced it with ETH_P_MAX internally defined.
Also just rebased on the latest commit.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,148,2017-08-15T17:57:46Z,2017-08-15T20:01:35Z,2017-10-06T20:14:51Z,MERGED,True,11,0,4,https://github.com/pacien,Add LogLevel config option,1,[],https://github.com/gsliepen/tinc/pull/148,https://github.com/pacien,1,https://github.com/gsliepen/tinc/pull/148,"For issue #147.
Untested ; Please review.","For issue #147.
Untested ; Please review.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,151,2017-08-25T16:59:14Z,2017-08-25T19:07:03Z,2017-08-25T19:07:03Z,CLOSED,False,1,1,1,https://github.com/millert,Pass correct size to read_pem() in ecdsa_read_pem_private_key().,1,[],https://github.com/gsliepen/tinc/pull/151,https://github.com/millert,1,https://github.com/gsliepen/tinc/pull/151,"Pass the size of the private key, not the entire struct.","Pass the size of the private key, not the entire struct.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,153,2017-10-03T08:24:54Z,2017-10-03T19:11:58Z,2017-10-03T19:11:58Z,CLOSED,False,4,3,1,https://github.com/sizeofvoid,fix tinc.conf for OpenBSD,1,[],https://github.com/gsliepen/tinc/pull/153,https://github.com/sizeofvoid,1,https://github.com/gsliepen/tinc/pull/153,OpenBSD switch from tun* to tap a long time ago,OpenBSD switch from tun* to tap a long time ago,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,153,2017-10-03T08:24:54Z,2017-10-03T19:11:58Z,2017-10-03T19:11:58Z,CLOSED,False,4,3,1,https://github.com/sizeofvoid,fix tinc.conf for OpenBSD,1,[],https://github.com/gsliepen/tinc/pull/153,https://github.com/gsliepen,2,https://github.com/gsliepen/tinc/pull/153#issuecomment-333947807,OpenBSD switch from tun* to tap a long time ago,"Merged, thanks!",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,154,2017-10-03T14:37:30Z,2017-10-03T19:14:02Z,2017-10-03T19:14:02Z,CLOSED,False,19,16,6,https://github.com/nemunaire,Allow compilation from a build directory,1,[],https://github.com/gsliepen/tinc/pull/154,https://github.com/nemunaire,1,https://github.com/gsliepen/tinc/pull/154,"Currently, it is not possible to build the project from a separate directory than the one containing sources.
In fact:
$ make distcheck
[...]
  CC       avl_tree.o
In file included from ../../src/avl_tree.c:33:0:
../../src/system.h:24:23: fatal error: ../config.h: No such file or directory
 #include ""../config.h""

This patch fixes that and then avoid creating exceptional behavior for tinc in some automated packager that relies on clean separate builds.
Moreover, one last error was due to the use of wildcard in m4/Makefile.am whereas it is not supported by design.
Thanks for your project!","Currently, it is not possible to build the project from a separate directory than the one containing sources.
In fact:
$ make distcheck
[...]
  CC       avl_tree.o
In file included from ../../src/avl_tree.c:33:0:
../../src/system.h:24:23: fatal error: ../config.h: No such file or directory
 #include ""../config.h""

This patch fixes that and then avoid creating exceptional behavior for tinc in some automated packager that relies on clean separate builds.
Moreover, one last error was due to the use of wildcard in m4/Makefile.am whereas it is not supported by design.
Thanks for your project!",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,154,2017-10-03T14:37:30Z,2017-10-03T19:14:02Z,2017-10-03T19:14:02Z,CLOSED,False,19,16,6,https://github.com/nemunaire,Allow compilation from a build directory,1,[],https://github.com/gsliepen/tinc/pull/154,https://github.com/dechamps,2,https://github.com/gsliepen/tinc/pull/154#issuecomment-333919773,"Currently, it is not possible to build the project from a separate directory than the one containing sources.
In fact:
$ make distcheck
[...]
  CC       avl_tree.o
In file included from ../../src/avl_tree.c:33:0:
../../src/system.h:24:23: fatal error: ../config.h: No such file or directory
 #include ""../config.h""

This patch fixes that and then avoid creating exceptional behavior for tinc in some automated packager that relies on clean separate builds.
Moreover, one last error was due to the use of wildcard in m4/Makefile.am whereas it is not supported by design.
Thanks for your project!",Related: #77 (but mine was for the 1.1 branch),True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,154,2017-10-03T14:37:30Z,2017-10-03T19:14:02Z,2017-10-03T19:14:02Z,CLOSED,False,19,16,6,https://github.com/nemunaire,Allow compilation from a build directory,1,[],https://github.com/gsliepen/tinc/pull/154,https://github.com/gsliepen,3,https://github.com/gsliepen/tinc/pull/154#issuecomment-333948279,"Currently, it is not possible to build the project from a separate directory than the one containing sources.
In fact:
$ make distcheck
[...]
  CC       avl_tree.o
In file included from ../../src/avl_tree.c:33:0:
../../src/system.h:24:23: fatal error: ../config.h: No such file or directory
 #include ""../config.h""

This patch fixes that and then avoid creating exceptional behavior for tinc in some automated packager that relies on clean separate builds.
Moreover, one last error was due to the use of wildcard in m4/Makefile.am whereas it is not supported by design.
Thanks for your project!","Merged, thanks! I've also looked at #77, and copied the way it's doing #include $srcdir/src/have.h in autoconf.ac, instead of saving/restoring the CPPFLAGS.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,156,2017-10-05T07:24:42Z,2017-10-06T19:06:35Z,2017-10-06T19:06:35Z,MERGED,True,1,1,1,https://github.com/quite,"doc: there is, not their is",1,[],https://github.com/gsliepen/tinc/pull/156,https://github.com/quite,1,https://github.com/gsliepen/tinc/pull/156,,,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,158,2017-10-25T16:08:37Z,2017-10-25T17:16:04Z,2017-10-25T20:32:47Z,MERGED,True,24,24,9,https://github.com/millert,Replace remaining sizeof foo with sizeof(foo).,1,[],https://github.com/gsliepen/tinc/pull/158,https://github.com/millert,1,https://github.com/gsliepen/tinc/pull/158,,,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,166,2018-01-04T20:34:59Z,2018-01-05T18:58:46Z,2018-01-05T18:58:46Z,MERGED,True,9,0,1,https://github.com/dechamps,Support MSS clamping for IP in IP (RFC 2003) packets,1,[],https://github.com/gsliepen/tinc/pull/166,https://github.com/dechamps,1,https://github.com/gsliepen/tinc/pull/166,This change allows tinc MSS clamping to operate on TCP streams that are inside an IP in IP tunnel.,This change allows tinc MSS clamping to operate on TCP streams that are inside an IP in IP tunnel.,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,166,2018-01-04T20:34:59Z,2018-01-05T18:58:46Z,2018-01-05T18:58:46Z,MERGED,True,9,0,1,https://github.com/dechamps,Support MSS clamping for IP in IP (RFC 2003) packets,1,[],https://github.com/gsliepen/tinc/pull/166,https://github.com/gsliepen,2,https://github.com/gsliepen/tinc/pull/166#issuecomment-355417634,This change allows tinc MSS clamping to operate on TCP streams that are inside an IP in IP tunnel.,"It's missing a check that packet->len > start + 20 after you adjust start, otherwise subsequent if statements might right after the end of the packet.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,166,2018-01-04T20:34:59Z,2018-01-05T18:58:46Z,2018-01-05T18:58:46Z,MERGED,True,9,0,1,https://github.com/dechamps,Support MSS clamping for IP in IP (RFC 2003) packets,1,[],https://github.com/gsliepen/tinc/pull/166,https://github.com/dechamps,3,https://github.com/gsliepen/tinc/pull/166#issuecomment-355629133,This change allows tinc MSS clamping to operate on TCP streams that are inside an IP in IP tunnel.,Right. Fixed.,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,167,2018-01-07T14:57:15Z,2018-01-07T18:43:07Z,2018-01-07T18:43:07Z,MERGED,True,24,15,5,https://github.com/dechamps,Various build cleanups,3,[],https://github.com/gsliepen/tinc/pull/167,https://github.com/dechamps,1,https://github.com/gsliepen/tinc/pull/167,Fix fixes a few warnings and issues I encountered while building tinc.,Fix fixes a few warnings and issues I encountered while building tinc.,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,169,2018-01-17T19:51:19Z,2018-01-17T19:56:59Z,2018-01-17T19:57:00Z,MERGED,True,2,3,1,https://github.com/dechamps,Move ResetEvent() call before ReadFile(),1,[],https://github.com/gsliepen/tinc/pull/169,https://github.com/dechamps,1,https://github.com/gsliepen/tinc/pull/169,"Commit 313a752 changed the Windows device code such that ResetEvent() is called on the read OVERLAPPED structure before GetOverlappedResult(), as opposed to before ReadFile(). Guus pointed out that this doesn't make a ton of sense, and I agree with him; it must have been an oversight on my part when I wrote this code.
Surprisingly, none of this makes any difference in my testing, at least with the standard TAP 9.0.0.9 driver. Nevertheless, this code is probably wrong and fixing it will make me sleep better at night.","Commit 313a752 changed the Windows device code such that ResetEvent() is called on the read OVERLAPPED structure before GetOverlappedResult(), as opposed to before ReadFile(). Guus pointed out that this doesn't make a ton of sense, and I agree with him; it must have been an oversight on my part when I wrote this code.
Surprisingly, none of this makes any difference in my testing, at least with the standard TAP 9.0.0.9 driver. Nevertheless, this code is probably wrong and fixing it will make me sleep better at night.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,171,2018-01-22T17:29:22Z,2018-01-22T17:38:13Z,2018-01-23T22:55:47Z,MERGED,True,4,0,2,https://github.com/millert,Add some missing freeaddrinfo() calls to avoid leaking memory.,1,[],https://github.com/gsliepen/tinc/pull/171,https://github.com/millert,1,https://github.com/gsliepen/tinc/pull/171,,,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,173,2018-01-23T23:03:40Z,2018-01-24T07:11:08Z,2018-01-24T18:18:47Z,MERGED,True,7,1,1,https://github.com/millert,Fix io_compare() for 64-bit Windows,1,[],https://github.com/gsliepen/tinc/pull/173,https://github.com/millert,1,https://github.com/gsliepen/tinc/pull/173,"WSAEVENT is a pointer, so we cannot simply return the different of two events in io_compare(), which returns an int.  This can return the wrong result for 64-bit executables.","WSAEVENT is a pointer, so we cannot simply return the different of two events in io_compare(), which returns an int.  This can return the wrong result for 64-bit executables.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,174,2018-02-01T00:04:06Z,2018-02-01T21:31:22Z,2018-02-03T19:06:50Z,MERGED,True,11,6,1,https://github.com/millert,Reset the write event before each call to WriteFile(),1,[],https://github.com/gsliepen/tinc/pull/174,https://github.com/millert,1,https://github.com/gsliepen/tinc/pull/174,"In device_issue_read() there is no need to reset Offset and OffsetHigh to 0; they are only used for seekable files (not sockets).
Reset the write event before the call to WriteFile().  This is consistent with how the read event is reset before ReadFile().
Clear device_write_packet.len() if WriteFile() fails with an error other than ERROR_IO_PENDING; otherwise write_packet() will call GetOverlappedResult() the next time it is run even though there is no write in progress.","In device_issue_read() there is no need to reset Offset and OffsetHigh to 0; they are only used for seekable files (not sockets).
Reset the write event before the call to WriteFile().  This is consistent with how the read event is reset before ReadFile().
Clear device_write_packet.len() if WriteFile() fails with an error other than ERROR_IO_PENDING; otherwise write_packet() will call GetOverlappedResult() the next time it is run even though there is no write in progress.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,174,2018-02-01T00:04:06Z,2018-02-01T21:31:22Z,2018-02-03T19:06:50Z,MERGED,True,11,6,1,https://github.com/millert,Reset the write event before each call to WriteFile(),1,[],https://github.com/gsliepen/tinc/pull/174,https://github.com/dechamps,2,https://github.com/gsliepen/tinc/pull/174#issuecomment-362419730,"In device_issue_read() there is no need to reset Offset and OffsetHigh to 0; they are only used for seekable files (not sockets).
Reset the write event before the call to WriteFile().  This is consistent with how the read event is reset before ReadFile().
Clear device_write_packet.len() if WriteFile() fails with an error other than ERROR_IO_PENDING; otherwise write_packet() will call GetOverlappedResult() the next time it is run even though there is no write in progress.","Thank you for fixing my code :)
I wonder if the potential bug you found on the write path for errors other than ERROR_IO_PENDING could explain why I've witnessed tinc sometimes getting stuck when the computer is waking up from sleep. It's difficult to confirm though, because reproducing the issue has proven difficult thus far.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,174,2018-02-01T00:04:06Z,2018-02-01T21:31:22Z,2018-02-03T19:06:50Z,MERGED,True,11,6,1,https://github.com/millert,Reset the write event before each call to WriteFile(),1,[],https://github.com/gsliepen/tinc/pull/174,https://github.com/dechamps,3,https://github.com/gsliepen/tinc/pull/174#issuecomment-362845569,"In device_issue_read() there is no need to reset Offset and OffsetHigh to 0; they are only used for seekable files (not sockets).
Reset the write event before the call to WriteFile().  This is consistent with how the read event is reset before ReadFile().
Clear device_write_packet.len() if WriteFile() fails with an error other than ERROR_IO_PENDING; otherwise write_packet() will call GetOverlappedResult() the next time it is run even though there is no write in progress.","I did some more investigation, and I can indeed confirm that this specific commit fixes an issue where, if the computer is put to sleep while there there is traffic on the tinc interface, tinc will get stuck on wakeup with the following errors in the log:

Error while checking previous write to Windows tap device: (996) Overlapped I/O event is not in a signaled state.

I can reliably reproduce the issue by stressing the interface using iperf while putting the computer to sleep at the same time. I was unable to reproduce it again with your fix in place.
@gsliepen: you might want to mention that bugfix when writing the release notes for the next version.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,175,2018-02-02T06:02:21Z,2018-02-02T08:21:57Z,2018-02-02T08:21:58Z,CLOSED,False,4,3,1,https://github.com/heroxbd,"src/route.c: pad the ""next"" field of ipv6 pseudo header correctly.",1,[],https://github.com/gsliepen/tinc/pull/175,https://github.com/heroxbd,1,https://github.com/gsliepen/tinc/pull/175,"According to Section 8.1 of RFC2460 reproduced below, in the pseudo
header of checksum calculation, 3 bytes of 0's should prepend the
""next header"" field.
""uint32_t next"" does not give the correct structure on little-endian
systems, because ""htonl(IPPROTO_ICMPV6)"" puts the ""next header"" into
the left most byte.
Sympton of this bug: all the tinc-generated ICMPv6 packets have bad
checksums and get ignored by the hosts.  For example, ICMPv6 Packet
Too Big Messages with bad checksums are ignored and consequently
path MTU discovery of tinc does not function for ipv6 VPN networks.

  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
  |                                                               |
  +                                                               +
  |                                                               |
  +                         Source Address                        +
  |                                                               |
  +                                                               +
  |                                                               |
  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
  |                                                               |
  +                                                               +
  |                                                               |
  +                      Destination Address                      +
  |                                                               |
  +                                                               +
  |                                                               |
  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
  |                   Upper-Layer Packet Length                   |
  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
  |                      zero                     |  Next Header  |
  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+","According to Section 8.1 of RFC2460 reproduced below, in the pseudo
header of checksum calculation, 3 bytes of 0's should prepend the
""next header"" field.
""uint32_t next"" does not give the correct structure on little-endian
systems, because ""htonl(IPPROTO_ICMPV6)"" puts the ""next header"" into
the left most byte.
Sympton of this bug: all the tinc-generated ICMPv6 packets have bad
checksums and get ignored by the hosts.  For example, ICMPv6 Packet
Too Big Messages with bad checksums are ignored and consequently
path MTU discovery of tinc does not function for ipv6 VPN networks.

  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
  |                                                               |
  +                                                               +
  |                                                               |
  +                         Source Address                        +
  |                                                               |
  +                                                               +
  |                                                               |
  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
  |                                                               |
  +                                                               +
  |                                                               |
  +                      Destination Address                      +
  |                                                               |
  +                                                               +
  |                                                               |
  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
  |                   Upper-Layer Packet Length                   |
  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
  |                      zero                     |  Next Header  |
  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,175,2018-02-02T06:02:21Z,2018-02-02T08:21:57Z,2018-02-02T08:21:58Z,CLOSED,False,4,3,1,https://github.com/heroxbd,"src/route.c: pad the ""next"" field of ipv6 pseudo header correctly.",1,[],https://github.com/gsliepen/tinc/pull/175,https://github.com/heroxbd,2,https://github.com/gsliepen/tinc/pull/175#issuecomment-362517580,"According to Section 8.1 of RFC2460 reproduced below, in the pseudo
header of checksum calculation, 3 bytes of 0's should prepend the
""next header"" field.
""uint32_t next"" does not give the correct structure on little-endian
systems, because ""htonl(IPPROTO_ICMPV6)"" puts the ""next header"" into
the left most byte.
Sympton of this bug: all the tinc-generated ICMPv6 packets have bad
checksums and get ignored by the hosts.  For example, ICMPv6 Packet
Too Big Messages with bad checksums are ignored and consequently
path MTU discovery of tinc does not function for ipv6 VPN networks.

  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
  |                                                               |
  +                                                               +
  |                                                               |
  +                         Source Address                        +
  |                                                               |
  +                                                               +
  |                                                               |
  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
  |                                                               |
  +                                                               +
  |                                                               |
  +                      Destination Address                      +
  |                                                               |
  +                                                               +
  |                                                               |
  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
  |                   Upper-Layer Packet Length                   |
  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
  |                      zero                     |  Next Header  |
  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+","No, I am wrong.  The patch does not make a difference.
The checksum bug is only triggered when gcc has -finline-small-function.  Need further studies.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,177,2018-02-16T21:19:09Z,2018-02-17T13:39:50Z,2018-02-21T03:23:15Z,MERGED,True,11,14,3,https://github.com/millert,Fix a use-after-free bug in get_recent_address() and two related issues.,1,[],https://github.com/gsliepen/tinc/pull/177,https://github.com/millert,1,https://github.com/gsliepen/tinc/pull/177,"The sockaddr_t * returned may be part of memory freed by the call to
freeaddrinfo().
The sockaddr_t * returned from a recently seen address not in the
cache was cast from struct addrinfo *ai, not the struct sockaddr *
inside of it.
In do_outgoing_connection(), when filling in the address in the
connection_t, there is a buffer overflow (read, not write) if
the sa returned by get_recent_address() didn't come from the
cache of recently seen addresses.  That is, it was really a
struct sockaddr * and not a sockaddr_t *.  This last was
found by building tinc with address sanitizer.","The sockaddr_t * returned may be part of memory freed by the call to
freeaddrinfo().
The sockaddr_t * returned from a recently seen address not in the
cache was cast from struct addrinfo *ai, not the struct sockaddr *
inside of it.
In do_outgoing_connection(), when filling in the address in the
connection_t, there is a buffer overflow (read, not write) if
the sa returned by get_recent_address() didn't come from the
cache of recently seen addresses.  That is, it was really a
struct sockaddr * and not a sockaddr_t *.  This last was
found by building tinc with address sanitizer.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,178,2018-02-21T03:24:21Z,2018-02-21T18:59:17Z,2018-02-22T21:29:14Z,MERGED,True,24,11,1,https://github.com/millert,Fix heap corruption on Windows exposed by the use-after free fix.,1,[],https://github.com/gsliepen/tinc/pull/178,https://github.com/millert,1,https://github.com/gsliepen/tinc/pull/178,"reset_address_cache() could call free_known_addresses() on a struct
addrinfo * that was returned by getaddrinfo().  It seems safest to just
make a copy of the addresses returned by getaddrinfo() so we can always
use free_known_addresses() instead of trying to determine whether or
not we need to use freeaddrinfo().","reset_address_cache() could call free_known_addresses() on a struct
addrinfo * that was returned by getaddrinfo().  It seems safest to just
make a copy of the addresses returned by getaddrinfo() so we can always
use free_known_addresses() instead of trying to determine whether or
not we need to use freeaddrinfo().",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,181,2018-02-22T21:31:03Z,2018-02-26T21:30:59Z,2018-02-27T21:27:22Z,MERGED,True,6,0,1,https://github.com/millert,reset read event on error,1,[],https://github.com/gsliepen/tinc/pull/181,https://github.com/millert,1,https://github.com/gsliepen/tinc/pull/181,In device_handle_read() we need to reset the read event on error or it will keep firing.  This is easy to reproduce by suspending the machine while tincd is running.,In device_handle_read() we need to reset the read event on error or it will keep firing.  This is easy to reproduce by suspending the machine while tincd is running.,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,182,2018-02-26T17:07:38Z,2018-02-26T23:08:59Z,2018-03-01T17:27:37Z,CLOSED,False,8,3,1,https://github.com/millert,"On Windows, fill the events[] array in reverse order.",1,[],https://github.com/gsliepen/tinc/pull/182,https://github.com/millert,1,https://github.com/gsliepen/tinc/pull/182,"This helps guarantee the events will be processed in round robin order even when one event is busier than the others.  The event loop uses splay_search() to lookup the io_t by the selected event, splaying the tree.  As a result, the busy event (usually TAP) will always be first in the events[] array, which usually results in its index being returned by the next call to WSAWaitForMultipleEvents().  By putting the most active event last in events[], other active events get a chance to run.
Otherwise, we may starve events other than the TAP, which is usually at the head.  This can cause
missed PING replies.","This helps guarantee the events will be processed in round robin order even when one event is busier than the others.  The event loop uses splay_search() to lookup the io_t by the selected event, splaying the tree.  As a result, the busy event (usually TAP) will always be first in the events[] array, which usually results in its index being returned by the next call to WSAWaitForMultipleEvents().  By putting the most active event last in events[], other active events get a chance to run.
Otherwise, we may starve events other than the TAP, which is usually at the head.  This can cause
missed PING replies.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,183,2018-02-27T21:28:13Z,2018-03-01T17:27:46Z,2018-03-01T17:27:47Z,CLOSED,False,62,41,3,https://github.com/millert,Call WSAWaitForMultipleEvents() in a loop until we have checked all events,1,[],https://github.com/gsliepen/tinc/pull/183,https://github.com/millert,1,https://github.com/gsliepen/tinc/pull/183,"WSAWaitForMultipleEvents() only returns the index of the first event that is read.  We need to call WSAWaitForMultipleEvents() repeatedly to check if other events are also ready.  Otherwise, a single busy event (such as the TAP device) can starve the other events.","WSAWaitForMultipleEvents() only returns the index of the first event that is read.  We need to call WSAWaitForMultipleEvents() repeatedly to check if other events are also ready.  Otherwise, a single busy event (such as the TAP device) can starve the other events.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,186,2018-03-06T10:15:22Z,2018-03-06T18:22:26Z,2018-03-06T18:22:26Z,MERGED,True,4,1,1,https://github.com/Gjergj,fix service removal.,1,[],https://github.com/gsliepen/tinc/pull/186,https://github.com/Gjergj,1,https://github.com/gsliepen/tinc/pull/186,Windows service was not removed until tincctl exits,Windows service was not removed until tincctl exits,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,190,2018-05-10T10:36:07Z,2018-05-10T11:24:10Z,2018-05-10T11:24:10Z,MERGED,True,0,1,1,https://github.com/movie-travel-code,Remove redundant 'break'.,1,[],https://github.com/gsliepen/tinc/pull/190,https://github.com/movie-travel-code,1,https://github.com/gsliepen/tinc/pull/190,"I'm henry wong, from Qihoo360 CodeSafe Team. We found a issue about dead
code.
Since I'm unfamiliar with themis, please forgive me if there is anything
wrong with my description.
Henry Wong
Qihoo360 CodeSafe Team","I'm henry wong, from Qihoo360 CodeSafe Team. We found a issue about dead
code.
Since I'm unfamiliar with themis, please forgive me if there is anything
wrong with my description.
Henry Wong
Qihoo360 CodeSafe Team",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,201,2018-09-01T08:07:38Z,2018-09-02T09:12:12Z,2018-09-02T09:12:12Z,MERGED,True,1,1,1,https://github.com/amine177,Fixing typo,1,[],https://github.com/gsliepen/tinc/pull/201,https://github.com/amine177,1,https://github.com/gsliepen/tinc/pull/201,,,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,208,2018-10-01T13:15:49Z,2018-10-18T14:19:36Z,2018-10-18T14:19:36Z,CLOSED,False,1,3,1,https://github.com/sizeofvoid,Zap wrong OpenBSD docs,3,[],https://github.com/gsliepen/tinc/pull/208,https://github.com/sizeofvoid,1,https://github.com/gsliepen/tinc/pull/208,,,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,208,2018-10-01T13:15:49Z,2018-10-18T14:19:36Z,2018-10-18T14:19:36Z,CLOSED,False,1,3,1,https://github.com/sizeofvoid,Zap wrong OpenBSD docs,3,[],https://github.com/gsliepen/tinc/pull/208,https://github.com/gsliepen,2,https://github.com/gsliepen/tinc/pull/208#issuecomment-431027388,,Fixed in 9fac7ad.,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,210,2018-10-10T07:02:14Z,2018-10-18T14:14:58Z,2018-10-18T14:19:40Z,MERGED,True,1,1,1,https://github.com/zhsj,Fix manpage mdoc syntax,1,[],https://github.com/gsliepen/tinc/pull/210,https://github.com/zhsj,1,https://github.com/gsliepen/tinc/pull/210,,,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,212,2018-10-17T05:59:08Z,2018-10-18T14:20:37Z,2018-10-18T14:20:37Z,CLOSED,False,6,6,1,https://github.com/iczero,Fix tinc-up generation on windows,1,[],https://github.com/gsliepen/tinc/pull/212,https://github.com/iczero,1,https://github.com/gsliepen/tinc/pull/212,"use %INTERFACE% instead of $INTERFACE on windows
correct typo in netsh interface (was netsh inetface)
remove static when setting ipv6 address","use %INTERFACE% instead of $INTERFACE on windows
correct typo in netsh interface (was netsh inetface)
remove static when setting ipv6 address",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,212,2018-10-17T05:59:08Z,2018-10-18T14:20:37Z,2018-10-18T14:20:37Z,CLOSED,False,6,6,1,https://github.com/iczero,Fix tinc-up generation on windows,1,[],https://github.com/gsliepen/tinc/pull/212,https://github.com/gsliepen,2,https://github.com/gsliepen/tinc/pull/212#issuecomment-431027756,"use %INTERFACE% instead of $INTERFACE on windows
correct typo in netsh interface (was netsh inetface)
remove static when setting ipv6 address",Thanks for the patch! Cherry-picked as c926b3b.,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,213,2018-10-18T01:45:42Z,2018-10-18T14:17:26Z,2018-10-18T14:17:26Z,CLOSED,False,4,3,1,https://github.com/iczero,Set interface up before running ip route on linux,1,[],https://github.com/gsliepen/tinc/pull/213,https://github.com/iczero,1,https://github.com/gsliepen/tinc/pull/213,"iproute2 expects the interface to be up before adding routes, or
the error ""Error: Device for nexthop is not up."" happens","iproute2 expects the interface to be up before adding routes, or
the error ""Error: Device for nexthop is not up."" happens",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,213,2018-10-18T01:45:42Z,2018-10-18T14:17:26Z,2018-10-18T14:17:26Z,CLOSED,False,4,3,1,https://github.com/iczero,Set interface up before running ip route on linux,1,[],https://github.com/gsliepen/tinc/pull/213,https://github.com/gsliepen,2,https://github.com/gsliepen/tinc/pull/213#issuecomment-431026545,"iproute2 expects the interface to be up before adding routes, or
the error ""Error: Device for nexthop is not up."" happens","Fixed in 5f76bc0 by using the onlink flag, which should handle even more corner-cases.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,214,2018-11-19T21:22:22Z,2018-11-30T13:52:11Z,2018-11-30T13:52:11Z,MERGED,True,2,2,1,https://github.com/DarkShadow44,Fix interface spelling,1,[],https://github.com/gsliepen/tinc/pull/214,https://github.com/DarkShadow44,1,https://github.com/gsliepen/tinc/pull/214,"This is needed when using ""tinc join"".","This is needed when using ""tinc join"".",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,215,2018-11-19T21:23:26Z,2018-11-30T13:53:23Z,2018-11-30T13:53:23Z,CLOSED,False,5,0,1,https://github.com/DarkShadow44,Generate tinc-up.bat on windows,1,[],https://github.com/gsliepen/tinc/pull/215,https://github.com/DarkShadow44,1,https://github.com/gsliepen/tinc/pull/215,"On windows a file called ""tinc-up"" won't be executed - it needs to be named tinc-up.bat. Since it is also documented like this, we should generate a bat file when using ""tinc join"" on windows.","On windows a file called ""tinc-up"" won't be executed - it needs to be named tinc-up.bat. Since it is also documented like this, we should generate a bat file when using ""tinc join"" on windows.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,215,2018-11-19T21:23:26Z,2018-11-30T13:53:23Z,2018-11-30T13:53:23Z,CLOSED,False,5,0,1,https://github.com/DarkShadow44,Generate tinc-up.bat on windows,1,[],https://github.com/gsliepen/tinc/pull/215,https://github.com/gsliepen,2,https://github.com/gsliepen/tinc/pull/215#issuecomment-443209750,"On windows a file called ""tinc-up"" won't be executed - it needs to be named tinc-up.bat. Since it is also documented like this, we should generate a bat file when using ""tinc join"" on windows.",This has been cherry picked as commit 2bc4752. Thanks for the patch!,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,217,2018-12-12T21:48:13Z,2020-05-29T21:16:00Z,2020-05-29T21:16:00Z,CLOSED,False,18,2,4,https://github.com/neheb,OpenSSL: Fix compilation without deprecated APIs or ENGINE support,2,[],https://github.com/gsliepen/tinc/pull/217,https://github.com/neheb,1,https://github.com/gsliepen/tinc/pull/217,,,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,217,2018-12-12T21:48:13Z,2020-05-29T21:16:00Z,2020-05-29T21:16:00Z,CLOSED,False,18,2,4,https://github.com/neheb,OpenSSL: Fix compilation without deprecated APIs or ENGINE support,2,[],https://github.com/gsliepen/tinc/pull/217,https://github.com/mark-stopka,2,https://github.com/gsliepen/tinc/pull/217#issuecomment-502476747,,Is there some problem with merging this one? It has no conflicts...,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,217,2018-12-12T21:48:13Z,2020-05-29T21:16:00Z,2020-05-29T21:16:00Z,CLOSED,False,18,2,4,https://github.com/neheb,OpenSSL: Fix compilation without deprecated APIs or ENGINE support,2,[],https://github.com/gsliepen/tinc/pull/217,https://github.com/neheb,3,https://github.com/gsliepen/tinc/pull/217#issuecomment-502498270,,No interest probably.,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,217,2018-12-12T21:48:13Z,2020-05-29T21:16:00Z,2020-05-29T21:16:00Z,CLOSED,False,18,2,4,https://github.com/neheb,OpenSSL: Fix compilation without deprecated APIs or ENGINE support,2,[],https://github.com/gsliepen/tinc/pull/217,https://github.com/mark-stopka,4,https://github.com/gsliepen/tinc/pull/217#issuecomment-502538454,,"@neheb, it seems the upstream of this project is pretty dead, maybe worth forking it... I really like the plans for Tinc 2.0., but with this speed it's never going to get there.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,217,2018-12-12T21:48:13Z,2020-05-29T21:16:00Z,2020-05-29T21:16:00Z,CLOSED,False,18,2,4,https://github.com/neheb,OpenSSL: Fix compilation without deprecated APIs or ENGINE support,2,[],https://github.com/gsliepen/tinc/pull/217,https://github.com/neheb,5,https://github.com/gsliepen/tinc/pull/217#issuecomment-502538996,,Oh. This seems to have gotten merged back in December.,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,217,2018-12-12T21:48:13Z,2020-05-29T21:16:00Z,2020-05-29T21:16:00Z,CLOSED,False,18,2,4,https://github.com/neheb,OpenSSL: Fix compilation without deprecated APIs or ENGINE support,2,[],https://github.com/gsliepen/tinc/pull/217,https://github.com/neheb,6,https://github.com/gsliepen/tinc/pull/217#issuecomment-636195624,,This was merged it seems...,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,220,2019-02-20T00:50:04Z,2019-02-20T00:50:40Z,2019-02-20T00:50:40Z,CLOSED,False,0,0,0,https://github.com/requiredtruth,Merge pull request #1 from gsliepen/master,1,[],https://github.com/gsliepen/tinc/pull/220,https://github.com/requiredtruth,1,https://github.com/gsliepen/tinc/pull/220,Releasing 1.0.34.,Releasing 1.0.34.,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,221,2019-04-16T13:05:56Z,2019-07-17T22:35:13Z,2019-07-17T22:35:13Z,CLOSED,False,6,9,1,https://github.com/maciejsszmigiero,Fix a strict aliasing violation in inet_checksum(),2,[],https://github.com/gsliepen/tinc/pull/221,https://github.com/maciejsszmigiero,1,https://github.com/gsliepen/tinc/pull/221,"inet_checksum() accesses packet data as an array of uint16_t, but the
packet data can be for example of ""anonymous struct pseudo"" type from
route_ipv6_unreachable().
This type isn't a compatible type with uint16_t so a strict aliasing
violation occurs and causes the checksum to be computed incorrectly.
This was previously worked around by commit 7c73cb3 that thought this was
a GCC bug, however it really isn't.
Fix this by using the memcpy() idiom to read the packet data as an array of
uint16_t in inet_checksum() (this should be understood by compilers and
optimized accordingly, so no actual copy occurs).","inet_checksum() accesses packet data as an array of uint16_t, but the
packet data can be for example of ""anonymous struct pseudo"" type from
route_ipv6_unreachable().
This type isn't a compatible type with uint16_t so a strict aliasing
violation occurs and causes the checksum to be computed incorrectly.
This was previously worked around by commit 7c73cb3 that thought this was
a GCC bug, however it really isn't.
Fix this by using the memcpy() idiom to read the packet data as an array of
uint16_t in inet_checksum() (this should be understood by compilers and
optimized accordingly, so no actual copy occurs).",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,221,2019-04-16T13:05:56Z,2019-07-17T22:35:13Z,2019-07-17T22:35:13Z,CLOSED,False,6,9,1,https://github.com/maciejsszmigiero,Fix a strict aliasing violation in inet_checksum(),2,[],https://github.com/gsliepen/tinc/pull/221,https://github.com/mark-stopka,2,https://github.com/gsliepen/tinc/pull/221#issuecomment-502476881,"inet_checksum() accesses packet data as an array of uint16_t, but the
packet data can be for example of ""anonymous struct pseudo"" type from
route_ipv6_unreachable().
This type isn't a compatible type with uint16_t so a strict aliasing
violation occurs and causes the checksum to be computed incorrectly.
This was previously worked around by commit 7c73cb3 that thought this was
a GCC bug, however it really isn't.
Fix this by using the memcpy() idiom to read the packet data as an array of
uint16_t in inet_checksum() (this should be understood by compilers and
optimized accordingly, so no actual copy occurs).","@gsliepen, the change request has been reviewed and the pull request has no conflicts with your branch.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,221,2019-04-16T13:05:56Z,2019-07-17T22:35:13Z,2019-07-17T22:35:13Z,CLOSED,False,6,9,1,https://github.com/maciejsszmigiero,Fix a strict aliasing violation in inet_checksum(),2,[],https://github.com/gsliepen/tinc/pull/221,https://github.com/gsliepen,3,https://github.com/gsliepen/tinc/pull/221#issuecomment-512593698,"inet_checksum() accesses packet data as an array of uint16_t, but the
packet data can be for example of ""anonymous struct pseudo"" type from
route_ipv6_unreachable().
This type isn't a compatible type with uint16_t so a strict aliasing
violation occurs and causes the checksum to be computed incorrectly.
This was previously worked around by commit 7c73cb3 that thought this was
a GCC bug, however it really isn't.
Fix this by using the memcpy() idiom to read the packet data as an array of
uint16_t in inet_checksum() (this should be understood by compilers and
optimized accordingly, so no actual copy occurs).","Merged into tinc 1.1. Thanks for the patch, apologies for the delay.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,228,2019-09-24T11:29:38Z,2021-06-22T20:40:00Z,2021-06-22T20:40:00Z,CLOSED,False,42,24,5,https://github.com/admincheg, Fix infinity loop when network address and  prefix do not match,2,[],https://github.com/gsliepen/tinc/pull/228,https://github.com/admincheg,1,https://github.com/gsliepen/tinc/pull/228,We can got a tinc in infinity loop with wrong Subnet in any card and reload command.,We can got a tinc in infinity loop with wrong Subnet in any card and reload command.,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,228,2019-09-24T11:29:38Z,2021-06-22T20:40:00Z,2021-06-22T20:40:00Z,CLOSED,False,42,24,5,https://github.com/admincheg, Fix infinity loop when network address and  prefix do not match,2,[],https://github.com/gsliepen/tinc/pull/228,https://github.com/admincheg,2,https://github.com/gsliepen/tinc/pull/228#issuecomment-534520564,We can got a tinc in infinity loop with wrong Subnet in any card and reload command.,"You can reproduce issue by next steps:

Make a simple tinc config directory

tinc.conf
Name                 = left    
AddressFamily        = ipv4    
AutoConnect          = yes     
Broadcast            = no      
DecrementTTL         = yes     
DeviceStandby        = no      
DeviceType           = tun     
DirectOnly           = no      
ExperimentalProtocol = yes     
Forwarding           = internal
Hostnames            = no      
Mode                 = router  
InvitationExpire     = 1       
MaxConnectionBurst   = 4096    
ProcessPriority      = high    
ReplayWindow         = 256     
Port = 10665                   

tinc-up
#!/bin/bash                             
                                        
ip link set up $INTERFACE               
ip a add 192.168.182.1/24 dev $INTERFACE 

hosts/left
Address = 192.168.11.1  
Subnet = 192.168.182.1/32


Add executable bit for tinc-up chmod +x tinc-up
Generate keys tinc -c <cfgdir> -n left generate-keys
(Optional) If public keys placed near private -> put it to node card
Run tinc like tincd -c <cfgdir> -n left -D -d4
Try to add wrong subnet through cli tinc -c <cfgdir> -n left add Subnet 192.168.3.2/24
?????
Infinity loop

It's not happened at start, because tincd check cards and exit if found mistake.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,228,2019-09-24T11:29:38Z,2021-06-22T20:40:00Z,2021-06-22T20:40:00Z,CLOSED,False,42,24,5,https://github.com/admincheg, Fix infinity loop when network address and  prefix do not match,2,[],https://github.com/gsliepen/tinc/pull/228,https://github.com/gsliepen,3,https://github.com/gsliepen/tinc/pull/228#issuecomment-866317920,We can got a tinc in infinity loop with wrong Subnet in any card and reload command.,Merged in commits f1baecb and b7792fa.,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,229,2019-09-24T21:02:16Z,2022-03-01T12:40:48Z,2022-03-01T12:40:48Z,CLOSED,False,85,41,2,https://github.com/admincheg,Add export public ed25519 key command to tinc cli,1,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/229,https://github.com/admincheg,1,https://github.com/gsliepen/tinc/pull/229,"Old OS haven't native builds of openssl 1.1, but if they have backported packages - it's a big headache at maintenance.
Tinc can be builded statically for old systems and with that additional cli command we can operate with ed25519 keys without openssl 1.1. (At this moment we can generate key pair, but we can't get public key from private)","Old OS haven't native builds of openssl 1.1, but if they have backported packages - it's a big headache at maintenance.
Tinc can be builded statically for old systems and with that additional cli command we can operate with ed25519 keys without openssl 1.1. (At this moment we can generate key pair, but we can't get public key from private)",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,229,2019-09-24T21:02:16Z,2022-03-01T12:40:48Z,2022-03-01T12:40:48Z,CLOSED,False,85,41,2,https://github.com/admincheg,Add export public ed25519 key command to tinc cli,1,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/229,https://github.com/gsliepen,2,https://github.com/gsliepen/tinc/pull/229#issuecomment-535195618,"Old OS haven't native builds of openssl 1.1, but if they have backported packages - it's a big headache at maintenance.
Tinc can be builded statically for old systems and with that additional cli command we can operate with ed25519 keys without openssl 1.1. (At this moment we can generate key pair, but we can't get public key from private)","But you can already export the Ed25519 public key with this command:
tinc -n <netname> get Ed25519PublicKey

So I do not see a reason to add the command you propose. Unless there is a reason why the above command cannot be used?",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,229,2019-09-24T21:02:16Z,2022-03-01T12:40:48Z,2022-03-01T12:40:48Z,CLOSED,False,85,41,2,https://github.com/admincheg,Add export public ed25519 key command to tinc cli,1,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/229,https://github.com/admincheg,3,https://github.com/gsliepen/tinc/pull/229#issuecomment-535347976,"Old OS haven't native builds of openssl 1.1, but if they have backported packages - it's a big headache at maintenance.
Tinc can be builded statically for old systems and with that additional cli command we can operate with ed25519 keys without openssl 1.1. (At this moment we can generate key pair, but we can't get public key from private)","Tinc client using a host card. If you have only private key - you can't get public without external program

.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,229,2019-09-24T21:02:16Z,2022-03-01T12:40:48Z,2022-03-01T12:40:48Z,CLOSED,False,85,41,2,https://github.com/admincheg,Add export public ed25519 key command to tinc cli,1,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/229,https://github.com/stronny,4,https://github.com/gsliepen/tinc/pull/229#issuecomment-535517505,"Old OS haven't native builds of openssl 1.1, but if they have backported packages - it's a big headache at maintenance.
Tinc can be builded statically for old systems and with that additional cli command we can operate with ed25519 keys without openssl 1.1. (At this moment we can generate key pair, but we can't get public key from private)","This command is meant to be analogous to something like openssl rsa -in priv.pem -pubout. We have no way to do that with command-line tools, and tinc already has all the necessary infrastructure to make it really easy. Arguably it doesn't have much to do with tinc itself, as it's just a generic crypto call in its essense, but we don't see a better place for it.
Maybe we can introduce another binary like tinc-utils, but that also has its overhead.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,234,2020-01-20T13:04:53Z,2020-01-20T20:13:36Z,2020-01-20T20:13:36Z,MERGED,True,113,12,3,https://github.com/pacien,fd_device: allow fd to be passed through a unix socket,1,[],https://github.com/gsliepen/tinc/pull/234,https://github.com/pacien,1,https://github.com/gsliepen/tinc/pull/234,"New restrictions on the Android OS forbid direct leaking of file descriptors.
This patch allows the tinc daemon to have an fd and the associated
permissions transferred to it through a Unix domain socket.","New restrictions on the Android OS forbid direct leaking of file descriptors.
This patch allows the tinc daemon to have an fd and the associated
permissions transferred to it through a Unix domain socket.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,235,2020-02-26T07:37:57Z,,2022-03-13T20:01:20Z,OPEN,False,64,6,1,https://github.com/iczero,Prefer routes with lowest rtt,2,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/235,https://github.com/iczero,1,https://github.com/gsliepen/tinc/pull/235,"In situations where two identical routes exist, prefer the node with the lowest rtt.
An implementation of ""poor man's anycast"" as originally proposed in #194.","In situations where two identical routes exist, prefer the node with the lowest rtt.
An implementation of ""poor man's anycast"" as originally proposed in #194.",True,"{'THUMBS_UP': ['https://github.com/wolfy1339', 'https://github.com/io4', 'https://github.com/leptonyu', 'https://github.com/pacien', 'https://github.com/BWBellairs', 'https://github.com/fangfufu', 'https://github.com/CoelacanthusHex', 'https://github.com/djahandarie']}"
gsliepen/tinc,https://github.com/gsliepen/tinc,235,2020-02-26T07:37:57Z,,2022-03-13T20:01:20Z,OPEN,False,64,6,1,https://github.com/iczero,Prefer routes with lowest rtt,2,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/235,https://github.com/leptonyu,2,https://github.com/gsliepen/tinc/pull/235#issuecomment-610816156,"In situations where two identical routes exist, prefer the node with the lowest rtt.
An implementation of ""poor man's anycast"" as originally proposed in #194.","I tested it with wireguard. It seems that this strategy will affect tinc to choose the right endpoint of node.
I have 3 nodes, A,B,C
A, has public ip 1.2.3.4
B and C has no public ip.
I set tinc cidr as 10.0.0.0/24
wireguard cidr as 10.0.1.0/24
A has ip 10.0.0.1, 10.0.1.1, 1.2.3.4
B has ip 10.0.0.2,10.0.1.2
C has ip 10.0.0.3,10.0.1.3
Wireguard only support forword packets from B to C By A. So B can ping C using 10.0.1.3，and this is stable.
Tinc can make nat hole punching, using A, so C may has some public ip 2.3.4.5 with port 34562.
C endpoint 2.3.4.5:34562 is not stable due to nat timeout.
With this strategy, i find that tinc node C's endpoint will become 10.0.1.3:655.
I want this,
C = 2.3.4.5 => B
But, result in
C = 1.0.1.3 => A => 1.0.0.3 => B
.
I think this strategy should be controlled by configuration, not automatically. Some situations may not fit this strategy.",True,"{'THUMBS_DOWN': ['https://github.com/wolfy1339', 'https://github.com/djahandarie']}"
gsliepen/tinc,https://github.com/gsliepen/tinc,235,2020-02-26T07:37:57Z,,2022-03-13T20:01:20Z,OPEN,False,64,6,1,https://github.com/iczero,Prefer routes with lowest rtt,2,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/235,https://github.com/wolfy1339,3,https://github.com/gsliepen/tinc/pull/235#issuecomment-611079020,"In situations where two identical routes exist, prefer the node with the lowest rtt.
An implementation of ""poor man's anycast"" as originally proposed in #194.","This shouldn't affect the current behaviour, only for situations where 1 or more nodes have the same subnet (what you're referring to as CIDR).
Example:
A has 0.0.0.0/0 and 10.0.0.1/24
B has 0.0.0.0/0 and 10.0.0.2/24
C has 10.0.0.3/24
If C has a lower RTT to A rather than B, it will choose to forward those packets to A. If B has a better RTT than A, C will forward the packets to B.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,235,2020-02-26T07:37:57Z,,2022-03-13T20:01:20Z,OPEN,False,64,6,1,https://github.com/iczero,Prefer routes with lowest rtt,2,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/235,https://github.com/iczero,4,https://github.com/gsliepen/tinc/pull/235#issuecomment-611165894,"In situations where two identical routes exist, prefer the node with the lowest rtt.
An implementation of ""poor man's anycast"" as originally proposed in #194.","This PR does not affect the behavior you describe. Tinc already does this automatically. This PR only affects which node packets are sent to, not how.",True,{'THUMBS_UP': ['https://github.com/wolfy1339']}
gsliepen/tinc,https://github.com/gsliepen/tinc,235,2020-02-26T07:37:57Z,,2022-03-13T20:01:20Z,OPEN,False,64,6,1,https://github.com/iczero,Prefer routes with lowest rtt,2,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/235,https://github.com/leptonyu,5,https://github.com/gsliepen/tinc/pull/235#issuecomment-611295208,"In situations where two identical routes exist, prefer the node with the lowest rtt.
An implementation of ""poor man's anycast"" as originally proposed in #194.","yeah, you are right. @iczero @wolfy1339.
I should disable forward between 10.0.0.0/24 and 10.0.1.0/24. This will make  C = 1.0.1.3 => A => 1.0.0.3 => B impossible.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,235,2020-02-26T07:37:57Z,,2022-03-13T20:01:20Z,OPEN,False,64,6,1,https://github.com/iczero,Prefer routes with lowest rtt,2,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/235,https://github.com/fangfufu,6,https://github.com/gsliepen/tinc/pull/235#issuecomment-868860562,"In situations where two identical routes exist, prefer the node with the lowest rtt.
An implementation of ""poor man's anycast"" as originally proposed in #194.","@gsliepen , I think this pull request is an excellent feature.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,235,2020-02-26T07:37:57Z,,2022-03-13T20:01:20Z,OPEN,False,64,6,1,https://github.com/iczero,Prefer routes with lowest rtt,2,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/235,https://github.com/splitice,7,https://github.com/gsliepen/tinc/pull/235#issuecomment-869650479,"In situations where two identical routes exist, prefer the node with the lowest rtt.
An implementation of ""poor man's anycast"" as originally proposed in #194.",Regarding cache I think it's perfectly acceptable to employ a heavy level of route caching. Not only is it something that should not change frequently route switches for small changes in network conditions should be avoided as many protocols (those designed to handle such situations) will become unstable.,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,235,2020-02-26T07:37:57Z,,2022-03-13T20:01:20Z,OPEN,False,64,6,1,https://github.com/iczero,Prefer routes with lowest rtt,2,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/235,https://github.com/gsliepen,8,https://github.com/gsliepen/tinc/pull/235#issuecomment-871731099,"In situations where two identical routes exist, prefer the node with the lowest rtt.
An implementation of ""poor man's anycast"" as originally proposed in #194.","Frequent route switches should indeed be averted, but there's no telling how long the route will stay cached, and thus it's rather unpredictable when, if ever, it will switch to a route with a lower RTT. A possible solution is to just flush the cache at regular intervals. Also, the second and third point I mentioned are still issues that should be solved.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,235,2020-02-26T07:37:57Z,,2022-03-13T20:01:20Z,OPEN,False,64,6,1,https://github.com/iczero,Prefer routes with lowest rtt,2,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/235,https://github.com/splitice,9,https://github.com/gsliepen/tinc/pull/235#issuecomment-875644335,"In situations where two identical routes exist, prefer the node with the lowest rtt.
An implementation of ""poor man's anycast"" as originally proposed in #194.","How does this PR affect relayed connections?
i.e
A has 10.0.0.1/24
B has 10.0.0.2/24
C has 10.0.0.3/24
D has 10.0.0.4/24
i.e where A is not connected to D but B&C are. A is connected to both B&C. Will this PR choose an improved route e.g A->B->D if B route has lower RTT than C?",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,235,2020-02-26T07:37:57Z,,2022-03-13T20:01:20Z,OPEN,False,64,6,1,https://github.com/iczero,Prefer routes with lowest rtt,2,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/235,https://github.com/iczero,10,https://github.com/gsliepen/tinc/pull/235#issuecomment-877843573,"In situations where two identical routes exist, prefer the node with the lowest rtt.
An implementation of ""poor man's anycast"" as originally proposed in #194.","Apparently github ate my previous comment... I currently do not have time to work on this, but I will update the PR when I do.
Regarding the current code, it seems that it could possibly work better if there was a separate table containing all routes announced by more than one node (anycast routes), then potentially doing things from there (udp probes, lookups for routes flagged anycast, etc).
@splitice this PR will not affect that case, it should only pick the lowest rtt node between 2 nodes advertising the same subnet.
Please ignore the rebases for now. They do not introduce changes.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,235,2020-02-26T07:37:57Z,,2022-03-13T20:01:20Z,OPEN,False,64,6,1,https://github.com/iczero,Prefer routes with lowest rtt,2,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/235,https://github.com/splitice,11,https://github.com/gsliepen/tinc/pull/235#issuecomment-877877759,"In situations where two identical routes exist, prefer the node with the lowest rtt.
An implementation of ""poor man's anycast"" as originally proposed in #194.","@iczero Have you thought about aproaching this in a way that could be used for general purpose routing? You might be able to kill a few birds with one PR too.
Perhaps each node advertises known subnets (routes) with the best RTT to that node (route cache can be used and as of #270 as it will not be cleared as frequently) to it's known nodes. On receipt simply update the splay entry and (if no conflict or subnet already exists in cache) the route cache on the receiving node. The routing algorithm could simply select the lowest RTT stored in the splay tree on cache miss.
This would be predictable in that each node would be expected to supply regular updates and by invalidating the cache. There would still be some room for improvement by further reducing over clearing of the subnet cache and perhaps linking the cache more closely with the splay to prevent the need to do regular splay searches on these updates.
To rehash my example from before:
NODE A knows: NODE B (100ms), NODE C (100ms)
NODE B knows: NODE A (100ms), NODE C (10ms), NODE D (100ms)
NODE C knows: NODE A (100ms), NODE B (10ms), NODE D (200ms)
NODE D knows: NODE B (100ms), NODE C (200ms)

In this case node A having received updates from both B and C would know that it's best path to D is via B.  This would also work for your case of anycast.
This would also resolve #45 (not of interest to me, but I do understand why it's interseting to other use cases) and the regular updates could be used to provide accurate RTT values.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,235,2020-02-26T07:37:57Z,,2022-03-13T20:01:20Z,OPEN,False,64,6,1,https://github.com/iczero,Prefer routes with lowest rtt,2,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/235,https://github.com/gsliepen,12,https://github.com/gsliepen/tinc/pull/235#issuecomment-879398598,"In situations where two identical routes exist, prefer the node with the lowest rtt.
An implementation of ""poor man's anycast"" as originally proposed in #194.","[...] This would be predictable in that each node would be expected to supply regular updates [...]

This is going to cause a lot of traffic in large meshes. Also, finding the path with the lowest total RTT if direct communication with a node is not possible would require running the graph algorithms more frequently as well, and the sum of measured RTTs along a path might be a poor indication of the actual RTT since it doesn't include the overhead of forwarding packets by all the intermediate nodes.
We have to balance some things here. Perfect path selection requires continuous measurement of RTT along all possible paths, which is intractable on meshes with many nodes. So we should forget about this. We currently have some knowledge of RTTs, but for paths not taken the RTT is currently not updated. So I think the approach should be that if we have traffic to a Subnet with multiple possible nodes, we have the one we currently are using, and then we regularly try to improve the selection by probing the RTT of one of the other possible nodes (using try_tx(candidate, false)), until we get a RTT that is lower than the current RTT of the currently used node. Then we switch.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,235,2020-02-26T07:37:57Z,,2022-03-13T20:01:20Z,OPEN,False,64,6,1,https://github.com/iczero,Prefer routes with lowest rtt,2,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/235,https://github.com/splitice,13,https://github.com/gsliepen/tinc/pull/235#issuecomment-879556755,"In situations where two identical routes exist, prefer the node with the lowest rtt.
An implementation of ""poor man's anycast"" as originally proposed in #194.","@gsliepen what would be too much traffic in your opinion?
Perhaps:
Each node sends a packet to each of it's directly connected nodes with the [node, rtt] of each subnet that has at-least one route cached (active check). I was thinking subnets originally but a consistent (32bit?) node id might be better. With the packet just being a list of these and node being an efficiently stored id (is there an ID that could be used or would it need to be the public address of the node?) you could target least 200+ updated routes per packet. The update cycle could be limited to one full packet if needed or configuration options could exist to limit the frequency of these updates.
Assuming that each node has has 200 active peers at a given time (thats alot) then that would be one full 1,500 byte packet every 30 seconds sent to each of them and received from each of those active peers. That means on a 30 second interval assuming all these numbers we would be looking in the ballpark of 10kb/s rx&tx at that large scale. Thats on the same scale as the TCP keepalives (if TCP connections are in use) and likely just as negligible.
For smaller networks the bandwidth cost of something like this would be miniscule and comparable to a regular tunnel check operation.
Sending these from each node to all their active peers every say 30 seconds with jitter (best to be configurable) wouldnt be substantial. Sending these updates to all peers (not just active) would be a nice feature to also resolve #45 (either a configuration option or an option to dio this on a reduced rate) and could be looked at.
As someone who operates a larger network I wouldnt have an issue with 10kb/s usage in tunnel upkeep (or even much more). I'm much more irritated when my traffic is hauled around the world twice.

(using try_tx(candidate, false)), until we get a RTT that is lower than the current RTT of the currently used node. Then we switch.

That sounds good but on larger networks it could take a VERY long time to find the best candidate if 200 connections have to be tested randomly.
I don't dislike the idea entirely (I do like it's seeming simplicity).
Some problems I see & thoughts:

The test of the new route couldnt use actual packet data or reordering could occur?
How do we know to do these tests (as opposed to using the current ""best"" route)?
Can the route search be ordered to improve the likelihood of finding the best route in the first say 10 routes or are we stuck with random order?
By being passive it's not able to cleanly react to short interruptions between nodes which is a common use case for forwarding
Would be a really good idea to improve the caching so both the current active and the secondary fallback route was maintained. This way if a route goes back up or is flapping the best relayed route was still known and the search for a good route would not have to begin again.
Do we need to search one node at a time? Could the TTL be searched over N nodes at a time?

Possibly difficult but perhaps on each route add (incl relayed route) each tinc node pings the node through that relay and generates a RTT to use. This RTT can be cached until its updated next.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,235,2020-02-26T07:37:57Z,,2022-03-13T20:01:20Z,OPEN,False,64,6,1,https://github.com/iczero,Prefer routes with lowest rtt,2,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/235,https://github.com/gsliepen,14,https://github.com/gsliepen/tinc/pull/235#issuecomment-882874262,"In situations where two identical routes exist, prefer the node with the lowest rtt.
An implementation of ""poor man's anycast"" as originally proposed in #194.","@gsliepen what would be too much traffic in your opinion?

We want to limit background traffic as much as possible. We need some keepalive packets for the meta-connections, and we have on-demand UDP probe packets (ie, probe packets are only sent while actual VPN packets are being exchanged between two nodes). Probing for better routes should also be on-demand.

Each node sends a packet to each of it's directly connected nodes with the [node, rtt] of each subnet that has at-least one route cached (active check). I was thinking subnets originally but a consistent (32bit?) node id might be better. With the packet just being a list of these and node being an efficiently stored id (is there an ID that could be used or would it need to be the public address of the node?) you could target least 200+ updated routes per packet. The update cycle could be limited to one full packet if needed or configuration options could exist to limit the frequency of these updates.

Sure, but that's just exchanging already known information. The problem is that unless nodes are exchanging data with each other, there is no information to share, because RTT times are only measured via the UDP probes, which are only sent on-demand. Consider nodes A, B, C and D. A, B, C all announce Subnet = 192.168.1.0/24, and then D wants to send a packet to 192.168.1.1. If it picks a random node, say A, it will learn the RTT of A, but then that is the best known RTT. The only way to learn more is if D starts actively probing the RTT to B and C. RTT updates from other nodes don't help at all here.
Note that tinc tries to avoid hop-by-hop routing, it always prefers to send packets directly to their destination. So if you have nodes A <-> B <-> C, then A tries to send directly to C via UDP, and knowing the RTT between A and B or B and C is not going to help, unless it couldn't send packets directly to C. But that would be the exceptional case.

Assuming that each node has has 200 active peers at a given time (thats alot) then that would be one full 1,500 byte packet every 30 seconds sent to each of them and received from each of those active peers. That means on a 30 second interval assuming all these numbers we would be looking in the ballpark of 10kb/s rx&tx at that large scale. Thats on the same scale as the TCP keepalives (if TCP connections are in use) and likely just as negligible.
[...]
As someone who operates a larger network I wouldnt have an issue with 10kb/s usage in tunnel upkeep (or even much more). I'm much more irritated when my traffic is hauled around the world twice.

Uhm no, the PING/PONG requests are only sent once a minute by default and are more like 50 bytes in size. If you mean TCP's own keepalive packets, then those are disabled by default, and if enabled, the default time before it sends a packet on an idle connection is 2 hours. 10 kb/s is already quite a lot for some users, especially those that pay for bandwidth.


(using try_tx(candidate, false)), until we get a RTT that is lower than the current RTT of the currently used node. Then we switch.

That sounds good but on larger networks it could take a VERY long time to find the best candidate if 200 connections have to be tested randomly.

But we don't have to do that. If we send a packet for a Subnet that is advertized by multiple nodes, only then do we need to ensure we also probe the other nodes that advertize that Subnet, we don't need to test all nodes in the mesh.

Some problems I see & thoughts:
* The test of the new route couldnt use actual packet data or reordering could occur?


The new routes should use the UDP probe packets first. These will also help punch holes through NAT. Actual data packets should go to the known working node unless we are sure the new route is viable and better.

* How do we know to do these tests (as opposed to using the current ""best"" route)?


We should detect when a Subnet is advertized by multiple nodes and set some flag, so when we send a packet to that Subnet and it's time to send a probe, we also probe one of the other candidates. That could be just a random pick, or round-robin.

* Can the route search be ordered to improve the likelihood of finding the best route in the first say 10 routes or are we stuck with random order?


You mean finding the best route in the first 10 seconds?

* By being passive it's not able to cleanly react to short interruptions between nodes which is a common use case for forwarding


It shouldn't be passive, it should react to actual demand for VPN traffic.

* Would be a really good idea to improve the caching so both the current active and the secondary fallback route was maintained. This way if a route goes back up or is flapping the best relayed route was still known and the search for a good route would not have to begin again.


Well if we probe other candidates regularly anyway, then we should have reasonably up-to-date RTT information for all candidates. So if one goes down or suddenly gets a bad RTT, then we just flush the bad entry from the cache, and then the cache will be repopulated with the remaining best candidate.

* Do we need to search one node at a time? Could the TTL be searched over N nodes at a time?


We could indeed do that.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,235,2020-02-26T07:37:57Z,,2022-03-13T20:01:20Z,OPEN,False,64,6,1,https://github.com/iczero,Prefer routes with lowest rtt,2,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/235,https://github.com/splitice,15,https://github.com/gsliepen/tinc/pull/235#issuecomment-883828716,"In situations where two identical routes exist, prefer the node with the lowest rtt.
An implementation of ""poor man's anycast"" as originally proposed in #194.","We want to limit background traffic as much as possible. We need some keepalive packets for the meta-connections, and we have on-demand UDP probe packets (ie, probe packets are only sent while actual VPN packets are being exchanged between two nodes). Probing for better routes should also be on-demand.

Wouldnt the liveness be covered simply by the route being in the cache?

Uhm no, the PING/PONG requests are only sent once a minute by default and are more like 50 bytes in size. If you mean TCP's own keepalive packets, then those are disabled by default, and if enabled, the default time before it sends a packet on an idle connection is 2 hours. 10 kb/s is already quite a lot for some users, especially those that pay for bandwidth.

I'm not suggesting is suggesting one datapoint per packet, as many records as possible should be packed into a single packet.
As you have already alluded to there is is already existing interactions that would use significantly more traffic than what this feature would.

But we don't have to do that. If we send a packet for a Subnet that is advertized by multiple nodes, only then do we need to ensure we also probe the other nodes that advertize that Subnet, we don't need to test all nodes in the mesh.

You do if you want to use the same implementation to also handle smarter routing for relaying (which is where my interest lies). Anycast improvement / support is just a buyproduct for me.

What about this as an alternative.

Route cache gets two slots per physical route, an active and a backup (key gains an additional member) or an extra member in the struct. This extra slot would be an ""optimal"" learnt relayed route.

It may be best to store this in the same hash table slot as a member of the primary entry instead of as a totally seperate slot. TBD.
If stored as a seperate slot a backup route has a lower storage priority, an active route should never be cleared to make room for a backup route


Periodically issue source probe requests for the nodes behind $N subnets where the subnets probed are taken from the route cache (therefore recently active), this could be performed on a periodic interval $T defined in config. We send these ping requests to randomly selected peer nodes. If the response comes back with a lower RTT than the stored backup route (or no backup route exists) then update the backup route if relayed (the active route if the node provides the subnet i.e anycast).

When requesting the RTT to a relayer for a child node the relayer will use it's cached RTT if available (and not stale). If the RTT is stale / missing it will perform a new ping and indicate this with a flag to the requester. In this way there are three main RTT  measurements:


ping request to subnet (where node provides subnet): RTT is detirmined by the measured time between request and response
ping request to relayer for subnet (where relayer had a non-stale RTT value): pong reply includes a data field for the cached RTT value which is added onto the measured time
ping request to the relayer for subnet (where relayer had a stale / missing RTT value): pong reply includes a zero RTT data field, the measured RTT time includes the ping to the child node.



This way the backup route is also ready when it's needed (providing that the chosen relay node isnt also offline). That's something I would also like to cover, but with the limitations expressed (no active information transfer) I'm not certain how at this stage. The reason I would like for more information transfer is that quite often when a partial interupution occurs between two points it's the result of a single transit provider or link but it may take out 50%+ of upstreams. Finding a working path is currently something tinc does not do well (quickly), and I would love if this was to improve that.
$N can be set to 0 in the config if active ""route optimization"" (name?) is not destired. Set to non zero with a regular enough interval this would also serve to keep holepunched ports open. Not important for my use cases, but for others it is.
If someone was in the situation where the <1MB/day (small network) to potentially 10's of MB/day (big network) something like this would use at reasonable $T interval and $N nodes they could disable the feature by setting the config option(s) to zero. Assuming that such nodes would also be non-relayers then there would be no difference to them, asside from the odd additional ping message (for their own subnet).",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,235,2020-02-26T07:37:57Z,,2022-03-13T20:01:20Z,OPEN,False,64,6,1,https://github.com/iczero,Prefer routes with lowest rtt,2,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/235,https://github.com/fangfufu,16,https://github.com/gsliepen/tinc/pull/235#issuecomment-901528234,"In situations where two identical routes exist, prefer the node with the lowest rtt.
An implementation of ""poor man's anycast"" as originally proposed in #194.","I think having a solution is better than having no solution. Personally, I wouldn't mind for using more bandwidth overall. I would much prefer if tinc can default to route with the lowest rtt, even if that means using more bandwidth overall. We could have this feature implemented and turned off by default, so tinc behaves the same as before by default. The users by default don't get an increase in bandwidth usage, unless they manually turn this feature on.

If you mean TCP's own keepalive packets, then those are disabled by default, and if enabled, the default time before it sends a packet on an idle connection is 2 hours. 10 kb/s is already quite a lot for some users, especially those that pay for bandwidth.

If the identities of these users are not sensitive information, I would love to know who they are. I think we could do with a testimonial section on tinc's website. I feel people don't realise how useful and versatile tinc is, compared to things like Wireguard and OpenVPN.
The amount of bandwidth people have access to have changed a lot since tinc was first originally written (20 years ago), and since tinc-1.1 was first released (10 years ago). Just to give some examples from my personal experiences, 10 years ago video chatting with my parents in China was a struggle probably around half of the time, and the resolution was probably 240p. These days I pretty much expect to see my parents' face in 720p, well, at least 480p. 20 years ago I was on dial up, ""broadband"" wasn't in my country yet... Even 5 years ago I wouldn't be watching Youtube non-stop on my mobile phone's data plan.",True,"{'THUMBS_UP': ['https://github.com/CoelacanthusHex', 'https://github.com/djahandarie', 'https://github.com/iYUYUE']}"
gsliepen/tinc,https://github.com/gsliepen/tinc,235,2020-02-26T07:37:57Z,,2022-03-13T20:01:20Z,OPEN,False,64,6,1,https://github.com/iczero,Prefer routes with lowest rtt,2,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/235,https://github.com/iczero,17,https://github.com/gsliepen/tinc/pull/235#issuecomment-920611237,"In situations where two identical routes exist, prefer the node with the lowest rtt.
An implementation of ""poor man's anycast"" as originally proposed in #194.","Fixed the subnet selection issue. The cache seems to be invalidated with graph changes, which may be enough.",True,{'THUMBS_UP': ['https://github.com/CoelacanthusHex']}
gsliepen/tinc,https://github.com/gsliepen/tinc,238,2020-03-15T01:40:54Z,2020-07-06T17:31:33Z,2020-10-31T01:24:34Z,MERGED,True,5,1,1,https://github.com/leptonyu,fix macos build,1,[],https://github.com/gsliepen/tinc/pull/238,https://github.com/leptonyu,1,https://github.com/gsliepen/tinc/pull/238,#234 breaks the macos build.,#234 breaks the macos build.,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,240,2020-04-05T11:20:11Z,2021-06-22T20:39:23Z,2021-06-22T20:39:24Z,CLOSED,False,5,0,1,https://github.com/liweitianux,"Use auto-clone device /dev/{tun,tap} as default on FreeBSD/DragonFly",1,[],https://github.com/gsliepen/tinc/pull/240,https://github.com/liweitianux,1,https://github.com/gsliepen/tinc/pull/240,"DragonFly BSD doesn't pre-create /dev/tunX or /dev/tapX devices
anymore since 2019-Jul-31 [0].  So it's better to use the auto-clone
device /dev/tun or /dev/tap as the default TUN or TAP device.
The TUN/TAP device has the same behavior on DragonFly BSD and FreeBSD.
See also pull request: DragonFlyBSD/DeltaPorts#925
[0] DragonFlyBSD/DragonFlyBSD@f1e9a4f
Please review.  Thanks.","DragonFly BSD doesn't pre-create /dev/tunX or /dev/tapX devices
anymore since 2019-Jul-31 [0].  So it's better to use the auto-clone
device /dev/tun or /dev/tap as the default TUN or TAP device.
The TUN/TAP device has the same behavior on DragonFly BSD and FreeBSD.
See also pull request: DragonFlyBSD/DeltaPorts#925
[0] DragonFlyBSD/DragonFlyBSD@f1e9a4f
Please review.  Thanks.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,240,2020-04-05T11:20:11Z,2021-06-22T20:39:23Z,2021-06-22T20:39:24Z,CLOSED,False,5,0,1,https://github.com/liweitianux,"Use auto-clone device /dev/{tun,tap} as default on FreeBSD/DragonFly",1,[],https://github.com/gsliepen/tinc/pull/240,https://github.com/gsliepen,2,https://github.com/gsliepen/tinc/pull/240#issuecomment-866317549,"DragonFly BSD doesn't pre-create /dev/tunX or /dev/tapX devices
anymore since 2019-Jul-31 [0].  So it's better to use the auto-clone
device /dev/tun or /dev/tap as the default TUN or TAP device.
The TUN/TAP device has the same behavior on DragonFly BSD and FreeBSD.
See also pull request: DragonFlyBSD/DeltaPorts#925
[0] DragonFlyBSD/DragonFlyBSD@f1e9a4f
Please review.  Thanks.",Merged in commit f8c1e74.,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,241,2020-04-05T11:20:54Z,2020-04-06T03:08:38Z,2020-04-06T03:08:39Z,CLOSED,False,5,0,1,https://github.com/liweitianux,"Use auto-clone device /dev/{tun,tap} as default on FreeBSD/DragonFly",1,[],https://github.com/gsliepen/tinc/pull/241,https://github.com/liweitianux,1,https://github.com/gsliepen/tinc/pull/241,"DragonFly BSD doesn't pre-create /dev/tunX or /dev/tapX devices
anymore since 2019-Jul-31 [0].  So it's better to use the auto-clone
device /dev/tun or /dev/tap as the default TUN or TAP device.
The TUN/TAP device has the same behavior on DragonFly BSD and FreeBSD.
See also pull request: DragonFlyBSD/DeltaPorts#925
[0] DragonFlyBSD/DragonFlyBSD@f1e9a4f
See also PR #240 .  Please review.  Thanks.","DragonFly BSD doesn't pre-create /dev/tunX or /dev/tapX devices
anymore since 2019-Jul-31 [0].  So it's better to use the auto-clone
device /dev/tun or /dev/tap as the default TUN or TAP device.
The TUN/TAP device has the same behavior on DragonFly BSD and FreeBSD.
See also pull request: DragonFlyBSD/DeltaPorts#925
[0] DragonFlyBSD/DragonFlyBSD@f1e9a4f
See also PR #240 .  Please review.  Thanks.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,241,2020-04-05T11:20:54Z,2020-04-06T03:08:38Z,2020-04-06T03:08:39Z,CLOSED,False,5,0,1,https://github.com/liweitianux,"Use auto-clone device /dev/{tun,tap} as default on FreeBSD/DragonFly",1,[],https://github.com/gsliepen/tinc/pull/241,https://github.com/wolfy1339,2,https://github.com/gsliepen/tinc/pull/241#issuecomment-609480730,"DragonFly BSD doesn't pre-create /dev/tunX or /dev/tapX devices
anymore since 2019-Jul-31 [0].  So it's better to use the auto-clone
device /dev/tun or /dev/tap as the default TUN or TAP device.
The TUN/TAP device has the same behavior on DragonFly BSD and FreeBSD.
See also pull request: DragonFlyBSD/DeltaPorts#925
[0] DragonFlyBSD/DragonFlyBSD@f1e9a4f
See also PR #240 .  Please review.  Thanks.",This is a duplicate PR of #240. There's no need to open 2 pull requests with the same code,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,241,2020-04-05T11:20:54Z,2020-04-06T03:08:38Z,2020-04-06T03:08:39Z,CLOSED,False,5,0,1,https://github.com/liweitianux,"Use auto-clone device /dev/{tun,tap} as default on FreeBSD/DragonFly",1,[],https://github.com/gsliepen/tinc/pull/241,https://github.com/liweitianux,3,https://github.com/gsliepen/tinc/pull/241#issuecomment-609542571,"DragonFly BSD doesn't pre-create /dev/tunX or /dev/tapX devices
anymore since 2019-Jul-31 [0].  So it's better to use the auto-clone
device /dev/tun or /dev/tap as the default TUN or TAP device.
The TUN/TAP device has the same behavior on DragonFly BSD and FreeBSD.
See also pull request: DragonFlyBSD/DeltaPorts#925
[0] DragonFlyBSD/DragonFlyBSD@f1e9a4f
See also PR #240 .  Please review.  Thanks.","@wolfy1339, Thanks. That PR #240 is for the 1.1 development branch, while this PR is for the master branch. I'll close this PR.  Once the developers merged PR #240, they can also cherry pick it over to the master branch.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,242,2020-04-12T18:24:04Z,2021-06-30T22:18:21Z,2021-06-30T22:18:22Z,CLOSED,False,30,0,1,https://github.com/nh2,Warn if system capped requested socket buffer sizes,1,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/242,https://github.com/nh2,1,https://github.com/gsliepen/tinc/pull/242,This helps noticing when the system does not apply the requested sizes.,This helps noticing when the system does not apply the requested sizes.,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,242,2020-04-12T18:24:04Z,2021-06-30T22:18:21Z,2021-06-30T22:18:22Z,CLOSED,False,30,0,1,https://github.com/nh2,Warn if system capped requested socket buffer sizes,1,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/242,https://github.com/nh2,2,https://github.com/gsliepen/tinc/pull/242#issuecomment-612662154,This helps noticing when the system does not apply the requested sizes.,"There are also some things I don't understand. When I run with this with
UDPRcvBuf = 25000000
UDPSndBuf = 25000000

in the tinc-1.1pre17 on config on Linux 5.4.27, I see:
Can't set UDP SO_RCVBUF to 25000000, the system set it to 50000000 instead
Can't set UDP SO_SNDBUF to 25000000, the system set it to 50000000 instead
Can't set UDP SO_RCVBUF to 25000000, the system set it to 50000000 instead
Can't set UDP SO_SNDBUF to 25000000, the system set it to 50000000 instead

The same thing happens with the default config:
Can't set UDP SO_RCVBUF to 1048576, the system set it to 425984 instead
Can't set UDP SO_SNDBUF to 1048576, the system set it to 425984 instead
Can't set UDP SO_RCVBUF to 1048576, the system set it to 425984 instead
Can't set UDP SO_SNDBUF to 1048576, the system set it to 425984 instead

So it looks like the system set it to 2x the requested amount. Why would that be?",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,242,2020-04-12T18:24:04Z,2021-06-30T22:18:21Z,2021-06-30T22:18:22Z,CLOSED,False,30,0,1,https://github.com/nh2,Warn if system capped requested socket buffer sizes,1,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/242,https://github.com/gsliepen,3,https://github.com/gsliepen/tinc/pull/242#issuecomment-871763706,This helps noticing when the system does not apply the requested sizes.,"Thanks, cherry-picked as 73a45af.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,251,2020-09-08T23:55:52Z,2021-06-27T14:27:56Z,2021-06-27T14:27:56Z,CLOSED,False,1,1,1,https://github.com/pacien,[android] tincctl: restrict umask argument for FORTIFY,1,[],https://github.com/gsliepen/tinc/pull/251,https://github.com/pacien,1,https://github.com/gsliepen/tinc/pull/251,"umask(mode) calls that do not verify (mode & 0777) == mode are
rejected when the libc FORTIFY checks are enabled 1.
The unrestricted ~perms was indeed making this assertion fail.

This is needed for tinc to correctly run when built with the latest Android NDK,
which enables the FORTIFY checks.","umask(mode) calls that do not verify (mode & 0777) == mode are
rejected when the libc FORTIFY checks are enabled 1.
The unrestricted ~perms was indeed making this assertion fail.

This is needed for tinc to correctly run when built with the latest Android NDK,
which enables the FORTIFY checks.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,251,2020-09-08T23:55:52Z,2021-06-27T14:27:56Z,2021-06-27T14:27:56Z,CLOSED,False,1,1,1,https://github.com/pacien,[android] tincctl: restrict umask argument for FORTIFY,1,[],https://github.com/gsliepen/tinc/pull/251,https://github.com/gsliepen,2,https://github.com/gsliepen/tinc/pull/251#issuecomment-869172608,"umask(mode) calls that do not verify (mode & 0777) == mode are
rejected when the libc FORTIFY checks are enabled 1.
The unrestricted ~perms was indeed making this assertion fail.

This is needed for tinc to correctly run when built with the latest Android NDK,
which enables the FORTIFY checks.",Cherry-picked as commit 4cc4b9b,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,258,2021-04-02T21:38:01Z,2021-06-22T20:38:57Z,2021-06-22T20:39:44Z,CLOSED,False,5,1,2,https://github.com/neheb,fix compilation without deprecated OpenSSL APIs,1,[],https://github.com/gsliepen/tinc/pull/258,https://github.com/neheb,1,https://github.com/gsliepen/tinc/pull/258,"This was fixed for 1.0 but missing for 1.1.
Signed-off-by: Rosen Penev rosenp@gmail.com","This was fixed for 1.0 but missing for 1.1.
Signed-off-by: Rosen Penev rosenp@gmail.com",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,258,2021-04-02T21:38:01Z,2021-06-22T20:38:57Z,2021-06-22T20:39:44Z,CLOSED,False,5,1,2,https://github.com/neheb,fix compilation without deprecated OpenSSL APIs,1,[],https://github.com/gsliepen/tinc/pull/258,https://github.com/gsliepen,2,https://github.com/gsliepen/tinc/pull/258#issuecomment-866317287,"This was fixed for 1.0 but missing for 1.1.
Signed-off-by: Rosen Penev rosenp@gmail.com",Merged in commit f12e34d.,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,263,2021-06-23T21:46:39Z,2021-06-27T14:24:27Z,2021-06-27T14:24:27Z,CLOSED,False,94,15,17,https://github.com/fangfufu,Pull request to fix issue #230 (Segfault with x86_64-w64-mingw-w64),11,[],https://github.com/gsliepen/tinc/pull/263,https://github.com/fangfufu,1,https://github.com/gsliepen/tinc/pull/263,"This pull request fix the problem described in issue #230.

Segfault with x86_64-w64-mingw-w64
I have determined via git bisect that d6b45d0 is the commit that introduces the segfault.
The produced binary runs for a couple seconds then it segfaults
1.1-pre17 compiles and runs fine","This pull request fix the problem described in issue #230.

Segfault with x86_64-w64-mingw-w64
I have determined via git bisect that d6b45d0 is the commit that introduces the segfault.
The produced binary runs for a couple seconds then it segfaults
1.1-pre17 compiles and runs fine",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,263,2021-06-23T21:46:39Z,2021-06-27T14:24:27Z,2021-06-27T14:24:27Z,CLOSED,False,94,15,17,https://github.com/fangfufu,Pull request to fix issue #230 (Segfault with x86_64-w64-mingw-w64),11,[],https://github.com/gsliepen/tinc/pull/263,https://github.com/gsliepen,2,https://github.com/gsliepen/tinc/pull/263#issuecomment-869172119,"This pull request fix the problem described in issue #230.

Segfault with x86_64-w64-mingw-w64
I have determined via git bisect that d6b45d0 is the commit that introduces the segfault.
The produced binary runs for a couple seconds then it segfaults
1.1-pre17 compiles and runs fine","This pull request is in a bad state: it's adding lots of files that shouldn't be there, and there were merge conflicts. I've picked the few things I think were relevant for the 1.1 branch and merged those individually.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,268,2021-06-29T00:25:59Z,2021-07-13T20:27:36Z,2021-07-13T20:27:36Z,CLOSED,False,19,12,1,https://github.com/splitice,bail out of logging early,1,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/268,https://github.com/splitice,1,https://github.com/gsliepen/tinc/pull/268,"Very Low hanging fruit.
Accounts for 2% of RX perf trace on Vultr Single Core 1GB VM.","Very Low hanging fruit.
Accounts for 2% of RX perf trace on Vultr Single Core 1GB VM.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,268,2021-06-29T00:25:59Z,2021-07-13T20:27:36Z,2021-07-13T20:27:36Z,CLOSED,False,19,12,1,https://github.com/splitice,bail out of logging early,1,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/268,https://github.com/splitice,2,https://github.com/gsliepen/tinc/pull/268#issuecomment-870136794,"Very Low hanging fruit.
Accounts for 2% of RX perf trace on Vultr Single Core 1GB VM.",Found while profiling for #110,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,268,2021-06-29T00:25:59Z,2021-07-13T20:27:36Z,2021-07-13T20:27:36Z,CLOSED,False,19,12,1,https://github.com/splitice,bail out of logging early,1,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/268,https://github.com/gsliepen,3,https://github.com/gsliepen/tinc/pull/268#issuecomment-879379765,"Very Low hanging fruit.
Accounts for 2% of RX perf trace on Vultr Single Core 1GB VM.","Cherry-picked as a459e57, thanks!",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,269,2021-06-29T00:50:42Z,2021-06-30T21:45:03Z,2021-06-30T21:45:03Z,CLOSED,False,2,2,1,https://github.com/splitice,Perform cheap checks first,1,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/269,https://github.com/splitice,1,https://github.com/gsliepen/tinc/pull/269,"minor optimization. Some memcpy's arent being correctly inlined by gcc.
In my search found these.","minor optimization. Some memcpy's arent being correctly inlined by gcc.
In my search found these.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,269,2021-06-29T00:50:42Z,2021-06-30T21:45:03Z,2021-06-30T21:45:03Z,CLOSED,False,2,2,1,https://github.com/splitice,Perform cheap checks first,1,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/269,https://github.com/gsliepen,2,https://github.com/gsliepen/tinc/pull/269#issuecomment-871747850,"minor optimization. Some memcpy's arent being correctly inlined by gcc.
In my search found these.",Cherry-picked as fd27c14,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,270,2021-06-29T01:52:28Z,2021-08-13T19:17:49Z,2021-08-13T19:17:49Z,CLOSED,False,188,174,8,https://github.com/splitice,Inline each hashtable using macros,2,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/270,https://github.com/splitice,1,https://github.com/gsliepen/tinc/pull/270,"This allows for the compiler to optimize out a significant number of instructions (calls to memcmp and hashing function conditionals).
There is room for a further PR after this:
a) further optimizing the hash table
b) making the table collision safe (!!)
As this is a micro optimization at this stage its liable to be difficult to benchmark on it's own. I got a 0.2% improvement, but that's well within the margin of error for my environment.","This allows for the compiler to optimize out a significant number of instructions (calls to memcmp and hashing function conditionals).
There is room for a further PR after this:
a) further optimizing the hash table
b) making the table collision safe (!!)
As this is a micro optimization at this stage its liable to be difficult to benchmark on it's own. I got a 0.2% improvement, but that's well within the margin of error for my environment.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,270,2021-06-29T01:52:28Z,2021-08-13T19:17:49Z,2021-08-13T19:17:49Z,CLOSED,False,188,174,8,https://github.com/splitice,Inline each hashtable using macros,2,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/270,https://github.com/splitice,2,https://github.com/gsliepen/tinc/pull/270#issuecomment-871795509,"This allows for the compiler to optimize out a significant number of instructions (calls to memcmp and hashing function conditionals).
There is room for a further PR after this:
a) further optimizing the hash table
b) making the table collision safe (!!)
As this is a micro optimization at this stage its liable to be difficult to benchmark on it's own. I got a 0.2% improvement, but that's well within the margin of error for my environment.","@gsliepen
There is two new types macros defined a define and a call for each called function. Effectively I'm emulating C++ template functions.
With O0 i'm highly doubtful of the compiler inlining the methods even if there are gains in dead code elimination from second level global static members.
Main reason this needs to be inlined is to make the hash function significantly faster. Right now it's unoptimized in the produced code. Although I intend to replace it with versions for 4 (or any division of 4), 6 variants and fallback to this current method for any other size (won't be used).
I'm expecting the order of low hanging fruit optimizations to be epoll (easy), tap overheads (hard), encryption (hard), hash (easy). Of course I've found a few unexpected improvements along the way and this may happen again. Hash improvements are easy to make :)",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,270,2021-06-29T01:52:28Z,2021-08-13T19:17:49Z,2021-08-13T19:17:49Z,CLOSED,False,188,174,8,https://github.com/splitice,Inline each hashtable using macros,2,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/270,https://github.com/splitice,3,https://github.com/gsliepen/tinc/pull/270#issuecomment-872629718,"This allows for the compiler to optimize out a significant number of instructions (calls to memcmp and hashing function conditionals).
There is room for a further PR after this:
a) further optimizing the hash table
b) making the table collision safe (!!)
As this is a micro optimization at this stage its liable to be difficult to benchmark on it's own. I got a 0.2% improvement, but that's well within the margin of error for my environment.","Why not make sure modulo() can be inlined by moving it into hash.h as well?

Because I verified it was inline without it. That and in a future patch I intend to test a simplified modulo calculation, and masking is better (faster, lower code) when the hash table sizes are fixed to powers of 2 (which all of them currently are and are fixed to).

Hm, instead of having creating multiple versions of the hash functions, why not have an explicit size parameter, so that you have to do: hash_search(sizeof(mac_t), mac_cache, address)?

I feel using types may open up additional room for optimization. Specifically ip addresses have different distribution paramters (being largely within 1 subnet with a common prefix). While it's possible do this by size (size=4 aka ipv4) since you don't have many hash types I felt putting the type name in the definition was cleaner. It also makes the GCC backtrace better (hash_search_ipv4_t is much nicer than hash_search_4). This is stage 1 of what I intend to offer up in PRs for the hash table.

If we want to go this way, then instead of having a hash_alloc_ ## t() that returns a generic hash_t *, I'd rather have a hash_alloc_define(t) create a specialized hash_ ## t ## _t, that has a member variable t keys[0x100],

re; static.  Me too, I didnt do it because of the resize function that exists. I was hence intending it as a later optional commit as it depends on your plans to (in the future) use this currently unused function.
I'm happy to merge that into this single commit. I'd also be removing the currently unused resize function (no plans to use that?). NOTE: The unused hash_resize is also possibly incomplete it doesnt redistribute over the hash table it only resizes the underlying allocation.
While I'm doing that what about I add open addressing? That way your hash table will be conflict safe. Or i can add both of these to the next stage PR for the hash table.
I generally perfer smaller incremental PRs.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,270,2021-06-29T01:52:28Z,2021-08-13T19:17:49Z,2021-08-13T19:17:49Z,CLOSED,False,188,174,8,https://github.com/splitice,Inline each hashtable using macros,2,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/270,https://github.com/splitice,4,https://github.com/gsliepen/tinc/pull/270#issuecomment-872643938,"This allows for the compiler to optimize out a significant number of instructions (calls to memcmp and hashing function conditionals).
There is room for a further PR after this:
a) further optimizing the hash table
b) making the table collision safe (!!)
As this is a micro optimization at this stage its liable to be difficult to benchmark on it's own. I got a 0.2% improvement, but that's well within the margin of error for my environment.","By the way re; open addressing I think thats definately something for another PR.
I havent benchmarked it yet.
It might be better to just place a key check in hash_delete and not delete the node if the key doesnt match. The cost of cache misses (i.e due replacement or erroneous delete) needs to be weight against the costs of open addressing.
Open addressing with a linear (next hash over in the positive direction) search is very cheap and takes advantage of the cache. There are ways to make it even cheaper again but a simple search over say the next 3 buckets would only take a 4/8 byte read to 16/32 bytes and provide significantly less hash conflicts on large networks.
Currently the birthday paradox suggests that with:

100 nodes in cache: 99.99999998278067529% of at-least one collision
50 nodes in cache: 99.406783227075113949% chance of at-least one collision
25 nodes in cache 70.214748117218117013% chance of at-least one collision

Also what would be your oppinion on increasing the size of the cache by default? 1024 might be a more sensible default.
If i was willing to touch autoconf I'd suggest a configure defined definition.
On low memory devices (which are likely all 32bit) the ipv4 hash table uses 2kb of ram, the ipv6 3kb, the mac 2.5kb (7.5kb). An increase to 1024 slots would times these requirements by 4 (30kb ram usage) but reduce conflicts greatly (to approx what 25 nodes are now in the <=50 nodes category).
High memory devices and those on 64bit linux are unlikely to care about a few KB. Perhaps for the 64bit arch we use an even larger constant?
Open addressing would make conflicts basically non existant for the size of networks currently reasonable with tinc.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,270,2021-06-29T01:52:28Z,2021-08-13T19:17:49Z,2021-08-13T19:17:49Z,CLOSED,False,188,174,8,https://github.com/splitice,Inline each hashtable using macros,2,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/270,https://github.com/splitice,5,https://github.com/gsliepen/tinc/pull/270#issuecomment-872647504,"This allows for the compiler to optimize out a significant number of instructions (calls to memcmp and hashing function conditionals).
There is room for a further PR after this:
a) further optimizing the hash table
b) making the table collision safe (!!)
As this is a micro optimization at this stage its liable to be difficult to benchmark on it's own. I got a 0.2% improvement, but that's well within the margin of error for my environment.","I went all the way to 4094 for 32bit devices with c4ef1b6
When thinking about tinc's memory usage and the size of the smallest reasonable devices I think they can spare 120kb of ram.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,270,2021-06-29T01:52:28Z,2021-08-13T19:17:49Z,2021-08-13T19:17:49Z,CLOSED,False,188,174,8,https://github.com/splitice,Inline each hashtable using macros,2,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/270,https://github.com/gsliepen,6,https://github.com/gsliepen/tinc/pull/270#issuecomment-872856938,"This allows for the compiler to optimize out a significant number of instructions (calls to memcmp and hashing function conditionals).
There is room for a further PR after this:
a) further optimizing the hash table
b) making the table collision safe (!!)
As this is a micro optimization at this stage its liable to be difficult to benchmark on it's own. I got a 0.2% improvement, but that's well within the margin of error for my environment.","The hash tables are just use to cache things, so if there is a conflict overwriting what was there before is safe. Most of the time, we will have large groups of packets being sent to and received from the same address. However, it uses two entries in the cache (one for the destination address of packets sent, and one for the destination address of packets received). So we want to avoid those two conflicting. So linear probing once might be ideal (then we also don't have to worry about the load factor).
Bumping the size to 1024 entries seems reasonable, the only drawback is that hash_clear() will take longer. So if open addressing solves the conflict issue, I don't think we need to increase the size.
Resizing should indeed be removed. The patches look good, small PRs are fine with me as long as each commit leaves tinc in a working state :)",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,270,2021-06-29T01:52:28Z,2021-08-13T19:17:49Z,2021-08-13T19:17:49Z,CLOSED,False,188,174,8,https://github.com/splitice,Inline each hashtable using macros,2,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/270,https://github.com/splitice,7,https://github.com/gsliepen/tinc/pull/270#issuecomment-872879069,"This allows for the compiler to optimize out a significant number of instructions (calls to memcmp and hashing function conditionals).
There is room for a further PR after this:
a) further optimizing the hash table
b) making the table collision safe (!!)
As this is a micro optimization at this stage its liable to be difficult to benchmark on it's own. I got a 0.2% improvement, but that's well within the margin of error for my environment.","@gsliepen I'd like to reduce or remove hash_clear anyway. In my testing I've had an horrible hash table hit rate. Initially I noticed the collisions, but I'm sure hash_clear would also factor in if I benchmarked it.
hash_clear() can be largely eliminated from most peoples networks anyway I suspect. Many people run /32 per node networks I dare say. Of course not all.
Perhaps if the subnet that is being added is a /32 (/128 for IPv6) only that IP could be removed? And if it's actually a subnet (<31 etc) then and only then do a clear operation (also ipv4 subnets only needs to clear ipv4_cache & mac_cache).

Most of the time, we will have large groups of packets being sent to and received from the same address.

I have quite the opposite use case, one server receiving packets from a large (approx 50 currently) other servers. For it the cache is basically useless.

Bumping the size to 1024 entries seems reasonable, the only drawback is that hash_clear() will take longer. So if open addressing solves the conflict issue, I don't think we need to increase the size.

Would you be able to make it a configure option? I've long since become terminally fed up with autoconf.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,270,2021-06-29T01:52:28Z,2021-08-13T19:17:49Z,2021-08-13T19:17:49Z,CLOSED,False,188,174,8,https://github.com/splitice,Inline each hashtable using macros,2,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/270,https://github.com/splitice,8,https://github.com/gsliepen/tinc/pull/270#issuecomment-872894503,"This allows for the compiler to optimize out a significant number of instructions (calls to memcmp and hashing function conditionals).
There is room for a further PR after this:
a) further optimizing the hash table
b) making the table collision safe (!!)
As this is a micro optimization at this stage its liable to be difficult to benchmark on it's own. I got a 0.2% improvement, but that's well within the margin of error for my environment.",Also hash_search_or_insert() is entirely unused. Should it be removed?,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,270,2021-06-29T01:52:28Z,2021-08-13T19:17:49Z,2021-08-13T19:17:49Z,CLOSED,False,188,174,8,https://github.com/splitice,Inline each hashtable using macros,2,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/270,https://github.com/gsliepen,9,https://github.com/gsliepen/tinc/pull/270#issuecomment-872901747,"This allows for the compiler to optimize out a significant number of instructions (calls to memcmp and hashing function conditionals).
There is room for a further PR after this:
a) further optimizing the hash table
b) making the table collision safe (!!)
As this is a micro optimization at this stage its liable to be difficult to benchmark on it's own. I got a 0.2% improvement, but that's well within the margin of error for my environment.","Unused functions should be removed. I shouldn't have added them in the first place...
As for hash_clear(), removing individual /32 or /128s would be great, and especially for Mode = switch the possibility to remove a single MAC address would be helpful. We can solve the overhead of hash_clear() for other cases by introducing a generation counter. This way we can increase the size of the cache easily.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,270,2021-06-29T01:52:28Z,2021-08-13T19:17:49Z,2021-08-13T19:17:49Z,CLOSED,False,188,174,8,https://github.com/splitice,Inline each hashtable using macros,2,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/270,https://github.com/splitice,10,https://github.com/gsliepen/tinc/pull/270#issuecomment-872909480,"This allows for the compiler to optimize out a significant number of instructions (calls to memcmp and hashing function conditionals).
There is room for a further PR after this:
a) further optimizing the hash table
b) making the table collision safe (!!)
As this is a micro optimization at this stage its liable to be difficult to benchmark on it's own. I got a 0.2% improvement, but that's well within the margin of error for my environment.","@gsliepen Individual IP removal complete. Open addressing too.

introducing a generation counter

I thought similar. But honestly clearing a few pages as long as its done sparingly is cheap. Ideally it shouldnt be needed at all.
I suspect the best way would be a reference counter on the actual node_t combined with a flag to mark staleness. I'm not looking to do that currently though. At-least until lower hanging fruit have been dealt with.

the possibility to remove a single MAC address would be helpful.

Easy enough but I made the subnet function static for now.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,270,2021-06-29T01:52:28Z,2021-08-13T19:17:49Z,2021-08-13T19:17:49Z,CLOSED,False,188,174,8,https://github.com/splitice,Inline each hashtable using macros,2,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/270,https://github.com/splitice,11,https://github.com/gsliepen/tinc/pull/270#issuecomment-872964662,"This allows for the compiler to optimize out a significant number of instructions (calls to memcmp and hashing function conditionals).
There is room for a further PR after this:
a) further optimizing the hash table
b) making the table collision safe (!!)
As this is a micro optimization at this stage its liable to be difficult to benchmark on it's own. I got a 0.2% improvement, but that's well within the margin of error for my environment.","Why not make sure modulo() can be inlined by moving it into hash.h as well?

As the last hold out in hash.c I've taken your suggestion.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,270,2021-06-29T01:52:28Z,2021-08-13T19:17:49Z,2021-08-13T19:17:49Z,CLOSED,False,188,174,8,https://github.com/splitice,Inline each hashtable using macros,2,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/270,https://github.com/splitice,12,https://github.com/gsliepen/tinc/pull/270#issuecomment-872988599,"This allows for the compiler to optimize out a significant number of instructions (calls to memcmp and hashing function conditionals).
There is room for a further PR after this:
a) further optimizing the hash table
b) making the table collision safe (!!)
As this is a micro optimization at this stage its liable to be difficult to benchmark on it's own. I got a 0.2% improvement, but that's well within the margin of error for my environment.","Added type specific hash functions with a particular emphasis on IPv4. IPv6 and MAC addresses could probably benefit from similar algorithms in the future. For now though I implemented a similar bit scrambler using the Golden Prime constant supplied. Nothing fancy but simpler than the existing implementation (and no more while(true) loop).
Added a hash seed. Its a small security issue but technically someone could exploit known collisions to (currently) force cache clears or (this PR) reduce performance. A randomized seed prevents IP/MAC address collisions from being predictable.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,270,2021-06-29T01:52:28Z,2021-08-13T19:17:49Z,2021-08-13T19:17:49Z,CLOSED,False,188,174,8,https://github.com/splitice,Inline each hashtable using macros,2,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/270,https://github.com/splitice,13,https://github.com/gsliepen/tinc/pull/270#issuecomment-872993791,"This allows for the compiler to optimize out a significant number of instructions (calls to memcmp and hashing function conditionals).
There is room for a further PR after this:
a) further optimizing the hash table
b) making the table collision safe (!!)
As this is a micro optimization at this stage its liable to be difficult to benchmark on it's own. I got a 0.2% improvement, but that's well within the margin of error for my environment.",By the way that IPv4 hashing algorithm should be collision free for /24 on 32bit and 64bit and collision free for a /16 on 64bit (on the first slot).,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,270,2021-06-29T01:52:28Z,2021-08-13T19:17:49Z,2021-08-13T19:17:49Z,CLOSED,False,188,174,8,https://github.com/splitice,Inline each hashtable using macros,2,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/270,https://github.com/splitice,14,https://github.com/gsliepen/tinc/pull/270#issuecomment-873004232,"This allows for the compiler to optimize out a significant number of instructions (calls to memcmp and hashing function conditionals).
There is room for a further PR after this:
a) further optimizing the hash table
b) making the table collision safe (!!)
As this is a micro optimization at this stage its liable to be difficult to benchmark on it's own. I got a 0.2% improvement, but that's well within the margin of error for my environment.","The hash_seed for IPv4 is of limited use. Unfortunately I'm not sure the algorithm can be seeded securely while maintaining the no collision properties for standard network sizes.
Specifically someone could purposefully choose to send traffic to/from 10.0.0.1,10.1.0.1 etc to force collisions. Given that the same property applied (although you would have more work to calculate out the collisions previously) to the existing implementation. I'm hence not super worried.
Choices are really:
a) perhaps apply a small hash_seed as a multiplier to the return value. This would remove the predictability of collision properties. It should be quite good, but not zero. If 0...255 /24 no collision could be maintained for 64bit.
b) live with it. Its not a big issue (and it already exists)
c) apply a 8,16 or 32bit bit scrambling hash (or really any) as they have a higher bar to calculate collisions for",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,270,2021-06-29T01:52:28Z,2021-08-13T19:17:49Z,2021-08-13T19:17:49Z,CLOSED,False,188,174,8,https://github.com/splitice,Inline each hashtable using macros,2,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/270,https://github.com/fangfufu,15,https://github.com/gsliepen/tinc/pull/270#issuecomment-895541363,"This allows for the compiler to optimize out a significant number of instructions (calls to memcmp and hashing function conditionals).
There is room for a further PR after this:
a) further optimizing the hash table
b) making the table collision safe (!!)
As this is a micro optimization at this stage its liable to be difficult to benchmark on it's own. I got a 0.2% improvement, but that's well within the margin of error for my environment.","It would be great if the 18 commits could be squashed into one before merging this pull request.

@gsliepen , you can always press the ""Squash and merge"" button, and this whole pull request would be merged into one commit. You can then edit the commit message. The documentation is here.
I did exactly that here: fangfufu/httpdirfs#78, the resulting commit is here: fangfufu/httpdirfs@60b8851",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,270,2021-06-29T01:52:28Z,2021-08-13T19:17:49Z,2021-08-13T19:17:49Z,CLOSED,False,188,174,8,https://github.com/splitice,Inline each hashtable using macros,2,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/270,https://github.com/gsliepen,16,https://github.com/gsliepen/tinc/pull/270#issuecomment-895562615,"This allows for the compiler to optimize out a significant number of instructions (calls to memcmp and hashing function conditionals).
There is room for a further PR after this:
a) further optimizing the hash table
b) making the table collision safe (!!)
As this is a micro optimization at this stage its liable to be difficult to benchmark on it's own. I got a 0.2% improvement, but that's well within the margin of error for my environment.","you can always press the ""Squash and merge"" button, and this whole pull request would be merged into one commit.

I know, but first of all, GitHub for me is just a mirror of the official Git repository at https://tinc-vpn.org/git/tinc/, so I wouldn't use that button (but of course I'd just squash and merge it locally on my own machine almost as easily). Second, ideally pull requests are already in a state I can merge them without any extra work. There's also still some pending change requests, which is the main reason this hasn't been merged.
I'm still not happy with the size of the hash tables. The amount of memory available for tinc can vary a lot depending on which machine it is running on, if someone wants to put it into a constrained cgroup for example, regardless of whether it is on a 32 bit or 64 bit machine. Maybe dynamically growing the tables is the right thing to do after all?",True,"{'THUMBS_UP': ['https://github.com/fangfufu'], 'CONFUSED': ['https://github.com/splitice']}"
gsliepen/tinc,https://github.com/gsliepen/tinc,270,2021-06-29T01:52:28Z,2021-08-13T19:17:49Z,2021-08-13T19:17:49Z,CLOSED,False,188,174,8,https://github.com/splitice,Inline each hashtable using macros,2,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/270,https://github.com/fangfufu,17,https://github.com/gsliepen/tinc/pull/270#issuecomment-895599435,"This allows for the compiler to optimize out a significant number of instructions (calls to memcmp and hashing function conditionals).
There is room for a further PR after this:
a) further optimizing the hash table
b) making the table collision safe (!!)
As this is a micro optimization at this stage its liable to be difficult to benchmark on it's own. I got a 0.2% improvement, but that's well within the margin of error for my environment.","Here are some of my thoughts, I am not sure how useful they are.

Maybe dynamically growing the tables is the right thing to do after all?

I suppose it depends on whether you want to go for memory footprint or performance. Earlier on in the thread you said:

That way we also avoid malloc calls and pointer dereferencing as much as possible.

Is there a cheap way to do both? I'll admit that I am a bit clueless. Right now, how much performance difference does this pull request make anyway? @splitice
Right now the performance of tinc doesn't seem to be great: https://vpncloud.ddswd.de/features/comparison. However I like tinc because of its P2P nature, and the stability and maturity of the project. Personally I think the performance is enough / reasonable for me. Personally, I am limited by the physical bandwidth, than the overhead of tinc.
I do note the memory requirement of this patch:

So subnet cache usage on a 32bit system 152KB
On a 64bit system it's 2.3MB for comparison.

I think these are reasonable.
With respect to:

The amount of memory available for tinc can vary a lot depending on which machine it is running on, if someone wants to put it into a constrained cgroup for example, regardless of whether it is on a 32 bit or 64 bit machine.

If a user is using cgroup on a 64-bit machine, how much memory do you reckon the user will allocate to tinc? Perhaps we can write it down somewhere on the manual on the minimum requirement for the users.",True,{'THUMBS_UP': ['https://github.com/splitice']}
gsliepen/tinc,https://github.com/gsliepen/tinc,270,2021-06-29T01:52:28Z,2021-08-13T19:17:49Z,2021-08-13T19:17:49Z,CLOSED,False,188,174,8,https://github.com/splitice,Inline each hashtable using macros,2,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/270,https://github.com/splitice,18,https://github.com/gsliepen/tinc/pull/270#issuecomment-895652289,"This allows for the compiler to optimize out a significant number of instructions (calls to memcmp and hashing function conditionals).
There is room for a further PR after this:
a) further optimizing the hash table
b) making the table collision safe (!!)
As this is a micro optimization at this stage its liable to be difficult to benchmark on it's own. I got a 0.2% improvement, but that's well within the margin of error for my environment.","you can always press the ""Squash and merge"" button, and this whole pull request would be merged into one commit.


Someting that shouldnt be done at-least (if at all) until the maintainer is happy with all aspects and ready to merge.

There's also still some pending change requests, which is the main reason this hasn't been merged.

Thats news to me. This PR is not waiting on me to reply or make changes. From my point of view this is complete.

Is there a cheap way to do both? I'll admit that I am a bit clueless. Right now, how much performance difference does this pull request make anyway? @splitice

It stops (extends) a performance regression on large networks (where the subnet cache on current versions is nearly useless). I don't have accurate numbers at this stage as its very workload dependant. Its resolved the peaks to full saturation we receive on a network where nearly every node communicates with each other (rendering the subnet cache thrashed). Splay tree lookup is fast, but not as fast as the cache lookup and lookup time increases with size (appears to be roughly O log?). With high PPS thrashing theres considerable gains.

Right now the performance of tinc doesn't seem to be great: https://vpncloud.ddswd.de/features/comparison

Very true, and there is multiple areas that need to be tackled to get the performance up to comparable levels. This is just one area.
I do hope by making the subnet cache more useful in the future there will also get more gains. Not performance related; I particularly want to explore improving route finding through the network with relay nodes as thats a big issue for me with a world spanning network. Having a useful (non-thrashed) subnet cache is essential to my plans here.

Maybe dynamically growing the tables is the right thing to do after all?

Thats a substantial re-write, and I quite like the statically allocated tables you suggested. For the small memory requirement of the subnet cache I think it's not worth making configurable. Perhaps a autoconf option for low memory (default true on 32bit)?",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,270,2021-06-29T01:52:28Z,2021-08-13T19:17:49Z,2021-08-13T19:17:49Z,CLOSED,False,188,174,8,https://github.com/splitice,Inline each hashtable using macros,2,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/270,https://github.com/gsliepen,19,https://github.com/gsliepen/tinc/pull/270#issuecomment-895775157,"This allows for the compiler to optimize out a significant number of instructions (calls to memcmp and hashing function conditionals).
There is room for a further PR after this:
a) further optimizing the hash table
b) making the table collision safe (!!)
As this is a micro optimization at this stage its liable to be difficult to benchmark on it's own. I got a 0.2% improvement, but that's well within the margin of error for my environment.","On a 64bit system it's 2.3MB for comparison.



I think these are reasonable.

Maybe I'm just overreacting.

Thats news to me. This PR is not waiting on me to reply or make changes. From my point of view this is complete.

Ah, GitHub still shows it in the ""Changes requested"" state for me. I'll review it again tonight.

Perhaps a autoconf option for low memory (default true on 32bit)?

That could work.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,270,2021-06-29T01:52:28Z,2021-08-13T19:17:49Z,2021-08-13T19:17:49Z,CLOSED,False,188,174,8,https://github.com/splitice,Inline each hashtable using macros,2,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/270,https://github.com/fangfufu,20,https://github.com/gsliepen/tinc/pull/270#issuecomment-895893847,"This allows for the compiler to optimize out a significant number of instructions (calls to memcmp and hashing function conditionals).
There is room for a further PR after this:
a) further optimizing the hash table
b) making the table collision safe (!!)
As this is a micro optimization at this stage its liable to be difficult to benchmark on it's own. I got a 0.2% improvement, but that's well within the margin of error for my environment.","@splitice , it shows ""Changes requested"" on my side as well.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,270,2021-06-29T01:52:28Z,2021-08-13T19:17:49Z,2021-08-13T19:17:49Z,CLOSED,False,188,174,8,https://github.com/splitice,Inline each hashtable using macros,2,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/270,https://github.com/splitice,21,https://github.com/gsliepen/tinc/pull/270#issuecomment-895905453,"This allows for the compiler to optimize out a significant number of instructions (calls to memcmp and hashing function conditionals).
There is room for a further PR after this:
a) further optimizing the hash table
b) making the table collision safe (!!)
As this is a micro optimization at this stage its liable to be difficult to benchmark on it's own. I got a 0.2% improvement, but that's well within the margin of error for my environment.",@fangfufu it will show that until myself or gsliepen marks the conversation as resolved,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,270,2021-06-29T01:52:28Z,2021-08-13T19:17:49Z,2021-08-13T19:17:49Z,CLOSED,False,188,174,8,https://github.com/splitice,Inline each hashtable using macros,2,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/270,https://github.com/splitice,22,https://github.com/gsliepen/tinc/pull/270#issuecomment-898102389,"This allows for the compiler to optimize out a significant number of instructions (calls to memcmp and hashing function conditionals).
There is room for a further PR after this:
a) further optimizing the hash table
b) making the table collision safe (!!)
As this is a micro optimization at this stage its liable to be difficult to benchmark on it's own. I got a 0.2% improvement, but that's well within the margin of error for my environment.","Rebased, requested changes applied. Squashed as per request.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,270,2021-06-29T01:52:28Z,2021-08-13T19:17:49Z,2021-08-13T19:17:49Z,CLOSED,False,188,174,8,https://github.com/splitice,Inline each hashtable using macros,2,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/270,https://github.com/splitice,23,https://github.com/gsliepen/tinc/pull/270#issuecomment-898193830,"This allows for the compiler to optimize out a significant number of instructions (calls to memcmp and hashing function conditionals).
There is room for a further PR after this:
a) further optimizing the hash table
b) making the table collision safe (!!)
As this is a micro optimization at this stage its liable to be difficult to benchmark on it's own. I got a 0.2% improvement, but that's well within the margin of error for my environment.",Still needs further work by someone who understands what to do in autoconf to get both static analysis and sanitizer passing.,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,270,2021-06-29T01:52:28Z,2021-08-13T19:17:49Z,2021-08-13T19:17:49Z,CLOSED,False,188,174,8,https://github.com/splitice,Inline each hashtable using macros,2,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/270,https://github.com/gsliepen,24,https://github.com/gsliepen/tinc/pull/270#issuecomment-898499183,"This allows for the compiler to optimize out a significant number of instructions (calls to memcmp and hashing function conditionals).
There is room for a further PR after this:
a) further optimizing the hash table
b) making the table collision safe (!!)
As this is a micro optimization at this stage its liable to be difficult to benchmark on it's own. I got a 0.2% improvement, but that's well within the margin of error for my environment.","Still needs further work by someone who understands what to do in autoconf to get both static analysis and sanitizer passing.

Yeah it's a bit weird it's complaining about those integers when you explicitly cast them. I'll try to see what the best way is to fix these warnings. The code looks fine to me otherwise!",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,270,2021-06-29T01:52:28Z,2021-08-13T19:17:49Z,2021-08-13T19:17:49Z,CLOSED,False,188,174,8,https://github.com/splitice,Inline each hashtable using macros,2,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/270,https://github.com/splitice,25,https://github.com/gsliepen/tinc/pull/270#issuecomment-898506609,"This allows for the compiler to optimize out a significant number of instructions (calls to memcmp and hashing function conditionals).
There is room for a further PR after this:
a) further optimizing the hash table
b) making the table collision safe (!!)
As this is a micro optimization at this stage its liable to be difficult to benchmark on it's own. I got a 0.2% improvement, but that's well within the margin of error for my environment.",I tried explicit casting in two different ways without luck too (reverted),True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,270,2021-06-29T01:52:28Z,2021-08-13T19:17:49Z,2021-08-13T19:17:49Z,CLOSED,False,188,174,8,https://github.com/splitice,Inline each hashtable using macros,2,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/270,https://github.com/gsliepen,26,https://github.com/gsliepen/tinc/pull/270#issuecomment-898670342,"This allows for the compiler to optimize out a significant number of instructions (calls to memcmp and hashing function conditionals).
There is room for a further PR after this:
a) further optimizing the hash table
b) making the table collision safe (!!)
As this is a micro optimization at this stage its liable to be difficult to benchmark on it's own. I got a 0.2% improvement, but that's well within the margin of error for my environment.","Merged 9a018c2, fixed the sanitizer warnings by some more casting that keeps Clang's sanitizer happy. Thanks for the patch!",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,273,2021-06-29T04:58:11Z,2021-06-30T21:57:06Z,2021-06-30T21:57:07Z,CLOSED,False,17,8,1,https://github.com/splitice,Fix stack smash,3,"['bug', '1.1']",https://github.com/gsliepen/tinc/pull/273,https://github.com/splitice,1,https://github.com/gsliepen/tinc/pull/273,"Issue #252 proposed fix.

Prevent overrun of send_udp_probe_packet. It's low cost and helps make tinc safer for the future.
Prevent negative interval

In the case of negative interval minmtu will be used.","Issue #252 proposed fix.

Prevent overrun of send_udp_probe_packet. It's low cost and helps make tinc safer for the future.
Prevent negative interval

In the case of negative interval minmtu will be used.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,273,2021-06-29T04:58:11Z,2021-06-30T21:57:06Z,2021-06-30T21:57:07Z,CLOSED,False,17,8,1,https://github.com/splitice,Fix stack smash,3,"['bug', '1.1']",https://github.com/gsliepen/tinc/pull/273,https://github.com/gsliepen,2,https://github.com/gsliepen/tinc/pull/273#issuecomment-871753419,"Issue #252 proposed fix.

Prevent overrun of send_udp_probe_packet. It's low cost and helps make tinc safer for the future.
Prevent negative interval

In the case of negative interval minmtu will be used.","Cherry-picked and reformatted as 9eb34eb, e7a422c and bceaa80.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,275,2021-07-02T11:20:55Z,2021-08-17T14:56:18Z,2021-08-17T14:56:25Z,CLOSED,False,520,278,20,https://github.com/splitice,initial epoll & initial tx buffering support,17,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/275,https://github.com/splitice,1,https://github.com/gsliepen/tinc/pull/275,adds epoll and basic tx buffers as per research paper https://www.cs.cornell.edu/courses/cs5413/2014fa/projects/group_of_ej222_jj329_jsh263/ as developed in #266,adds epoll and basic tx buffers as per research paper https://www.cs.cornell.edu/courses/cs5413/2014fa/projects/group_of_ej222_jj329_jsh263/ as developed in #266,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,275,2021-07-02T11:20:55Z,2021-08-17T14:56:18Z,2021-08-17T14:56:25Z,CLOSED,False,520,278,20,https://github.com/splitice,initial epoll & initial tx buffering support,17,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/275,https://github.com/splitice,2,https://github.com/gsliepen/tinc/pull/275#issuecomment-872927072,adds epoll and basic tx buffers as per research paper https://www.cs.cornell.edu/courses/cs5413/2014fa/projects/group_of_ej222_jj329_jsh263/ as developed in #266,"Packet buffers are as defined in the paper. They arent particularly useful yet outside of broadcasted packets.
Tun ARP messages would probably be the main user of the buffering capability?",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,275,2021-07-02T11:20:55Z,2021-08-17T14:56:18Z,2021-08-17T14:56:25Z,CLOSED,False,520,278,20,https://github.com/splitice,initial epoll & initial tx buffering support,17,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/275,https://github.com/gsliepen,3,https://github.com/gsliepen/tinc/pull/275#issuecomment-877844734,adds epoll and basic tx buffers as per research paper https://www.cs.cornell.edu/courses/cs5413/2014fa/projects/group_of_ej222_jj329_jsh263/ as developed in #266,"adds epoll and basic tx buffers

It would be nice to split this into two pull requests, one for epoll support and one for sendmmsg(), as I think they are orthogonal.

Packet buffers are as defined in the paper. They arent particularly useful yet outside of broadcasted packets.
Tun ARP messages would probably be the main user of the buffering capability?

Why not use it for all UDP packets? Just always add packets to the socket's packet_buffer, and then call send_buffered_packets() if either the packet buffer is full, or right before calling select() or epoll_wait().",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,275,2021-07-02T11:20:55Z,2021-08-17T14:56:18Z,2021-08-17T14:56:25Z,CLOSED,False,520,278,20,https://github.com/splitice,initial epoll & initial tx buffering support,17,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/275,https://github.com/splitice,4,https://github.com/gsliepen/tinc/pull/275#issuecomment-877856789,adds epoll and basic tx buffers as per research paper https://www.cs.cornell.edu/courses/cs5413/2014fa/projects/group_of_ej222_jj329_jsh263/ as developed in #266,"As per the issue larger architectual issues prevent that currently. All fds would need to be non-blocking.
I'm not super against splitting this however I feel they both support each other and would likely conflict if your suggestion was implemented.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,275,2021-07-02T11:20:55Z,2021-08-17T14:56:18Z,2021-08-17T14:56:25Z,CLOSED,False,520,278,20,https://github.com/splitice,initial epoll & initial tx buffering support,17,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/275,https://github.com/gsliepen,5,https://github.com/gsliepen/tinc/pull/275#issuecomment-877858430,adds epoll and basic tx buffers as per research paper https://www.cs.cornell.edu/courses/cs5413/2014fa/projects/group_of_ej222_jj329_jsh263/ as developed in #266,"All fds are non-blocking. Also, I still don't see how the sendmmsg and epoll parts depend on each other. There is nothing in your code that suggests so.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,275,2021-07-02T11:20:55Z,2021-08-17T14:56:18Z,2021-08-17T14:56:25Z,CLOSED,False,520,278,20,https://github.com/splitice,initial epoll & initial tx buffering support,17,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/275,https://github.com/splitice,6,https://github.com/gsliepen/tinc/pull/275#issuecomment-877880811,adds epoll and basic tx buffers as per research paper https://www.cs.cornell.edu/courses/cs5413/2014fa/projects/group_of_ej222_jj329_jsh263/ as developed in #266,"and then call send_buffered_packets() if either the packet buffer is full, or right before calling select() or epoll_wait().

Introduces the expected cross dependency mentioned. I'd consider this packet buffering functional but basic currently. It's greatly extended in the vhost net work (which also depends on epoll_wait).
Unfortunately I have limited time available so want to merge as much as possible where possible to keep conflicts to a bare minimum.

We discussed making the loop safe to handle multiple io operations per loop, I'd prefer if you were to make that commit. At this stage I don't feel confident enough in my undestanding of that area.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,275,2021-07-02T11:20:55Z,2021-08-17T14:56:18Z,2021-08-17T14:56:25Z,CLOSED,False,520,278,20,https://github.com/splitice,initial epoll & initial tx buffering support,17,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/275,https://github.com/splitice,7,https://github.com/gsliepen/tinc/pull/275#issuecomment-898876365,adds epoll and basic tx buffers as per research paper https://www.cs.cornell.edu/courses/cs5413/2014fa/projects/group_of_ej222_jj329_jsh263/ as developed in #266,"Since hashtable has merged I'll start work on getting this up to merge.
Removed the splay each iteration of the io tree, this should boost performance on the epoll path. Needs further testing though.
I'm looking into the multiple IO ops through the event paths.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,275,2021-07-02T11:20:55Z,2021-08-17T14:56:18Z,2021-08-17T14:56:25Z,CLOSED,False,520,278,20,https://github.com/splitice,initial epoll & initial tx buffering support,17,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/275,https://github.com/splitice,8,https://github.com/gsliepen/tinc/pull/275#issuecomment-898997737,adds epoll and basic tx buffers as per research paper https://www.cs.cornell.edu/courses/cs5413/2014fa/projects/group_of_ej222_jj329_jsh263/ as developed in #266,It would appear that epoll_wait is more efficient than doing multiple read/writes per cycle even at moderate rates of transfer (and significantly better at low rates). The 2x syscall for every socket quickly dwarfs gains from reduction in epoll_waits.,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,275,2021-07-02T11:20:55Z,2021-08-17T14:56:18Z,2021-08-17T14:56:25Z,CLOSED,False,520,278,20,https://github.com/splitice,initial epoll & initial tx buffering support,17,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/275,https://github.com/splitice,9,https://github.com/gsliepen/tinc/pull/275#issuecomment-899028004,adds epoll and basic tx buffers as per research paper https://www.cs.cornell.edu/courses/cs5413/2014fa/projects/group_of_ej222_jj329_jsh263/ as developed in #266,"I'm thinking I'll submit a seperate PR at around a0ff2d8 squashed to just the epoll parts.
I think a more general cleanup and refactor of net_packet as discussed in #319 would be better done before packet buffers are added (as nice as they are).",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,275,2021-07-02T11:20:55Z,2021-08-17T14:56:18Z,2021-08-17T14:56:25Z,CLOSED,False,520,278,20,https://github.com/splitice,initial epoll & initial tx buffering support,17,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/275,https://github.com/splitice,10,https://github.com/gsliepen/tinc/pull/275#issuecomment-900371536,adds epoll and basic tx buffers as per research paper https://www.cs.cornell.edu/courses/cs5413/2014fa/projects/group_of_ej222_jj329_jsh263/ as developed in #266,Closing PR. Will resubmit packet buffers at a later date. Epoll V2 pr already sent.,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,276,2021-07-02T13:55:22Z,2021-07-02T14:20:36Z,2021-07-02T14:20:36Z,MERGED,True,237,24,8,https://github.com/hg,Add CI testing through GitHub Actions,3,[],https://github.com/gsliepen/tinc/pull/276,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/276,"Hi,
This is a proposal to add CI to the project which will:

build every incoming pull request (and pushes to main branches) on Linux/Windows/macOS, using different compilers and build flags
check code formatting using existing astyle config
run tests on every supported platform (Linux and macOS)
when a release tag is pushed, build debs for Ubuntu 20.04 / 18.04 and attach them to the release

This will help with catching broken and badly formatted pull requests earlier without merging and manually testing everything.
The .debs this thing produces are pretty far from what the Debian project recommends. As a user I would still like to see them though, possibly with a disclaimer (""auto builds, not supported, use at your own risk""). It's a pain to get tinc 1.1 binaries on my Ubuntu machines without relying on shady random PPAs.
examples

push
PR
release tag, created release
broken test in PR (logs at the bottom of the page here)

tests
I had to change the tests a bit to make them run on macOS without switching everything to coreutils (this seems to be strongly advised against in their world.) They were mostly compatible, so why not? Please let me know if this should be dropped altogether, or moved to a separate PR.
Thank you for continuing to maintain this amazing project more more than two decades. It's miles ahead of everything released since then.","Hi,
This is a proposal to add CI to the project which will:

build every incoming pull request (and pushes to main branches) on Linux/Windows/macOS, using different compilers and build flags
check code formatting using existing astyle config
run tests on every supported platform (Linux and macOS)
when a release tag is pushed, build debs for Ubuntu 20.04 / 18.04 and attach them to the release

This will help with catching broken and badly formatted pull requests earlier without merging and manually testing everything.
The .debs this thing produces are pretty far from what the Debian project recommends. As a user I would still like to see them though, possibly with a disclaimer (""auto builds, not supported, use at your own risk""). It's a pain to get tinc 1.1 binaries on my Ubuntu machines without relying on shady random PPAs.
examples

push
PR
release tag, created release
broken test in PR (logs at the bottom of the page here)

tests
I had to change the tests a bit to make them run on macOS without switching everything to coreutils (this seems to be strongly advised against in their world.) They were mostly compatible, so why not? Please let me know if this should be dropped altogether, or moved to a separate PR.
Thank you for continuing to maintain this amazing project more more than two decades. It's miles ahead of everything released since then.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,277,2021-07-09T14:29:40Z,2021-07-19T14:05:22Z,2022-03-13T05:05:41Z,MERGED,True,933,523,17,https://github.com/hg,Rewrite of the test suite for compatibility with more operating systems and less failures,1,['CI'],https://github.com/gsliepen/tinc/pull/277,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/277,"Current (2021-07-17) test results for BSDs:

freebsd
netbsd
openbsd


Demos:

commit
release


Changes to the test suite
The current test suite proved to be reliable when running under Linux and on decently specced systems. However, when I started running a massive number of jobs on overloaded GitHub VMs, tests start breaking due to things not establishing properly before the sleep wait expires.
The same thing happened after porting them to Windows and the BSDs. The test suite would be running fine for a few iterations and then break, always in a different place from before.
Thus tests were reworked quite a bit:

Windows / FreeBSD / OpenBSD / NetBSD support
time limits everywhere to detect tinc/tincd hangs (which now manifest as a single test failure instead of blocking the whole job)
remove sleep(1) whenever possible in favor of tinc scripts, which notify the test when it should proceed (this greatly reduced the frequency of spurious test failures)
increase log verbosity and (hopefully) make tests easier to read
support for weird/whitespaced FS paths
remove duplication whenever possible
add shellcheck and fix everything it reported
add shfmt to force a single style on all scripts (similar to astyle for C)

Tests still do fail. However, it happens much more rarely and I believe that these failures are no longer due to timing issues in tests themselves. They seem to indicate genuine issues in tinc's code, like the two things described above. Here are the remaining issues I gather from looking at a lot of test runs (most of them listed further down):

sometimes tinc is not able to connect to tincd, either failing with a timeout (which is set to 30 seconds), or with ""Cannot read greeting from control socket: Invalid argument"", even though in most places it is now called only after host-up or subnet-up. See examples here (mac), here (mac), here (mac), here (mac), here (freebsd), here (freebsd), here (linux), here (linux), here (mac), etc.
sptps-basic.test is disabled on Windows because both client and server completely hang there and never send any data to another.
algorithms.test is still disabled on Windows because it fails very often there there (sometimes tinc does not report the other node as reachable even though we check only after waiting for hosts/foo-up or hosts/bar-up).
security.test frequently breaks on macOS in one particular place.

I'll start digging once we get this PR out of the way.
Original tests
Original tests do not include algorithms.test as it was never actually enabled. I've done more extensive testing than listed here thanks to GitHub's generous limits, until they seem to have started throttling me (on the order of 1k separate builds and a few thousand test runs; plus a lot of runs on local VMs), with pretty similar results.
Single runs
Build on a fresh VM, run the test suite once:

Linux (196 ok / 200)
Linux (197 ok / 200)
Linux (199 ok / 200)
hang on NetBSD
hang on FreeBSD

Looped runs
Build on a fresh VM, run the suite in a loop until it fails:

Linux, failed on 56th iteration
macOS (failed in a few minutes) + Windows (hanged at the start and never started running the test suite)
quick failures on Linux here, here here, here, here, here, here, here, here, here, etc.

Updated tests
These have all the tests in the original suite + algorithms.test.
Single

Linux (200 ok / 200)
Linux (200 ok / 200)
Linux (200 ok / 200)
Linux + macOS + Windows (.deb jobs were being worked on and are broken in most of these): one, two, three, four, five, six, seven, eight
NetBSD
FreeBSD one, two
OpenBSD one, two

Looped

Linux + macOS + Windows, also this, this, and this — each ran for hours, most terminated by GitHub after going over the six-hour time limit or killed by myself after running out of patience
Windows — same
FreeBSD one — stopped manually after 250+ iterations to free up resources, two
NetBSD — ran for 800+ iterations
OpenBSD one, two, three — same results here
Linux — stopped manually
macOS + Windows — ran for hours, killed manually","Current (2021-07-17) test results for BSDs:

freebsd
netbsd
openbsd


Demos:

commit
release


Changes to the test suite
The current test suite proved to be reliable when running under Linux and on decently specced systems. However, when I started running a massive number of jobs on overloaded GitHub VMs, tests start breaking due to things not establishing properly before the sleep wait expires.
The same thing happened after porting them to Windows and the BSDs. The test suite would be running fine for a few iterations and then break, always in a different place from before.
Thus tests were reworked quite a bit:

Windows / FreeBSD / OpenBSD / NetBSD support
time limits everywhere to detect tinc/tincd hangs (which now manifest as a single test failure instead of blocking the whole job)
remove sleep(1) whenever possible in favor of tinc scripts, which notify the test when it should proceed (this greatly reduced the frequency of spurious test failures)
increase log verbosity and (hopefully) make tests easier to read
support for weird/whitespaced FS paths
remove duplication whenever possible
add shellcheck and fix everything it reported
add shfmt to force a single style on all scripts (similar to astyle for C)

Tests still do fail. However, it happens much more rarely and I believe that these failures are no longer due to timing issues in tests themselves. They seem to indicate genuine issues in tinc's code, like the two things described above. Here are the remaining issues I gather from looking at a lot of test runs (most of them listed further down):

sometimes tinc is not able to connect to tincd, either failing with a timeout (which is set to 30 seconds), or with ""Cannot read greeting from control socket: Invalid argument"", even though in most places it is now called only after host-up or subnet-up. See examples here (mac), here (mac), here (mac), here (mac), here (freebsd), here (freebsd), here (linux), here (linux), here (mac), etc.
sptps-basic.test is disabled on Windows because both client and server completely hang there and never send any data to another.
algorithms.test is still disabled on Windows because it fails very often there there (sometimes tinc does not report the other node as reachable even though we check only after waiting for hosts/foo-up or hosts/bar-up).
security.test frequently breaks on macOS in one particular place.

I'll start digging once we get this PR out of the way.
Original tests
Original tests do not include algorithms.test as it was never actually enabled. I've done more extensive testing than listed here thanks to GitHub's generous limits, until they seem to have started throttling me (on the order of 1k separate builds and a few thousand test runs; plus a lot of runs on local VMs), with pretty similar results.
Single runs
Build on a fresh VM, run the test suite once:

Linux (196 ok / 200)
Linux (197 ok / 200)
Linux (199 ok / 200)
hang on NetBSD
hang on FreeBSD

Looped runs
Build on a fresh VM, run the suite in a loop until it fails:

Linux, failed on 56th iteration
macOS (failed in a few minutes) + Windows (hanged at the start and never started running the test suite)
quick failures on Linux here, here here, here, here, here, here, here, here, here, etc.

Updated tests
These have all the tests in the original suite + algorithms.test.
Single

Linux (200 ok / 200)
Linux (200 ok / 200)
Linux (200 ok / 200)
Linux + macOS + Windows (.deb jobs were being worked on and are broken in most of these): one, two, three, four, five, six, seven, eight
NetBSD
FreeBSD one, two
OpenBSD one, two

Looped

Linux + macOS + Windows, also this, this, and this — each ran for hours, most terminated by GitHub after going over the six-hour time limit or killed by myself after running out of patience
Windows — same
FreeBSD one — stopped manually after 250+ iterations to free up resources, two
NetBSD — ran for 800+ iterations
OpenBSD one, two, three — same results here
Linux — stopped manually
macOS + Windows — ran for hours, killed manually",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,277,2021-07-09T14:29:40Z,2021-07-19T14:05:22Z,2022-03-13T05:05:41Z,MERGED,True,933,523,17,https://github.com/hg,Rewrite of the test suite for compatibility with more operating systems and less failures,1,['CI'],https://github.com/gsliepen/tinc/pull/277,https://github.com/gsliepen,2,https://github.com/gsliepen/tinc/pull/277#issuecomment-877646557,"Current (2021-07-17) test results for BSDs:

freebsd
netbsd
openbsd


Demos:

commit
release


Changes to the test suite
The current test suite proved to be reliable when running under Linux and on decently specced systems. However, when I started running a massive number of jobs on overloaded GitHub VMs, tests start breaking due to things not establishing properly before the sleep wait expires.
The same thing happened after porting them to Windows and the BSDs. The test suite would be running fine for a few iterations and then break, always in a different place from before.
Thus tests were reworked quite a bit:

Windows / FreeBSD / OpenBSD / NetBSD support
time limits everywhere to detect tinc/tincd hangs (which now manifest as a single test failure instead of blocking the whole job)
remove sleep(1) whenever possible in favor of tinc scripts, which notify the test when it should proceed (this greatly reduced the frequency of spurious test failures)
increase log verbosity and (hopefully) make tests easier to read
support for weird/whitespaced FS paths
remove duplication whenever possible
add shellcheck and fix everything it reported
add shfmt to force a single style on all scripts (similar to astyle for C)

Tests still do fail. However, it happens much more rarely and I believe that these failures are no longer due to timing issues in tests themselves. They seem to indicate genuine issues in tinc's code, like the two things described above. Here are the remaining issues I gather from looking at a lot of test runs (most of them listed further down):

sometimes tinc is not able to connect to tincd, either failing with a timeout (which is set to 30 seconds), or with ""Cannot read greeting from control socket: Invalid argument"", even though in most places it is now called only after host-up or subnet-up. See examples here (mac), here (mac), here (mac), here (mac), here (freebsd), here (freebsd), here (linux), here (linux), here (mac), etc.
sptps-basic.test is disabled on Windows because both client and server completely hang there and never send any data to another.
algorithms.test is still disabled on Windows because it fails very often there there (sometimes tinc does not report the other node as reachable even though we check only after waiting for hosts/foo-up or hosts/bar-up).
security.test frequently breaks on macOS in one particular place.

I'll start digging once we get this PR out of the way.
Original tests
Original tests do not include algorithms.test as it was never actually enabled. I've done more extensive testing than listed here thanks to GitHub's generous limits, until they seem to have started throttling me (on the order of 1k separate builds and a few thousand test runs; plus a lot of runs on local VMs), with pretty similar results.
Single runs
Build on a fresh VM, run the test suite once:

Linux (196 ok / 200)
Linux (197 ok / 200)
Linux (199 ok / 200)
hang on NetBSD
hang on FreeBSD

Looped runs
Build on a fresh VM, run the suite in a loop until it fails:

Linux, failed on 56th iteration
macOS (failed in a few minutes) + Windows (hanged at the start and never started running the test suite)
quick failures on Linux here, here here, here, here, here, here, here, here, here, etc.

Updated tests
These have all the tests in the original suite + algorithms.test.
Single

Linux (200 ok / 200)
Linux (200 ok / 200)
Linux (200 ok / 200)
Linux + macOS + Windows (.deb jobs were being worked on and are broken in most of these): one, two, three, four, five, six, seven, eight
NetBSD
FreeBSD one, two
OpenBSD one, two

Looped

Linux + macOS + Windows, also this, this, and this — each ran for hours, most terminated by GitHub after going over the six-hour time limit or killed by myself after running out of patience
Windows — same
FreeBSD one — stopped manually after 250+ iterations to free up resources, two
NetBSD — ran for 800+ iterations
OpenBSD one, two, three — same results here
Linux — stopped manually
macOS + Windows — ran for hours, killed manually","Some overal remarks about this pull request:

More testing is great, especially covering the BSDs. There is a cost though, not only for sourcehut, but also for GitHub Actions if you spend more than a certain amount of time per month. I see GitHub allows you to host your own actions runners, and this will also allow you to use other operating systems than the ones provided by GitHub's own runners. So in the long run I'll probably try to set those up on my own machines. But we can use sourcehut as well :)
It's better to have several smaller pull requests, even if they are related. For example, fixing the tests themselves should be a separate pull request from adding support for testing on sourcehut. This way, one smaller pull request can already be merged while another one is still worked on.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,277,2021-07-09T14:29:40Z,2021-07-19T14:05:22Z,2022-03-13T05:05:41Z,MERGED,True,933,523,17,https://github.com/hg,Rewrite of the test suite for compatibility with more operating systems and less failures,1,['CI'],https://github.com/gsliepen/tinc/pull/277,https://github.com/gsliepen,3,https://github.com/gsliepen/tinc/pull/277#issuecomment-877647633,"Current (2021-07-17) test results for BSDs:

freebsd
netbsd
openbsd


Demos:

commit
release


Changes to the test suite
The current test suite proved to be reliable when running under Linux and on decently specced systems. However, when I started running a massive number of jobs on overloaded GitHub VMs, tests start breaking due to things not establishing properly before the sleep wait expires.
The same thing happened after porting them to Windows and the BSDs. The test suite would be running fine for a few iterations and then break, always in a different place from before.
Thus tests were reworked quite a bit:

Windows / FreeBSD / OpenBSD / NetBSD support
time limits everywhere to detect tinc/tincd hangs (which now manifest as a single test failure instead of blocking the whole job)
remove sleep(1) whenever possible in favor of tinc scripts, which notify the test when it should proceed (this greatly reduced the frequency of spurious test failures)
increase log verbosity and (hopefully) make tests easier to read
support for weird/whitespaced FS paths
remove duplication whenever possible
add shellcheck and fix everything it reported
add shfmt to force a single style on all scripts (similar to astyle for C)

Tests still do fail. However, it happens much more rarely and I believe that these failures are no longer due to timing issues in tests themselves. They seem to indicate genuine issues in tinc's code, like the two things described above. Here are the remaining issues I gather from looking at a lot of test runs (most of them listed further down):

sometimes tinc is not able to connect to tincd, either failing with a timeout (which is set to 30 seconds), or with ""Cannot read greeting from control socket: Invalid argument"", even though in most places it is now called only after host-up or subnet-up. See examples here (mac), here (mac), here (mac), here (mac), here (freebsd), here (freebsd), here (linux), here (linux), here (mac), etc.
sptps-basic.test is disabled on Windows because both client and server completely hang there and never send any data to another.
algorithms.test is still disabled on Windows because it fails very often there there (sometimes tinc does not report the other node as reachable even though we check only after waiting for hosts/foo-up or hosts/bar-up).
security.test frequently breaks on macOS in one particular place.

I'll start digging once we get this PR out of the way.
Original tests
Original tests do not include algorithms.test as it was never actually enabled. I've done more extensive testing than listed here thanks to GitHub's generous limits, until they seem to have started throttling me (on the order of 1k separate builds and a few thousand test runs; plus a lot of runs on local VMs), with pretty similar results.
Single runs
Build on a fresh VM, run the test suite once:

Linux (196 ok / 200)
Linux (197 ok / 200)
Linux (199 ok / 200)
hang on NetBSD
hang on FreeBSD

Looped runs
Build on a fresh VM, run the suite in a loop until it fails:

Linux, failed on 56th iteration
macOS (failed in a few minutes) + Windows (hanged at the start and never started running the test suite)
quick failures on Linux here, here here, here, here, here, here, here, here, here, etc.

Updated tests
These have all the tests in the original suite + algorithms.test.
Single

Linux (200 ok / 200)
Linux (200 ok / 200)
Linux (200 ok / 200)
Linux + macOS + Windows (.deb jobs were being worked on and are broken in most of these): one, two, three, four, five, six, seven, eight
NetBSD
FreeBSD one, two
OpenBSD one, two

Looped

Linux + macOS + Windows, also this, this, and this — each ran for hours, most terminated by GitHub after going over the six-hour time limit or killed by myself after running out of patience
Windows — same
FreeBSD one — stopped manually after 250+ iterations to free up resources, two
NetBSD — ran for 800+ iterations
OpenBSD one, two, three — same results here
Linux — stopped manually
macOS + Windows — ran for hours, killed manually","I see GitHub allows you to host your own actions runners, and this will also allow you to use other operating systems than the ones provided by GitHub's own runners.

I spoke too soon. While they do mention you can use your own OSes, the runner application is only available for Linux, macOS and Windows.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,277,2021-07-09T14:29:40Z,2021-07-19T14:05:22Z,2022-03-13T05:05:41Z,MERGED,True,933,523,17,https://github.com/hg,Rewrite of the test suite for compatibility with more operating systems and less failures,1,['CI'],https://github.com/gsliepen/tinc/pull/277,https://github.com/fangfufu,4,https://github.com/gsliepen/tinc/pull/277#issuecomment-877648205,"Current (2021-07-17) test results for BSDs:

freebsd
netbsd
openbsd


Demos:

commit
release


Changes to the test suite
The current test suite proved to be reliable when running under Linux and on decently specced systems. However, when I started running a massive number of jobs on overloaded GitHub VMs, tests start breaking due to things not establishing properly before the sleep wait expires.
The same thing happened after porting them to Windows and the BSDs. The test suite would be running fine for a few iterations and then break, always in a different place from before.
Thus tests were reworked quite a bit:

Windows / FreeBSD / OpenBSD / NetBSD support
time limits everywhere to detect tinc/tincd hangs (which now manifest as a single test failure instead of blocking the whole job)
remove sleep(1) whenever possible in favor of tinc scripts, which notify the test when it should proceed (this greatly reduced the frequency of spurious test failures)
increase log verbosity and (hopefully) make tests easier to read
support for weird/whitespaced FS paths
remove duplication whenever possible
add shellcheck and fix everything it reported
add shfmt to force a single style on all scripts (similar to astyle for C)

Tests still do fail. However, it happens much more rarely and I believe that these failures are no longer due to timing issues in tests themselves. They seem to indicate genuine issues in tinc's code, like the two things described above. Here are the remaining issues I gather from looking at a lot of test runs (most of them listed further down):

sometimes tinc is not able to connect to tincd, either failing with a timeout (which is set to 30 seconds), or with ""Cannot read greeting from control socket: Invalid argument"", even though in most places it is now called only after host-up or subnet-up. See examples here (mac), here (mac), here (mac), here (mac), here (freebsd), here (freebsd), here (linux), here (linux), here (mac), etc.
sptps-basic.test is disabled on Windows because both client and server completely hang there and never send any data to another.
algorithms.test is still disabled on Windows because it fails very often there there (sometimes tinc does not report the other node as reachable even though we check only after waiting for hosts/foo-up or hosts/bar-up).
security.test frequently breaks on macOS in one particular place.

I'll start digging once we get this PR out of the way.
Original tests
Original tests do not include algorithms.test as it was never actually enabled. I've done more extensive testing than listed here thanks to GitHub's generous limits, until they seem to have started throttling me (on the order of 1k separate builds and a few thousand test runs; plus a lot of runs on local VMs), with pretty similar results.
Single runs
Build on a fresh VM, run the test suite once:

Linux (196 ok / 200)
Linux (197 ok / 200)
Linux (199 ok / 200)
hang on NetBSD
hang on FreeBSD

Looped runs
Build on a fresh VM, run the suite in a loop until it fails:

Linux, failed on 56th iteration
macOS (failed in a few minutes) + Windows (hanged at the start and never started running the test suite)
quick failures on Linux here, here here, here, here, here, here, here, here, here, etc.

Updated tests
These have all the tests in the original suite + algorithms.test.
Single

Linux (200 ok / 200)
Linux (200 ok / 200)
Linux (200 ok / 200)
Linux + macOS + Windows (.deb jobs were being worked on and are broken in most of these): one, two, three, four, five, six, seven, eight
NetBSD
FreeBSD one, two
OpenBSD one, two

Looped

Linux + macOS + Windows, also this, this, and this — each ran for hours, most terminated by GitHub after going over the six-hour time limit or killed by myself after running out of patience
Windows — same
FreeBSD one — stopped manually after 250+ iterations to free up resources, two
NetBSD — ran for 800+ iterations
OpenBSD one, two, three — same results here
Linux — stopped manually
macOS + Windows — ran for hours, killed manually","I am happy for my server to be used for CI as well. It is a bit underpowered, but it should be enough for our purposes. It has
Intel(R) Core(TM) i3-2130 CPU @ 3.40GHz and 8GB of RAM, and magnetic HDD.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,277,2021-07-09T14:29:40Z,2021-07-19T14:05:22Z,2022-03-13T05:05:41Z,MERGED,True,933,523,17,https://github.com/hg,Rewrite of the test suite for compatibility with more operating systems and less failures,1,['CI'],https://github.com/gsliepen/tinc/pull/277,https://github.com/hg,5,https://github.com/gsliepen/tinc/pull/277#issuecomment-877649685,"Current (2021-07-17) test results for BSDs:

freebsd
netbsd
openbsd


Demos:

commit
release


Changes to the test suite
The current test suite proved to be reliable when running under Linux and on decently specced systems. However, when I started running a massive number of jobs on overloaded GitHub VMs, tests start breaking due to things not establishing properly before the sleep wait expires.
The same thing happened after porting them to Windows and the BSDs. The test suite would be running fine for a few iterations and then break, always in a different place from before.
Thus tests were reworked quite a bit:

Windows / FreeBSD / OpenBSD / NetBSD support
time limits everywhere to detect tinc/tincd hangs (which now manifest as a single test failure instead of blocking the whole job)
remove sleep(1) whenever possible in favor of tinc scripts, which notify the test when it should proceed (this greatly reduced the frequency of spurious test failures)
increase log verbosity and (hopefully) make tests easier to read
support for weird/whitespaced FS paths
remove duplication whenever possible
add shellcheck and fix everything it reported
add shfmt to force a single style on all scripts (similar to astyle for C)

Tests still do fail. However, it happens much more rarely and I believe that these failures are no longer due to timing issues in tests themselves. They seem to indicate genuine issues in tinc's code, like the two things described above. Here are the remaining issues I gather from looking at a lot of test runs (most of them listed further down):

sometimes tinc is not able to connect to tincd, either failing with a timeout (which is set to 30 seconds), or with ""Cannot read greeting from control socket: Invalid argument"", even though in most places it is now called only after host-up or subnet-up. See examples here (mac), here (mac), here (mac), here (mac), here (freebsd), here (freebsd), here (linux), here (linux), here (mac), etc.
sptps-basic.test is disabled on Windows because both client and server completely hang there and never send any data to another.
algorithms.test is still disabled on Windows because it fails very often there there (sometimes tinc does not report the other node as reachable even though we check only after waiting for hosts/foo-up or hosts/bar-up).
security.test frequently breaks on macOS in one particular place.

I'll start digging once we get this PR out of the way.
Original tests
Original tests do not include algorithms.test as it was never actually enabled. I've done more extensive testing than listed here thanks to GitHub's generous limits, until they seem to have started throttling me (on the order of 1k separate builds and a few thousand test runs; plus a lot of runs on local VMs), with pretty similar results.
Single runs
Build on a fresh VM, run the test suite once:

Linux (196 ok / 200)
Linux (197 ok / 200)
Linux (199 ok / 200)
hang on NetBSD
hang on FreeBSD

Looped runs
Build on a fresh VM, run the suite in a loop until it fails:

Linux, failed on 56th iteration
macOS (failed in a few minutes) + Windows (hanged at the start and never started running the test suite)
quick failures on Linux here, here here, here, here, here, here, here, here, here, etc.

Updated tests
These have all the tests in the original suite + algorithms.test.
Single

Linux (200 ok / 200)
Linux (200 ok / 200)
Linux (200 ok / 200)
Linux + macOS + Windows (.deb jobs were being worked on and are broken in most of these): one, two, three, four, five, six, seven, eight
NetBSD
FreeBSD one, two
OpenBSD one, two

Looped

Linux + macOS + Windows, also this, this, and this — each ran for hours, most terminated by GitHub after going over the six-hour time limit or killed by myself after running out of patience
Windows — same
FreeBSD one — stopped manually after 250+ iterations to free up resources, two
NetBSD — ran for 800+ iterations
OpenBSD one, two, three — same results here
Linux — stopped manually
macOS + Windows — ran for hours, killed manually","GitHub Actions if you spend more than a certain amount of time per month

Nope, they have no limits for public repositories.
https://github.community/t/for-public-repositories-is-there-a-monthly-limit-on-minutes/129017
These limits apply only to private ones:
https://docs.github.com/en/billing/managing-billing-for-github-actions/about-billing-for-github-actions
I've spent an insane amount of their computation time while testing tinc in the past two weeks. I have also run two small jobs on a private repository of mine. It was the only one that counted:


While they do mention you can use your own OSes, the runner application is only available for Linux, macOS and Windows.

There is a contrived way to run other operating systems — by running it in nested virtualization on top of a macOS VM:
https://github.com/vmactions/freebsd-vm
We can also add another CI service — Cirrus has official support for FreeBSD and I used it in the past with success (it also is completely free).
https://cirrus-ci.org/guide/FreeBSD/
OpenBSD and NetBSD will still have to be self-hosted or provided by sourcehut, though.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,277,2021-07-09T14:29:40Z,2021-07-19T14:05:22Z,2022-03-13T05:05:41Z,MERGED,True,933,523,17,https://github.com/hg,Rewrite of the test suite for compatibility with more operating systems and less failures,1,['CI'],https://github.com/gsliepen/tinc/pull/277,https://github.com/hg,6,https://github.com/gsliepen/tinc/pull/277#issuecomment-877657035,"Current (2021-07-17) test results for BSDs:

freebsd
netbsd
openbsd


Demos:

commit
release


Changes to the test suite
The current test suite proved to be reliable when running under Linux and on decently specced systems. However, when I started running a massive number of jobs on overloaded GitHub VMs, tests start breaking due to things not establishing properly before the sleep wait expires.
The same thing happened after porting them to Windows and the BSDs. The test suite would be running fine for a few iterations and then break, always in a different place from before.
Thus tests were reworked quite a bit:

Windows / FreeBSD / OpenBSD / NetBSD support
time limits everywhere to detect tinc/tincd hangs (which now manifest as a single test failure instead of blocking the whole job)
remove sleep(1) whenever possible in favor of tinc scripts, which notify the test when it should proceed (this greatly reduced the frequency of spurious test failures)
increase log verbosity and (hopefully) make tests easier to read
support for weird/whitespaced FS paths
remove duplication whenever possible
add shellcheck and fix everything it reported
add shfmt to force a single style on all scripts (similar to astyle for C)

Tests still do fail. However, it happens much more rarely and I believe that these failures are no longer due to timing issues in tests themselves. They seem to indicate genuine issues in tinc's code, like the two things described above. Here are the remaining issues I gather from looking at a lot of test runs (most of them listed further down):

sometimes tinc is not able to connect to tincd, either failing with a timeout (which is set to 30 seconds), or with ""Cannot read greeting from control socket: Invalid argument"", even though in most places it is now called only after host-up or subnet-up. See examples here (mac), here (mac), here (mac), here (mac), here (freebsd), here (freebsd), here (linux), here (linux), here (mac), etc.
sptps-basic.test is disabled on Windows because both client and server completely hang there and never send any data to another.
algorithms.test is still disabled on Windows because it fails very often there there (sometimes tinc does not report the other node as reachable even though we check only after waiting for hosts/foo-up or hosts/bar-up).
security.test frequently breaks on macOS in one particular place.

I'll start digging once we get this PR out of the way.
Original tests
Original tests do not include algorithms.test as it was never actually enabled. I've done more extensive testing than listed here thanks to GitHub's generous limits, until they seem to have started throttling me (on the order of 1k separate builds and a few thousand test runs; plus a lot of runs on local VMs), with pretty similar results.
Single runs
Build on a fresh VM, run the test suite once:

Linux (196 ok / 200)
Linux (197 ok / 200)
Linux (199 ok / 200)
hang on NetBSD
hang on FreeBSD

Looped runs
Build on a fresh VM, run the suite in a loop until it fails:

Linux, failed on 56th iteration
macOS (failed in a few minutes) + Windows (hanged at the start and never started running the test suite)
quick failures on Linux here, here here, here, here, here, here, here, here, here, etc.

Updated tests
These have all the tests in the original suite + algorithms.test.
Single

Linux (200 ok / 200)
Linux (200 ok / 200)
Linux (200 ok / 200)
Linux + macOS + Windows (.deb jobs were being worked on and are broken in most of these): one, two, three, four, five, six, seven, eight
NetBSD
FreeBSD one, two
OpenBSD one, two

Looped

Linux + macOS + Windows, also this, this, and this — each ran for hours, most terminated by GitHub after going over the six-hour time limit or killed by myself after running out of patience
Windows — same
FreeBSD one — stopped manually after 250+ iterations to free up resources, two
NetBSD — ran for 800+ iterations
OpenBSD one, two, three — same results here
Linux — stopped manually
macOS + Windows — ran for hours, killed manually","It is a bit underpowered, but it should be enough for our purposes

Your server is more powerful than both GitHub and sourcehut VMs.
If you are not afraid of dealing with the devil, Oracle gives out VMs with 4 cores/24 GB RAM/10 TB of outbound data each month for absolutely free. (I've been using one since it was introduced). It has an additional advantage of having a completely different processor architecture (additional aarch64 testing, anyone?)

It's better to have several smaller pull requests, even if they are related

Sorry, I'll make sure not to repeat this mistake. I left only the test changes here and moved everything else to separate pull requests. We'll have to keep those commits here for the time being and drop them at the last possible moment, or CI checks won't run on this PR properly.
#279 will probably have to go first so that this PR can be rebased on top of it, then this one, and then #280.
I'll have to wait for your decision on what to do with #277 (comment).",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,277,2021-07-09T14:29:40Z,2021-07-19T14:05:22Z,2022-03-13T05:05:41Z,MERGED,True,933,523,17,https://github.com/hg,Rewrite of the test suite for compatibility with more operating systems and less failures,1,['CI'],https://github.com/gsliepen/tinc/pull/277,https://github.com/fangfufu,7,https://github.com/gsliepen/tinc/pull/277#issuecomment-877695880,"Current (2021-07-17) test results for BSDs:

freebsd
netbsd
openbsd


Demos:

commit
release


Changes to the test suite
The current test suite proved to be reliable when running under Linux and on decently specced systems. However, when I started running a massive number of jobs on overloaded GitHub VMs, tests start breaking due to things not establishing properly before the sleep wait expires.
The same thing happened after porting them to Windows and the BSDs. The test suite would be running fine for a few iterations and then break, always in a different place from before.
Thus tests were reworked quite a bit:

Windows / FreeBSD / OpenBSD / NetBSD support
time limits everywhere to detect tinc/tincd hangs (which now manifest as a single test failure instead of blocking the whole job)
remove sleep(1) whenever possible in favor of tinc scripts, which notify the test when it should proceed (this greatly reduced the frequency of spurious test failures)
increase log verbosity and (hopefully) make tests easier to read
support for weird/whitespaced FS paths
remove duplication whenever possible
add shellcheck and fix everything it reported
add shfmt to force a single style on all scripts (similar to astyle for C)

Tests still do fail. However, it happens much more rarely and I believe that these failures are no longer due to timing issues in tests themselves. They seem to indicate genuine issues in tinc's code, like the two things described above. Here are the remaining issues I gather from looking at a lot of test runs (most of them listed further down):

sometimes tinc is not able to connect to tincd, either failing with a timeout (which is set to 30 seconds), or with ""Cannot read greeting from control socket: Invalid argument"", even though in most places it is now called only after host-up or subnet-up. See examples here (mac), here (mac), here (mac), here (mac), here (freebsd), here (freebsd), here (linux), here (linux), here (mac), etc.
sptps-basic.test is disabled on Windows because both client and server completely hang there and never send any data to another.
algorithms.test is still disabled on Windows because it fails very often there there (sometimes tinc does not report the other node as reachable even though we check only after waiting for hosts/foo-up or hosts/bar-up).
security.test frequently breaks on macOS in one particular place.

I'll start digging once we get this PR out of the way.
Original tests
Original tests do not include algorithms.test as it was never actually enabled. I've done more extensive testing than listed here thanks to GitHub's generous limits, until they seem to have started throttling me (on the order of 1k separate builds and a few thousand test runs; plus a lot of runs on local VMs), with pretty similar results.
Single runs
Build on a fresh VM, run the test suite once:

Linux (196 ok / 200)
Linux (197 ok / 200)
Linux (199 ok / 200)
hang on NetBSD
hang on FreeBSD

Looped runs
Build on a fresh VM, run the suite in a loop until it fails:

Linux, failed on 56th iteration
macOS (failed in a few minutes) + Windows (hanged at the start and never started running the test suite)
quick failures on Linux here, here here, here, here, here, here, here, here, here, etc.

Updated tests
These have all the tests in the original suite + algorithms.test.
Single

Linux (200 ok / 200)
Linux (200 ok / 200)
Linux (200 ok / 200)
Linux + macOS + Windows (.deb jobs were being worked on and are broken in most of these): one, two, three, four, five, six, seven, eight
NetBSD
FreeBSD one, two
OpenBSD one, two

Looped

Linux + macOS + Windows, also this, this, and this — each ran for hours, most terminated by GitHub after going over the six-hour time limit or killed by myself after running out of patience
Windows — same
FreeBSD one — stopped manually after 250+ iterations to free up resources, two
NetBSD — ran for 800+ iterations
OpenBSD one, two, three — same results here
Linux — stopped manually
macOS + Windows — ran for hours, killed manually","If you want to test aarch64, I am always happy to sacrifice a Raspberry Pi 4B. I don't guarantee 100% uptime, but it is up all the time.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,277,2021-07-09T14:29:40Z,2021-07-19T14:05:22Z,2022-03-13T05:05:41Z,MERGED,True,933,523,17,https://github.com/hg,Rewrite of the test suite for compatibility with more operating systems and less failures,1,['CI'],https://github.com/gsliepen/tinc/pull/277,https://github.com/gsliepen,8,https://github.com/gsliepen/tinc/pull/277#issuecomment-877700429,"Current (2021-07-17) test results for BSDs:

freebsd
netbsd
openbsd


Demos:

commit
release


Changes to the test suite
The current test suite proved to be reliable when running under Linux and on decently specced systems. However, when I started running a massive number of jobs on overloaded GitHub VMs, tests start breaking due to things not establishing properly before the sleep wait expires.
The same thing happened after porting them to Windows and the BSDs. The test suite would be running fine for a few iterations and then break, always in a different place from before.
Thus tests were reworked quite a bit:

Windows / FreeBSD / OpenBSD / NetBSD support
time limits everywhere to detect tinc/tincd hangs (which now manifest as a single test failure instead of blocking the whole job)
remove sleep(1) whenever possible in favor of tinc scripts, which notify the test when it should proceed (this greatly reduced the frequency of spurious test failures)
increase log verbosity and (hopefully) make tests easier to read
support for weird/whitespaced FS paths
remove duplication whenever possible
add shellcheck and fix everything it reported
add shfmt to force a single style on all scripts (similar to astyle for C)

Tests still do fail. However, it happens much more rarely and I believe that these failures are no longer due to timing issues in tests themselves. They seem to indicate genuine issues in tinc's code, like the two things described above. Here are the remaining issues I gather from looking at a lot of test runs (most of them listed further down):

sometimes tinc is not able to connect to tincd, either failing with a timeout (which is set to 30 seconds), or with ""Cannot read greeting from control socket: Invalid argument"", even though in most places it is now called only after host-up or subnet-up. See examples here (mac), here (mac), here (mac), here (mac), here (freebsd), here (freebsd), here (linux), here (linux), here (mac), etc.
sptps-basic.test is disabled on Windows because both client and server completely hang there and never send any data to another.
algorithms.test is still disabled on Windows because it fails very often there there (sometimes tinc does not report the other node as reachable even though we check only after waiting for hosts/foo-up or hosts/bar-up).
security.test frequently breaks on macOS in one particular place.

I'll start digging once we get this PR out of the way.
Original tests
Original tests do not include algorithms.test as it was never actually enabled. I've done more extensive testing than listed here thanks to GitHub's generous limits, until they seem to have started throttling me (on the order of 1k separate builds and a few thousand test runs; plus a lot of runs on local VMs), with pretty similar results.
Single runs
Build on a fresh VM, run the test suite once:

Linux (196 ok / 200)
Linux (197 ok / 200)
Linux (199 ok / 200)
hang on NetBSD
hang on FreeBSD

Looped runs
Build on a fresh VM, run the suite in a loop until it fails:

Linux, failed on 56th iteration
macOS (failed in a few minutes) + Windows (hanged at the start and never started running the test suite)
quick failures on Linux here, here here, here, here, here, here, here, here, here, etc.

Updated tests
These have all the tests in the original suite + algorithms.test.
Single

Linux (200 ok / 200)
Linux (200 ok / 200)
Linux (200 ok / 200)
Linux + macOS + Windows (.deb jobs were being worked on and are broken in most of these): one, two, three, four, five, six, seven, eight
NetBSD
FreeBSD one, two
OpenBSD one, two

Looped

Linux + macOS + Windows, also this, this, and this — each ran for hours, most terminated by GitHub after going over the six-hour time limit or killed by myself after running out of patience
Windows — same
FreeBSD one — stopped manually after 250+ iterations to free up resources, two
NetBSD — ran for 800+ iterations
OpenBSD one, two, three — same results here
Linux — stopped manually
macOS + Windows — ran for hours, killed manually","If you are not afraid of dealing with the devil, Oracle gives out VMs with 4 cores/24 GB RAM/10 TB of outbound data each month for absolutely free. (I've been using one since it was introduced). It has an additional advantage of having a completely different processor architecture (additional aarch64 testing, anyone?)

I have aarch64 machines as well I can test on, so I don't have to sign away my firstborn :)


It's better to have several smaller pull requests, even if they are related

Sorry, I'll make sure not to repeat this mistake. I left only the test changes here and moved everything else to separate pull requests. We'll have to keep those commits here for the time being and drop them at the last possible moment, or CI checks won't run on this PR properly.

Sure.

#279 will probably have to go first so that this PR can be rebased on top of it, then this one, and then #280.
I'll have to wait for your decision on what to do with #277 (comment).

Merged #279, and I'll merge #277 and #280 once those have been sorted out. Thanks!",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,277,2021-07-09T14:29:40Z,2021-07-19T14:05:22Z,2022-03-13T05:05:41Z,MERGED,True,933,523,17,https://github.com/hg,Rewrite of the test suite for compatibility with more operating systems and less failures,1,['CI'],https://github.com/gsliepen/tinc/pull/277,https://github.com/hg,9,https://github.com/gsliepen/tinc/pull/277#issuecomment-877802962,"Current (2021-07-17) test results for BSDs:

freebsd
netbsd
openbsd


Demos:

commit
release


Changes to the test suite
The current test suite proved to be reliable when running under Linux and on decently specced systems. However, when I started running a massive number of jobs on overloaded GitHub VMs, tests start breaking due to things not establishing properly before the sleep wait expires.
The same thing happened after porting them to Windows and the BSDs. The test suite would be running fine for a few iterations and then break, always in a different place from before.
Thus tests were reworked quite a bit:

Windows / FreeBSD / OpenBSD / NetBSD support
time limits everywhere to detect tinc/tincd hangs (which now manifest as a single test failure instead of blocking the whole job)
remove sleep(1) whenever possible in favor of tinc scripts, which notify the test when it should proceed (this greatly reduced the frequency of spurious test failures)
increase log verbosity and (hopefully) make tests easier to read
support for weird/whitespaced FS paths
remove duplication whenever possible
add shellcheck and fix everything it reported
add shfmt to force a single style on all scripts (similar to astyle for C)

Tests still do fail. However, it happens much more rarely and I believe that these failures are no longer due to timing issues in tests themselves. They seem to indicate genuine issues in tinc's code, like the two things described above. Here are the remaining issues I gather from looking at a lot of test runs (most of them listed further down):

sometimes tinc is not able to connect to tincd, either failing with a timeout (which is set to 30 seconds), or with ""Cannot read greeting from control socket: Invalid argument"", even though in most places it is now called only after host-up or subnet-up. See examples here (mac), here (mac), here (mac), here (mac), here (freebsd), here (freebsd), here (linux), here (linux), here (mac), etc.
sptps-basic.test is disabled on Windows because both client and server completely hang there and never send any data to another.
algorithms.test is still disabled on Windows because it fails very often there there (sometimes tinc does not report the other node as reachable even though we check only after waiting for hosts/foo-up or hosts/bar-up).
security.test frequently breaks on macOS in one particular place.

I'll start digging once we get this PR out of the way.
Original tests
Original tests do not include algorithms.test as it was never actually enabled. I've done more extensive testing than listed here thanks to GitHub's generous limits, until they seem to have started throttling me (on the order of 1k separate builds and a few thousand test runs; plus a lot of runs on local VMs), with pretty similar results.
Single runs
Build on a fresh VM, run the test suite once:

Linux (196 ok / 200)
Linux (197 ok / 200)
Linux (199 ok / 200)
hang on NetBSD
hang on FreeBSD

Looped runs
Build on a fresh VM, run the suite in a loop until it fails:

Linux, failed on 56th iteration
macOS (failed in a few minutes) + Windows (hanged at the start and never started running the test suite)
quick failures on Linux here, here here, here, here, here, here, here, here, here, etc.

Updated tests
These have all the tests in the original suite + algorithms.test.
Single

Linux (200 ok / 200)
Linux (200 ok / 200)
Linux (200 ok / 200)
Linux + macOS + Windows (.deb jobs were being worked on and are broken in most of these): one, two, three, four, five, six, seven, eight
NetBSD
FreeBSD one, two
OpenBSD one, two

Looped

Linux + macOS + Windows, also this, this, and this — each ran for hours, most terminated by GitHub after going over the six-hour time limit or killed by myself after running out of patience
Windows — same
FreeBSD one — stopped manually after 250+ iterations to free up resources, two
NetBSD — ran for 800+ iterations
OpenBSD one, two, three — same results here
Linux — stopped manually
macOS + Windows — ran for hours, killed manually","If you want to test aarch64, I am always happy to sacrifice a Raspberry Pi 4B.

If it's using a flash memory card, sacrifice is the right word here. With CI we want to run in as fresh an environment as possible, and thus have to reinstall every dependency on every build. It won't last long in these conditions unless you split it into a readonly base image with a read-write overlay in tmpfs.
Whatever @gsliepen decides to do, I'll be happy to adjust the CI stuff to run on anything.

be43017 (a separate commit for now for easier review) seems to cover everything we've discussed.
Tests:

looped (each VM has gone through 15+ iterations by now)
plus the looped run below this message
and this

BSD, five iterations each:

FreeBSD
NetBSD
OpenBSD

Timeout changes to security.test are supported by this and this (previously it failed on macOS in almost every iteration due to tinc not being able to connect to tincd through the unix socket before the timeout expires).
legacy-protocol still has this problem, as was posted in the original message, and I wasn't able to make it work by monkeying with timeouts. However, it fails relatively rarely (as it did originally) and it probably does not make sense to disable it everywhere because of this.
I tried running CI tests in parallel. It seems that GitHub's VMs don't have a good source of pseudo-random data. Most tests on macOS and Windows never even got past the key generation step before running out of time.
Linux runs are better, but they too can timeout on key generation.

Note: the checks for this PR below will finish either when all the jobs fail, or when they go over the 6-hour time limit. You can probably kill them once you're satisfied with the result.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,277,2021-07-09T14:29:40Z,2021-07-19T14:05:22Z,2022-03-13T05:05:41Z,MERGED,True,933,523,17,https://github.com/hg,Rewrite of the test suite for compatibility with more operating systems and less failures,1,['CI'],https://github.com/gsliepen/tinc/pull/277,https://github.com/hg,10,https://github.com/gsliepen/tinc/pull/277#issuecomment-877807354,"Current (2021-07-17) test results for BSDs:

freebsd
netbsd
openbsd


Demos:

commit
release


Changes to the test suite
The current test suite proved to be reliable when running under Linux and on decently specced systems. However, when I started running a massive number of jobs on overloaded GitHub VMs, tests start breaking due to things not establishing properly before the sleep wait expires.
The same thing happened after porting them to Windows and the BSDs. The test suite would be running fine for a few iterations and then break, always in a different place from before.
Thus tests were reworked quite a bit:

Windows / FreeBSD / OpenBSD / NetBSD support
time limits everywhere to detect tinc/tincd hangs (which now manifest as a single test failure instead of blocking the whole job)
remove sleep(1) whenever possible in favor of tinc scripts, which notify the test when it should proceed (this greatly reduced the frequency of spurious test failures)
increase log verbosity and (hopefully) make tests easier to read
support for weird/whitespaced FS paths
remove duplication whenever possible
add shellcheck and fix everything it reported
add shfmt to force a single style on all scripts (similar to astyle for C)

Tests still do fail. However, it happens much more rarely and I believe that these failures are no longer due to timing issues in tests themselves. They seem to indicate genuine issues in tinc's code, like the two things described above. Here are the remaining issues I gather from looking at a lot of test runs (most of them listed further down):

sometimes tinc is not able to connect to tincd, either failing with a timeout (which is set to 30 seconds), or with ""Cannot read greeting from control socket: Invalid argument"", even though in most places it is now called only after host-up or subnet-up. See examples here (mac), here (mac), here (mac), here (mac), here (freebsd), here (freebsd), here (linux), here (linux), here (mac), etc.
sptps-basic.test is disabled on Windows because both client and server completely hang there and never send any data to another.
algorithms.test is still disabled on Windows because it fails very often there there (sometimes tinc does not report the other node as reachable even though we check only after waiting for hosts/foo-up or hosts/bar-up).
security.test frequently breaks on macOS in one particular place.

I'll start digging once we get this PR out of the way.
Original tests
Original tests do not include algorithms.test as it was never actually enabled. I've done more extensive testing than listed here thanks to GitHub's generous limits, until they seem to have started throttling me (on the order of 1k separate builds and a few thousand test runs; plus a lot of runs on local VMs), with pretty similar results.
Single runs
Build on a fresh VM, run the test suite once:

Linux (196 ok / 200)
Linux (197 ok / 200)
Linux (199 ok / 200)
hang on NetBSD
hang on FreeBSD

Looped runs
Build on a fresh VM, run the suite in a loop until it fails:

Linux, failed on 56th iteration
macOS (failed in a few minutes) + Windows (hanged at the start and never started running the test suite)
quick failures on Linux here, here here, here, here, here, here, here, here, here, etc.

Updated tests
These have all the tests in the original suite + algorithms.test.
Single

Linux (200 ok / 200)
Linux (200 ok / 200)
Linux (200 ok / 200)
Linux + macOS + Windows (.deb jobs were being worked on and are broken in most of these): one, two, three, four, five, six, seven, eight
NetBSD
FreeBSD one, two
OpenBSD one, two

Looped

Linux + macOS + Windows, also this, this, and this — each ran for hours, most terminated by GitHub after going over the six-hour time limit or killed by myself after running out of patience
Windows — same
FreeBSD one — stopped manually after 250+ iterations to free up resources, two
NetBSD — ran for 800+ iterations
OpenBSD one, two, three — same results here
Linux — stopped manually
macOS + Windows — ran for hours, killed manually","Yeah, that failure is the legacy-protocol problem. It hasn't shown up on my desktop or VMs even once. I'll try adjusting timeouts some more and see what happens.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,277,2021-07-09T14:29:40Z,2021-07-19T14:05:22Z,2022-03-13T05:05:41Z,MERGED,True,933,523,17,https://github.com/hg,Rewrite of the test suite for compatibility with more operating systems and less failures,1,['CI'],https://github.com/gsliepen/tinc/pull/277,https://github.com/fangfufu,11,https://github.com/gsliepen/tinc/pull/277#issuecomment-877828784,"Current (2021-07-17) test results for BSDs:

freebsd
netbsd
openbsd


Demos:

commit
release


Changes to the test suite
The current test suite proved to be reliable when running under Linux and on decently specced systems. However, when I started running a massive number of jobs on overloaded GitHub VMs, tests start breaking due to things not establishing properly before the sleep wait expires.
The same thing happened after porting them to Windows and the BSDs. The test suite would be running fine for a few iterations and then break, always in a different place from before.
Thus tests were reworked quite a bit:

Windows / FreeBSD / OpenBSD / NetBSD support
time limits everywhere to detect tinc/tincd hangs (which now manifest as a single test failure instead of blocking the whole job)
remove sleep(1) whenever possible in favor of tinc scripts, which notify the test when it should proceed (this greatly reduced the frequency of spurious test failures)
increase log verbosity and (hopefully) make tests easier to read
support for weird/whitespaced FS paths
remove duplication whenever possible
add shellcheck and fix everything it reported
add shfmt to force a single style on all scripts (similar to astyle for C)

Tests still do fail. However, it happens much more rarely and I believe that these failures are no longer due to timing issues in tests themselves. They seem to indicate genuine issues in tinc's code, like the two things described above. Here are the remaining issues I gather from looking at a lot of test runs (most of them listed further down):

sometimes tinc is not able to connect to tincd, either failing with a timeout (which is set to 30 seconds), or with ""Cannot read greeting from control socket: Invalid argument"", even though in most places it is now called only after host-up or subnet-up. See examples here (mac), here (mac), here (mac), here (mac), here (freebsd), here (freebsd), here (linux), here (linux), here (mac), etc.
sptps-basic.test is disabled on Windows because both client and server completely hang there and never send any data to another.
algorithms.test is still disabled on Windows because it fails very often there there (sometimes tinc does not report the other node as reachable even though we check only after waiting for hosts/foo-up or hosts/bar-up).
security.test frequently breaks on macOS in one particular place.

I'll start digging once we get this PR out of the way.
Original tests
Original tests do not include algorithms.test as it was never actually enabled. I've done more extensive testing than listed here thanks to GitHub's generous limits, until they seem to have started throttling me (on the order of 1k separate builds and a few thousand test runs; plus a lot of runs on local VMs), with pretty similar results.
Single runs
Build on a fresh VM, run the test suite once:

Linux (196 ok / 200)
Linux (197 ok / 200)
Linux (199 ok / 200)
hang on NetBSD
hang on FreeBSD

Looped runs
Build on a fresh VM, run the suite in a loop until it fails:

Linux, failed on 56th iteration
macOS (failed in a few minutes) + Windows (hanged at the start and never started running the test suite)
quick failures on Linux here, here here, here, here, here, here, here, here, here, etc.

Updated tests
These have all the tests in the original suite + algorithms.test.
Single

Linux (200 ok / 200)
Linux (200 ok / 200)
Linux (200 ok / 200)
Linux + macOS + Windows (.deb jobs were being worked on and are broken in most of these): one, two, three, four, five, six, seven, eight
NetBSD
FreeBSD one, two
OpenBSD one, two

Looped

Linux + macOS + Windows, also this, this, and this — each ran for hours, most terminated by GitHub after going over the six-hour time limit or killed by myself after running out of patience
Windows — same
FreeBSD one — stopped manually after 250+ iterations to free up resources, two
NetBSD — ran for 800+ iterations
OpenBSD one, two, three — same results here
Linux — stopped manually
macOS + Windows — ran for hours, killed manually",My Raspberry Pi 4B is configured to run on HDD. I did that by changing the EEPROM. It wouldn't even boot from the microSD card.,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,277,2021-07-09T14:29:40Z,2021-07-19T14:05:22Z,2022-03-13T05:05:41Z,MERGED,True,933,523,17,https://github.com/hg,Rewrite of the test suite for compatibility with more operating systems and less failures,1,['CI'],https://github.com/gsliepen/tinc/pull/277,https://github.com/splitice,12,https://github.com/gsliepen/tinc/pull/277#issuecomment-877876026,"Current (2021-07-17) test results for BSDs:

freebsd
netbsd
openbsd


Demos:

commit
release


Changes to the test suite
The current test suite proved to be reliable when running under Linux and on decently specced systems. However, when I started running a massive number of jobs on overloaded GitHub VMs, tests start breaking due to things not establishing properly before the sleep wait expires.
The same thing happened after porting them to Windows and the BSDs. The test suite would be running fine for a few iterations and then break, always in a different place from before.
Thus tests were reworked quite a bit:

Windows / FreeBSD / OpenBSD / NetBSD support
time limits everywhere to detect tinc/tincd hangs (which now manifest as a single test failure instead of blocking the whole job)
remove sleep(1) whenever possible in favor of tinc scripts, which notify the test when it should proceed (this greatly reduced the frequency of spurious test failures)
increase log verbosity and (hopefully) make tests easier to read
support for weird/whitespaced FS paths
remove duplication whenever possible
add shellcheck and fix everything it reported
add shfmt to force a single style on all scripts (similar to astyle for C)

Tests still do fail. However, it happens much more rarely and I believe that these failures are no longer due to timing issues in tests themselves. They seem to indicate genuine issues in tinc's code, like the two things described above. Here are the remaining issues I gather from looking at a lot of test runs (most of them listed further down):

sometimes tinc is not able to connect to tincd, either failing with a timeout (which is set to 30 seconds), or with ""Cannot read greeting from control socket: Invalid argument"", even though in most places it is now called only after host-up or subnet-up. See examples here (mac), here (mac), here (mac), here (mac), here (freebsd), here (freebsd), here (linux), here (linux), here (mac), etc.
sptps-basic.test is disabled on Windows because both client and server completely hang there and never send any data to another.
algorithms.test is still disabled on Windows because it fails very often there there (sometimes tinc does not report the other node as reachable even though we check only after waiting for hosts/foo-up or hosts/bar-up).
security.test frequently breaks on macOS in one particular place.

I'll start digging once we get this PR out of the way.
Original tests
Original tests do not include algorithms.test as it was never actually enabled. I've done more extensive testing than listed here thanks to GitHub's generous limits, until they seem to have started throttling me (on the order of 1k separate builds and a few thousand test runs; plus a lot of runs on local VMs), with pretty similar results.
Single runs
Build on a fresh VM, run the test suite once:

Linux (196 ok / 200)
Linux (197 ok / 200)
Linux (199 ok / 200)
hang on NetBSD
hang on FreeBSD

Looped runs
Build on a fresh VM, run the suite in a loop until it fails:

Linux, failed on 56th iteration
macOS (failed in a few minutes) + Windows (hanged at the start and never started running the test suite)
quick failures on Linux here, here here, here, here, here, here, here, here, here, etc.

Updated tests
These have all the tests in the original suite + algorithms.test.
Single

Linux (200 ok / 200)
Linux (200 ok / 200)
Linux (200 ok / 200)
Linux + macOS + Windows (.deb jobs were being worked on and are broken in most of these): one, two, three, four, five, six, seven, eight
NetBSD
FreeBSD one, two
OpenBSD one, two

Looped

Linux + macOS + Windows, also this, this, and this — each ran for hours, most terminated by GitHub after going over the six-hour time limit or killed by myself after running out of patience
Windows — same
FreeBSD one — stopped manually after 250+ iterations to free up resources, two
NetBSD — ran for 800+ iterations
OpenBSD one, two, three — same results here
Linux — stopped manually
macOS + Windows — ran for hours, killed manually","@hg since you are doing CI work any chance of getting C unit tests while you are at it?
Not sure what the current defacto standard is for unit testing libraries in C but something simple would be very useful.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,277,2021-07-09T14:29:40Z,2021-07-19T14:05:22Z,2022-03-13T05:05:41Z,MERGED,True,933,523,17,https://github.com/hg,Rewrite of the test suite for compatibility with more operating systems and less failures,1,['CI'],https://github.com/gsliepen/tinc/pull/277,https://github.com/hg,13,https://github.com/gsliepen/tinc/pull/277#issuecomment-877949686,"Current (2021-07-17) test results for BSDs:

freebsd
netbsd
openbsd


Demos:

commit
release


Changes to the test suite
The current test suite proved to be reliable when running under Linux and on decently specced systems. However, when I started running a massive number of jobs on overloaded GitHub VMs, tests start breaking due to things not establishing properly before the sleep wait expires.
The same thing happened after porting them to Windows and the BSDs. The test suite would be running fine for a few iterations and then break, always in a different place from before.
Thus tests were reworked quite a bit:

Windows / FreeBSD / OpenBSD / NetBSD support
time limits everywhere to detect tinc/tincd hangs (which now manifest as a single test failure instead of blocking the whole job)
remove sleep(1) whenever possible in favor of tinc scripts, which notify the test when it should proceed (this greatly reduced the frequency of spurious test failures)
increase log verbosity and (hopefully) make tests easier to read
support for weird/whitespaced FS paths
remove duplication whenever possible
add shellcheck and fix everything it reported
add shfmt to force a single style on all scripts (similar to astyle for C)

Tests still do fail. However, it happens much more rarely and I believe that these failures are no longer due to timing issues in tests themselves. They seem to indicate genuine issues in tinc's code, like the two things described above. Here are the remaining issues I gather from looking at a lot of test runs (most of them listed further down):

sometimes tinc is not able to connect to tincd, either failing with a timeout (which is set to 30 seconds), or with ""Cannot read greeting from control socket: Invalid argument"", even though in most places it is now called only after host-up or subnet-up. See examples here (mac), here (mac), here (mac), here (mac), here (freebsd), here (freebsd), here (linux), here (linux), here (mac), etc.
sptps-basic.test is disabled on Windows because both client and server completely hang there and never send any data to another.
algorithms.test is still disabled on Windows because it fails very often there there (sometimes tinc does not report the other node as reachable even though we check only after waiting for hosts/foo-up or hosts/bar-up).
security.test frequently breaks on macOS in one particular place.

I'll start digging once we get this PR out of the way.
Original tests
Original tests do not include algorithms.test as it was never actually enabled. I've done more extensive testing than listed here thanks to GitHub's generous limits, until they seem to have started throttling me (on the order of 1k separate builds and a few thousand test runs; plus a lot of runs on local VMs), with pretty similar results.
Single runs
Build on a fresh VM, run the test suite once:

Linux (196 ok / 200)
Linux (197 ok / 200)
Linux (199 ok / 200)
hang on NetBSD
hang on FreeBSD

Looped runs
Build on a fresh VM, run the suite in a loop until it fails:

Linux, failed on 56th iteration
macOS (failed in a few minutes) + Windows (hanged at the start and never started running the test suite)
quick failures on Linux here, here here, here, here, here, here, here, here, here, etc.

Updated tests
These have all the tests in the original suite + algorithms.test.
Single

Linux (200 ok / 200)
Linux (200 ok / 200)
Linux (200 ok / 200)
Linux + macOS + Windows (.deb jobs were being worked on and are broken in most of these): one, two, three, four, five, six, seven, eight
NetBSD
FreeBSD one, two
OpenBSD one, two

Looped

Linux + macOS + Windows, also this, this, and this — each ran for hours, most terminated by GitHub after going over the six-hour time limit or killed by myself after running out of patience
Windows — same
FreeBSD one — stopped manually after 250+ iterations to free up resources, two
NetBSD — ran for 800+ iterations
OpenBSD one, two, three — same results here
Linux — stopped manually
macOS + Windows — ran for hours, killed manually","@splitice sure, I'll take a look at it when we get to merging #280. This thing is too big already.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,277,2021-07-09T14:29:40Z,2021-07-19T14:05:22Z,2022-03-13T05:05:41Z,MERGED,True,933,523,17,https://github.com/hg,Rewrite of the test suite for compatibility with more operating systems and less failures,1,['CI'],https://github.com/gsliepen/tinc/pull/277,https://github.com/gsliepen,14,https://github.com/gsliepen/tinc/pull/277#issuecomment-882108442,"Current (2021-07-17) test results for BSDs:

freebsd
netbsd
openbsd


Demos:

commit
release


Changes to the test suite
The current test suite proved to be reliable when running under Linux and on decently specced systems. However, when I started running a massive number of jobs on overloaded GitHub VMs, tests start breaking due to things not establishing properly before the sleep wait expires.
The same thing happened after porting them to Windows and the BSDs. The test suite would be running fine for a few iterations and then break, always in a different place from before.
Thus tests were reworked quite a bit:

Windows / FreeBSD / OpenBSD / NetBSD support
time limits everywhere to detect tinc/tincd hangs (which now manifest as a single test failure instead of blocking the whole job)
remove sleep(1) whenever possible in favor of tinc scripts, which notify the test when it should proceed (this greatly reduced the frequency of spurious test failures)
increase log verbosity and (hopefully) make tests easier to read
support for weird/whitespaced FS paths
remove duplication whenever possible
add shellcheck and fix everything it reported
add shfmt to force a single style on all scripts (similar to astyle for C)

Tests still do fail. However, it happens much more rarely and I believe that these failures are no longer due to timing issues in tests themselves. They seem to indicate genuine issues in tinc's code, like the two things described above. Here are the remaining issues I gather from looking at a lot of test runs (most of them listed further down):

sometimes tinc is not able to connect to tincd, either failing with a timeout (which is set to 30 seconds), or with ""Cannot read greeting from control socket: Invalid argument"", even though in most places it is now called only after host-up or subnet-up. See examples here (mac), here (mac), here (mac), here (mac), here (freebsd), here (freebsd), here (linux), here (linux), here (mac), etc.
sptps-basic.test is disabled on Windows because both client and server completely hang there and never send any data to another.
algorithms.test is still disabled on Windows because it fails very often there there (sometimes tinc does not report the other node as reachable even though we check only after waiting for hosts/foo-up or hosts/bar-up).
security.test frequently breaks on macOS in one particular place.

I'll start digging once we get this PR out of the way.
Original tests
Original tests do not include algorithms.test as it was never actually enabled. I've done more extensive testing than listed here thanks to GitHub's generous limits, until they seem to have started throttling me (on the order of 1k separate builds and a few thousand test runs; plus a lot of runs on local VMs), with pretty similar results.
Single runs
Build on a fresh VM, run the test suite once:

Linux (196 ok / 200)
Linux (197 ok / 200)
Linux (199 ok / 200)
hang on NetBSD
hang on FreeBSD

Looped runs
Build on a fresh VM, run the suite in a loop until it fails:

Linux, failed on 56th iteration
macOS (failed in a few minutes) + Windows (hanged at the start and never started running the test suite)
quick failures on Linux here, here here, here, here, here, here, here, here, here, etc.

Updated tests
These have all the tests in the original suite + algorithms.test.
Single

Linux (200 ok / 200)
Linux (200 ok / 200)
Linux (200 ok / 200)
Linux + macOS + Windows (.deb jobs were being worked on and are broken in most of these): one, two, three, four, five, six, seven, eight
NetBSD
FreeBSD one, two
OpenBSD one, two

Looped

Linux + macOS + Windows, also this, this, and this — each ran for hours, most terminated by GitHub after going over the six-hour time limit or killed by myself after running out of patience
Windows — same
FreeBSD one — stopped manually after 250+ iterations to free up resources, two
NetBSD — ran for 800+ iterations
OpenBSD one, two, three — same results here
Linux — stopped manually
macOS + Windows — ran for hours, killed manually","Commit b7845c3 looks very good! Do you want to squash & rebase the pull request, or shall I cherry-pick the good stuff?",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,277,2021-07-09T14:29:40Z,2021-07-19T14:05:22Z,2022-03-13T05:05:41Z,MERGED,True,933,523,17,https://github.com/hg,Rewrite of the test suite for compatibility with more operating systems and less failures,1,['CI'],https://github.com/gsliepen/tinc/pull/277,https://github.com/hg,15,https://github.com/gsliepen/tinc/pull/277#issuecomment-882363617,"Current (2021-07-17) test results for BSDs:

freebsd
netbsd
openbsd


Demos:

commit
release


Changes to the test suite
The current test suite proved to be reliable when running under Linux and on decently specced systems. However, when I started running a massive number of jobs on overloaded GitHub VMs, tests start breaking due to things not establishing properly before the sleep wait expires.
The same thing happened after porting them to Windows and the BSDs. The test suite would be running fine for a few iterations and then break, always in a different place from before.
Thus tests were reworked quite a bit:

Windows / FreeBSD / OpenBSD / NetBSD support
time limits everywhere to detect tinc/tincd hangs (which now manifest as a single test failure instead of blocking the whole job)
remove sleep(1) whenever possible in favor of tinc scripts, which notify the test when it should proceed (this greatly reduced the frequency of spurious test failures)
increase log verbosity and (hopefully) make tests easier to read
support for weird/whitespaced FS paths
remove duplication whenever possible
add shellcheck and fix everything it reported
add shfmt to force a single style on all scripts (similar to astyle for C)

Tests still do fail. However, it happens much more rarely and I believe that these failures are no longer due to timing issues in tests themselves. They seem to indicate genuine issues in tinc's code, like the two things described above. Here are the remaining issues I gather from looking at a lot of test runs (most of them listed further down):

sometimes tinc is not able to connect to tincd, either failing with a timeout (which is set to 30 seconds), or with ""Cannot read greeting from control socket: Invalid argument"", even though in most places it is now called only after host-up or subnet-up. See examples here (mac), here (mac), here (mac), here (mac), here (freebsd), here (freebsd), here (linux), here (linux), here (mac), etc.
sptps-basic.test is disabled on Windows because both client and server completely hang there and never send any data to another.
algorithms.test is still disabled on Windows because it fails very often there there (sometimes tinc does not report the other node as reachable even though we check only after waiting for hosts/foo-up or hosts/bar-up).
security.test frequently breaks on macOS in one particular place.

I'll start digging once we get this PR out of the way.
Original tests
Original tests do not include algorithms.test as it was never actually enabled. I've done more extensive testing than listed here thanks to GitHub's generous limits, until they seem to have started throttling me (on the order of 1k separate builds and a few thousand test runs; plus a lot of runs on local VMs), with pretty similar results.
Single runs
Build on a fresh VM, run the test suite once:

Linux (196 ok / 200)
Linux (197 ok / 200)
Linux (199 ok / 200)
hang on NetBSD
hang on FreeBSD

Looped runs
Build on a fresh VM, run the suite in a loop until it fails:

Linux, failed on 56th iteration
macOS (failed in a few minutes) + Windows (hanged at the start and never started running the test suite)
quick failures on Linux here, here here, here, here, here, here, here, here, here, etc.

Updated tests
These have all the tests in the original suite + algorithms.test.
Single

Linux (200 ok / 200)
Linux (200 ok / 200)
Linux (200 ok / 200)
Linux + macOS + Windows (.deb jobs were being worked on and are broken in most of these): one, two, three, four, five, six, seven, eight
NetBSD
FreeBSD one, two
OpenBSD one, two

Looped

Linux + macOS + Windows, also this, this, and this — each ran for hours, most terminated by GitHub after going over the six-hour time limit or killed by myself after running out of patience
Windows — same
FreeBSD one — stopped manually after 250+ iterations to free up resources, two
NetBSD — ran for 800+ iterations
OpenBSD one, two, three — same results here
Linux — stopped manually
macOS + Windows — ran for hours, killed manually","Sure, this 046a10d should do it. Thanks a lot.
sourcehut can be enabled after merging this, but #280 needs a bit more work.
Some last-minute checks:

https://github.com/hg/tinc/actions/runs/1044512505
https://builds.sr.ht/~reducer/job/547788
https://builds.sr.ht/~reducer/job/547789
https://builds.sr.ht/~reducer/job/547790

To reiterate for future reference: some tests still fail due to what I strongly suspect to be a tinc bug, because it happens in an ""impossible"" way — tincd goes through the full initialization phase and triggers tinc through tinc-up/subnet-up/host-up. tinc then tries to connect to tincd that started it (through a localhost/UNIX socket connection!), but fails with a timeout, or sometimes right away.
The relatively large number of build jobs should allow you to distinguish between an actual new bug (tests failed everywhere) and one of these things cropping up (only one job failed).
Looking into this is on my todo list.",True,{'THUMBS_UP': ['https://github.com/splitice']}
gsliepen/tinc,https://github.com/gsliepen/tinc,278,2021-07-10T15:15:46Z,2021-07-10T20:42:18Z,2021-07-20T12:23:22Z,CLOSED,False,97,0,4,https://github.com/hg,Add CI testing on FreeBSD/NetBSD/OpenBSD through sr.ht,1,['CI'],https://github.com/gsliepen/tinc/pull/278,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/278,"This was split off #277 to reduce its size a bit. It should only be merged after #277 because the current test suite does not run on BSDs (that's the reason they were bundled initially).

Historically there was some breakage on various BSDs due to lower amount of testing there. This should help with preventing it in the future.
The only decent service here is sourcehut. It's cheap and I'll be happy to cover at least the first two years. (Not affiliated, but very interested in more testing on less popular platforms).
Here are some of their users: neovim, sway, wlroots.
I'll post instructions on what to do next if this is merged.","This was split off #277 to reduce its size a bit. It should only be merged after #277 because the current test suite does not run on BSDs (that's the reason they were bundled initially).

Historically there was some breakage on various BSDs due to lower amount of testing there. This should help with preventing it in the future.
The only decent service here is sourcehut. It's cheap and I'll be happy to cover at least the first two years. (Not affiliated, but very interested in more testing on less popular platforms).
Here are some of their users: neovim, sway, wlroots.
I'll post instructions on what to do next if this is merged.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,278,2021-07-10T15:15:46Z,2021-07-10T20:42:18Z,2021-07-20T12:23:22Z,CLOSED,False,97,0,4,https://github.com/hg,Add CI testing on FreeBSD/NetBSD/OpenBSD through sr.ht,1,['CI'],https://github.com/gsliepen/tinc/pull/278,https://github.com/gsliepen,2,https://github.com/gsliepen/tinc/pull/278#issuecomment-877701344,"This was split off #277 to reduce its size a bit. It should only be merged after #277 because the current test suite does not run on BSDs (that's the reason they were bundled initially).

Historically there was some breakage on various BSDs due to lower amount of testing there. This should help with preventing it in the future.
The only decent service here is sourcehut. It's cheap and I'll be happy to cover at least the first two years. (Not affiliated, but very interested in more testing on less popular platforms).
Here are some of their users: neovim, sway, wlroots.
I'll post instructions on what to do next if this is merged.",Cherry-picked as 83fa4ea.,True,{'THUMBS_UP': ['https://github.com/hg']}
gsliepen/tinc,https://github.com/gsliepen/tinc,278,2021-07-10T15:15:46Z,2021-07-10T20:42:18Z,2021-07-20T12:23:22Z,CLOSED,False,97,0,4,https://github.com/hg,Add CI testing on FreeBSD/NetBSD/OpenBSD through sr.ht,1,['CI'],https://github.com/gsliepen/tinc/pull/278,https://github.com/gsliepen,3,https://github.com/gsliepen/tinc/pull/278#issuecomment-882750774,"This was split off #277 to reduce its size a bit. It should only be merged after #277 because the current test suite does not run on BSDs (that's the reason they were bundled initially).

Historically there was some breakage on various BSDs due to lower amount of testing there. This should help with preventing it in the future.
The only decent service here is sourcehut. It's cheap and I'll be happy to cover at least the first two years. (Not affiliated, but very interested in more testing on less popular platforms).
Here are some of their users: neovim, sway, wlroots.
I'll post instructions on what to do next if this is merged.","So, now we just need those promised instructions :)",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,278,2021-07-10T15:15:46Z,2021-07-10T20:42:18Z,2021-07-20T12:23:22Z,CLOSED,False,97,0,4,https://github.com/hg,Add CI testing on FreeBSD/NetBSD/OpenBSD through sr.ht,1,['CI'],https://github.com/gsliepen/tinc/pull/278,https://github.com/hg,4,https://github.com/gsliepen/tinc/pull/278#issuecomment-882761722,"This was split off #277 to reduce its size a bit. It should only be merged after #277 because the current test suite does not run on BSDs (that's the reason they were bundled initially).

Historically there was some breakage on various BSDs due to lower amount of testing there. This should help with preventing it in the future.
The only decent service here is sourcehut. It's cheap and I'll be happy to cover at least the first two years. (Not affiliated, but very interested in more testing on less popular platforms).
Here are some of their users: neovim, sway, wlroots.
I'll post instructions on what to do next if this is merged.","Totally forgot about that, sorry.

create an account at https://sr.ht
pay for the first year (I sent the money to your paypal account about a week ago)
visit here; it should ask you to authorize it on GitHub (it reads only public information IIRC, and the code is 100% open anyway)
after the authorization is complete, choose tinc from the list of your repositories and click ""add task""
repeat for pull requests here",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,278,2021-07-10T15:15:46Z,2021-07-10T20:42:18Z,2021-07-20T12:23:22Z,CLOSED,False,97,0,4,https://github.com/hg,Add CI testing on FreeBSD/NetBSD/OpenBSD through sr.ht,1,['CI'],https://github.com/gsliepen/tinc/pull/278,https://github.com/gsliepen,5,https://github.com/gsliepen/tinc/pull/278#issuecomment-883349692,"This was split off #277 to reduce its size a bit. It should only be merged after #277 because the current test suite does not run on BSDs (that's the reason they were bundled initially).

Historically there was some breakage on various BSDs due to lower amount of testing there. This should help with preventing it in the future.
The only decent service here is sourcehut. It's cheap and I'll be happy to cover at least the first two years. (Not affiliated, but very interested in more testing on less popular platforms).
Here are some of their users: neovim, sway, wlroots.
I'll post instructions on what to do next if this is merged.","Worked perfectly, thanks very much for the donation for the first year and for all the work of setting this up (I just had to click a few things to enable it)!",True,{'THUMBS_UP': ['https://github.com/hg']}
gsliepen/tinc,https://github.com/gsliepen/tinc,279,2021-07-10T15:23:35Z,2021-07-10T20:32:58Z,2021-07-11T03:08:31Z,MERGED,True,15,4,3,https://github.com/hg,Two bugfixes in MinGW build of tinc,2,['CI'],https://github.com/gsliepen/tinc/pull/279,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/279,"This was split off #277 to reduce its size. Sorry about that, won't happen again.
If you would like to see this properly tested, do not merge it before #277. Tests do not currently run on Windows. (Although this gives us the chicken-and-egg problem because most tests will fail without these bug fixes).
This test run (see also the commit that triggered it) includes changes from this PR and runs the fully compatible test suite from #277 on Windows.

socket error checking in invitation.c
On Windows, recv() failures here

  
    
      tinc/src/invitation.c
    
    
        Lines 1325 to 1331
      in
      2bc4752
    
  
  
    

        
          
           while((len = recv(sock, line, sizeof(line), 0))) { 
        

        
          
           	if(len < 0) { 
        

        
          
           		if(errno == EINTR) { 
        

        
          
           			continue; 
        

        
          
           		} 
        

        
          
            
        

        
          
           		fprintf(stderr, ""Error reading data from %s port %s: %s\n"", address, port, strerror(errno)); 
        
    
  


were not handled properly and it printed ""file already exists"" (for a socket error) in all invite-* tests: before, after.
It also did not detect socket shutdown after the initial exchange, which (after fixing the first thing) printed this:
Error reading data from 127.0.0.1 port 32759: (10058) A request to send or receive data was disallowed because the socket had already been shut down in that direction with aprevious shutdown call.

src/tincctl.c: inverse exit code for 'tinc stop' on Windows
tinc stop on Windows returned the opposite of what it does on Unixen — 0 exit code for failure, 1 for success. See more here.","This was split off #277 to reduce its size. Sorry about that, won't happen again.
If you would like to see this properly tested, do not merge it before #277. Tests do not currently run on Windows. (Although this gives us the chicken-and-egg problem because most tests will fail without these bug fixes).
This test run (see also the commit that triggered it) includes changes from this PR and runs the fully compatible test suite from #277 on Windows.

socket error checking in invitation.c
On Windows, recv() failures here

  
    
      tinc/src/invitation.c
    
    
        Lines 1325 to 1331
      in
      2bc4752
    
  
  
    

        
          
           while((len = recv(sock, line, sizeof(line), 0))) { 
        

        
          
           	if(len < 0) { 
        

        
          
           		if(errno == EINTR) { 
        

        
          
           			continue; 
        

        
          
           		} 
        

        
          
            
        

        
          
           		fprintf(stderr, ""Error reading data from %s port %s: %s\n"", address, port, strerror(errno)); 
        
    
  


were not handled properly and it printed ""file already exists"" (for a socket error) in all invite-* tests: before, after.
It also did not detect socket shutdown after the initial exchange, which (after fixing the first thing) printed this:
Error reading data from 127.0.0.1 port 32759: (10058) A request to send or receive data was disallowed because the socket had already been shut down in that direction with aprevious shutdown call.

src/tincctl.c: inverse exit code for 'tinc stop' on Windows
tinc stop on Windows returned the opposite of what it does on Unixen — 0 exit code for failure, 1 for success. See more here.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,280,2021-07-10T16:53:49Z,2021-07-20T17:40:37Z,2022-03-13T05:04:54Z,MERGED,True,565,132,21,https://github.com/hg,GitHub actions cleanups; running tests on Windows,3,"['1.1', 'CI']",https://github.com/gsliepen/tinc/pull/280,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/280,"Split off #277 for easier review. This currently won't pass CI checks until both #277 and #279 are merged (with this rebased on top) because of the compatibility fixes introduced there.

These are some things here that could have been done better the first time (like actually testing .debs before publishing them). Sorry about that!

check code formatting only once
check test scripts formatting (shfmt)
static analysis for test scripts (shellcheck)
save more test logs and other debug info
add missing pieces to Ubuntu packages
test .debs on clean machine before publishing (example)
git clone full history for changelog generation
rename some steps","Split off #277 for easier review. This currently won't pass CI checks until both #277 and #279 are merged (with this rebased on top) because of the compatibility fixes introduced there.

These are some things here that could have been done better the first time (like actually testing .debs before publishing them). Sorry about that!

check code formatting only once
check test scripts formatting (shfmt)
static analysis for test scripts (shellcheck)
save more test logs and other debug info
add missing pieces to Ubuntu packages
test .debs on clean machine before publishing (example)
git clone full history for changelog generation
rename some steps",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,280,2021-07-10T16:53:49Z,2021-07-20T17:40:37Z,2022-03-13T05:04:54Z,MERGED,True,565,132,21,https://github.com/hg,GitHub actions cleanups; running tests on Windows,3,"['1.1', 'CI']",https://github.com/gsliepen/tinc/pull/280,https://github.com/gsliepen,2,https://github.com/gsliepen/tinc/pull/280#issuecomment-882750026,"Split off #277 for easier review. This currently won't pass CI checks until both #277 and #279 are merged (with this rebased on top) because of the compatibility fixes introduced there.

These are some things here that could have been done better the first time (like actually testing .debs before publishing them). Sorry about that!

check code formatting only once
check test scripts formatting (shfmt)
static analysis for test scripts (shellcheck)
save more test logs and other debug info
add missing pieces to Ubuntu packages
test .debs on clean machine before publishing (example)
git clone full history for changelog generation
rename some steps","The changes look OK to me; they should be rebased, then we can see if they pass the tests.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,280,2021-07-10T16:53:49Z,2021-07-20T17:40:37Z,2022-03-13T05:04:54Z,MERGED,True,565,132,21,https://github.com/hg,GitHub actions cleanups; running tests on Windows,3,"['1.1', 'CI']",https://github.com/gsliepen/tinc/pull/280,https://github.com/hg,3,https://github.com/gsliepen/tinc/pull/280#issuecomment-882757183,"Split off #277 for easier review. This currently won't pass CI checks until both #277 and #279 are merged (with this rebased on top) because of the compatibility fixes introduced there.

These are some things here that could have been done better the first time (like actually testing .debs before publishing them). Sorry about that!

check code formatting only once
check test scripts formatting (shfmt)
static analysis for test scripts (shellcheck)
save more test logs and other debug info
add missing pieces to Ubuntu packages
test .debs on clean machine before publishing (example)
git clone full history for changelog generation
rename some steps","Sure, I was putting some finishing touches to them. Here's the current state.
The ASAN job will be failing for the time being because of a bunch of known memory leaks. Some of them are not important (a single allocation to a global variable which is not cleaned up before the exit()), and some look like they are. I've been cleaning them up and suppressing others where it does not make sense to add two dozen free()s because we're exiting anyway, but it'll take some time.
Linux jobs now do two test runs — with and without legacy protocol support. I wanted to add a libgcrypt test run, but couldn't get it to link without also adding OpenSSL (it requires some functions that are only defined in openssl/cipher.c and openssl/rsa.c).
Windows and macOS should still be split in two separate jobs IMO, because if one of them fails, you still have the other one as reference. We can add more jobs, but they run much slower than Linux, and definitely have much lower concurrency limits (Mac jobs cost 10× as much as Linux jobs for paying customers!)",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,280,2021-07-10T16:53:49Z,2021-07-20T17:40:37Z,2022-03-13T05:04:54Z,MERGED,True,565,132,21,https://github.com/hg,GitHub actions cleanups; running tests on Windows,3,"['1.1', 'CI']",https://github.com/gsliepen/tinc/pull/280,https://github.com/gsliepen,4,https://github.com/gsliepen/tinc/pull/280#issuecomment-882762037,"Split off #277 for easier review. This currently won't pass CI checks until both #277 and #279 are merged (with this rebased on top) because of the compatibility fixes introduced there.

These are some things here that could have been done better the first time (like actually testing .debs before publishing them). Sorry about that!

check code formatting only once
check test scripts formatting (shfmt)
static analysis for test scripts (shellcheck)
save more test logs and other debug info
add missing pieces to Ubuntu packages
test .debs on clean machine before publishing (example)
git clone full history for changelog generation
rename some steps","Ok, lots of missing calls to free() at program exit time making the address sanitizer disappointed. I'll fix those first.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,280,2021-07-10T16:53:49Z,2021-07-20T17:40:37Z,2022-03-13T05:04:54Z,MERGED,True,565,132,21,https://github.com/hg,GitHub actions cleanups; running tests on Windows,3,"['1.1', 'CI']",https://github.com/gsliepen/tinc/pull/280,https://github.com/gsliepen,5,https://github.com/gsliepen/tinc/pull/280#issuecomment-882762689,"Split off #277 for easier review. This currently won't pass CI checks until both #277 and #279 are merged (with this rebased on top) because of the compatibility fixes introduced there.

These are some things here that could have been done better the first time (like actually testing .debs before publishing them). Sorry about that!

check code formatting only once
check test scripts formatting (shfmt)
static analysis for test scripts (shellcheck)
save more test logs and other debug info
add missing pieces to Ubuntu packages
test .debs on clean machine before publishing (example)
git clone full history for changelog generation
rename some steps","Ah, I only just now saw your comment. If you are going to fix them, be my guest.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,280,2021-07-10T16:53:49Z,2021-07-20T17:40:37Z,2022-03-13T05:04:54Z,MERGED,True,565,132,21,https://github.com/hg,GitHub actions cleanups; running tests on Windows,3,"['1.1', 'CI']",https://github.com/gsliepen/tinc/pull/280,https://github.com/hg,6,https://github.com/gsliepen/tinc/pull/280#issuecomment-882765272,"Split off #277 for easier review. This currently won't pass CI checks until both #277 and #279 are merged (with this rebased on top) because of the compatibility fixes introduced there.

These are some things here that could have been done better the first time (like actually testing .debs before publishing them). Sorry about that!

check code formatting only once
check test scripts formatting (shfmt)
static analysis for test scripts (shellcheck)
save more test logs and other debug info
add missing pieces to Ubuntu packages
test .debs on clean machine before publishing (example)
git clone full history for changelog generation
rename some steps","Nah, I'll be happy to do it. Most of them are already fixed here, I just need to find a way to disable vasprintf in CI without patching tinc (otherwise you get very short stack traces whenever it produces a leak, and those are impossible to suppress), and recheck everything thrice.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,280,2021-07-10T16:53:49Z,2021-07-20T17:40:37Z,2022-03-13T05:04:54Z,MERGED,True,565,132,21,https://github.com/hg,GitHub actions cleanups; running tests on Windows,3,"['1.1', 'CI']",https://github.com/gsliepen/tinc/pull/280,https://github.com/gsliepen,7,https://github.com/gsliepen/tinc/pull/280#issuecomment-882765976,"Split off #277 for easier review. This currently won't pass CI checks until both #277 and #279 are merged (with this rebased on top) because of the compatibility fixes introduced there.

These are some things here that could have been done better the first time (like actually testing .debs before publishing them). Sorry about that!

check code formatting only once
check test scripts formatting (shfmt)
static analysis for test scripts (shellcheck)
save more test logs and other debug info
add missing pieces to Ubuntu packages
test .debs on clean machine before publishing (example)
git clone full history for changelog generation
rename some steps","Alternatively, remove testing for --with-libgcrypt and the address sanitizer from this pull request, and add it back together with the necessary fixes in another pull request. But it's up to you :)",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,280,2021-07-10T16:53:49Z,2021-07-20T17:40:37Z,2022-03-13T05:04:54Z,MERGED,True,565,132,21,https://github.com/hg,GitHub actions cleanups; running tests on Windows,3,"['1.1', 'CI']",https://github.com/gsliepen/tinc/pull/280,https://github.com/hg,8,https://github.com/gsliepen/tinc/pull/280#issuecomment-882792988,"Split off #277 for easier review. This currently won't pass CI checks until both #277 and #279 are merged (with this rebased on top) because of the compatibility fixes introduced there.

These are some things here that could have been done better the first time (like actually testing .debs before publishing them). Sorry about that!

check code formatting only once
check test scripts formatting (shfmt)
static analysis for test scripts (shellcheck)
save more test logs and other debug info
add missing pieces to Ubuntu packages
test .debs on clean machine before publishing (example)
git clone full history for changelog generation
rename some steps","This is probably the best solution. Cleaning up those leaks will take some time, and everything else here is ready.
Demo.
ASAN can be re-enabled by adding address to jobs.sanitizer.strategy.matrix.sanitizer in test.yml:
      matrix:
        sanitizer:
          - address
          - thread
          - undefined
Alpine is still failing a bit more often than I would like, but it will be impossible to fix quickly with my current level of knowledge of tinc's internals. Just don't pay too much attention to it for now.

By the way, UBSAN produces a lot of these things:
net_setup.c:234:17: runtime error: implicit conversion from type 'int' of value -33217 (32-bit, signed) to type 'unsigned int' changed the value to 4294934079 (32-bit, unsigned)
    #0 0x55be8d73e42a in read_ecdsa_private_key /home/runner/work/tinc/tinc/src/net_setup.c:234:17
    #1 0x55be8d73b3c0 in setup_myself /home/runner/work/tinc/tinc/src/net_setup.c:866:18
    #2 0x55be8d73ab54 in setup_network /home/runner/work/tinc/tinc/src/net_setup.c:1246:6
    #3 0x55be8d7abf26 in main /home/runner/work/tinc/tinc/src/tincd.c:513:6
    #4 0x7f0f6801e0b2 in __libc_start_main (/lib/x86_64-linux-gnu/libc.so.6+0x270b2)
    #5 0x55be8d6c4dfd in _start (/home/runner/work/tinc/tinc/src/tincd+0x9ddfd)

This is easy enough to fix IIUC:
diff --git a/src/net_setup.c b/src/net_setup.c
@@ -231,7 +231,7 @@ static bool read_ecdsa_private_key(void) {
 		return false;
 	}

-	if(s.st_mode & ~0100700) {
+	if(s.st_mode & ~0100700u) {
 		logger(DEBUG_ALWAYS, LOG_WARNING, ""Warning: insecure file permissions for Ed25519 private key file `%s'!"", fname);
 	}

and I am willing to do the work just for the higher signal-to-noise ratio. Would you be willing to accept these changes, or do we go the suppression route?
Thanks!",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,280,2021-07-10T16:53:49Z,2021-07-20T17:40:37Z,2022-03-13T05:04:54Z,MERGED,True,565,132,21,https://github.com/hg,GitHub actions cleanups; running tests on Windows,3,"['1.1', 'CI']",https://github.com/gsliepen/tinc/pull/280,https://github.com/gsliepen,9,https://github.com/gsliepen/tinc/pull/280#issuecomment-882850047,"Split off #277 for easier review. This currently won't pass CI checks until both #277 and #279 are merged (with this rebased on top) because of the compatibility fixes introduced there.

These are some things here that could have been done better the first time (like actually testing .debs before publishing them). Sorry about that!

check code formatting only once
check test scripts formatting (shfmt)
static analysis for test scripts (shellcheck)
save more test logs and other debug info
add missing pieces to Ubuntu packages
test .debs on clean machine before publishing (example)
git clone full history for changelog generation
rename some steps",I'll accept those changes.,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,280,2021-07-10T16:53:49Z,2021-07-20T17:40:37Z,2022-03-13T05:04:54Z,MERGED,True,565,132,21,https://github.com/hg,GitHub actions cleanups; running tests on Windows,3,"['1.1', 'CI']",https://github.com/gsliepen/tinc/pull/280,https://github.com/hg,10,https://github.com/gsliepen/tinc/pull/280#issuecomment-883482728,"Split off #277 for easier review. This currently won't pass CI checks until both #277 and #279 are merged (with this rebased on top) because of the compatibility fixes introduced there.

These are some things here that could have been done better the first time (like actually testing .debs before publishing them). Sorry about that!

check code formatting only once
check test scripts formatting (shfmt)
static analysis for test scripts (shellcheck)
save more test logs and other debug info
add missing pieces to Ubuntu packages
test .debs on clean machine before publishing (example)
git clone full history for changelog generation
rename some steps","Additional BSD checks

https://builds.sr.ht/~reducer/job/548869
https://builds.sr.ht/~reducer/job/548868
https://builds.sr.ht/~reducer/job/548867",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,282,2021-07-12T01:40:13Z,2021-07-12T17:34:30Z,2021-07-12T17:34:30Z,CLOSED,False,0,6,1,https://github.com/splitice,ci: run for all branches,1,['CI'],https://github.com/gsliepen/tinc/pull/282,https://github.com/splitice,1,https://github.com/gsliepen/tinc/pull/282,It's much more useful,It's much more useful,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,282,2021-07-12T01:40:13Z,2021-07-12T17:34:30Z,2021-07-12T17:34:30Z,CLOSED,False,0,6,1,https://github.com/splitice,ci: run for all branches,1,['CI'],https://github.com/gsliepen/tinc/pull/282,https://github.com/gsliepen,2,https://github.com/gsliepen/tinc/pull/282#issuecomment-878463627,It's much more useful,Cherry-picked as f2df183. Thanks!,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,283,2021-07-12T02:55:52Z,2021-07-12T17:29:09Z,2021-07-12T17:29:10Z,MERGED,True,4,2,1,https://github.com/splitice,Fix overrun in prf() if hmac size not divisible into key size,1,"['bug', '1.1']",https://github.com/gsliepen/tinc/pull/283,https://github.com/splitice,1,https://github.com/gsliepen/tinc/pull/283,"Not seen only due to chacha having a 64byte key and a 64byte HMAC (SHA512) being used having a 64byte key and a 64byte HMAC (SHA512) being used
Found when exploring alternative crypto (AES).","Not seen only due to chacha having a 64byte key and a 64byte HMAC (SHA512) being used having a 64byte key and a 64byte HMAC (SHA512) being used
Found when exploring alternative crypto (AES).",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,284,2021-07-12T10:56:38Z,2021-07-12T17:29:56Z,2022-03-13T05:04:49Z,CLOSED,False,2,0,1,https://github.com/hg,src/getopt.h: add missing header guard,1,"['bug', '1.1']",https://github.com/gsliepen/tinc/pull/284,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/284,"If the system is missing its own getopt.h, tinc uses the vendored copy.
If we simulate such a system by flipping the condition in configure.ac, this is what we get.
After applying this change it builds and passes the test suite.","If the system is missing its own getopt.h, tinc uses the vendored copy.
If we simulate such a system by flipping the condition in configure.ac, this is what we get.
After applying this change it builds and passes the test suite.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,284,2021-07-12T10:56:38Z,2021-07-12T17:29:56Z,2022-03-13T05:04:49Z,CLOSED,False,2,0,1,https://github.com/hg,src/getopt.h: add missing header guard,1,"['bug', '1.1']",https://github.com/gsliepen/tinc/pull/284,https://github.com/gsliepen,2,https://github.com/gsliepen/tinc/pull/284#issuecomment-878460839,"If the system is missing its own getopt.h, tinc uses the vendored copy.
If we simulate such a system by flipping the condition in configure.ac, this is what we get.
After applying this change it builds and passes the test suite.",Cherry-picked as 7081c09. Thanks!,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,285,2021-07-16T15:30:37Z,2021-07-18T15:48:58Z,2022-03-13T05:05:26Z,MERGED,True,193,4,2,https://github.com/hg,Allow running sptps_test on Windows,1,['CI'],https://github.com/gsliepen/tinc/pull/285,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/285,"sptps_test.c was hanging on Windows and never sending any data because one is not supposed to call select() there on anything except proper BSD sockets.
After looking around the web for possible solutions I wasn't able to find anything less hackish than creating a separate thread which reads stdin and pushes data through a TCP socket to the main thread. The main thread can reuse the same select() loop that's used for every other operating system.
Here are the test results:

one
two
three
four
five
six
seven
eight
nine
ten

My C skills are very rusty. Apologies for the eye bleeds.","sptps_test.c was hanging on Windows and never sending any data because one is not supposed to call select() there on anything except proper BSD sockets.
After looking around the web for possible solutions I wasn't able to find anything less hackish than creating a separate thread which reads stdin and pushes data through a TCP socket to the main thread. The main thread can reuse the same select() loop that's used for every other operating system.
Here are the test results:

one
two
three
four
five
six
seven
eight
nine
ten

My C skills are very rusty. Apologies for the eye bleeds.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,285,2021-07-16T15:30:37Z,2021-07-18T15:48:58Z,2022-03-13T05:05:26Z,MERGED,True,193,4,2,https://github.com/hg,Allow running sptps_test on Windows,1,['CI'],https://github.com/gsliepen/tinc/pull/285,https://github.com/hg,2,https://github.com/gsliepen/tinc/pull/285#issuecomment-881894834,"sptps_test.c was hanging on Windows and never sending any data because one is not supposed to call select() there on anything except proper BSD sockets.
After looking around the web for possible solutions I wasn't able to find anything less hackish than creating a separate thread which reads stdin and pushes data through a TCP socket to the main thread. The main thread can reuse the same select() loop that's used for every other operating system.
Here are the test results:

one
two
three
four
five
six
seven
eight
nine
ten

My C skills are very rusty. Apologies for the eye bleeds.","Oh-oh. Thank you for the review and for spoonfeding me. Everything should be fixed. I'll look into implementing the proper solution with WSAWaitForMultipleEvents later. If you decide against merging this, it only fixes one test on a single operating system. We can just disable the test for now.
Checks.

FWIW I think #277 is ready for merging. It's marked as work in progress as an additional safety measure because it contains a lot of junk that needs to be dropped at the last possible moment.
There's no low hanging fruit left in there. I know of at least one bug that crops up periodically (tinc-to-tincd connection failure, more frequent in musl builds and on Windows), but it looks like a bug in tinc's internals. The whole test suite has been running for ~80 hours on my aarch64 machine before it happened, so it needs some careful debugging.

By the way, while looking for build instructions for Alpine I noticed this
# s390x: tests hang
# armhf: tests fail
arch=""all !s390x !armhf !armv7""
and this
	# Disable test
	sed -i '/legacy-protocol.test/d' test/Makefile
so having tests run on more architectures would definitely be nice.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,286,2021-07-18T13:33:24Z,2022-03-27T14:27:35Z,2022-03-27T14:27:36Z,MERGED,True,1080,95,35,https://github.com/hg,RFC: unit testing for C,4,"['1.1', 'CI']",https://github.com/gsliepen/tinc/pull/286,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/286,"Note: this is purely an RFC at this point.
cc @splitice

There was some interest in adding C unit testing to the project.
There doesn't seem to be an agreement about any de facto standard, so this PR adds two well maintaned, popular, and tested libraries for your evaluation. Pick something (or suggest something else) and I'll remove the rest.
Some popular libraries were not considered because of their reliance on a different build system or a working C++ compiler (and the the rest is really similar to cmocka).
The choice here is between:

a very lightweight library with can be fully bundled with the project;
or a bit more features which bring a separate dependency (with different versions on every platform, or the requirement of a separate source build).

Unity
Link.
See sample tests in unittest/unity.
How to use (remove other test section from unittest/Makefile.am or install the appropriate library beforehand):
$ make check

Pros

the simplest solution, basically just a bunch of convenience macros that you would have to write anyway.
can be easily vendored (which I did), and does not require installing anything on dev machines or CI systems.

Cons

all tests from the same source file run as a single process — a misbehaving test can corrupt the whole group.
no support for test mocks, this requires another library which pulls Ruby and a bunch of other things.
single output format (not really important at the moment, but would be nice to have if we were to add some sort of autogenerated summary in the future).

Similar libraries

https://github.com/silentbicycle/greatest
https://github.com/siu/minunit
https://github.com/nemequ/munit

cmocka
Link.
See sample tests in unittest/cmocka.
More realistic tests from other projects: SSSD, samba, OpenVPN, coreboot.
How to use:
# apt install libcmocka-dev
$ make check

Pros

supports mocking out of the box (see more here and here).
does its own memory corruption checks which could be helpful on platforms where ASAN is not available.
many output formats, should we require that at some point.

Cons

requires installing a pre-built library on every dev machine and every CI build, or building from source.
same limitation about the single process.

The first one is a real pain. The tests that ran just fine on my machine failed on Ubuntu 18.04 because its version of cmocka does not provide the newer functions that were used.
Similar libraries

https://libcheck.github.io/check/
https://github.com/Snaipe/Criterion
https://gitlab.com/cunity/cunit/


PS: don't pay attention to the Makefile changes. Let me know which type of a testing library you'd rather see and I'll redo them from scratch (probably using libtool).","Note: this is purely an RFC at this point.
cc @splitice

There was some interest in adding C unit testing to the project.
There doesn't seem to be an agreement about any de facto standard, so this PR adds two well maintaned, popular, and tested libraries for your evaluation. Pick something (or suggest something else) and I'll remove the rest.
Some popular libraries were not considered because of their reliance on a different build system or a working C++ compiler (and the the rest is really similar to cmocka).
The choice here is between:

a very lightweight library with can be fully bundled with the project;
or a bit more features which bring a separate dependency (with different versions on every platform, or the requirement of a separate source build).

Unity
Link.
See sample tests in unittest/unity.
How to use (remove other test section from unittest/Makefile.am or install the appropriate library beforehand):
$ make check

Pros

the simplest solution, basically just a bunch of convenience macros that you would have to write anyway.
can be easily vendored (which I did), and does not require installing anything on dev machines or CI systems.

Cons

all tests from the same source file run as a single process — a misbehaving test can corrupt the whole group.
no support for test mocks, this requires another library which pulls Ruby and a bunch of other things.
single output format (not really important at the moment, but would be nice to have if we were to add some sort of autogenerated summary in the future).

Similar libraries

https://github.com/silentbicycle/greatest
https://github.com/siu/minunit
https://github.com/nemequ/munit

cmocka
Link.
See sample tests in unittest/cmocka.
More realistic tests from other projects: SSSD, samba, OpenVPN, coreboot.
How to use:
# apt install libcmocka-dev
$ make check

Pros

supports mocking out of the box (see more here and here).
does its own memory corruption checks which could be helpful on platforms where ASAN is not available.
many output formats, should we require that at some point.

Cons

requires installing a pre-built library on every dev machine and every CI build, or building from source.
same limitation about the single process.

The first one is a real pain. The tests that ran just fine on my machine failed on Ubuntu 18.04 because its version of cmocka does not provide the newer functions that were used.
Similar libraries

https://libcheck.github.io/check/
https://github.com/Snaipe/Criterion
https://gitlab.com/cunity/cunit/


PS: don't pay attention to the Makefile changes. Let me know which type of a testing library you'd rather see and I'll redo them from scratch (probably using libtool).",True,{'THUMBS_UP': ['https://github.com/furkanmustafa']}
gsliepen/tinc,https://github.com/gsliepen/tinc,286,2021-07-18T13:33:24Z,2022-03-27T14:27:35Z,2022-03-27T14:27:36Z,MERGED,True,1080,95,35,https://github.com/hg,RFC: unit testing for C,4,"['1.1', 'CI']",https://github.com/gsliepen/tinc/pull/286,https://github.com/gsliepen,2,https://github.com/gsliepen/tinc/pull/286#issuecomment-882097054,"Note: this is purely an RFC at this point.
cc @splitice

There was some interest in adding C unit testing to the project.
There doesn't seem to be an agreement about any de facto standard, so this PR adds two well maintaned, popular, and tested libraries for your evaluation. Pick something (or suggest something else) and I'll remove the rest.
Some popular libraries were not considered because of their reliance on a different build system or a working C++ compiler (and the the rest is really similar to cmocka).
The choice here is between:

a very lightweight library with can be fully bundled with the project;
or a bit more features which bring a separate dependency (with different versions on every platform, or the requirement of a separate source build).

Unity
Link.
See sample tests in unittest/unity.
How to use (remove other test section from unittest/Makefile.am or install the appropriate library beforehand):
$ make check

Pros

the simplest solution, basically just a bunch of convenience macros that you would have to write anyway.
can be easily vendored (which I did), and does not require installing anything on dev machines or CI systems.

Cons

all tests from the same source file run as a single process — a misbehaving test can corrupt the whole group.
no support for test mocks, this requires another library which pulls Ruby and a bunch of other things.
single output format (not really important at the moment, but would be nice to have if we were to add some sort of autogenerated summary in the future).

Similar libraries

https://github.com/silentbicycle/greatest
https://github.com/siu/minunit
https://github.com/nemequ/munit

cmocka
Link.
See sample tests in unittest/cmocka.
More realistic tests from other projects: SSSD, samba, OpenVPN, coreboot.
How to use:
# apt install libcmocka-dev
$ make check

Pros

supports mocking out of the box (see more here and here).
does its own memory corruption checks which could be helpful on platforms where ASAN is not available.
many output formats, should we require that at some point.

Cons

requires installing a pre-built library on every dev machine and every CI build, or building from source.
same limitation about the single process.

The first one is a real pain. The tests that ran just fine on my machine failed on Ubuntu 18.04 because its version of cmocka does not provide the newer functions that were used.
Similar libraries

https://libcheck.github.io/check/
https://github.com/Snaipe/Criterion
https://gitlab.com/cunity/cunit/


PS: don't pay attention to the Makefile changes. Let me know which type of a testing library you'd rather see and I'll redo them from scratch (probably using libtool).","Nice. I think depending on cmocka is fine. It certainly allows us to do more kinds of tests, like the one mocking the execute_script() function. We don't need to do unit testing on all platforms; 95% of the code is platform independent, and I think the rest is covered by the integration tests.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,286,2021-07-18T13:33:24Z,2022-03-27T14:27:35Z,2022-03-27T14:27:36Z,MERGED,True,1080,95,35,https://github.com/hg,RFC: unit testing for C,4,"['1.1', 'CI']",https://github.com/gsliepen/tinc/pull/286,https://github.com/hg,3,https://github.com/gsliepen/tinc/pull/286#issuecomment-882100655,"Note: this is purely an RFC at this point.
cc @splitice

There was some interest in adding C unit testing to the project.
There doesn't seem to be an agreement about any de facto standard, so this PR adds two well maintaned, popular, and tested libraries for your evaluation. Pick something (or suggest something else) and I'll remove the rest.
Some popular libraries were not considered because of their reliance on a different build system or a working C++ compiler (and the the rest is really similar to cmocka).
The choice here is between:

a very lightweight library with can be fully bundled with the project;
or a bit more features which bring a separate dependency (with different versions on every platform, or the requirement of a separate source build).

Unity
Link.
See sample tests in unittest/unity.
How to use (remove other test section from unittest/Makefile.am or install the appropriate library beforehand):
$ make check

Pros

the simplest solution, basically just a bunch of convenience macros that you would have to write anyway.
can be easily vendored (which I did), and does not require installing anything on dev machines or CI systems.

Cons

all tests from the same source file run as a single process — a misbehaving test can corrupt the whole group.
no support for test mocks, this requires another library which pulls Ruby and a bunch of other things.
single output format (not really important at the moment, but would be nice to have if we were to add some sort of autogenerated summary in the future).

Similar libraries

https://github.com/silentbicycle/greatest
https://github.com/siu/minunit
https://github.com/nemequ/munit

cmocka
Link.
See sample tests in unittest/cmocka.
More realistic tests from other projects: SSSD, samba, OpenVPN, coreboot.
How to use:
# apt install libcmocka-dev
$ make check

Pros

supports mocking out of the box (see more here and here).
does its own memory corruption checks which could be helpful on platforms where ASAN is not available.
many output formats, should we require that at some point.

Cons

requires installing a pre-built library on every dev machine and every CI build, or building from source.
same limitation about the single process.

The first one is a real pain. The tests that ran just fine on my machine failed on Ubuntu 18.04 because its version of cmocka does not provide the newer functions that were used.
Similar libraries

https://libcheck.github.io/check/
https://github.com/Snaipe/Criterion
https://gitlab.com/cunity/cunit/


PS: don't pay attention to the Makefile changes. Let me know which type of a testing library you'd rather see and I'll redo them from scratch (probably using libtool).","Alright, thank you. I'll rework this in the next few days when time permits.
I am not too sure about the best way to link tests against the project's code. Which solution would you rather see?

as it's implemented currently: build tinc / tincd (except the main() object files) into two separate static libraries, and then:

link each library against its main() object file to produce the binary
link one of the libraries against each test



This will probably require switching the project to libtool because the libraries it produces can remember the required linker flags (no need to write -lminiupnpc twice) (link).


move tests inside src/tests and add them to src/Makefile.am (no need for libraries then, just pass dependencies in variables)


remove src/Makefile.am and unittest/Makefile.am and move their contents to the top Makefile.am (same)


I've also been experimenting with porting tinc to the meson build system. With meson all of this would be way easier to implement. But this is probably asking too much for now.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,286,2021-07-18T13:33:24Z,2022-03-27T14:27:35Z,2022-03-27T14:27:36Z,MERGED,True,1080,95,35,https://github.com/hg,RFC: unit testing for C,4,"['1.1', 'CI']",https://github.com/gsliepen/tinc/pull/286,https://github.com/gsliepen,4,https://github.com/gsliepen/tinc/pull/286#issuecomment-882103621,"Note: this is purely an RFC at this point.
cc @splitice

There was some interest in adding C unit testing to the project.
There doesn't seem to be an agreement about any de facto standard, so this PR adds two well maintaned, popular, and tested libraries for your evaluation. Pick something (or suggest something else) and I'll remove the rest.
Some popular libraries were not considered because of their reliance on a different build system or a working C++ compiler (and the the rest is really similar to cmocka).
The choice here is between:

a very lightweight library with can be fully bundled with the project;
or a bit more features which bring a separate dependency (with different versions on every platform, or the requirement of a separate source build).

Unity
Link.
See sample tests in unittest/unity.
How to use (remove other test section from unittest/Makefile.am or install the appropriate library beforehand):
$ make check

Pros

the simplest solution, basically just a bunch of convenience macros that you would have to write anyway.
can be easily vendored (which I did), and does not require installing anything on dev machines or CI systems.

Cons

all tests from the same source file run as a single process — a misbehaving test can corrupt the whole group.
no support for test mocks, this requires another library which pulls Ruby and a bunch of other things.
single output format (not really important at the moment, but would be nice to have if we were to add some sort of autogenerated summary in the future).

Similar libraries

https://github.com/silentbicycle/greatest
https://github.com/siu/minunit
https://github.com/nemequ/munit

cmocka
Link.
See sample tests in unittest/cmocka.
More realistic tests from other projects: SSSD, samba, OpenVPN, coreboot.
How to use:
# apt install libcmocka-dev
$ make check

Pros

supports mocking out of the box (see more here and here).
does its own memory corruption checks which could be helpful on platforms where ASAN is not available.
many output formats, should we require that at some point.

Cons

requires installing a pre-built library on every dev machine and every CI build, or building from source.
same limitation about the single process.

The first one is a real pain. The tests that ran just fine on my machine failed on Ubuntu 18.04 because its version of cmocka does not provide the newer functions that were used.
Similar libraries

https://libcheck.github.io/check/
https://github.com/Snaipe/Criterion
https://gitlab.com/cunity/cunit/


PS: don't pay attention to the Makefile changes. Let me know which type of a testing library you'd rather see and I'll redo them from scratch (probably using libtool).","All options are fine, perhaps option 2 is the cleanest of them all.
Moving to Meson would be very nice as well; I've been using that in other projects, but I didn't do this for tinc because it's not so trivial; there's conditional building of source files, and the test suite might need some work as well to work with meson. Last but not least, autotools provides excellent support for cross-compiling out of the box, and I've been using that to build the Windows binaries on Linux. With Meson you need to write ""cross files"" yourself, and I wonder how portable they are.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,286,2021-07-18T13:33:24Z,2022-03-27T14:27:35Z,2022-03-27T14:27:36Z,MERGED,True,1080,95,35,https://github.com/hg,RFC: unit testing for C,4,"['1.1', 'CI']",https://github.com/gsliepen/tinc/pull/286,https://github.com/splitice,5,https://github.com/gsliepen/tinc/pull/286#issuecomment-882379087,"Note: this is purely an RFC at this point.
cc @splitice

There was some interest in adding C unit testing to the project.
There doesn't seem to be an agreement about any de facto standard, so this PR adds two well maintaned, popular, and tested libraries for your evaluation. Pick something (or suggest something else) and I'll remove the rest.
Some popular libraries were not considered because of their reliance on a different build system or a working C++ compiler (and the the rest is really similar to cmocka).
The choice here is between:

a very lightweight library with can be fully bundled with the project;
or a bit more features which bring a separate dependency (with different versions on every platform, or the requirement of a separate source build).

Unity
Link.
See sample tests in unittest/unity.
How to use (remove other test section from unittest/Makefile.am or install the appropriate library beforehand):
$ make check

Pros

the simplest solution, basically just a bunch of convenience macros that you would have to write anyway.
can be easily vendored (which I did), and does not require installing anything on dev machines or CI systems.

Cons

all tests from the same source file run as a single process — a misbehaving test can corrupt the whole group.
no support for test mocks, this requires another library which pulls Ruby and a bunch of other things.
single output format (not really important at the moment, but would be nice to have if we were to add some sort of autogenerated summary in the future).

Similar libraries

https://github.com/silentbicycle/greatest
https://github.com/siu/minunit
https://github.com/nemequ/munit

cmocka
Link.
See sample tests in unittest/cmocka.
More realistic tests from other projects: SSSD, samba, OpenVPN, coreboot.
How to use:
# apt install libcmocka-dev
$ make check

Pros

supports mocking out of the box (see more here and here).
does its own memory corruption checks which could be helpful on platforms where ASAN is not available.
many output formats, should we require that at some point.

Cons

requires installing a pre-built library on every dev machine and every CI build, or building from source.
same limitation about the single process.

The first one is a real pain. The tests that ran just fine on my machine failed on Ubuntu 18.04 because its version of cmocka does not provide the newer functions that were used.
Similar libraries

https://libcheck.github.io/check/
https://github.com/Snaipe/Criterion
https://gitlab.com/cunity/cunit/


PS: don't pay attention to the Makefile changes. Let me know which type of a testing library you'd rather see and I'll redo them from scratch (probably using libtool).","@hg cmocka looks awesome.
Is it worth exploring some abstraction to split fixtures into seperate processes?",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,286,2021-07-18T13:33:24Z,2022-03-27T14:27:35Z,2022-03-27T14:27:36Z,MERGED,True,1080,95,35,https://github.com/hg,RFC: unit testing for C,4,"['1.1', 'CI']",https://github.com/gsliepen/tinc/pull/286,https://github.com/lancethepants,6,https://github.com/gsliepen/tinc/pull/286#issuecomment-883935035,"Note: this is purely an RFC at this point.
cc @splitice

There was some interest in adding C unit testing to the project.
There doesn't seem to be an agreement about any de facto standard, so this PR adds two well maintaned, popular, and tested libraries for your evaluation. Pick something (or suggest something else) and I'll remove the rest.
Some popular libraries were not considered because of their reliance on a different build system or a working C++ compiler (and the the rest is really similar to cmocka).
The choice here is between:

a very lightweight library with can be fully bundled with the project;
or a bit more features which bring a separate dependency (with different versions on every platform, or the requirement of a separate source build).

Unity
Link.
See sample tests in unittest/unity.
How to use (remove other test section from unittest/Makefile.am or install the appropriate library beforehand):
$ make check

Pros

the simplest solution, basically just a bunch of convenience macros that you would have to write anyway.
can be easily vendored (which I did), and does not require installing anything on dev machines or CI systems.

Cons

all tests from the same source file run as a single process — a misbehaving test can corrupt the whole group.
no support for test mocks, this requires another library which pulls Ruby and a bunch of other things.
single output format (not really important at the moment, but would be nice to have if we were to add some sort of autogenerated summary in the future).

Similar libraries

https://github.com/silentbicycle/greatest
https://github.com/siu/minunit
https://github.com/nemequ/munit

cmocka
Link.
See sample tests in unittest/cmocka.
More realistic tests from other projects: SSSD, samba, OpenVPN, coreboot.
How to use:
# apt install libcmocka-dev
$ make check

Pros

supports mocking out of the box (see more here and here).
does its own memory corruption checks which could be helpful on platforms where ASAN is not available.
many output formats, should we require that at some point.

Cons

requires installing a pre-built library on every dev machine and every CI build, or building from source.
same limitation about the single process.

The first one is a real pain. The tests that ran just fine on my machine failed on Ubuntu 18.04 because its version of cmocka does not provide the newer functions that were used.
Similar libraries

https://libcheck.github.io/check/
https://github.com/Snaipe/Criterion
https://gitlab.com/cunity/cunit/


PS: don't pay attention to the Makefile changes. Let me know which type of a testing library you'd rather see and I'll redo them from scratch (probably using libtool).","Sorry, off topic for this pull request, but since this is where the discussion is happening.
+1 for staying with autotools, hands down the best build system for cross-compiling.
./configure --host=arm-linux
I'd even take cmake before meson.
cmake \
-DCMAKE_CROSSCOMPILING=True \
-DCMAKE_C_COMPILER=""arm-linux-gcc"" \
-DCMAKE_CXX_COMPILER=""arm-linux-g++"" \
.

https://mesonbuild.com/Cross-compilation.html
Meson requires you to write a cross build definition file. 
If you can't configure a cross-compile in a single command then cross-compilation is a 2nd class citizen.
libGLib moved to meson, and after tinkering with it for two hours I decided I was wasting my time and am staying with their last autotools build until I don't have anything better to do then mess with cross-compiling with meson.
Tinc runs on a host of architectures. I myself run it on mipsel, arm, aarch64, android, x86_64 on windows and linux.  I even compile it myself for all these targets minus android. Complicating the build process will raise the barrier to entry for those wanting to compile and try it out.
I applaud tinc for its simplicity. I integrated tinc+gui into tomato firmware, and it's been a hit!  People love the simplicity of easily creating a mesh vpn.  Let's please keep the build process simple as well!",True,{'THUMBS_UP': ['https://github.com/hg']}
gsliepen/tinc,https://github.com/gsliepen/tinc,286,2021-07-18T13:33:24Z,2022-03-27T14:27:35Z,2022-03-27T14:27:36Z,MERGED,True,1080,95,35,https://github.com/hg,RFC: unit testing for C,4,"['1.1', 'CI']",https://github.com/gsliepen/tinc/pull/286,https://github.com/hg,7,https://github.com/gsliepen/tinc/pull/286#issuecomment-883945407,"Note: this is purely an RFC at this point.
cc @splitice

There was some interest in adding C unit testing to the project.
There doesn't seem to be an agreement about any de facto standard, so this PR adds two well maintaned, popular, and tested libraries for your evaluation. Pick something (or suggest something else) and I'll remove the rest.
Some popular libraries were not considered because of their reliance on a different build system or a working C++ compiler (and the the rest is really similar to cmocka).
The choice here is between:

a very lightweight library with can be fully bundled with the project;
or a bit more features which bring a separate dependency (with different versions on every platform, or the requirement of a separate source build).

Unity
Link.
See sample tests in unittest/unity.
How to use (remove other test section from unittest/Makefile.am or install the appropriate library beforehand):
$ make check

Pros

the simplest solution, basically just a bunch of convenience macros that you would have to write anyway.
can be easily vendored (which I did), and does not require installing anything on dev machines or CI systems.

Cons

all tests from the same source file run as a single process — a misbehaving test can corrupt the whole group.
no support for test mocks, this requires another library which pulls Ruby and a bunch of other things.
single output format (not really important at the moment, but would be nice to have if we were to add some sort of autogenerated summary in the future).

Similar libraries

https://github.com/silentbicycle/greatest
https://github.com/siu/minunit
https://github.com/nemequ/munit

cmocka
Link.
See sample tests in unittest/cmocka.
More realistic tests from other projects: SSSD, samba, OpenVPN, coreboot.
How to use:
# apt install libcmocka-dev
$ make check

Pros

supports mocking out of the box (see more here and here).
does its own memory corruption checks which could be helpful on platforms where ASAN is not available.
many output formats, should we require that at some point.

Cons

requires installing a pre-built library on every dev machine and every CI build, or building from source.
same limitation about the single process.

The first one is a real pain. The tests that ran just fine on my machine failed on Ubuntu 18.04 because its version of cmocka does not provide the newer functions that were used.
Similar libraries

https://libcheck.github.io/check/
https://github.com/Snaipe/Criterion
https://gitlab.com/cunity/cunit/


PS: don't pay attention to the Makefile changes. Let me know which type of a testing library you'd rather see and I'll redo them from scratch (probably using libtool).","@lancethepants thanks for the input! I do not speak for the project, but if this complicates cross-compilation so much, I definitely would not want to break it. I'll put the idea on the back-burner for the time being, maybe the situation will improve some day.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,286,2021-07-18T13:33:24Z,2022-03-27T14:27:35Z,2022-03-27T14:27:36Z,MERGED,True,1080,95,35,https://github.com/hg,RFC: unit testing for C,4,"['1.1', 'CI']",https://github.com/gsliepen/tinc/pull/286,https://github.com/hg,8,https://github.com/gsliepen/tinc/pull/286#issuecomment-885050486,"Note: this is purely an RFC at this point.
cc @splitice

There was some interest in adding C unit testing to the project.
There doesn't seem to be an agreement about any de facto standard, so this PR adds two well maintaned, popular, and tested libraries for your evaluation. Pick something (or suggest something else) and I'll remove the rest.
Some popular libraries were not considered because of their reliance on a different build system or a working C++ compiler (and the the rest is really similar to cmocka).
The choice here is between:

a very lightweight library with can be fully bundled with the project;
or a bit more features which bring a separate dependency (with different versions on every platform, or the requirement of a separate source build).

Unity
Link.
See sample tests in unittest/unity.
How to use (remove other test section from unittest/Makefile.am or install the appropriate library beforehand):
$ make check

Pros

the simplest solution, basically just a bunch of convenience macros that you would have to write anyway.
can be easily vendored (which I did), and does not require installing anything on dev machines or CI systems.

Cons

all tests from the same source file run as a single process — a misbehaving test can corrupt the whole group.
no support for test mocks, this requires another library which pulls Ruby and a bunch of other things.
single output format (not really important at the moment, but would be nice to have if we were to add some sort of autogenerated summary in the future).

Similar libraries

https://github.com/silentbicycle/greatest
https://github.com/siu/minunit
https://github.com/nemequ/munit

cmocka
Link.
See sample tests in unittest/cmocka.
More realistic tests from other projects: SSSD, samba, OpenVPN, coreboot.
How to use:
# apt install libcmocka-dev
$ make check

Pros

supports mocking out of the box (see more here and here).
does its own memory corruption checks which could be helpful on platforms where ASAN is not available.
many output formats, should we require that at some point.

Cons

requires installing a pre-built library on every dev machine and every CI build, or building from source.
same limitation about the single process.

The first one is a real pain. The tests that ran just fine on my machine failed on Ubuntu 18.04 because its version of cmocka does not provide the newer functions that were used.
Similar libraries

https://libcheck.github.io/check/
https://github.com/Snaipe/Criterion
https://gitlab.com/cunity/cunit/


PS: don't pay attention to the Makefile changes. Let me know which type of a testing library you'd rather see and I'll redo them from scratch (probably using libtool).","After trying several approaches, I think shoving everything into one giant makefile is the best autotools can offer.
If you're curious, my libtool experiments can be found here. Convenience libraries (which is what seems to be the preferred solution for code reuse) proved to be more trouble than they're worth — you get the separation between project sources and test sources, plus a proper top-level unit test directory, but pay with:

five additional m4 macro files
~50% more compilation time (because it needs to build most sources twice — once for the two libtool libraries, and once for sptps_* binaries; the blame doesn't seem to lie entirely on my incompetence)
weird runtime errors, particularly on Windows (this can be worked around as described here (look for compiled a program under Windows and it crashes), but who knows what else is broken and won't be found until it hits end-user machines)

What's nice is that it remembers linker flags and does not require you to write three lines of Makefile boilerplate for every new test you add.
Some projects (e.g. profanity) bundle all unit tests into a single binary, but this is pretty difficult to read IMO.
Would you rather have everything thrown into a single test binary (so we get faster compilation times and smaller makefiles), or do we keep them separated?

Run:
$ make -j check

Autoconf will perform a couple of checks:

if libcmocka is not installed, unit testing will be skipped altogether
if your linker does not support function wrapping (--wrap), tests that require mock objects to run will be skipped with a warning

Tests:

https://github.com/hg/tinc/actions/runs/1056085728
https://github.com/hg/tinc/actions/runs/1056833176



Is it worth exploring some abstraction to split fixtures into seperate processes?

I wouldn't know of any decent abstractions right now. If you have any ideas, please do share, I'm willing to do the work.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,286,2021-07-18T13:33:24Z,2022-03-27T14:27:35Z,2022-03-27T14:27:36Z,MERGED,True,1080,95,35,https://github.com/hg,RFC: unit testing for C,4,"['1.1', 'CI']",https://github.com/gsliepen/tinc/pull/286,https://github.com/eli-schwartz,9,https://github.com/gsliepen/tinc/pull/286#issuecomment-1003244092,"Note: this is purely an RFC at this point.
cc @splitice

There was some interest in adding C unit testing to the project.
There doesn't seem to be an agreement about any de facto standard, so this PR adds two well maintaned, popular, and tested libraries for your evaluation. Pick something (or suggest something else) and I'll remove the rest.
Some popular libraries were not considered because of their reliance on a different build system or a working C++ compiler (and the the rest is really similar to cmocka).
The choice here is between:

a very lightweight library with can be fully bundled with the project;
or a bit more features which bring a separate dependency (with different versions on every platform, or the requirement of a separate source build).

Unity
Link.
See sample tests in unittest/unity.
How to use (remove other test section from unittest/Makefile.am or install the appropriate library beforehand):
$ make check

Pros

the simplest solution, basically just a bunch of convenience macros that you would have to write anyway.
can be easily vendored (which I did), and does not require installing anything on dev machines or CI systems.

Cons

all tests from the same source file run as a single process — a misbehaving test can corrupt the whole group.
no support for test mocks, this requires another library which pulls Ruby and a bunch of other things.
single output format (not really important at the moment, but would be nice to have if we were to add some sort of autogenerated summary in the future).

Similar libraries

https://github.com/silentbicycle/greatest
https://github.com/siu/minunit
https://github.com/nemequ/munit

cmocka
Link.
See sample tests in unittest/cmocka.
More realistic tests from other projects: SSSD, samba, OpenVPN, coreboot.
How to use:
# apt install libcmocka-dev
$ make check

Pros

supports mocking out of the box (see more here and here).
does its own memory corruption checks which could be helpful on platforms where ASAN is not available.
many output formats, should we require that at some point.

Cons

requires installing a pre-built library on every dev machine and every CI build, or building from source.
same limitation about the single process.

The first one is a real pain. The tests that ran just fine on my machine failed on Ubuntu 18.04 because its version of cmocka does not provide the newer functions that were used.
Similar libraries

https://libcheck.github.io/check/
https://github.com/Snaipe/Criterion
https://gitlab.com/cunity/cunit/


PS: don't pay attention to the Makefile changes. Let me know which type of a testing library you'd rather see and I'll redo them from scratch (probably using libtool).","Moving to Meson would be very nice as well; I've been using that in other projects, but I didn't do this for tinc because it's not so trivial; there's conditional building of source files, and the test suite might need some work as well to work with meson. Last but not least, autotools provides excellent support for cross-compiling out of the box, and I've been using that to build the Windows binaries on Linux. With Meson you need to write ""cross files"" yourself, and I wonder how portable they are.

Conditional building of source files should be as easy to do in meson as it is in autotools.
For cross compiling, you may be able to get away with this:
CC=/path/to/my/$TRIPLET-gcc meson setup builddir/ --cross-file /dev/null

meson will trigger cross building due to passing the cross-file option, but no settings will be added because the file is an empty file. Meanwhile, CC is respected as usual and sets the cross compiler you want.
Most of the actual settings you can set, probably don't need to be set.
...
In terms of cross file portability, what is supposed to be portable -- or not portable -- about them? The purpose of a cross file is to override settings such as a compiler, a PKG_CONFIG_LIBDIR, and various other things. Anything interesting to set, is probably heavily dependent on your local system. This is not portable on autotools either, but autotools uses custom user-specific environment variables to perform that configuration, so it looks less intimidating?
Meson cross files can have a [constants] section and refer to it in other values, so you can have each user specify e.g. the root directory of a cross toolchain, and then share a portable cross file that does cpp = basedir / 'aarch64-linux-gnu-g++'.
Cross files can be layered. Specify two of them, and one can be a user-supplied set of constants while the other is a portable toolchain file.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,286,2021-07-18T13:33:24Z,2022-03-27T14:27:35Z,2022-03-27T14:27:36Z,MERGED,True,1080,95,35,https://github.com/hg,RFC: unit testing for C,4,"['1.1', 'CI']",https://github.com/gsliepen/tinc/pull/286,https://github.com/hg,10,https://github.com/gsliepen/tinc/pull/286#issuecomment-1065396430,"Note: this is purely an RFC at this point.
cc @splitice

There was some interest in adding C unit testing to the project.
There doesn't seem to be an agreement about any de facto standard, so this PR adds two well maintaned, popular, and tested libraries for your evaluation. Pick something (or suggest something else) and I'll remove the rest.
Some popular libraries were not considered because of their reliance on a different build system or a working C++ compiler (and the the rest is really similar to cmocka).
The choice here is between:

a very lightweight library with can be fully bundled with the project;
or a bit more features which bring a separate dependency (with different versions on every platform, or the requirement of a separate source build).

Unity
Link.
See sample tests in unittest/unity.
How to use (remove other test section from unittest/Makefile.am or install the appropriate library beforehand):
$ make check

Pros

the simplest solution, basically just a bunch of convenience macros that you would have to write anyway.
can be easily vendored (which I did), and does not require installing anything on dev machines or CI systems.

Cons

all tests from the same source file run as a single process — a misbehaving test can corrupt the whole group.
no support for test mocks, this requires another library which pulls Ruby and a bunch of other things.
single output format (not really important at the moment, but would be nice to have if we were to add some sort of autogenerated summary in the future).

Similar libraries

https://github.com/silentbicycle/greatest
https://github.com/siu/minunit
https://github.com/nemequ/munit

cmocka
Link.
See sample tests in unittest/cmocka.
More realistic tests from other projects: SSSD, samba, OpenVPN, coreboot.
How to use:
# apt install libcmocka-dev
$ make check

Pros

supports mocking out of the box (see more here and here).
does its own memory corruption checks which could be helpful on platforms where ASAN is not available.
many output formats, should we require that at some point.

Cons

requires installing a pre-built library on every dev machine and every CI build, or building from source.
same limitation about the single process.

The first one is a real pain. The tests that ran just fine on my machine failed on Ubuntu 18.04 because its version of cmocka does not provide the newer functions that were used.
Similar libraries

https://libcheck.github.io/check/
https://github.com/Snaipe/Criterion
https://gitlab.com/cunity/cunit/


PS: don't pay attention to the Makefile changes. Let me know which type of a testing library you'd rather see and I'll redo them from scratch (probably using libtool).","@gsliepen
Apologies, I've been a bit busy lately. Please have another look.
tests (two jobs ran into timeout because of slow disk i/o)

It makes senses to not bother to support cmocka older than 1.1.5. I was sitting on this PR for so long it's now available pretty much everywhere.
Not sure about the comment on global.h, though. Should all extern variable declarations be moved into separate headers (one for tinc and one for tincd)?
Also not sure about PKG_CHECK_MODULES. It adds a new dependency on pkg-config which is not really needed for anything else.
Which solution you'd prefer — require pkg-config to run unit tests, or leave the current version in place?
Here are rough drafts for both:
pkg-config
dnl Check the existence of cmocka unit testing library

AC_DEFUN([tinc_CMOCKA], [

  PKG_CHECK_MODULES([CMOCKA], [cmocka >= 1.1.5], [
    cmocka_found=yes

    AX_CHECK_LINK_FLAG([-Wl,--wrap=func], [
      linker_has_wrap=yes
      AC_DEFINE(HAVE_MOCK_SUPPORT, 1, [linker has support for the --wrap flag.])
    ], [
      AC_MSG_WARN(""linker does not support function wrapping; tests that require mocks will not run."")
    ], [-Werror])

  ], [
    AC_MSG_WARN(""cmocka was not found; unit tests will not run."")
  ])

  AM_CONDITIONAL(HAVE_CMOCKA, test ""x$cmocka_found"" = 'xyes')

  # can use --wrap for test mocks
  AM_CONDITIONAL(HAVE_MOCK_SUPPORT, test ""x$linker_has_wrap"" = 'xyes')

])
manual checks
dnl Check the existence of cmocka unit testing library

AC_DEFUN([tinc_CMOCKA], [

  m4_define([cmocka_headers], [
    #include <stdarg.h>
    #include <stddef.h>
    #include <setjmp.h>
    #include <cmocka.h>
  ])

  dnl Neither AC_CHECK_LIB nor AC_CHECK_FUNC allow adding custom headers.
  AC_CHECK_DECL(assert_int_equal, [
    cmocka_found=yes

    AX_CHECK_LINK_FLAG([-Wl,--wrap=func], [
      linker_has_wrap=yes
      AC_DEFINE(HAVE_MOCK_SUPPORT, 1, [linker has support for the --wrap flag.])
    ], [
      AC_MSG_WARN(""linker does not support function wrapping; tests that require mocks will not run."")
    ], [-Werror])

  ], [], cmocka_headers)

  AS_IF([test ""x$cmocka_found"" != ""xyes""], [
    AC_MSG_WARN(""cmocka was not found; unit tests will not run."")
  ])

  AM_CONDITIONAL(HAVE_CMOCKA, test ""x$cmocka_found"" = 'xyes')

  # can use --wrap for test mocks
  AM_CONDITIONAL(HAVE_MOCK_SUPPORT, test ""x$linker_has_wrap"" = 'xyes')

])",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,286,2021-07-18T13:33:24Z,2022-03-27T14:27:35Z,2022-03-27T14:27:36Z,MERGED,True,1080,95,35,https://github.com/hg,RFC: unit testing for C,4,"['1.1', 'CI']",https://github.com/gsliepen/tinc/pull/286,https://github.com/eli-schwartz,11,https://github.com/gsliepen/tinc/pull/286#issuecomment-1065425940,"Note: this is purely an RFC at this point.
cc @splitice

There was some interest in adding C unit testing to the project.
There doesn't seem to be an agreement about any de facto standard, so this PR adds two well maintaned, popular, and tested libraries for your evaluation. Pick something (or suggest something else) and I'll remove the rest.
Some popular libraries were not considered because of their reliance on a different build system or a working C++ compiler (and the the rest is really similar to cmocka).
The choice here is between:

a very lightweight library with can be fully bundled with the project;
or a bit more features which bring a separate dependency (with different versions on every platform, or the requirement of a separate source build).

Unity
Link.
See sample tests in unittest/unity.
How to use (remove other test section from unittest/Makefile.am or install the appropriate library beforehand):
$ make check

Pros

the simplest solution, basically just a bunch of convenience macros that you would have to write anyway.
can be easily vendored (which I did), and does not require installing anything on dev machines or CI systems.

Cons

all tests from the same source file run as a single process — a misbehaving test can corrupt the whole group.
no support for test mocks, this requires another library which pulls Ruby and a bunch of other things.
single output format (not really important at the moment, but would be nice to have if we were to add some sort of autogenerated summary in the future).

Similar libraries

https://github.com/silentbicycle/greatest
https://github.com/siu/minunit
https://github.com/nemequ/munit

cmocka
Link.
See sample tests in unittest/cmocka.
More realistic tests from other projects: SSSD, samba, OpenVPN, coreboot.
How to use:
# apt install libcmocka-dev
$ make check

Pros

supports mocking out of the box (see more here and here).
does its own memory corruption checks which could be helpful on platforms where ASAN is not available.
many output formats, should we require that at some point.

Cons

requires installing a pre-built library on every dev machine and every CI build, or building from source.
same limitation about the single process.

The first one is a real pain. The tests that ran just fine on my machine failed on Ubuntu 18.04 because its version of cmocka does not provide the newer functions that were used.
Similar libraries

https://libcheck.github.io/check/
https://github.com/Snaipe/Criterion
https://gitlab.com/cunity/cunit/


PS: don't pay attention to the Makefile changes. Let me know which type of a testing library you'd rather see and I'll redo them from scratch (probably using libtool).","Also not sure about PKG_CHECK_MODULES. It adds a new dependency on pkg-config which is not really needed for anything else.

The PKG_CHECK_MODULES autotools macro allows users to specify CMOCKA_LIBS and CMOCKA_CFLAGS. If you don't specify an action-if-not-found, it will print this error message:
checking for CMOCKA... no
configure: error: Package requirements (cmocka >= 1.1.5) were not met:

Package 'cmocka', required by 'virtual:world', not found

Consider adjusting the PKG_CONFIG_PATH environment variable if you
installed software in a non-standard prefix.

Alternatively, you may set the environment variables CMOCKA_CFLAGS
and CMOCKA_LIBS to avoid the need to call pkg-config.
See the pkg-config man page for more details.

You can include part of that messaging, like this:
checking for CMOCKA... no
configure: WARNING: cmocka was not found; unit tests will not run.

Alternatively, you may set the environment variables CMOCKA_CFLAGS
and CMOCKA_LIBS to avoid the need to call pkg-config.
See the pkg-config man page for more details.

Just change this:
  ], [
    AC_MSG_WARN(""cmocka was not found; unit tests will not run."")
  ])
to this:
  ], [
    AC_MSG_WARN([cmocka was not found; unit tests will not run.

_PKG_TEXT])
  ])",True,{'THUMBS_UP': ['https://github.com/hg']}
gsliepen/tinc,https://github.com/gsliepen/tinc,286,2021-07-18T13:33:24Z,2022-03-27T14:27:35Z,2022-03-27T14:27:36Z,MERGED,True,1080,95,35,https://github.com/hg,RFC: unit testing for C,4,"['1.1', 'CI']",https://github.com/gsliepen/tinc/pull/286,https://github.com/gsliepen,12,https://github.com/gsliepen/tinc/pull/286#issuecomment-1066110476,"Note: this is purely an RFC at this point.
cc @splitice

There was some interest in adding C unit testing to the project.
There doesn't seem to be an agreement about any de facto standard, so this PR adds two well maintaned, popular, and tested libraries for your evaluation. Pick something (or suggest something else) and I'll remove the rest.
Some popular libraries were not considered because of their reliance on a different build system or a working C++ compiler (and the the rest is really similar to cmocka).
The choice here is between:

a very lightweight library with can be fully bundled with the project;
or a bit more features which bring a separate dependency (with different versions on every platform, or the requirement of a separate source build).

Unity
Link.
See sample tests in unittest/unity.
How to use (remove other test section from unittest/Makefile.am or install the appropriate library beforehand):
$ make check

Pros

the simplest solution, basically just a bunch of convenience macros that you would have to write anyway.
can be easily vendored (which I did), and does not require installing anything on dev machines or CI systems.

Cons

all tests from the same source file run as a single process — a misbehaving test can corrupt the whole group.
no support for test mocks, this requires another library which pulls Ruby and a bunch of other things.
single output format (not really important at the moment, but would be nice to have if we were to add some sort of autogenerated summary in the future).

Similar libraries

https://github.com/silentbicycle/greatest
https://github.com/siu/minunit
https://github.com/nemequ/munit

cmocka
Link.
See sample tests in unittest/cmocka.
More realistic tests from other projects: SSSD, samba, OpenVPN, coreboot.
How to use:
# apt install libcmocka-dev
$ make check

Pros

supports mocking out of the box (see more here and here).
does its own memory corruption checks which could be helpful on platforms where ASAN is not available.
many output formats, should we require that at some point.

Cons

requires installing a pre-built library on every dev machine and every CI build, or building from source.
same limitation about the single process.

The first one is a real pain. The tests that ran just fine on my machine failed on Ubuntu 18.04 because its version of cmocka does not provide the newer functions that were used.
Similar libraries

https://libcheck.github.io/check/
https://github.com/Snaipe/Criterion
https://gitlab.com/cunity/cunit/


PS: don't pay attention to the Makefile changes. Let me know which type of a testing library you'd rather see and I'll redo them from scratch (probably using libtool).","It's great to have working unit tests, so I am tempted to merge this if you think it is ready. However, while I did say in the past to go for building the unit tests inside src/, as that was the simplest automake solution, it makes the src/ directory quite messy, for two reasons:

The need for changing the main() function, and adding stub tinc/tincd_main.c files. Ideally, no changes to the actual source should be needed for unit tests. But partly this is due to the way global variables are used in tinc, perhaps that requires some cleanup.
Test binaries end up inside src/. Switching to meson was discussed, and while @lancethepants and I thought it would be best to stick with autotools for its excellent cross-compilation support, @eli-schwartz mentioned it should be possible to make cross-compilation easy with meson too. It would also be a step towards compiling tinc natively on Windows without using MinGW, although that would bring its own challenges.

I don't know if you think it's worth adressing either of these points in this pull request or if that should be done at a later point?",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,286,2021-07-18T13:33:24Z,2022-03-27T14:27:35Z,2022-03-27T14:27:36Z,MERGED,True,1080,95,35,https://github.com/hg,RFC: unit testing for C,4,"['1.1', 'CI']",https://github.com/gsliepen/tinc/pull/286,https://github.com/eli-schwartz,13,https://github.com/gsliepen/tinc/pull/286#issuecomment-1066112671,"Note: this is purely an RFC at this point.
cc @splitice

There was some interest in adding C unit testing to the project.
There doesn't seem to be an agreement about any de facto standard, so this PR adds two well maintaned, popular, and tested libraries for your evaluation. Pick something (or suggest something else) and I'll remove the rest.
Some popular libraries were not considered because of their reliance on a different build system or a working C++ compiler (and the the rest is really similar to cmocka).
The choice here is between:

a very lightweight library with can be fully bundled with the project;
or a bit more features which bring a separate dependency (with different versions on every platform, or the requirement of a separate source build).

Unity
Link.
See sample tests in unittest/unity.
How to use (remove other test section from unittest/Makefile.am or install the appropriate library beforehand):
$ make check

Pros

the simplest solution, basically just a bunch of convenience macros that you would have to write anyway.
can be easily vendored (which I did), and does not require installing anything on dev machines or CI systems.

Cons

all tests from the same source file run as a single process — a misbehaving test can corrupt the whole group.
no support for test mocks, this requires another library which pulls Ruby and a bunch of other things.
single output format (not really important at the moment, but would be nice to have if we were to add some sort of autogenerated summary in the future).

Similar libraries

https://github.com/silentbicycle/greatest
https://github.com/siu/minunit
https://github.com/nemequ/munit

cmocka
Link.
See sample tests in unittest/cmocka.
More realistic tests from other projects: SSSD, samba, OpenVPN, coreboot.
How to use:
# apt install libcmocka-dev
$ make check

Pros

supports mocking out of the box (see more here and here).
does its own memory corruption checks which could be helpful on platforms where ASAN is not available.
many output formats, should we require that at some point.

Cons

requires installing a pre-built library on every dev machine and every CI build, or building from source.
same limitation about the single process.

The first one is a real pain. The tests that ran just fine on my machine failed on Ubuntu 18.04 because its version of cmocka does not provide the newer functions that were used.
Similar libraries

https://libcheck.github.io/check/
https://github.com/Snaipe/Criterion
https://gitlab.com/cunity/cunit/


PS: don't pay attention to the Makefile changes. Let me know which type of a testing library you'd rather see and I'll redo them from scratch (probably using libtool).","For what it's worth, I've heard from certain groups that they find Meson's cross compilation support much better in their workflow than autotools. e.g. Void Linux which actually does cross compile the entire distro.
(Of course it is better than cmake, cmake is legendarily bad at cross compiling...)",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,286,2021-07-18T13:33:24Z,2022-03-27T14:27:35Z,2022-03-27T14:27:36Z,MERGED,True,1080,95,35,https://github.com/hg,RFC: unit testing for C,4,"['1.1', 'CI']",https://github.com/gsliepen/tinc/pull/286,https://github.com/hg,14,https://github.com/gsliepen/tinc/pull/286#issuecomment-1066134337,"Note: this is purely an RFC at this point.
cc @splitice

There was some interest in adding C unit testing to the project.
There doesn't seem to be an agreement about any de facto standard, so this PR adds two well maintaned, popular, and tested libraries for your evaluation. Pick something (or suggest something else) and I'll remove the rest.
Some popular libraries were not considered because of their reliance on a different build system or a working C++ compiler (and the the rest is really similar to cmocka).
The choice here is between:

a very lightweight library with can be fully bundled with the project;
or a bit more features which bring a separate dependency (with different versions on every platform, or the requirement of a separate source build).

Unity
Link.
See sample tests in unittest/unity.
How to use (remove other test section from unittest/Makefile.am or install the appropriate library beforehand):
$ make check

Pros

the simplest solution, basically just a bunch of convenience macros that you would have to write anyway.
can be easily vendored (which I did), and does not require installing anything on dev machines or CI systems.

Cons

all tests from the same source file run as a single process — a misbehaving test can corrupt the whole group.
no support for test mocks, this requires another library which pulls Ruby and a bunch of other things.
single output format (not really important at the moment, but would be nice to have if we were to add some sort of autogenerated summary in the future).

Similar libraries

https://github.com/silentbicycle/greatest
https://github.com/siu/minunit
https://github.com/nemequ/munit

cmocka
Link.
See sample tests in unittest/cmocka.
More realistic tests from other projects: SSSD, samba, OpenVPN, coreboot.
How to use:
# apt install libcmocka-dev
$ make check

Pros

supports mocking out of the box (see more here and here).
does its own memory corruption checks which could be helpful on platforms where ASAN is not available.
many output formats, should we require that at some point.

Cons

requires installing a pre-built library on every dev machine and every CI build, or building from source.
same limitation about the single process.

The first one is a real pain. The tests that ran just fine on my machine failed on Ubuntu 18.04 because its version of cmocka does not provide the newer functions that were used.
Similar libraries

https://libcheck.github.io/check/
https://github.com/Snaipe/Criterion
https://gitlab.com/cunity/cunit/


PS: don't pay attention to the Makefile changes. Let me know which type of a testing library you'd rather see and I'll redo them from scratch (probably using libtool).","@gsliepen not sure TBH. I tried rearranging globals properly yesterday, and it turned into such a mess (touching almost every file in the project) that I thought it best to create a couple of stubs and call it a day.
Some global variables alias (they have the same name even if it's two separate globals underneath — one for tinc and one for tincd), so you get either the ugliness below, or a bunch of warnings about unnecessary redeclaration. A few examples: now, scriptextension, scriptinterpreter.
I think in longer term it would make sense to combine them into larger structs and then (maybe) get rid of globals altogether by passing them as some sort of context.

Here's another try. Some globals were only really used by a single translation unit; I moved them there. Others are more popular and were moved to globals.c.
Let me know what you think. It's in a separate commit, so it can be thrown away more easily.

Regarding meson: there was a bit of a meson experiment last year, I'll try cross-compiling it and see how it goes.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,286,2021-07-18T13:33:24Z,2022-03-27T14:27:35Z,2022-03-27T14:27:36Z,MERGED,True,1080,95,35,https://github.com/hg,RFC: unit testing for C,4,"['1.1', 'CI']",https://github.com/gsliepen/tinc/pull/286,https://github.com/gsliepen,15,https://github.com/gsliepen/tinc/pull/286#issuecomment-1066178691,"Note: this is purely an RFC at this point.
cc @splitice

There was some interest in adding C unit testing to the project.
There doesn't seem to be an agreement about any de facto standard, so this PR adds two well maintaned, popular, and tested libraries for your evaluation. Pick something (or suggest something else) and I'll remove the rest.
Some popular libraries were not considered because of their reliance on a different build system or a working C++ compiler (and the the rest is really similar to cmocka).
The choice here is between:

a very lightweight library with can be fully bundled with the project;
or a bit more features which bring a separate dependency (with different versions on every platform, or the requirement of a separate source build).

Unity
Link.
See sample tests in unittest/unity.
How to use (remove other test section from unittest/Makefile.am or install the appropriate library beforehand):
$ make check

Pros

the simplest solution, basically just a bunch of convenience macros that you would have to write anyway.
can be easily vendored (which I did), and does not require installing anything on dev machines or CI systems.

Cons

all tests from the same source file run as a single process — a misbehaving test can corrupt the whole group.
no support for test mocks, this requires another library which pulls Ruby and a bunch of other things.
single output format (not really important at the moment, but would be nice to have if we were to add some sort of autogenerated summary in the future).

Similar libraries

https://github.com/silentbicycle/greatest
https://github.com/siu/minunit
https://github.com/nemequ/munit

cmocka
Link.
See sample tests in unittest/cmocka.
More realistic tests from other projects: SSSD, samba, OpenVPN, coreboot.
How to use:
# apt install libcmocka-dev
$ make check

Pros

supports mocking out of the box (see more here and here).
does its own memory corruption checks which could be helpful on platforms where ASAN is not available.
many output formats, should we require that at some point.

Cons

requires installing a pre-built library on every dev machine and every CI build, or building from source.
same limitation about the single process.

The first one is a real pain. The tests that ran just fine on my machine failed on Ubuntu 18.04 because its version of cmocka does not provide the newer functions that were used.
Similar libraries

https://libcheck.github.io/check/
https://github.com/Snaipe/Criterion
https://gitlab.com/cunity/cunit/


PS: don't pay attention to the Makefile changes. Let me know which type of a testing library you'd rather see and I'll redo them from scratch (probably using libtool).","Hm, I think I'll have a try at rearranging where the global variables are. Some are just in the wrong place; like scriptextension, which should definitely just live in script.c and not in net_setup.c. The end goal is not to have any occurence of extern anymore in .c files, and ideally also no need for an actual global.c, but still allow unit tests, tinc and tincd to compile without hacks.
About the meson experiment, it looks good, there are some issues though, like the check for res_init() failing, paths in manpages have quote marks added incorrectly. It looks like cross-compiling does need a cross build definition file after all, since it doesn't seem to be able to deduce ""windows"" has the host machine's system if you tell it to use the MinGW compiler. With a definition file it manages to build the main binaries, but the test suite fails to work correctly. Interestingly, ./configure is only marginally slower than meson build, and make -j${nproc} is just as fast as ninja from a cold start. ninja wins for rebuilds because it uses ccache automatically, which is quite nice.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,286,2021-07-18T13:33:24Z,2022-03-27T14:27:35Z,2022-03-27T14:27:36Z,MERGED,True,1080,95,35,https://github.com/hg,RFC: unit testing for C,4,"['1.1', 'CI']",https://github.com/gsliepen/tinc/pull/286,https://github.com/eli-schwartz,16,https://github.com/gsliepen/tinc/pull/286#issuecomment-1066190936,"Note: this is purely an RFC at this point.
cc @splitice

There was some interest in adding C unit testing to the project.
There doesn't seem to be an agreement about any de facto standard, so this PR adds two well maintaned, popular, and tested libraries for your evaluation. Pick something (or suggest something else) and I'll remove the rest.
Some popular libraries were not considered because of their reliance on a different build system or a working C++ compiler (and the the rest is really similar to cmocka).
The choice here is between:

a very lightweight library with can be fully bundled with the project;
or a bit more features which bring a separate dependency (with different versions on every platform, or the requirement of a separate source build).

Unity
Link.
See sample tests in unittest/unity.
How to use (remove other test section from unittest/Makefile.am or install the appropriate library beforehand):
$ make check

Pros

the simplest solution, basically just a bunch of convenience macros that you would have to write anyway.
can be easily vendored (which I did), and does not require installing anything on dev machines or CI systems.

Cons

all tests from the same source file run as a single process — a misbehaving test can corrupt the whole group.
no support for test mocks, this requires another library which pulls Ruby and a bunch of other things.
single output format (not really important at the moment, but would be nice to have if we were to add some sort of autogenerated summary in the future).

Similar libraries

https://github.com/silentbicycle/greatest
https://github.com/siu/minunit
https://github.com/nemequ/munit

cmocka
Link.
See sample tests in unittest/cmocka.
More realistic tests from other projects: SSSD, samba, OpenVPN, coreboot.
How to use:
# apt install libcmocka-dev
$ make check

Pros

supports mocking out of the box (see more here and here).
does its own memory corruption checks which could be helpful on platforms where ASAN is not available.
many output formats, should we require that at some point.

Cons

requires installing a pre-built library on every dev machine and every CI build, or building from source.
same limitation about the single process.

The first one is a real pain. The tests that ran just fine on my machine failed on Ubuntu 18.04 because its version of cmocka does not provide the newer functions that were used.
Similar libraries

https://libcheck.github.io/check/
https://github.com/Snaipe/Criterion
https://gitlab.com/cunity/cunit/


PS: don't pay attention to the Makefile changes. Let me know which type of a testing library you'd rather see and I'll redo them from scratch (probably using libtool).","The Meson source code repository includes the example file cross/linux-mingw-w64-32bit.txt which could be used to cross compile using the mingw-w64 compiler from Linux, it includes an exe_wrapper entry for wine so the testsuite should work too. Of course, this assumes you have a standard cross toolchain utilizing /usr/bin
You just need to run the built binary using $MESON_EXE_WRAPPER. See https://mesonbuild.com/Reference-manual_functions.html#test for details.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,286,2021-07-18T13:33:24Z,2022-03-27T14:27:35Z,2022-03-27T14:27:36Z,MERGED,True,1080,95,35,https://github.com/hg,RFC: unit testing for C,4,"['1.1', 'CI']",https://github.com/gsliepen/tinc/pull/286,https://github.com/hg,17,https://github.com/gsliepen/tinc/pull/286#issuecomment-1066497014,"Note: this is purely an RFC at this point.
cc @splitice

There was some interest in adding C unit testing to the project.
There doesn't seem to be an agreement about any de facto standard, so this PR adds two well maintaned, popular, and tested libraries for your evaluation. Pick something (or suggest something else) and I'll remove the rest.
Some popular libraries were not considered because of their reliance on a different build system or a working C++ compiler (and the the rest is really similar to cmocka).
The choice here is between:

a very lightweight library with can be fully bundled with the project;
or a bit more features which bring a separate dependency (with different versions on every platform, or the requirement of a separate source build).

Unity
Link.
See sample tests in unittest/unity.
How to use (remove other test section from unittest/Makefile.am or install the appropriate library beforehand):
$ make check

Pros

the simplest solution, basically just a bunch of convenience macros that you would have to write anyway.
can be easily vendored (which I did), and does not require installing anything on dev machines or CI systems.

Cons

all tests from the same source file run as a single process — a misbehaving test can corrupt the whole group.
no support for test mocks, this requires another library which pulls Ruby and a bunch of other things.
single output format (not really important at the moment, but would be nice to have if we were to add some sort of autogenerated summary in the future).

Similar libraries

https://github.com/silentbicycle/greatest
https://github.com/siu/minunit
https://github.com/nemequ/munit

cmocka
Link.
See sample tests in unittest/cmocka.
More realistic tests from other projects: SSSD, samba, OpenVPN, coreboot.
How to use:
# apt install libcmocka-dev
$ make check

Pros

supports mocking out of the box (see more here and here).
does its own memory corruption checks which could be helpful on platforms where ASAN is not available.
many output formats, should we require that at some point.

Cons

requires installing a pre-built library on every dev machine and every CI build, or building from source.
same limitation about the single process.

The first one is a real pain. The tests that ran just fine on my machine failed on Ubuntu 18.04 because its version of cmocka does not provide the newer functions that were used.
Similar libraries

https://libcheck.github.io/check/
https://github.com/Snaipe/Criterion
https://gitlab.com/cunity/cunit/


PS: don't pay attention to the Makefile changes. Let me know which type of a testing library you'd rather see and I'll redo them from scratch (probably using libtool).","Yeah, that meson stuff was in a half-working state. I rebased it on top of current 1.1 if anyone wants to have a look at it.
Unit tests are not supported yet (obviously).

Targeting Linux armhf in a fresh amd64 Debian container turned out to be pretty painless, but I couldn't make it use the correct pkg-config and had to specify it separately:
export HOST=armhf

dpkg --add-architecture $HOST

apt-get install -y \
    meson qemu-user git binutils make gcc diffutils sudo texinfo texlive netcat-openbsd procps socat \
    crossbuild-essential-$HOST \
    zlib1g-dev:$HOST \
    libssl-dev:$HOST \
    liblzo2-dev:$HOST \
    liblz4-dev:$HOST \
    libncurses-dev:$HOST \
    libreadline-dev:$HOST \
    libgcrypt-dev:$HOST \
    libminiupnpc-dev:$HOST \
    libvdeplug-dev:$HOST

export CC=/usr/bin/arm-linux-gnueabihf-gcc
export PKG_CONFIG=/usr/bin/arm-linux-gnueabihf-pkg-config

meson setup build --cross-file /dev/null

Windows is more painful (I used Arch here because there are few precompiled libraries in Debian repositories):
yay -S mingw-w64{,-{pkg-config,openssl}}

export CC=/usr/bin/x86_64-w64-mingw32-gcc
export PKG_CONFIG=/usr/bin/x86_64-w64-mingw32-pkg-config

meson setup build --cross-file cross

And I had to write this cross file, or it wouldn't detect the correct operating system:
[host_machine]
system = 'windows'
endian = 'little'
cpu = 'x86_64'
cpu_family = 'x86'
So it's a bit more involved than autotools.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,286,2021-07-18T13:33:24Z,2022-03-27T14:27:35Z,2022-03-27T14:27:36Z,MERGED,True,1080,95,35,https://github.com/hg,RFC: unit testing for C,4,"['1.1', 'CI']",https://github.com/gsliepen/tinc/pull/286,https://github.com/hg,18,https://github.com/gsliepen/tinc/pull/286#issuecomment-1076296959,"Note: this is purely an RFC at this point.
cc @splitice

There was some interest in adding C unit testing to the project.
There doesn't seem to be an agreement about any de facto standard, so this PR adds two well maintaned, popular, and tested libraries for your evaluation. Pick something (or suggest something else) and I'll remove the rest.
Some popular libraries were not considered because of their reliance on a different build system or a working C++ compiler (and the the rest is really similar to cmocka).
The choice here is between:

a very lightweight library with can be fully bundled with the project;
or a bit more features which bring a separate dependency (with different versions on every platform, or the requirement of a separate source build).

Unity
Link.
See sample tests in unittest/unity.
How to use (remove other test section from unittest/Makefile.am or install the appropriate library beforehand):
$ make check

Pros

the simplest solution, basically just a bunch of convenience macros that you would have to write anyway.
can be easily vendored (which I did), and does not require installing anything on dev machines or CI systems.

Cons

all tests from the same source file run as a single process — a misbehaving test can corrupt the whole group.
no support for test mocks, this requires another library which pulls Ruby and a bunch of other things.
single output format (not really important at the moment, but would be nice to have if we were to add some sort of autogenerated summary in the future).

Similar libraries

https://github.com/silentbicycle/greatest
https://github.com/siu/minunit
https://github.com/nemequ/munit

cmocka
Link.
See sample tests in unittest/cmocka.
More realistic tests from other projects: SSSD, samba, OpenVPN, coreboot.
How to use:
# apt install libcmocka-dev
$ make check

Pros

supports mocking out of the box (see more here and here).
does its own memory corruption checks which could be helpful on platforms where ASAN is not available.
many output formats, should we require that at some point.

Cons

requires installing a pre-built library on every dev machine and every CI build, or building from source.
same limitation about the single process.

The first one is a real pain. The tests that ran just fine on my machine failed on Ubuntu 18.04 because its version of cmocka does not provide the newer functions that were used.
Similar libraries

https://libcheck.github.io/check/
https://github.com/Snaipe/Criterion
https://gitlab.com/cunity/cunit/


PS: don't pay attention to the Makefile changes. Let me know which type of a testing library you'd rather see and I'll redo them from scratch (probably using libtool).","I was wondering about linking everything into a single static library, and then adding tincctl.c / tincd.c to it to produce two main binaries.
There are some conflicts, but those should be solvable by shuffling the globals around.
Should make lib_tinc and lib_tincd unnecessary, and all unit tests could be linked with the same library, simplifying their definition.
Bad idea?",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,286,2021-07-18T13:33:24Z,2022-03-27T14:27:35Z,2022-03-27T14:27:36Z,MERGED,True,1080,95,35,https://github.com/hg,RFC: unit testing for C,4,"['1.1', 'CI']",https://github.com/gsliepen/tinc/pull/286,https://github.com/gsliepen,19,https://github.com/gsliepen/tinc/pull/286#issuecomment-1076427134,"Note: this is purely an RFC at this point.
cc @splitice

There was some interest in adding C unit testing to the project.
There doesn't seem to be an agreement about any de facto standard, so this PR adds two well maintaned, popular, and tested libraries for your evaluation. Pick something (or suggest something else) and I'll remove the rest.
Some popular libraries were not considered because of their reliance on a different build system or a working C++ compiler (and the the rest is really similar to cmocka).
The choice here is between:

a very lightweight library with can be fully bundled with the project;
or a bit more features which bring a separate dependency (with different versions on every platform, or the requirement of a separate source build).

Unity
Link.
See sample tests in unittest/unity.
How to use (remove other test section from unittest/Makefile.am or install the appropriate library beforehand):
$ make check

Pros

the simplest solution, basically just a bunch of convenience macros that you would have to write anyway.
can be easily vendored (which I did), and does not require installing anything on dev machines or CI systems.

Cons

all tests from the same source file run as a single process — a misbehaving test can corrupt the whole group.
no support for test mocks, this requires another library which pulls Ruby and a bunch of other things.
single output format (not really important at the moment, but would be nice to have if we were to add some sort of autogenerated summary in the future).

Similar libraries

https://github.com/silentbicycle/greatest
https://github.com/siu/minunit
https://github.com/nemequ/munit

cmocka
Link.
See sample tests in unittest/cmocka.
More realistic tests from other projects: SSSD, samba, OpenVPN, coreboot.
How to use:
# apt install libcmocka-dev
$ make check

Pros

supports mocking out of the box (see more here and here).
does its own memory corruption checks which could be helpful on platforms where ASAN is not available.
many output formats, should we require that at some point.

Cons

requires installing a pre-built library on every dev machine and every CI build, or building from source.
same limitation about the single process.

The first one is a real pain. The tests that ran just fine on my machine failed on Ubuntu 18.04 because its version of cmocka does not provide the newer functions that were used.
Similar libraries

https://libcheck.github.io/check/
https://github.com/Snaipe/Criterion
https://gitlab.com/cunity/cunit/


PS: don't pay attention to the Makefile changes. Let me know which type of a testing library you'd rather see and I'll redo them from scratch (probably using libtool).",I wonder how that would affect the final size of the binaries.,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,286,2021-07-18T13:33:24Z,2022-03-27T14:27:35Z,2022-03-27T14:27:36Z,MERGED,True,1080,95,35,https://github.com/hg,RFC: unit testing for C,4,"['1.1', 'CI']",https://github.com/gsliepen/tinc/pull/286,https://github.com/hg,20,https://github.com/gsliepen/tinc/pull/286#issuecomment-1076432779,"Note: this is purely an RFC at this point.
cc @splitice

There was some interest in adding C unit testing to the project.
There doesn't seem to be an agreement about any de facto standard, so this PR adds two well maintaned, popular, and tested libraries for your evaluation. Pick something (or suggest something else) and I'll remove the rest.
Some popular libraries were not considered because of their reliance on a different build system or a working C++ compiler (and the the rest is really similar to cmocka).
The choice here is between:

a very lightweight library with can be fully bundled with the project;
or a bit more features which bring a separate dependency (with different versions on every platform, or the requirement of a separate source build).

Unity
Link.
See sample tests in unittest/unity.
How to use (remove other test section from unittest/Makefile.am or install the appropriate library beforehand):
$ make check

Pros

the simplest solution, basically just a bunch of convenience macros that you would have to write anyway.
can be easily vendored (which I did), and does not require installing anything on dev machines or CI systems.

Cons

all tests from the same source file run as a single process — a misbehaving test can corrupt the whole group.
no support for test mocks, this requires another library which pulls Ruby and a bunch of other things.
single output format (not really important at the moment, but would be nice to have if we were to add some sort of autogenerated summary in the future).

Similar libraries

https://github.com/silentbicycle/greatest
https://github.com/siu/minunit
https://github.com/nemequ/munit

cmocka
Link.
See sample tests in unittest/cmocka.
More realistic tests from other projects: SSSD, samba, OpenVPN, coreboot.
How to use:
# apt install libcmocka-dev
$ make check

Pros

supports mocking out of the box (see more here and here).
does its own memory corruption checks which could be helpful on platforms where ASAN is not available.
many output formats, should we require that at some point.

Cons

requires installing a pre-built library on every dev machine and every CI build, or building from source.
same limitation about the single process.

The first one is a real pain. The tests that ran just fine on my machine failed on Ubuntu 18.04 because its version of cmocka does not provide the newer functions that were used.
Similar libraries

https://libcheck.github.io/check/
https://github.com/Snaipe/Criterion
https://gitlab.com/cunity/cunit/


PS: don't pay attention to the Makefile changes. Let me know which type of a testing library you'd rather see and I'll redo them from scratch (probably using libtool).","I checked when I was adding first static libraries for faster compilation. Doesn't seem to. meson uses 'thin' static libraries which are just a bunch of object files in a directory, with a symbol table nearby. It links only those object files that are actually needed.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,287,2021-07-20T13:34:45Z,2021-07-20T17:46:45Z,2022-03-13T05:05:07Z,CLOSED,False,3813,67,33,https://github.com/hg,Add support for the lz4 compression algorithm,7,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/287,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/287,"This adds lz4 block compression support, using either the vendored copy of the library, or (preferably) the one already found on the system.
Most of the work was done by Darik Horn (@dajhorn) in this pull request: #78.

Changes:

system lz4 is now tried first
builtin lz4 is used as a fallback if the system one is too old or missing

this can be prevented with --disable-lz4-builtin (in which case the build fails)
use of the builtin copy can be forced with --enable-lz4-builtin, even if the system library works fine


support for versions older than r129 has been removed, and the builtin copy is used in that case

it was released in May 2015
Debian oldstable and Ubuntu 18.04 ship with r131
CentOS 7 (oldest supported release) ships with 1.8.3 — much newer than r131



This behavior is documented.
Tests: this, this, and this (wrong package name on OpenSUSE and missing reformat from #280, everything else was fine).

af21369 is required for compression.test to determine which compression levels should work, and which should fail. I believe it's also quite useful by itself.
If you'd rather see a separate command (tinc features or tinc has_feature?), I can rewrite this. Either way, it can be split into a separate PR, but this commit will have to stay here for now, or compression.test will not pass.
$ ./src/tincd --version
tinc version 1.1pre18-23-g8aaf944f (built Jul 20 2021 13:54:00, protocol 17.7)
Features: openssl comp_lzo comp_zlib comp_lz4 legacy_protocol jumbograms miniupnpc uml vde

Copyright (C) 1998-2021 Ivo Timmermans, Guus Sliepen and others.
See the AUTHORS file for a complete list.

tinc comes with ABSOLUTELY NO WARRANTY.  This is free software,
and you are welcome to redistribute it under certain conditions;
see the file COPYING for details.","This adds lz4 block compression support, using either the vendored copy of the library, or (preferably) the one already found on the system.
Most of the work was done by Darik Horn (@dajhorn) in this pull request: #78.

Changes:

system lz4 is now tried first
builtin lz4 is used as a fallback if the system one is too old or missing

this can be prevented with --disable-lz4-builtin (in which case the build fails)
use of the builtin copy can be forced with --enable-lz4-builtin, even if the system library works fine


support for versions older than r129 has been removed, and the builtin copy is used in that case

it was released in May 2015
Debian oldstable and Ubuntu 18.04 ship with r131
CentOS 7 (oldest supported release) ships with 1.8.3 — much newer than r131



This behavior is documented.
Tests: this, this, and this (wrong package name on OpenSUSE and missing reformat from #280, everything else was fine).

af21369 is required for compression.test to determine which compression levels should work, and which should fail. I believe it's also quite useful by itself.
If you'd rather see a separate command (tinc features or tinc has_feature?), I can rewrite this. Either way, it can be split into a separate PR, but this commit will have to stay here for now, or compression.test will not pass.
$ ./src/tincd --version
tinc version 1.1pre18-23-g8aaf944f (built Jul 20 2021 13:54:00, protocol 17.7)
Features: openssl comp_lzo comp_zlib comp_lz4 legacy_protocol jumbograms miniupnpc uml vde

Copyright (C) 1998-2021 Ivo Timmermans, Guus Sliepen and others.
See the AUTHORS file for a complete list.

tinc comes with ABSOLUTELY NO WARRANTY.  This is free software,
and you are welcome to redistribute it under certain conditions;
see the file COPYING for details.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,287,2021-07-20T13:34:45Z,2021-07-20T17:46:45Z,2022-03-13T05:05:07Z,CLOSED,False,3813,67,33,https://github.com/hg,Add support for the lz4 compression algorithm,7,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/287,https://github.com/gsliepen,2,https://github.com/gsliepen/tinc/pull/287#issuecomment-883578390,"This adds lz4 block compression support, using either the vendored copy of the library, or (preferably) the one already found on the system.
Most of the work was done by Darik Horn (@dajhorn) in this pull request: #78.

Changes:

system lz4 is now tried first
builtin lz4 is used as a fallback if the system one is too old or missing

this can be prevented with --disable-lz4-builtin (in which case the build fails)
use of the builtin copy can be forced with --enable-lz4-builtin, even if the system library works fine


support for versions older than r129 has been removed, and the builtin copy is used in that case

it was released in May 2015
Debian oldstable and Ubuntu 18.04 ship with r131
CentOS 7 (oldest supported release) ships with 1.8.3 — much newer than r131



This behavior is documented.
Tests: this, this, and this (wrong package name on OpenSUSE and missing reformat from #280, everything else was fine).

af21369 is required for compression.test to determine which compression levels should work, and which should fail. I believe it's also quite useful by itself.
If you'd rather see a separate command (tinc features or tinc has_feature?), I can rewrite this. Either way, it can be split into a separate PR, but this commit will have to stay here for now, or compression.test will not pass.
$ ./src/tincd --version
tinc version 1.1pre18-23-g8aaf944f (built Jul 20 2021 13:54:00, protocol 17.7)
Features: openssl comp_lzo comp_zlib comp_lz4 legacy_protocol jumbograms miniupnpc uml vde

Copyright (C) 1998-2021 Ivo Timmermans, Guus Sliepen and others.
See the AUTHORS file for a complete list.

tinc comes with ABSOLUTELY NO WARRANTY.  This is free software,
and you are welcome to redistribute it under certain conditions;
see the file COPYING for details.",Rebased & merged. Thanks!,True,{'THUMBS_UP': ['https://github.com/hg']}
gsliepen/tinc,https://github.com/gsliepen/tinc,290,2021-07-23T13:05:57Z,2021-07-23T13:39:39Z,2021-07-25T10:23:11Z,MERGED,True,169,21,10,https://github.com/hg,Fix leaks triggered by integration test suite & enable ASAN in CI,3,[],https://github.com/gsliepen/tinc/pull/290,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/290,"This should fix all memory leaks that are triggered by running the integration test suite under ASAN.
Though these are definitely not all, fixing them lets us enable the ASAN job and spot new leaks right when they appear.
Tests:

https://github.com/hg/tinc/actions/runs/1059688675
https://github.com/hg/tinc/actions/runs/1059698688","This should fix all memory leaks that are triggered by running the integration test suite under ASAN.
Though these are definitely not all, fixing them lets us enable the ASAN job and spot new leaks right when they appear.
Tests:

https://github.com/hg/tinc/actions/runs/1059688675
https://github.com/hg/tinc/actions/runs/1059698688",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,291,2021-07-25T11:50:03Z,2021-07-25T15:35:14Z,2022-03-13T05:05:46Z,MERGED,True,170,77,20,https://github.com/hg,Fix known UndefinedBehaviorSanitizer warnings plus a few more leaks,5,[],https://github.com/gsliepen/tinc/pull/291,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/291,"This fixes all UBSAN warnings triggered by the integration test suite, plus a bunch of leaks across the project.
tinc fsck has a couple more memory safety issues and some other errors (that are not currently detected by tests), but it's so complicated that I've been refactoring and testing it for a while.
It's a relatively large patch, so I'll send it separately (after this one, because it builds on top of this.)
Tests:

https://github.com/hg/tinc/actions/runs/1064499905 (two separate successful runs that GitHub shows as a single one)
https://builds.sr.ht/~reducer/job/551897
https://builds.sr.ht/~reducer/job/551898
https://builds.sr.ht/~reducer/job/551899


What are your thoughts on fixing a lot of clang-tidy warnings similar to:

Narrowing conversion from 'unsigned long' to signed type 'int' is implementation-defined

these in particular often tend to trigger UBSAN at run time


'sscanf' used to convert a string to an integer value, but function will not report conversion errors; consider using 'strtol' instead
'atoi' used to convert a string to an integer value, but function will not report conversion errors; consider using 'strtol' instead
Unused header_name.h
Declaration shadows a local variable
Declaration shadows a variable in the global scope
…

and then adding clang-tidy with -Werror to CI?
I would like to reduce the number of these to zero.  However, it will produce a large diff which would be difficult to slice into pieces because fixing one warning often requires changing global functions or fields in widely used structs, which produces further warnings, and so on.
Will you accept patches to clean this up, seeing that this is not absolutely necessary and (as always) has a chance of breaking something?","This fixes all UBSAN warnings triggered by the integration test suite, plus a bunch of leaks across the project.
tinc fsck has a couple more memory safety issues and some other errors (that are not currently detected by tests), but it's so complicated that I've been refactoring and testing it for a while.
It's a relatively large patch, so I'll send it separately (after this one, because it builds on top of this.)
Tests:

https://github.com/hg/tinc/actions/runs/1064499905 (two separate successful runs that GitHub shows as a single one)
https://builds.sr.ht/~reducer/job/551897
https://builds.sr.ht/~reducer/job/551898
https://builds.sr.ht/~reducer/job/551899


What are your thoughts on fixing a lot of clang-tidy warnings similar to:

Narrowing conversion from 'unsigned long' to signed type 'int' is implementation-defined

these in particular often tend to trigger UBSAN at run time


'sscanf' used to convert a string to an integer value, but function will not report conversion errors; consider using 'strtol' instead
'atoi' used to convert a string to an integer value, but function will not report conversion errors; consider using 'strtol' instead
Unused header_name.h
Declaration shadows a local variable
Declaration shadows a variable in the global scope
…

and then adding clang-tidy with -Werror to CI?
I would like to reduce the number of these to zero.  However, it will produce a large diff which would be difficult to slice into pieces because fixing one warning often requires changing global functions or fields in widely used structs, which produces further warnings, and so on.
Will you accept patches to clean this up, seeing that this is not absolutely necessary and (as always) has a chance of breaking something?",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,291,2021-07-25T11:50:03Z,2021-07-25T15:35:14Z,2022-03-13T05:05:46Z,MERGED,True,170,77,20,https://github.com/hg,Fix known UndefinedBehaviorSanitizer warnings plus a few more leaks,5,[],https://github.com/gsliepen/tinc/pull/291,https://github.com/hg,2,https://github.com/gsliepen/tinc/pull/291#issuecomment-886192070,"This fixes all UBSAN warnings triggered by the integration test suite, plus a bunch of leaks across the project.
tinc fsck has a couple more memory safety issues and some other errors (that are not currently detected by tests), but it's so complicated that I've been refactoring and testing it for a while.
It's a relatively large patch, so I'll send it separately (after this one, because it builds on top of this.)
Tests:

https://github.com/hg/tinc/actions/runs/1064499905 (two separate successful runs that GitHub shows as a single one)
https://builds.sr.ht/~reducer/job/551897
https://builds.sr.ht/~reducer/job/551898
https://builds.sr.ht/~reducer/job/551899


What are your thoughts on fixing a lot of clang-tidy warnings similar to:

Narrowing conversion from 'unsigned long' to signed type 'int' is implementation-defined

these in particular often tend to trigger UBSAN at run time


'sscanf' used to convert a string to an integer value, but function will not report conversion errors; consider using 'strtol' instead
'atoi' used to convert a string to an integer value, but function will not report conversion errors; consider using 'strtol' instead
Unused header_name.h
Declaration shadows a local variable
Declaration shadows a variable in the global scope
…

and then adding clang-tidy with -Werror to CI?
I would like to reduce the number of these to zero.  However, it will produce a large diff which would be difficult to slice into pieces because fixing one warning often requires changing global functions or fields in widely used structs, which produces further warnings, and so on.
Will you accept patches to clean this up, seeing that this is not absolutely necessary and (as always) has a chance of breaking something?","The failing job is the old error which I haven't been able to trigger locally (yet)
Connected to localhost port 30010...
Cannot read greeting from peer
Could not connect to ::1 port 30010: Address not available",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,291,2021-07-25T11:50:03Z,2021-07-25T15:35:14Z,2022-03-13T05:05:46Z,MERGED,True,170,77,20,https://github.com/hg,Fix known UndefinedBehaviorSanitizer warnings plus a few more leaks,5,[],https://github.com/gsliepen/tinc/pull/291,https://github.com/hg,3,https://github.com/gsliepen/tinc/pull/291#issuecomment-886216257,"This fixes all UBSAN warnings triggered by the integration test suite, plus a bunch of leaks across the project.
tinc fsck has a couple more memory safety issues and some other errors (that are not currently detected by tests), but it's so complicated that I've been refactoring and testing it for a while.
It's a relatively large patch, so I'll send it separately (after this one, because it builds on top of this.)
Tests:

https://github.com/hg/tinc/actions/runs/1064499905 (two separate successful runs that GitHub shows as a single one)
https://builds.sr.ht/~reducer/job/551897
https://builds.sr.ht/~reducer/job/551898
https://builds.sr.ht/~reducer/job/551899


What are your thoughts on fixing a lot of clang-tidy warnings similar to:

Narrowing conversion from 'unsigned long' to signed type 'int' is implementation-defined

these in particular often tend to trigger UBSAN at run time


'sscanf' used to convert a string to an integer value, but function will not report conversion errors; consider using 'strtol' instead
'atoi' used to convert a string to an integer value, but function will not report conversion errors; consider using 'strtol' instead
Unused header_name.h
Declaration shadows a local variable
Declaration shadows a variable in the global scope
…

and then adding clang-tidy with -Werror to CI?
I would like to reduce the number of these to zero.  However, it will produce a large diff which would be difficult to slice into pieces because fixing one warning often requires changing global functions or fields in widely used structs, which produces further warnings, and so on.
Will you accept patches to clean this up, seeing that this is not absolutely necessary and (as always) has a chance of breaking something?","Everything else should be fixed. Thanks again for putting in time and patience to review this.

https://github.com/hg/tinc/actions/runs/1064801500 (reformatted since then)
https://github.com/hg/tinc/actions/runs/1064812845
https://builds.sr.ht/~reducer/job/552003
https://builds.sr.ht/~reducer/job/552004
https://builds.sr.ht/~reducer/job/552005


Another quick question — what is your stance on putting const everywhere possible (including non-pointer function arguments and things like const char *const str)?
C doesn't make it easy, but it seems to be a worthwhile thing to add as I continue to pick up the low hanging fruit. Or is it just noise?",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,291,2021-07-25T11:50:03Z,2021-07-25T15:35:14Z,2022-03-13T05:05:46Z,MERGED,True,170,77,20,https://github.com/hg,Fix known UndefinedBehaviorSanitizer warnings plus a few more leaks,5,[],https://github.com/gsliepen/tinc/pull/291,https://github.com/gsliepen,4,https://github.com/gsliepen/tinc/pull/291#issuecomment-886219286,"This fixes all UBSAN warnings triggered by the integration test suite, plus a bunch of leaks across the project.
tinc fsck has a couple more memory safety issues and some other errors (that are not currently detected by tests), but it's so complicated that I've been refactoring and testing it for a while.
It's a relatively large patch, so I'll send it separately (after this one, because it builds on top of this.)
Tests:

https://github.com/hg/tinc/actions/runs/1064499905 (two separate successful runs that GitHub shows as a single one)
https://builds.sr.ht/~reducer/job/551897
https://builds.sr.ht/~reducer/job/551898
https://builds.sr.ht/~reducer/job/551899


What are your thoughts on fixing a lot of clang-tidy warnings similar to:

Narrowing conversion from 'unsigned long' to signed type 'int' is implementation-defined

these in particular often tend to trigger UBSAN at run time


'sscanf' used to convert a string to an integer value, but function will not report conversion errors; consider using 'strtol' instead
'atoi' used to convert a string to an integer value, but function will not report conversion errors; consider using 'strtol' instead
Unused header_name.h
Declaration shadows a local variable
Declaration shadows a variable in the global scope
…

and then adding clang-tidy with -Werror to CI?
I would like to reduce the number of these to zero.  However, it will produce a large diff which would be difficult to slice into pieces because fixing one warning often requires changing global functions or fields in widely used structs, which produces further warnings, and so on.
Will you accept patches to clean this up, seeing that this is not absolutely necessary and (as always) has a chance of breaking something?","Another quick question — what is your stance on putting const everywhere possible (including non-pointer function arguments and things like const char *const str)?
C doesn't make it easy, but it seems to be a worthwhile thing to add as I continue to pick up the low hanging fruit. Or is it just noise?

I would give this very low priority. This is most likely not going to find any bugs.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,293,2021-07-28T17:25:02Z,2021-07-29T15:43:43Z,2021-07-29T19:01:04Z,MERGED,True,1291,787,25,https://github.com/hg,"`tinc fsck`: refactor, implement TODOs, fix bugs, reuse code from tincd",4,['1.1'],https://github.com/gsliepen/tinc/pull/293,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/293,"This started as an attempt to fix the remaining memory leaks and bugs in tinc fsck. However, it was obvious that the command could use some attention, so I refactored it into smaller pieces and added missing functionality:

implement TODOs
fix invalid warning: WARNING: public and private RSA keys do not match (on freshly tinc init'ed key pair)
use the same configuration reading & parsing logic as in tincd
read keys from all supported variables (PrivateKey + PrivateKeyFile + inline, same for Ed25519)
auto fix a few more broken key configurations
fix a couple of rare memory leaks
add warnings for host variables in server config and vice versa
check duplicates for all configuration variables (not the first 50)
check_conffile had a stack-buffer-underflow with going before the start of the line

I know it's a big ask to review this, but the new tests should ease this a bit as they cover every check performed by fsck (except for some error conditions that are impossible to produce without hooking into tinc's code).
Most of 17ba469 is shuffling existing functions around (to unbreak linkage with tinc). I had to change a few arguments to make them applicable to more situations.
Tests cannot be split off from this PR because they won't run on current fsck due to bugs and missing functionality.

https://github.com/hg/tinc/actions/runs/1075674524
https://github.com/hg/tinc/actions/runs/1075747412
https://builds.sr.ht/~reducer/job/554502
https://builds.sr.ht/~reducer/job/554503
https://builds.sr.ht/~reducer/job/554504

Windows jobs are hanging due to this: e050753","This started as an attempt to fix the remaining memory leaks and bugs in tinc fsck. However, it was obvious that the command could use some attention, so I refactored it into smaller pieces and added missing functionality:

implement TODOs
fix invalid warning: WARNING: public and private RSA keys do not match (on freshly tinc init'ed key pair)
use the same configuration reading & parsing logic as in tincd
read keys from all supported variables (PrivateKey + PrivateKeyFile + inline, same for Ed25519)
auto fix a few more broken key configurations
fix a couple of rare memory leaks
add warnings for host variables in server config and vice versa
check duplicates for all configuration variables (not the first 50)
check_conffile had a stack-buffer-underflow with going before the start of the line

I know it's a big ask to review this, but the new tests should ease this a bit as they cover every check performed by fsck (except for some error conditions that are impossible to produce without hooking into tinc's code).
Most of 17ba469 is shuffling existing functions around (to unbreak linkage with tinc). I had to change a few arguments to make them applicable to more situations.
Tests cannot be split off from this PR because they won't run on current fsck due to bugs and missing functionality.

https://github.com/hg/tinc/actions/runs/1075674524
https://github.com/hg/tinc/actions/runs/1075747412
https://builds.sr.ht/~reducer/job/554502
https://builds.sr.ht/~reducer/job/554503
https://builds.sr.ht/~reducer/job/554504

Windows jobs are hanging due to this: e050753",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,293,2021-07-28T17:25:02Z,2021-07-29T15:43:43Z,2021-07-29T19:01:04Z,MERGED,True,1291,787,25,https://github.com/hg,"`tinc fsck`: refactor, implement TODOs, fix bugs, reuse code from tincd",4,['1.1'],https://github.com/gsliepen/tinc/pull/293,https://github.com/hg,2,https://github.com/gsliepen/tinc/pull/293#issuecomment-889184498,"This started as an attempt to fix the remaining memory leaks and bugs in tinc fsck. However, it was obvious that the command could use some attention, so I refactored it into smaller pieces and added missing functionality:

implement TODOs
fix invalid warning: WARNING: public and private RSA keys do not match (on freshly tinc init'ed key pair)
use the same configuration reading & parsing logic as in tincd
read keys from all supported variables (PrivateKey + PrivateKeyFile + inline, same for Ed25519)
auto fix a few more broken key configurations
fix a couple of rare memory leaks
add warnings for host variables in server config and vice versa
check duplicates for all configuration variables (not the first 50)
check_conffile had a stack-buffer-underflow with going before the start of the line

I know it's a big ask to review this, but the new tests should ease this a bit as they cover every check performed by fsck (except for some error conditions that are impossible to produce without hooking into tinc's code).
Most of 17ba469 is shuffling existing functions around (to unbreak linkage with tinc). I had to change a few arguments to make them applicable to more situations.
Tests cannot be split off from this PR because they won't run on current fsck due to bugs and missing functionality.

https://github.com/hg/tinc/actions/runs/1075674524
https://github.com/hg/tinc/actions/runs/1075747412
https://builds.sr.ht/~reducer/job/554502
https://builds.sr.ht/~reducer/job/554503
https://builds.sr.ht/~reducer/job/554504

Windows jobs are hanging due to this: e050753","Diff for easier review. For some weird reason, GitHub does not allow comparing a forced-pushed commit against the previous one.
diff --git a/src/conf.c b/src/conf.c
index 7835f1d6..cbf3bea0 100644
--- a/src/conf.c
+++ b/src/conf.c
@@ -336,6 +336,10 @@ bool read_config_file(splay_tree_t *config_tree, const char *fname, bool verbose
 }
 
 void read_config_options(splay_tree_t *config_tree, const char *prefix) {
+	if(!cmdline_conf) {
+		return;
+	}
+
 	size_t prefix_len = prefix ? strlen(prefix) : 0;
 
 	for(const list_node_t *node = cmdline_conf->tail; node; node = node->prev) {
diff --git a/src/fsck.c b/src/fsck.c
index 72d31437..7b18c19a 100644
--- a/src/fsck.c
+++ b/src/fsck.c
@@ -80,6 +80,33 @@ static void print_tinc_cmd(const char *format, ...) {
 	fputc('\n', stderr);
 }
 
+typedef enum {
+	KEY_RSA,
+	KEY_ED25519,
+	KEY_BOTH,
+} key_type_t;
+
+static void print_new_keys_cmd(key_type_t key_type, const char *message) {
+	fprintf(stderr, ""%s\n\n"", message);
+
+	switch(key_type) {
+	case KEY_RSA:
+		fprintf(stderr, ""You can generate a new RSA keypair with:\n\n"");
+		print_tinc_cmd(""generate-rsa-keys"");
+		break;
+
+	case KEY_ED25519:
+		fprintf(stderr, ""You can generate a new Ed25519 keypair with:\n\n"");
+		print_tinc_cmd(""generate-ed25519-keys"");
+		break;
+
+	case KEY_BOTH:
+		fprintf(stderr, ""You can generate new keys with:\n\n"");
+		print_tinc_cmd(""generate-keys"");
+		break;
+	}
+}
+
 static int strtailcmp(const char *str, const char *tail) {
 	size_t slen = strlen(str);
 	size_t tlen = strlen(tail);
@@ -314,9 +341,7 @@ static bool test_rsa_keypair(rsa_t *rsa_priv, rsa_t *rsa_pub, const char *host_f
 				success = ask_fix_rsa_public_key(host_file, rsa_priv);
 			}
 		} else {
-			fprintf(stderr, ""ERROR: private RSA key does not work.\n"");
-			fprintf(stderr, ""You can create a new RSA keypair with:\n\n"");
-			print_tinc_cmd(""generate-rsa-keys"");
+			print_new_keys_cmd(KEY_RSA, ""ERROR: private RSA key does not work."");
 		}
 	} else {
 		fprintf(stderr, ""ERROR: public RSA key does not work.\n"");
@@ -346,25 +371,23 @@ static bool check_rsa_pubkey(rsa_t *rsa_priv, rsa_t *rsa_pub, const char *host_f
 #endif // DISABLE_LEGACY
 
 static bool test_ec_keypair(ecdsa_t *ec_priv, ecdsa_t *ec_pub, const char *host_file) {
+	// base64-encoded public key obtained from the PRIVATE key.
+	char *b64_priv_pub = ecdsa_get_base64_public_key(ec_priv);
+
+	if(!b64_priv_pub) {
+		print_new_keys_cmd(KEY_ED25519, ""ERROR: private Ed25519 key does not work."");
+		return false;
+	}
+
 	// base64-encoded public key obtained from the PUBLIC key.
 	char *b64_pub_pub = ecdsa_get_base64_public_key(ec_pub);
 
 	if(!b64_pub_pub) {
 		fprintf(stderr, ""ERROR: public Ed25519 key does not work.\n"");
+		free(b64_priv_pub);
 		return ask_fix_ec_public_key(host_file, ec_priv);
 	}
 
-	// base64-encoded public key obtained from the PRIVATE key.
-	char *b64_priv_pub = ecdsa_get_base64_public_key(ec_priv);
-
-	if(!b64_priv_pub) {
-		fprintf(stderr, ""ERROR: private Ed25519 key does not work.\n"");
-		fprintf(stderr, ""You can create a new Ed25519 keypair with:\n\n"");
-		print_tinc_cmd(""generate-ed25519-keys"");
-		free(b64_pub_pub);
-		return false;
-	}
-
 	bool match = strcmp(b64_pub_pub, b64_priv_pub) == 0;
 	free(b64_pub_pub);
 	free(b64_priv_pub);
@@ -380,7 +403,7 @@ static bool test_ec_keypair(ecdsa_t *ec_priv, ecdsa_t *ec_pub, const char *host_
 static bool check_ec_pubkey(ecdsa_t *ec_priv, ecdsa_t *ec_pub, const char *host_file) {
 	if(!ec_priv) {
 		if(ec_pub) {
-			fprintf(stderr, ""WARNING: A public Ed25519 key was found but no private key is known.\n"");
+			print_new_keys_cmd(KEY_ED25519, ""WARNING: A public Ed25519 key was found but no private key is known."");
 		}
 
 		return true;
@@ -547,9 +570,7 @@ static bool check_keypairs(splay_tree_t *config, const char *name) {
 #ifdef DISABLE_LEGACY
 
 	if(!ec_priv) {
-		fprintf(stderr, ""ERROR: No Ed25519 private key found.\n"");
-		fprintf(stderr, ""You can generate new keys with:\n\n"");
-		print_tinc_cmd(exe_name, ""generate-keys"");
+		print_new_keys_cmd(KEY_ED25519, ""ERROR: No Ed25519 private key found."");
 		return false;
 	}
 
@@ -562,9 +583,7 @@ static bool check_keypairs(splay_tree_t *config, const char *name) {
 	}
 
 	if(!rsa_priv && !ec_priv) {
-		fprintf(stderr, ""ERROR: Neither RSA or Ed25519 private key found.\n"");
-		fprintf(stderr, ""You can generate new keys with:\n\n"");
-		print_tinc_cmd(""generate-keys"");
+		print_new_keys_cmd(KEY_BOTH, ""ERROR: Neither RSA or Ed25519 private key found."");
 		return false;
 	}
 
diff --git a/src/tincctl.c b/src/tincctl.c
index 6e03bba1..14faf645 100644
--- a/src/tincctl.c
+++ b/src/tincctl.c
@@ -3264,7 +3264,6 @@ static int cmd_shell(int argc, char *argv[]) {
 }
 
 static void cleanup() {
-	free(cmdline_conf);
 	free(tinc_conf);
 	free(hosts_dir);
 	free_names();
@@ -3276,9 +3275,6 @@ int main(int argc, char *argv[]) {
 	orig_argc = argc;
 	tty = isatty(0) && isatty(1);
 
-	cmdline_conf = list_alloc((list_action_t)free_config);
-	atexit(cleanup);
-
 	if(!parse_options(argc, argv)) {
 		return 1;
 	}
@@ -3286,6 +3282,7 @@ int main(int argc, char *argv[]) {
 	make_names(false);
 	xasprintf(&tinc_conf, ""%s"" SLASH ""tinc.conf"", confbase);
 	xasprintf(&hosts_dir, ""%s"" SLASH ""hosts"", confbase);
+	atexit(cleanup);
 
 	if(show_version) {
 		version();
diff --git a/src/tincd.c b/src/tincd.c
index 488ddc8f..d8ab0ac0 100644
--- a/src/tincd.c
+++ b/src/tincd.c
@@ -297,7 +297,7 @@ static bool parse_options(int argc, char **argv) {
 
 exit_fail:
 	free_names();
-	free(cmdline_conf);
+	list_delete_list(cmdline_conf);
 	cmdline_conf = NULL;
 	return false;
 }
@@ -387,7 +387,7 @@ static void cleanup() {
 		exit_configuration(&config_tree);
 	}
 
-	free(cmdline_conf);
+	list_delete_list(cmdline_conf);
 	free_names();
 }
 
diff --git a/test/Makefile.am b/test/Makefile.am
index ab6eb0cd..20fee657 100644
--- a/test/Makefile.am
+++ b/test/Makefile.am
@@ -2,6 +2,7 @@ TESTS = \
 	basic.test \
 	executables.test \
 	commandline.test \
+	command-fsck.test \
 	import-export.test \
 	invite-join.test \
 	invite-offline.test \
@@ -17,11 +18,6 @@ TESTS += \
 	algorithms.test
 endif
 
-if !MINGW
-TESTS += \
-	command-fsck.test
-endif
-
 if LINUX
 TESTS += \
 	ns-ping.test \
diff --git a/test/command-fsck.test b/test/command-fsck.test
index d63bf9e1..36b2c998 100755
--- a/test/command-fsck.test
+++ b/test/command-fsck.test
@@ -7,11 +7,30 @@ foo_host=$foo_dir/hosts/foo
 foo_conf=$foo_dir/tinc.conf
 foo_rsa_priv=$foo_dir/rsa_key.priv
 foo_ec_priv=$foo_dir/ed25519_key.priv
+foo_tinc_up=$foo_dir/tinc-up
+foo_host_up=$foo_dir/host-up
+
+if is_windows; then
+  foo_tinc_up=$foo_tinc_up.cmd
+  foo_host_up=$foo_host_up.cmd
+fi
 
 # Sample RSA key pair (old format). Uses e = 0xFFFF.
 rsa_n=BB82C3A9B906E98ABF2D99FF9B320B229F5C1E58EC784762DA1F4D3509FFF78ECA7FFF19BA170736CDE458EC8E732DDE2C02009632DF731B4A6BD6C504E50B7B875484506AC1E49FD0DF624F6612F564C562BD20F870592A49195023D744963229C35081C8AE48BE2EBB5CC9A0D64924022DC0EB782A3A8F3EABCA04AA42B24B2A6BD2353A6893A73AE01FA54891DD24BF36CA032F19F7E78C01273334BAA2ECF36B6998754CB012BC985C975503D945E4D925F6F719ACC8FBA7B18C810FF850C3CCACD60565D4FCFE02A98FE793E2D45D481A34D1F90584D096561FF3184C462C606535F3F9BB260541DF0D1FEB16938FFDEC2FF96ACCC6BD5BFBC19471F6AB
 rsa_d=8CEC9A4316FE45E07900197D8FBB52D3AF01A51C4F8BD08A1E21A662E3CFCF7792AD7680673817B70AC1888A08B49E8C5835357016D9BF56A0EBDE8B5DF214EC422809BC8D88177F273419116EF2EC7951453F129768DE9BC31D963515CC7481559E4C0E65C549169F2B94AE68DB944171189DD654DC6970F2F5843FB7C8E9D057E2B5716752F1F5686811AC075ED3D3CBD06B5D35AE33D01260D9E0560AF545D0C9D89A31D5EAF96D5422F6567FE8A90E23906B840545805644DFD656E526A686D3B978DD271578CA3DA0F7D23FC1252A702A5D597CAE9D4A5BBF6398A75AF72582C7538A7937FB71A2610DCBC39625B77103FA3B7D0A55177FD98C39CD4A27
 
+# Extracts the PEM key from a config file, leaving the file unchanged.
+# usage: extract_pem_key_from_config path_to_file
+extract_pem_key_from_config() {
+  sed -n '/-----BEGIN /,/-----END /p' ""$1""
+}
+
+# Removes the PEM key from a config file.
+# usage: rm_pem_key_from_config path_to_file
+rm_pem_key_from_config() {
+  sed_cmd '/-----BEGIN /,/-----END /d' ""$1""
+}
+
 reinit_configs() {
   if [ -d ""$foo_dir"" ]; then
     chmod -f 755 ""$foo_dir""
@@ -29,6 +48,10 @@ fsck_test() {
   reinit_configs
 }
 
+run_access_checks() {
+  ! is_root && ! is_windows
+}
+
 test_private_keys() {
   keyfile=$1
 
@@ -40,7 +63,7 @@ test_private_keys() {
     must_fail_with_msg 'no Ed25519 private key found' tinc foo fsck
   fi
 
-  if ! is_root; then
+  if run_access_checks; then
     fsck_test ""Must fail on inaccessible $keyfile""
     chmod 000 ""$foo_dir/$keyfile""
     if with_legacy; then
@@ -50,9 +73,11 @@ test_private_keys() {
     fi
   fi
 
-  fsck_test ""Must warn about unsafe permissions on $keyfile""
-  chmod 666 ""$foo_dir/$keyfile""
-  expect_msg 'unsafe file permissions' tinc foo fsck
+  if ! is_windows; then
+    fsck_test ""Must warn about unsafe permissions on $keyfile""
+    chmod 666 ""$foo_dir/$keyfile""
+    expect_msg 'unsafe file permissions' tinc foo fsck
+  fi
 
   if with_legacy; then
     fsck_test ""Must pass on missing $keyfile when the other key is present""
@@ -67,7 +92,7 @@ test_private_key_var() {
 
   fsck_test ""Must find private key at $var""
   mv ""$foo_dir/$keyfile"" ""$foo_dir/renamed_private_key""
-  echo ""$var = $foo_dir/renamed_private_key"" >>""$foo_conf""
+  echo ""$var = $(normalize_path ""$foo_dir/renamed_private_key"")"" >>""$foo_conf""
   fail_on_msg 'key was found but no private key' tinc foo fsck
 }
 
@@ -80,7 +105,7 @@ $(awk '/^Ed25519PublicKey/ { printf $NF }' ""$foo_host"")
 -----END ED25519 PUBLIC KEY-----
 EOF
   sed_cmd '/Ed25519PublicKey/d' ""$foo_host""
-  echo ""Ed25519PublicKeyFile = $foo_dir/ec_pubkey"" >>""$foo_dir/$conf""
+  echo ""Ed25519PublicKeyFile = $(normalize_path ""$foo_dir/ec_pubkey"")"" >>""$foo_dir/$conf""
   fail_on_msg 'no (usable) public Ed25519' tinc foo fsck
 }
 
@@ -89,7 +114,7 @@ test_rsa_public_key_file_var() {
   fsck_test ""RSA public key in PublicKeyFile in $conf must work""
   extract_pem_key_from_config ""$foo_host"" >""$foo_dir/rsa_pubkey""
   rm_pem_key_from_config ""$foo_host""
-  echo ""PublicKeyFile = $foo_dir/rsa_pubkey"" >>""$foo_dir/$conf""
+  echo ""PublicKeyFile = $(normalize_path ""$foo_dir/rsa_pubkey"")"" >>""$foo_dir/$conf""
   fail_on_msg 'error reading RSA public key' tinc foo fsck
 }
 
@@ -100,21 +125,23 @@ fsck_test 'Must fail on missing tinc.conf'
 rm -f ""$foo_conf""
 must_fail_with_msg 'no tinc configuration found' tinc foo fsck
 
-if ! is_root; then
+if run_access_checks; then
   fsck_test 'Must fail on inaccessible tinc.conf'
   chmod 000 ""$foo_dir""
   must_fail_with_msg 'not running tinc as root' tinc foo fsck
 fi
 
-fsck_test 'Non-executable tinc-up MUST be fixed by tinc --force'
-chmod a-x ""$foo_dir/tinc-up""
-expect_msg 'cannot read and execute' tinc foo --force fsck
-test -x ""$foo_dir/tinc-up""
+if ! is_windows; then
+  fsck_test 'Non-executable tinc-up MUST be fixed by tinc --force'
+  chmod a-x ""$foo_tinc_up""
+  expect_msg 'cannot read and execute' tinc foo --force fsck
+  test -x ""$foo_tinc_up""
 
-fsck_test 'Non-executable tinc-up MUST NOT be fixed by tinc without --force'
-chmod a-x ""$foo_dir/tinc-up""
-expect_msg 'cannot read and execute' tinc foo fsck
-must_fail test -x ""$foo_dir/tinc-up""
+  fsck_test 'Non-executable tinc-up MUST NOT be fixed by tinc without --force'
+  chmod a-x ""$foo_tinc_up""
+  expect_msg 'cannot read and execute' tinc foo fsck
+  must_fail test -x ""$foo_tinc_up""
+fi
 
 fsck_test 'Unknown -up script warning'
 touch ""$foo_dir/fake-up""
@@ -124,19 +151,21 @@ fsck_test 'Unknown -down script warning'
 touch ""$foo_dir/fake-down""
 expect_msg 'unknown script' tinc foo fsck
 
-fsck_test 'Non-executable foo-up MUST be fixed by tinc --force'
-touch ""$foo_host-up""
-chmod a-x ""$foo_host-up""
-expect_msg 'cannot read and execute' tinc foo --force fsck
-test -x ""$foo_dir/tinc-up""
-
-fsck_test 'Non-executable bar-up MUST NOT be fixed by tinc'
-touch ""$foo_dir/hosts/bar-up""
-chmod a-x ""$foo_dir/hosts/bar-up""
-expect_msg 'cannot read and execute' tinc foo fsck
-must_fail test -x ""$foo_dir/bar-up""
+if ! is_windows; then
+  fsck_test 'Non-executable foo-up MUST be fixed by tinc --force'
+  touch ""$foo_host_up""
+  chmod a-x ""$foo_host_up""
+  expect_msg 'cannot read and execute' tinc foo --force fsck
+  test -x ""$foo_tinc_up""
+
+  fsck_test 'Non-executable bar-up MUST NOT be fixed by tinc'
+  touch ""$foo_dir/hosts/bar-up""
+  chmod a-x ""$foo_dir/hosts/bar-up""
+  expect_msg 'cannot read and execute' tinc foo fsck
+  must_fail test -x ""$foo_dir/bar-up""
+fi
 
-if ! is_root; then
+if run_access_checks; then
   fsck_test 'Inaccessible hosts/foo must fail'
   chmod 000 ""$foo_host""
   must_fail_with_msg 'cannot open config file' tinc foo fsck
@@ -153,11 +182,13 @@ fi
 if with_legacy; then
   test_private_keys rsa_key.priv
 
-  fsck_test 'Must warn about unsafe permissions on tinc.conf with PrivateKey'
-  rm -f ""$foo_rsa_priv""
-  echo ""PrivateKey = $rsa_d"" >>""$foo_conf""
-  echo ""PublicKey = $rsa_n"" >>""$foo_host""
-  expect_msg 'unsafe file permissions' tinc foo fsck
+  if ! is_windows; then
+    fsck_test 'Must warn about unsafe permissions on tinc.conf with PrivateKey'
+    rm -f ""$foo_rsa_priv""
+    echo ""PrivateKey = $rsa_d"" >>""$foo_conf""
+    echo ""PublicKey = $rsa_n"" >>""$foo_host""
+    expect_msg 'unsafe file permissions' tinc foo fsck
+  fi
 
   fsck_test 'Must warn about missing RSA private key if public key is present'
   rm -f ""$foo_rsa_priv""
diff --git a/test/testlib.sh.in b/test/testlib.sh.in
index 180272d5..c65bdde8 100644
--- a/test/testlib.sh.in
+++ b/test/testlib.sh.in
@@ -99,6 +99,12 @@ rm_cr() {
   tr -d '\r'
 }
 
+if is_windows; then
+  normalize_path() { cygpath --mixed -- ""$@""; }
+else
+  normalize_path() { echo ""$@""; }
+fi
+
 # Executes whatever is passed to it, checking that the resulting exit code is non-zero.
 must_fail() {
   if ""$@""; then
@@ -158,18 +164,6 @@ with_legacy() {
   tincd foo --version | grep -q legacy_protocol
 }
 
-# Extracts the PEM key from a config file, leaving the file unchanged.
-# usage: extract_pem_key_from_config path_to_file
-extract_pem_key_from_config() {
-  sed -n '/-----BEGIN /,/-----END /p' ""$1""
-}
-
-# Removes the PEM key from a config file.
-# usage: rm_pem_key_from_config path_to_file
-rm_pem_key_from_config() {
-  sed_cmd '/-----BEGIN /,/-----END /d' ""$1""
-}
-
 # Are we running with EUID 0?
 is_root() {
   test ""$(id -u)"" = 0
@@ -447,8 +441,8 @@ cleanup() {
 }
 
 # If we're on a CI server, the test requires superuser privileges to run, and we're not
-# currently a superuser, try running the test as one (if the system configuration allows
-# it — we need passwordless sudo).
+# currently a superuser, try running the test as one and fail if it doesn't work (the
+# system must be configured to provide passwordless sudo for our user).
 require_root() {
   if is_root; then
     return
@@ -456,12 +450,10 @@ require_root() {
   if is_ci; then
     echo ""root is required for test $SCRIPTNAME, but we're a regular user; elevating privileges...""
     if ! command -v sudo 2>/dev/null; then
-      echo >&2 ""sudo not found, skipping test $SCRIPTNAME""
-      exit $EXIT_SKIP_TEST
+      bail ""please install sudo and configure passwordless auth for user $USER""
     fi
     if ! sudo --preserve-env --non-interactive true; then
-      echo >&2 ""sudo is not allowed or requires a password, skipping test $SCRIPTNAME""
-      exit $EXIT_SKIP_TEST
+      bail ""sudo is not allowed or requires a password for user $USER""
     fi
     exec sudo --preserve-env ""$@""
   else
@@ -473,7 +465,7 @@ require_root() {
 
 # Generate path to current shell which can be used from Windows applications.
 if is_windows; then
-  MINGW_SHELL=$(cygpath --mixed -- ""$SHELL"")
+  MINGW_SHELL=$(normalize_path ""$SHELL"")
 fi
 
 # This was called from a tincd script. Skip executing commands with side effects.
@@ -484,10 +476,9 @@ echo [STEP] Check for leftover tinc daemons and test directories
 # Cleanup leftovers from previous runs.
 stop_all_tincs
 
-# On Windows this can actually fail. We don't want to suppress possible failure with -f.
-if [ -d ""$DIR_FOO"" ]; then rm -r ""$DIR_FOO""; fi
-if [ -d ""$DIR_BAR"" ]; then rm -r ""$DIR_BAR""; fi
-if [ -d ""$DIR_BAZ"" ]; then rm -r ""$DIR_BAZ""; fi
+if [ -d ""$DIR_FOO"" ]; then rm -rf ""$DIR_FOO""; fi
+if [ -d ""$DIR_BAR"" ]; then rm -rf ""$DIR_BAR""; fi
+if [ -d ""$DIR_BAZ"" ]; then rm -rf ""$DIR_BAZ""; fi
 
 # Register cleanup function so we don't have to call it everywhere
 # (and failed scripts do not leave stray tincd running).",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,295,2021-07-30T11:09:46Z,2021-07-30T21:15:39Z,2021-08-02T08:00:49Z,MERGED,True,24,121,48,https://github.com/hg,Remove unused variables/functions/types/includes (re #288),8,[],https://github.com/gsliepen/tinc/pull/295,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/295,"I would like to send cleanups as separate PRs (grouped by warning types) for easier review on your side.
This is the lowest hanging fruit. It should remove everything unused, except for things required to keep backwards compatibility. Because removing headers can introduce regressions for basically no gain, I included more test results than usual.
The script monitoring mechanism had to be changed to support the old version of ksh which is used on NetBSD 8.2. Before:

FreeBSD 13
FreeBSD 12
FreeBSD 11
OpenBSD 6.9
OpenBSD 6.8
NetBSD 9.2
NetBSD 8.2 <===
https://github.com/hg/tinc/actions/runs/1081472787
https://github.com/hg/tinc/actions/runs/1079755237

and after:

FreeBSD 13
FreeBSD 12
FreeBSD 11
OpenBSD 6.9
OpenBSD 6.8
NetBSD 9.2
NetBSD 8.2, another <===
https://github.com/hg/tinc/actions/runs/1081941896
https://github.com/hg/tinc/actions/runs/1081935718 (with Windows)
https://github.com/hg/tinc/actions/runs/1081904638
plus local testing on DragonFlyBSD 6.0.

We can add old BSDs to CI, but sourcehut only runs up to three jobs, which it picks randomly if there are too many. Seeing that most of these releases are close to EOL, it probably does not make much sense (for example, OpenBSD 6.8 is EOL at November this year; others are pretty close).","I would like to send cleanups as separate PRs (grouped by warning types) for easier review on your side.
This is the lowest hanging fruit. It should remove everything unused, except for things required to keep backwards compatibility. Because removing headers can introduce regressions for basically no gain, I included more test results than usual.
The script monitoring mechanism had to be changed to support the old version of ksh which is used on NetBSD 8.2. Before:

FreeBSD 13
FreeBSD 12
FreeBSD 11
OpenBSD 6.9
OpenBSD 6.8
NetBSD 9.2
NetBSD 8.2 <===
https://github.com/hg/tinc/actions/runs/1081472787
https://github.com/hg/tinc/actions/runs/1079755237

and after:

FreeBSD 13
FreeBSD 12
FreeBSD 11
OpenBSD 6.9
OpenBSD 6.8
NetBSD 9.2
NetBSD 8.2, another <===
https://github.com/hg/tinc/actions/runs/1081941896
https://github.com/hg/tinc/actions/runs/1081935718 (with Windows)
https://github.com/hg/tinc/actions/runs/1081904638
plus local testing on DragonFlyBSD 6.0.

We can add old BSDs to CI, but sourcehut only runs up to three jobs, which it picks randomly if there are too many. Seeing that most of these releases are close to EOL, it probably does not make much sense (for example, OpenBSD 6.8 is EOL at November this year; others are pretty close).",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,295,2021-07-30T11:09:46Z,2021-07-30T21:15:39Z,2021-08-02T08:00:49Z,MERGED,True,24,121,48,https://github.com/hg,Remove unused variables/functions/types/includes (re #288),8,[],https://github.com/gsliepen/tinc/pull/295,https://github.com/gsliepen,2,https://github.com/gsliepen/tinc/pull/295#issuecomment-890153646,"I would like to send cleanups as separate PRs (grouped by warning types) for easier review on your side.
This is the lowest hanging fruit. It should remove everything unused, except for things required to keep backwards compatibility. Because removing headers can introduce regressions for basically no gain, I included more test results than usual.
The script monitoring mechanism had to be changed to support the old version of ksh which is used on NetBSD 8.2. Before:

FreeBSD 13
FreeBSD 12
FreeBSD 11
OpenBSD 6.9
OpenBSD 6.8
NetBSD 9.2
NetBSD 8.2 <===
https://github.com/hg/tinc/actions/runs/1081472787
https://github.com/hg/tinc/actions/runs/1079755237

and after:

FreeBSD 13
FreeBSD 12
FreeBSD 11
OpenBSD 6.9
OpenBSD 6.8
NetBSD 9.2
NetBSD 8.2, another <===
https://github.com/hg/tinc/actions/runs/1081941896
https://github.com/hg/tinc/actions/runs/1081935718 (with Windows)
https://github.com/hg/tinc/actions/runs/1081904638
plus local testing on DragonFlyBSD 6.0.

We can add old BSDs to CI, but sourcehut only runs up to three jobs, which it picks randomly if there are too many. Seeing that most of these releases are close to EOL, it probably does not make much sense (for example, OpenBSD 6.8 is EOL at November this year; others are pretty close).","That's a lot of testing! It might make sense to limit the scope of the tests we run for each commit and pull request, and maybe do the more extensive tests in a nightly or weekendly. So frequent testing done on the latest stable versions of:

Debian
Alpine (because musl is quite different from glibc)
macOS
Windows
OpenBSD
FreeBSD
NetBSD

And then run tests for older versions and more Linux distros with a lower frequency. And of course require ALL tests to pass for releases.",True,{'THUMBS_UP': ['https://github.com/hg']}
gsliepen/tinc,https://github.com/gsliepen/tinc,296,2021-08-01T11:13:09Z,2021-08-02T10:10:11Z,2021-08-02T10:13:14Z,MERGED,True,647,431,95,https://github.com/hg,"Add clang-tidy to CI, fix reported narrowing conversion warnings",4,[],https://github.com/gsliepen/tinc/pull/296,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/296,"This gets rid of all reported narrowing casts (eliminating them whenever possible, and adding explicit casts to silence the useless warning otherwise), and adjusts variable types where it makes sense to do so:

char → uint8_t where memory is expected to contain opaque binary data
ssize_t where it is returned by library functions
size_t for sizeof(..) results, storing array indices, etc.
ptrdiff_t for pointer arithmetic results
and so on

clang-tidy has been added to CI and will fail if it finds anything suspicious. Only narrowing casts are checked for now (see .clang-tidy), we can enable more warning types one by one after fixing them.
The full list for you particular version of clang can be obtained with:
$ clang-tidy --checks='*' --list-checks

or here.
You may also find this page useful.
Cryptographic functions are skipped because they produce a ton of warnings and it's probably best not to mess with them.
Solaris and Windows code is also skipped because clang-tidy requires a fully working translation unit with all included headers present. I couldn't build compilation database on Windows (autotools really doesn't make it easy, and most tools to do it don't work there), and we have no CI for Solaris.
When (if) we switch the build system to something more modern that generates the compilation database without third-party tools, this could be updated.

https://builds.sr.ht/~reducer/job/557195
https://builds.sr.ht/~reducer/job/557202
https://builds.sr.ht/~reducer/job/557201
https://github.com/hg/tinc/actions/runs/1087055817 (with e050753 reverted)
https://github.com/hg/tinc/actions/runs/1087167564
https://github.com/hg/tinc/actions/runs/1087131224
https://github.com/hg/tinc/actions/runs/1087042963
https://github.com/hg/tinc/actions/runs/1086990423
https://github.com/hg/tinc/actions/runs/1086632473
https://github.com/hg/tinc/actions/runs/1086801641

These warnings are caused by system headers which we can't do anything about:
...
1184 warnings generated.
1201 warnings generated.
Suppressed 1201 warnings (1104 in non-user code, 97 with check filters).

For comparison, here's an example of a real issue:

FreeBSD
macOS

Linux job won't show this until GitHub update their Ubuntu VMs to clang-tidy 12 or later. It cannot easily be installed manually because of broken dependencies. We can work around this with a separate container, but the best solution IMHO is to simply wait until clang-tidy is updated, and rely on FreeBSD and macOS for now.","This gets rid of all reported narrowing casts (eliminating them whenever possible, and adding explicit casts to silence the useless warning otherwise), and adjusts variable types where it makes sense to do so:

char → uint8_t where memory is expected to contain opaque binary data
ssize_t where it is returned by library functions
size_t for sizeof(..) results, storing array indices, etc.
ptrdiff_t for pointer arithmetic results
and so on

clang-tidy has been added to CI and will fail if it finds anything suspicious. Only narrowing casts are checked for now (see .clang-tidy), we can enable more warning types one by one after fixing them.
The full list for you particular version of clang can be obtained with:
$ clang-tidy --checks='*' --list-checks

or here.
You may also find this page useful.
Cryptographic functions are skipped because they produce a ton of warnings and it's probably best not to mess with them.
Solaris and Windows code is also skipped because clang-tidy requires a fully working translation unit with all included headers present. I couldn't build compilation database on Windows (autotools really doesn't make it easy, and most tools to do it don't work there), and we have no CI for Solaris.
When (if) we switch the build system to something more modern that generates the compilation database without third-party tools, this could be updated.

https://builds.sr.ht/~reducer/job/557195
https://builds.sr.ht/~reducer/job/557202
https://builds.sr.ht/~reducer/job/557201
https://github.com/hg/tinc/actions/runs/1087055817 (with e050753 reverted)
https://github.com/hg/tinc/actions/runs/1087167564
https://github.com/hg/tinc/actions/runs/1087131224
https://github.com/hg/tinc/actions/runs/1087042963
https://github.com/hg/tinc/actions/runs/1086990423
https://github.com/hg/tinc/actions/runs/1086632473
https://github.com/hg/tinc/actions/runs/1086801641

These warnings are caused by system headers which we can't do anything about:
...
1184 warnings generated.
1201 warnings generated.
Suppressed 1201 warnings (1104 in non-user code, 97 with check filters).

For comparison, here's an example of a real issue:

FreeBSD
macOS

Linux job won't show this until GitHub update their Ubuntu VMs to clang-tidy 12 or later. It cannot easily be installed manually because of broken dependencies. We can work around this with a separate container, but the best solution IMHO is to simply wait until clang-tidy is updated, and rely on FreeBSD and macOS for now.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,296,2021-08-01T11:13:09Z,2021-08-02T10:10:11Z,2021-08-02T10:13:14Z,MERGED,True,647,431,95,https://github.com/hg,"Add clang-tidy to CI, fix reported narrowing conversion warnings",4,[],https://github.com/gsliepen/tinc/pull/296,https://github.com/hg,2,https://github.com/gsliepen/tinc/pull/296#issuecomment-890550884,"This gets rid of all reported narrowing casts (eliminating them whenever possible, and adding explicit casts to silence the useless warning otherwise), and adjusts variable types where it makes sense to do so:

char → uint8_t where memory is expected to contain opaque binary data
ssize_t where it is returned by library functions
size_t for sizeof(..) results, storing array indices, etc.
ptrdiff_t for pointer arithmetic results
and so on

clang-tidy has been added to CI and will fail if it finds anything suspicious. Only narrowing casts are checked for now (see .clang-tidy), we can enable more warning types one by one after fixing them.
The full list for you particular version of clang can be obtained with:
$ clang-tidy --checks='*' --list-checks

or here.
You may also find this page useful.
Cryptographic functions are skipped because they produce a ton of warnings and it's probably best not to mess with them.
Solaris and Windows code is also skipped because clang-tidy requires a fully working translation unit with all included headers present. I couldn't build compilation database on Windows (autotools really doesn't make it easy, and most tools to do it don't work there), and we have no CI for Solaris.
When (if) we switch the build system to something more modern that generates the compilation database without third-party tools, this could be updated.

https://builds.sr.ht/~reducer/job/557195
https://builds.sr.ht/~reducer/job/557202
https://builds.sr.ht/~reducer/job/557201
https://github.com/hg/tinc/actions/runs/1087055817 (with e050753 reverted)
https://github.com/hg/tinc/actions/runs/1087167564
https://github.com/hg/tinc/actions/runs/1087131224
https://github.com/hg/tinc/actions/runs/1087042963
https://github.com/hg/tinc/actions/runs/1086990423
https://github.com/hg/tinc/actions/runs/1086632473
https://github.com/hg/tinc/actions/runs/1086801641

These warnings are caused by system headers which we can't do anything about:
...
1184 warnings generated.
1201 warnings generated.
Suppressed 1201 warnings (1104 in non-user code, 97 with check filters).

For comparison, here's an example of a real issue:

FreeBSD
macOS

Linux job won't show this until GitHub update their Ubuntu VMs to clang-tidy 12 or later. It cannot easily be installed manually because of broken dependencies. We can work around this with a separate container, but the best solution IMHO is to simply wait until clang-tidy is updated, and rely on FreeBSD and macOS for now.","Huge thanks for taking the time to review this. I fixed everything except for this (I'll await your judgement on that), plus all calls to functions from ctype and unnecessary casts to unsigned int (instead of %zu).
Diff:
diff --git a/src/Makefile.am b/src/Makefile.am
index 306bbc42..5165b583 100644
--- a/src/Makefile.am
+++ b/src/Makefile.am
@@ -52,6 +52,7 @@ tincd_SOURCES = \
 	autoconnect.c autoconnect.h \
 	buffer.c buffer.h \
 	cipher.h \
+	compression.h \
 	conf.c conf.h \
 	conf_net.c conf_net.h \
 	connection.c connection.h \
diff --git a/src/autoconnect.c b/src/autoconnect.c
index ae514286..d819ee46 100644
--- a/src/autoconnect.c
+++ b/src/autoconnect.c
@@ -29,7 +29,7 @@ static void make_new_connection() {
 	int count = 0;
 
 	for splay_each(node_t, n, node_tree) {
-		if(n == myself || n->connection || !(n->status.has_address != 0u || n->status.reachable != 0u)) {
+		if(n == myself || n->connection || !(n->status.has_address || n->status.reachable)) {
 			continue;
 		}
 
@@ -43,7 +43,7 @@ static void make_new_connection() {
 	int r = rand() % count;
 
 	for splay_each(node_t, n, node_tree) {
-		if(n == myself || n->connection || !(n->status.has_address != 0u || n->status.reachable != 0u)) {
+		if(n == myself || n->connection || !(n->status.has_address || n->status.reachable)) {
 			continue;
 		}
 
@@ -88,7 +88,7 @@ static void connect_to_unreachable() {
 		}
 
 		/* Is it unreachable and do we know an address for it? If not, return. */
-		if(n == myself || n->connection || n->status.reachable != 0u || !n->status.has_address) {
+		if(n == myself || n->connection || n->status.reachable || !n->status.has_address) {
 			return;
 		}
 
diff --git a/src/bsd/tunemu.c b/src/bsd/tunemu.c
index 7d1c407a..6867c47b 100644
--- a/src/bsd/tunemu.c
+++ b/src/bsd/tunemu.c
@@ -50,10 +50,10 @@
 #define PPPIOCGUNIT     _IOR('t', 86, int)
 
 struct sockaddr_ppp {
-	u_int8_t ppp_len;
-	u_int8_t ppp_family;
-	u_int16_t ppp_proto;
-	u_int32_t ppp_cookie;
+	uint8_t ppp_len;
+	uint8_t ppp_family;
+	uint16_t ppp_proto;
+	uint32_t ppp_cookie;
 };
 
 enum NPmode {
diff --git a/src/compression.h b/src/compression.h
new file mode 100644
index 00000000..96fc9ea8
--- /dev/null
+++ b/src/compression.h
@@ -0,0 +1,25 @@
+#ifndef TINC_COMPRESSION_H
+#define TINC_COMPRESSION_H
+
+typedef enum compression_level_t {
+	COMPRESS_NONE = 0,
+
+	COMPRESS_ZLIB_1 = 1,
+	COMPRESS_ZLIB_2 = 2,
+	COMPRESS_ZLIB_3 = 3,
+	COMPRESS_ZLIB_4 = 4,
+	COMPRESS_ZLIB_5 = 5,
+	COMPRESS_ZLIB_6 = 6,
+	COMPRESS_ZLIB_7 = 7,
+	COMPRESS_ZLIB_8 = 8,
+	COMPRESS_ZLIB_9 = 9,
+
+	COMPRESS_LZO_LO = 10,
+	COMPRESS_LZO_HI = 11,
+
+	COMPRESS_LZ4 = 12,
+
+	COMPRESS_GUARD = INT_MAX, /* ensure that sizeof(compression_level_t) == sizeof(int) */
+} compression_level_t;
+
+#endif
diff --git a/src/connection.h b/src/connection.h
index 506e252f..2f652182 100644
--- a/src/connection.h
+++ b/src/connection.h
@@ -27,6 +27,7 @@
 #include ""rsa.h""
 #include ""list.h""
 #include ""sptps.h""
+#include ""compression.h""
 
 #define OPTION_INDIRECT         0x0001
 #define OPTION_TCPONLY          0x0002
@@ -35,21 +36,21 @@
 #define OPTION_VERSION(x) ((x) >> 24) /* Top 8 bits are for protocol minor version */
 
 typedef struct connection_status_t {
-	uint32_t pinged: 1;                 /* sent ping */
-	uint32_t unused_active: 1;
-	uint32_t connecting: 1;             /* 1 if we are waiting for a non-blocking connect() to finish */
-	uint32_t unused_termreq: 1;         /* the termination of this connection was requested */
-	uint32_t remove_unused: 1;          /* Set to 1 if you want this connection removed */
-	uint32_t timeout_unused: 1;         /* 1 if gotten timeout */
-	uint32_t encryptout: 1;             /* 1 if we can encrypt outgoing traffic */
-	uint32_t decryptin: 1;              /* 1 if we have to decrypt incoming traffic */
-	uint32_t mst: 1;                    /* 1 if this connection is part of a minimum spanning tree */
-	uint32_t control: 1;                /* 1 if this is a control connection */
-	uint32_t pcap: 1;                   /* 1 if this is a control connection requesting packet capture */
-	uint32_t log: 1;                    /* 1 if this is a control connection requesting log dump */
-	uint32_t invitation: 1;             /* 1 if this is an invitation */
-	uint32_t invitation_used: 1;        /* 1 if the invitation has been consumed */
-	uint32_t tarpit: 1;                 /* 1 if the connection should be added to the tarpit */
+	bool pinged: 1;                 /* sent ping */
+	bool unused_active: 1;
+	bool connecting: 1;             /* 1 if we are waiting for a non-blocking connect() to finish */
+	bool unused_termreq: 1;         /* the termination of this connection was requested */
+	bool remove_unused: 1;          /* Set to 1 if you want this connection removed */
+	bool timeout_unused: 1;         /* 1 if gotten timeout */
+	bool encryptout: 1;             /* 1 if we can encrypt outgoing traffic */
+	bool decryptin: 1;              /* 1 if we have to decrypt incoming traffic */
+	bool mst: 1;                    /* 1 if this connection is part of a minimum spanning tree */
+	bool control: 1;                /* 1 if this is a control connection */
+	bool pcap: 1;                   /* 1 if this is a control connection requesting packet capture */
+	bool log: 1;                    /* 1 if this is a control connection requesting log dump */
+	bool invitation: 1;             /* 1 if this is an invitation */
+	bool invitation_used: 1;        /* 1 if the invitation has been consumed */
+	bool tarpit: 1;                 /* 1 if the connection should be added to the tarpit */
 	uint32_t unused: 17;
 } connection_status_t;
 
@@ -90,7 +91,7 @@ typedef struct connection_t {
 	sptps_t sptps;
 
 	int outmaclength;
-	int outcompression;
+	compression_level_t outcompression;
 
 	uint8_t *hischallenge;             /* The challenge we sent to him */
 	uint8_t *mychallenge;              /* The challenge we received */
diff --git a/src/fd_device.c b/src/fd_device.c
index 0380f45f..7360d17e 100644
--- a/src/fd_device.c
+++ b/src/fd_device.c
@@ -83,8 +83,8 @@ static int read_fd(int socket) {
 	}
 
 	if(cmsgptr->cmsg_len != CMSG_LEN(sizeof(device_fd))) {
-		logger(DEBUG_ALWAYS, LOG_ERR, ""Wrong CMSG data length: %lu, expected %lu!"",
-		       (unsigned long)cmsgptr->cmsg_len, (unsigned long)CMSG_LEN(sizeof(device_fd)));
+		logger(DEBUG_ALWAYS, LOG_ERR, ""Wrong CMSG data length: %zu, expected %zu!"",
+		       cmsgptr->cmsg_len, CMSG_LEN(sizeof(device_fd)));
 		return -1;
 	}
 
diff --git a/src/gcrypt/digest.c b/src/gcrypt/digest.c
index f790c8fb..383842f6 100644
--- a/src/gcrypt/digest.c
+++ b/src/gcrypt/digest.c
@@ -143,7 +143,7 @@ bool digest_create(digest_t *digest, const void *indata, size_t inlen, void *out
 	unsigned int len = gcry_md_get_algo_dlen(digest->algo);
 
 	if(digest->hmac) {
-		u_int8_t *tmpdata;
+		uint8_t *tmpdata;
 		gcry_md_reset(digest->hmac);
 		gcry_md_write(digest->hmac, indata, inlen);
 		tmpdata = gcry_md_read(digest->hmac, digest->algo);
@@ -164,7 +164,7 @@ bool digest_create(digest_t *digest, const void *indata, size_t inlen, void *out
 
 bool digest_verify(digest_t *digest, const void *indata, size_t inlen, const void *cmpdata) {
 	ssize_t len = digest->maclength;
-	u_int8_t outdata[len];
+	uint8_t outdata[len];
 
 	return digest_create(digest, indata, inlen, outdata) && !memcmp(cmpdata, outdata, len);
 }
diff --git a/src/gcrypt/rsa.c b/src/gcrypt/rsa.c
index e44b3438..c026968a 100644
--- a/src/gcrypt/rsa.c
+++ b/src/gcrypt/rsa.c
@@ -297,7 +297,8 @@ bool rsa_public_encrypt(rsa_t *rsa, void *in, size_t len, void *out) {
 	gcry_mpi_t outmpi = gcry_mpi_new(len * 8);
 	gcry_mpi_powm(outmpi, inmpi, rsa->e, rsa->n);
 
-	size_t pad = len - (gcry_mpi_get_nbits(outmpi) + 7) / 8;
+	size_t out_bytes = (gcry_mpi_get_nbits(outmpi) + 7) / 8;
+	size_t pad = len - MIN(out_bytes, len);
 
 	while(pad--) {
 		*(char *)out++ = 0;
diff --git a/src/graph.c b/src/graph.c
index edd9fc78..4de9181c 100644
--- a/src/graph.c
+++ b/src/graph.c
@@ -90,7 +90,7 @@ static void mst_kruskal(void) {
 	bool skipped = false;
 
 	for splay_each(edge_t, e, edge_weight_tree) {
-		if(!e->reverse || ((uint32_t) e->from->status.visited == e->to->status.visited)) {
+		if(!e->reverse || (e->from->status.visited == e->to->status.visited)) {
 			skipped = true;
 			continue;
 		}
@@ -171,9 +171,9 @@ static void sssp_bfs(void) {
 			     of nodes behind it.
 			 */
 
-			bool indirect = n->status.indirect != 0u || e->options & OPTION_INDIRECT;
+			bool indirect = n->status.indirect || e->options & OPTION_INDIRECT;
 
-			if(e->to->status.visited != 0u
+			if(e->to->status.visited
 			                && (!e->to->status.indirect || indirect)
 			                && (e->to->distance != n->distance + 1 || e->weight >= e->to->prevedge->weight)) {
 				continue;
@@ -214,7 +214,7 @@ static void check_reachability(void) {
 	int became_unreachable_count = 0;
 
 	for splay_each(node_t, n, node_tree) {
-		if((int) n->status.visited != (int) n->status.reachable) {
+		if(n->status.visited != n->status.reachable) {
 			n->status.reachable = !n->status.reachable;
 			n->last_state_change = now.tv_sec;
 
@@ -268,9 +268,9 @@ static void check_reachability(void) {
 			environment_add(&env, ""REMOTEADDRESS=%s"", address);
 			environment_add(&env, ""REMOTEPORT=%s"", port);
 
-			execute_script(n->status.reachable != 0u ? ""host-up"" : ""host-down"", &env);
+			execute_script(n->status.reachable ? ""host-up"" : ""host-down"", &env);
 
-			xasprintf(&name, n->status.reachable != 0u ? ""hosts/%s-up"" : ""hosts/%s-down"", n->name);
+			xasprintf(&name, n->status.reachable ? ""hosts/%s-up"" : ""hosts/%s-down"", n->name);
 			execute_script(name, &env);
 
 			free(name);
@@ -292,7 +292,7 @@ static void check_reachability(void) {
 			}
 		}
 
-		if(n->status.reachable != 0u && n != myself) {
+		if(n->status.reachable && n != myself) {
 			reachable_count++;
 		}
 	}
diff --git a/src/invitation.c b/src/invitation.c
index e2384013..3c23a170 100644
--- a/src/invitation.c
+++ b/src/invitation.c
@@ -170,7 +170,7 @@ char *get_my_hostname() {
 	// Check that the hostname is reasonable
 	if(hostname) {
 		for(char *p = hostname; *p; p++) {
-			if(isalnum(*p) || *p == '-' || *p == '.' || *p == ':') {
+			if(isalnum((uint8_t) *p) || *p == '-' || *p == '.' || *p == ':') {
 				continue;
 			}
 
@@ -216,7 +216,7 @@ again:
 	}
 
 	for(char *p = line; *p; p++) {
-		if(isalnum(*p) || *p == '-' || *p == '.') {
+		if(isalnum((uint8_t) *p) || *p == '-' || *p == '.') {
 			continue;
 		}
 
@@ -572,7 +572,7 @@ static char *get_line(const char **data) {
 		return NULL;
 	}
 
-	if(len && !isprint(**data)) {
+	if(len && !isprint((uint8_t) **data)) {
 		abort();
 	}
 
diff --git a/src/logger.c b/src/logger.c
index 9f9e3f2d..587022a7 100644
--- a/src/logger.c
+++ b/src/logger.c
@@ -106,7 +106,7 @@ static void real_logger(debug_t level, int priority, const char *message) {
 
 			logcontrol = true;
 
-			if(level > (c->outcompression >= 0 ? c->outcompression : debug_level)) {
+			if(level > (c->outcompression >= COMPRESS_NONE ? c->outcompression : debug_level)) {
 				continue;
 			}
 
diff --git a/src/meta.c b/src/meta.c
index debeab45..afc98ab2 100644
--- a/src/meta.c
+++ b/src/meta.c
@@ -56,8 +56,8 @@ bool send_meta(connection_t *c, const void *buffer, size_t length) {
 		abort();
 	}
 
-	logger(DEBUG_META, LOG_DEBUG, ""Sending %lu bytes of metadata to %s (%s)"", (unsigned long)length,
-	       c->name, c->hostname);
+	logger(DEBUG_META, LOG_DEBUG, ""Sending %zu bytes of metadata to %s (%s)"",
+	       length, c->name, c->hostname);
 
 	if(c->protocol_minor >= 2) {
 		return sptps_send_record(&c->sptps, 0, buffer, length);
@@ -100,8 +100,8 @@ void send_meta_raw(connection_t *c, const void *buffer, size_t length) {
 		abort();
 	}
 
-	logger(DEBUG_META, LOG_DEBUG, ""Sending %lu bytes of raw metadata to %s (%s)"", (unsigned long)length,
-	       c->name, c->hostname);
+	logger(DEBUG_META, LOG_DEBUG, ""Sending %zu bytes of raw metadata to %s (%s)"",
+	       length, c->name, c->hostname);
 
 	buffer_add(&c->outbuf, buffer, length);
 
diff --git a/src/net_packet.c b/src/net_packet.c
index 3998dbeb..dab74e5d 100644
--- a/src/net_packet.c
+++ b/src/net_packet.c
@@ -41,6 +41,7 @@
 #include ""cipher.h""
 #include ""conf.h""
 #include ""connection.h""
+#include ""compression.h""
 #include ""crypto.h""
 #include ""digest.h""
 #include ""device.h""
@@ -955,8 +956,8 @@ bool send_sptps_data(node_t *to, node_t *from, int type, const void *data, size_
 
 	if(type == SPTPS_HANDSHAKE || tcponly || (!direct && !relay_supported) || (type != PKT_PROBE && (len - SPTPS_DATAGRAM_OVERHEAD) > relay->minmtu)) {
 		if(type != SPTPS_HANDSHAKE && (to->nexthop->connection->options >> 24) >= 7) {
-			char buf[len + sizeof(to->id) + sizeof(from->id)];
-			char *buf_ptr = buf;
+			uint8_t buf[len + sizeof(to->id) + sizeof(from->id)];
+			uint8_t *buf_ptr = buf;
 			memcpy(buf_ptr, &to->id, sizeof(to->id));
 			buf_ptr += sizeof(to->id);
 			memcpy(buf_ptr, &from->id, sizeof(from->id));
@@ -1137,7 +1138,7 @@ bool receive_sptps_record(void *handle, uint8_t type, const void *data, uint16_t
 		}
 	}
 
-	if(from->status.udppacket != 0u && inpkt.len > from->maxrecentlen) {
+	if(from->status.udppacket && inpkt.len > from->maxrecentlen) {
 		from->maxrecentlen = inpkt.len;
 	}
 
@@ -1195,7 +1196,7 @@ static void try_udp(node_t *n) {
 
 	/* Send gratuitous probe replies to 1.1 nodes. */
 
-	if((n->options >> 24) >= 3 && n->status.udp_confirmed != 0u) {
+	if((n->options >> 24) >= 3 && n->status.udp_confirmed) {
 		struct timeval ping_tx_elapsed;
 		timersub(&now, &n->udp_reply_sent, &ping_tx_elapsed);
 
@@ -1219,7 +1220,7 @@ static void try_udp(node_t *n) {
 	struct timeval ping_tx_elapsed;
 	timersub(&now, &n->udp_ping_sent, &ping_tx_elapsed);
 
-	int interval = n->status.udp_confirmed != 0u
+	int interval = n->status.udp_confirmed
 	               ? udp_discovery_keepalive_interval
 	               : udp_discovery_interval;
 
@@ -1623,7 +1624,7 @@ void broadcast_packet(const node_t *from, vpn_packet_t *packet) {
 	// usually distributes the sending of broadcast packets over all nodes.
 	case BMODE_MST:
 		for list_each(connection_t, c, connection_list)
-			if(c->edge && c->status.mst != 0u && c != from->nexthop->connection) {
+			if(c->edge && c->status.mst && c != from->nexthop->connection) {
 				send_packet(c->node, packet);
 			}
 
@@ -1638,7 +1639,7 @@ void broadcast_packet(const node_t *from, vpn_packet_t *packet) {
 		}
 
 		for splay_each(node_t, n, node_tree)
-			if(n->status.reachable != 0u && n != myself && ((n->via == myself && n->nexthop == n) || n->via == n)) {
+			if(n->status.reachable && n != myself && ((n->via == myself && n->nexthop == n) || n->via == n)) {
 				send_packet(n, packet);
 			}
 
@@ -1665,7 +1666,7 @@ static node_t *try_harder(const sockaddr_t *from, const vpn_packet_t *pkt) {
 			continue;
 		}
 
-		if(!n->status.validkey_in && !(n->status.sptps != 0u && n->sptps.instate)) {
+		if(!n->status.validkey_in && !(n->status.sptps && n->sptps.instate)) {
 			continue;
 		}
 
@@ -1726,7 +1727,7 @@ static void handle_incoming_vpn_packet(listen_socket_t *ls, vpn_packet_t *pkt, s
 		pkt->offset = 2 * sizeof(node_id_t);
 		from = lookup_node_id(SRCID(pkt));
 
-		if(from && from->status.sptps != 0u && !memcmp(DSTID(pkt), &nullid, sizeof(nullid))) {
+		if(from && from->status.sptps && !memcmp(DSTID(pkt), &nullid, sizeof(nullid))) {
 			if(sptps_verify_datagram(&from->sptps, DATA(pkt), pkt->len - 2 * sizeof(node_id_t))) {
 				n = from;
 			} else {
diff --git a/src/net_setup.c b/src/net_setup.c
index 42a67a7f..90a78495 100644
--- a/src/net_setup.c
+++ b/src/net_setup.c
@@ -26,6 +26,7 @@
 #include ""conf_net.h""
 #include ""conf.h""
 #include ""connection.h""
+#include ""compression.h""
 #include ""control.h""
 #include ""device.h""
 #include ""digest.h""
@@ -859,8 +860,9 @@ static bool setup_myself(void) {
 #endif
 
 	/* Compression */
+	int compression = COMPRESS_NONE;
 
-	if(get_config_int(lookup_config(config_tree, ""Compression""), (int *) &myself->incompression)) {
+	if(get_config_int(lookup_config(config_tree, ""Compression""), &compression)) {
 		switch(myself->incompression) {
 		case COMPRESS_LZ4:
 #ifdef HAVE_LZ4
@@ -906,6 +908,8 @@ static bool setup_myself(void) {
 			logger(DEBUG_ALWAYS, LOG_ERR, ""Compression level %i is unrecognized by this node."", myself->incompression);
 			return false;
 		}
+
+		myself->incompression = compression;
 	} else {
 		myself->incompression = COMPRESS_NONE;
 	}
diff --git a/src/node.h b/src/node.h
index f544ea09..f990c326 100644
--- a/src/node.h
+++ b/src/node.h
@@ -27,42 +27,22 @@
 #include ""digest.h""
 #include ""event.h""
 #include ""subnet.h""
-
-typedef enum compression_level_t {
-	COMPRESS_NONE = 0,
-
-	COMPRESS_ZLIB_1 = 1,
-	COMPRESS_ZLIB_2 = 2,
-	COMPRESS_ZLIB_3 = 3,
-	COMPRESS_ZLIB_4 = 4,
-	COMPRESS_ZLIB_5 = 5,
-	COMPRESS_ZLIB_6 = 6,
-	COMPRESS_ZLIB_7 = 7,
-	COMPRESS_ZLIB_8 = 8,
-	COMPRESS_ZLIB_9 = 9,
-
-	COMPRESS_LZO_LO = 10,
-	COMPRESS_LZO_HI = 11,
-
-	COMPRESS_LZ4 = 12,
-
-	COMPRESS_GUARD = INT_MAX, /* ensure that sizeof(compression_level_t) == sizeof(int) */
-} compression_level_t;
+#include ""compression.h""
 
 typedef struct node_status_t {
-	uint32_t unused_active: 1;          /* 1 if active (not used for nodes) */
-	uint32_t validkey: 1;               /* 1 if we currently have a valid key for him */
-	uint32_t waitingforkey: 1;          /* 1 if we already sent out a request */
-	uint32_t visited: 1;                /* 1 if this node has been visited by one of the graph algorithms */
-	uint32_t reachable: 1;              /* 1 if this node is reachable in the graph */
-	uint32_t indirect: 1;               /* 1 if this node is not directly reachable by us */
-	uint32_t sptps: 1;                  /* 1 if this node supports SPTPS */
-	uint32_t udp_confirmed: 1;          /* 1 if the address is one that we received UDP traffic on */
-	uint32_t send_locally: 1;           /* 1 if the next UDP packet should be sent on the local network */
-	uint32_t udppacket: 1;              /* 1 if the most recently received packet was UDP */
-	uint32_t validkey_in: 1;            /* 1 if we have sent a valid key to him */
-	uint32_t has_address: 1;            /* 1 if we know an external address for this node */
-	uint32_t ping_sent: 1;              /* 1 if we sent a UDP probe but haven't received the reply yet */
+	bool unused_active: 1;          /* 1 if active (not used for nodes) */
+	bool validkey: 1;               /* 1 if we currently have a valid key for him */
+	bool waitingforkey: 1;          /* 1 if we already sent out a request */
+	bool visited: 1;                /* 1 if this node has been visited by one of the graph algorithms */
+	bool reachable: 1;              /* 1 if this node is reachable in the graph */
+	bool indirect: 1;               /* 1 if this node is not directly reachable by us */
+	bool sptps: 1;                  /* 1 if this node supports SPTPS */
+	bool udp_confirmed: 1;          /* 1 if the address is one that we received UDP traffic on */
+	bool send_locally: 1;           /* 1 if the next UDP packet should be sent on the local network */
+	bool udppacket: 1;              /* 1 if the most recently received packet was UDP */
+	bool validkey_in: 1;            /* 1 if we have sent a valid key to him */
+	bool has_address: 1;            /* 1 if we know an external address for this node */
+	bool ping_sent: 1;              /* 1 if we sent a UDP probe but haven't received the reply yet */
 	uint32_t unused: 19;
 } node_status_t;
 
diff --git a/src/protocol.h b/src/protocol.h
index 62bfe1a8..4ea0c8c7 100644
--- a/src/protocol.h
+++ b/src/protocol.h
@@ -107,7 +107,7 @@ extern void send_key_changed(void);
 extern bool send_req_key(struct node_t *to);
 extern bool send_ans_key(struct node_t *to);
 extern bool send_tcppacket(struct connection_t *c, const struct vpn_packet_t *packet);
-extern bool send_sptps_tcppacket(struct connection_t *c, const char *packet, size_t len);
+extern bool send_sptps_tcppacket(struct connection_t *c, const void *packet, size_t len);
 extern bool send_udp_info(struct node_t *from, struct node_t *to);
 extern bool send_mtu_info(struct node_t *from, struct node_t *to, int mtu);
 
diff --git a/src/protocol_auth.c b/src/protocol_auth.c
index dc87f54d..c5ba071d 100644
--- a/src/protocol_auth.c
+++ b/src/protocol_auth.c
@@ -231,11 +231,11 @@ static bool receive_invitation_sptps(void *handle, uint8_t type, const void *dat
 		return true;
 	}
 
-	if(type == 1 && c->status.invitation_used != 0u) {
+	if(type == 1 && c->status.invitation_used) {
 		return finalize_invitation(c, data, len);
 	}
 
-	if(type != 0 || len != 18 || c->status.invitation_used != 0u) {
+	if(type != 0 || len != 18 || c->status.invitation_used) {
 		return false;
 	}
 
diff --git a/src/protocol_key.c b/src/protocol_key.c
index 223a1213..65fd35ec 100644
--- a/src/protocol_key.c
+++ b/src/protocol_key.c
@@ -39,7 +39,7 @@ void send_key_changed(void) {
 	/* Immediately send new keys to directly connected nodes to keep UDP mappings alive */
 
 	for list_each(connection_t, c, connection_list) {
-		if(c->edge && c->node && c->node->status.reachable != 0u && !c->node->status.sptps) {
+		if(c->edge && c->node && c->node->status.reachable && !c->node->status.sptps) {
 			send_ans_key(c->node);
 		}
 	}
@@ -50,7 +50,7 @@ void send_key_changed(void) {
 
 	if(experimental) {
 		for splay_each(node_t, n, node_tree) {
-			if(n->status.reachable != 0u && n->status.validkey != 0u && n->status.sptps != 0u) {
+			if(n->status.reachable && n->status.validkey && n->status.sptps) {
 				sptps_force_kex(&n->sptps);
 			}
 		}
diff --git a/src/protocol_misc.c b/src/protocol_misc.c
index 5c957533..7994f00d 100644
--- a/src/protocol_misc.c
+++ b/src/protocol_misc.c
@@ -110,7 +110,7 @@ bool tcppacket_h(connection_t *c, const char *request) {
 	return true;
 }
 
-bool send_sptps_tcppacket(connection_t *c, const char *packet, size_t len) {
+bool send_sptps_tcppacket(connection_t *c, const void *packet, size_t len) {
 	/* If there already is a lot of data in the outbuf buffer, discard this packet.
 	   We use a very simple Random Early Drop algorithm. */
 
diff --git a/src/solaris/device.c b/src/solaris/device.c
index f27954b1..d1e114ae 100644
--- a/src/solaris/device.c
+++ b/src/solaris/device.c
@@ -104,7 +104,7 @@ static bool setup_device(void) {
 	char *ptr = device;
 	get_config_string(lookup_config(config_tree, ""Interface""), &ptr);
 
-	while(*ptr && !isdigit(*ptr)) {
+	while(*ptr && !isdigit((uint8_t) *ptr)) {
 		ptr++;
 	}
 
diff --git a/src/subnet.c b/src/subnet.c
index 5e4c1b0e..13c46030 100644
--- a/src/subnet.c
+++ b/src/subnet.c
@@ -132,7 +132,7 @@ subnet_t *lookup_subnet_mac(const node_t *owner, const mac_t *address) {
 		if(!memcmp(address, &p->net.mac.address, sizeof(*address))) {
 			r = p;
 
-			if(!p->owner || p->owner->status.reachable != 0u) {
+			if(!p->owner || p->owner->status.reachable) {
 				break;
 			}
 		}
@@ -166,7 +166,7 @@ subnet_t *lookup_subnet_ipv4(const ipv4_t *address) {
 		if(!maskcmp(address, &p->net.ipv4.address, p->net.ipv4.prefixlength)) {
 			r = p;
 
-			if(!p->owner || p->owner->status.reachable != 0u) {
+			if(!p->owner || p->owner->status.reachable) {
 				break;
 			}
 		}
@@ -200,7 +200,7 @@ subnet_t *lookup_subnet_ipv6(const ipv6_t *address) {
 		if(!maskcmp(address, &p->net.ipv6.address, p->net.ipv6.prefixlength)) {
 			r = p;
 
-			if(!p->owner || p->owner->status.reachable != 0u) {
+			if(!p->owner || p->owner->status.reachable) {
 				break;
 			}
 		}
diff --git a/src/tincd.c b/src/tincd.c
index 3355067c..95872c34 100644
--- a/src/tincd.c
+++ b/src/tincd.c
@@ -507,8 +507,12 @@ int main(int argc, char **argv) {
 		return 1;
 	}
 
-	if(!debug_level) {
-		get_config_int(lookup_config(config_tree, ""LogLevel""), (int *) &debug_level);
+	if(debug_level == DEBUG_NOTHING) {
+		int level = 0;
+
+		if(get_config_int(lookup_config(config_tree, ""LogLevel""), &level)) {
+			debug_level = level;
+		}
 	}
 
 #ifdef HAVE_LZO
diff --git a/src/utils.c b/src/utils.c
index 71359f23..57983241 100644
--- a/src/utils.c
+++ b/src/utils.c
@@ -46,10 +46,12 @@ static const char base64_decode[256] = {
         };
 
 static uint8_t charhex2bin(char c) {
-	if(isdigit(c)) {
-		return c - '0';
+	uint8_t cu = (uint8_t) c;
+
+	if(isdigit(cu)) {
+		return cu - '0';
 	} else {
-		return toupper((uint8_t) c) - 'A' + 10;
+		return toupper(cu) - 'A' + 10;
 	}
 }
 
@@ -57,7 +59,7 @@ size_t hex2bin(const char *src, void *vdst, size_t length) {
 	uint8_t *dst = vdst;
 	size_t i;
 
-	for(i = 0; i < length && isxdigit(src[i * 2]) && isxdigit(src[i * 2 + 1]); i++) {
+	for(i = 0; i < length && isxdigit((uint8_t) src[i * 2]) && isxdigit((uint8_t) src[i * 2 + 1]); i++) {
 		dst[i] = charhex2bin(src[i * 2]) * 16 + charhex2bin(src[i * 2 + 1]);
 	}
 
@@ -210,7 +212,7 @@ bool check_id(const char *id) {
 	}
 
 	for(; *id; id++)
-		if(!isalnum(*id) && *id != '_') {
+		if(!isalnum((uint8_t) *id) && *id != '_') {
 			return false;
 		}
 
@@ -223,7 +225,7 @@ bool check_netname(const char *netname, bool strict) {
 	}
 
 	for(const char *c = netname; *c; c++) {
-		if(iscntrl(*c)) {
+		if(iscntrl((uint8_t) *c)) {
 			return false;
 		}
 
@@ -269,7 +271,7 @@ char *replace_name(const char *name) {
 		ret_name = xstrdup(envname);
 
 		for(char *c = ret_name; *c; c++)
-			if(!isalnum(*c)) {
+			if(!isalnum((uint8_t) *c)) {
 				*c = '_';
 			}
 	} else {",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,296,2021-08-01T11:13:09Z,2021-08-02T10:10:11Z,2021-08-02T10:13:14Z,MERGED,True,647,431,95,https://github.com/hg,"Add clang-tidy to CI, fix reported narrowing conversion warnings",4,[],https://github.com/gsliepen/tinc/pull/296,https://github.com/gsliepen,3,https://github.com/gsliepen/tinc/pull/296#issuecomment-890553623,"This gets rid of all reported narrowing casts (eliminating them whenever possible, and adding explicit casts to silence the useless warning otherwise), and adjusts variable types where it makes sense to do so:

char → uint8_t where memory is expected to contain opaque binary data
ssize_t where it is returned by library functions
size_t for sizeof(..) results, storing array indices, etc.
ptrdiff_t for pointer arithmetic results
and so on

clang-tidy has been added to CI and will fail if it finds anything suspicious. Only narrowing casts are checked for now (see .clang-tidy), we can enable more warning types one by one after fixing them.
The full list for you particular version of clang can be obtained with:
$ clang-tidy --checks='*' --list-checks

or here.
You may also find this page useful.
Cryptographic functions are skipped because they produce a ton of warnings and it's probably best not to mess with them.
Solaris and Windows code is also skipped because clang-tidy requires a fully working translation unit with all included headers present. I couldn't build compilation database on Windows (autotools really doesn't make it easy, and most tools to do it don't work there), and we have no CI for Solaris.
When (if) we switch the build system to something more modern that generates the compilation database without third-party tools, this could be updated.

https://builds.sr.ht/~reducer/job/557195
https://builds.sr.ht/~reducer/job/557202
https://builds.sr.ht/~reducer/job/557201
https://github.com/hg/tinc/actions/runs/1087055817 (with e050753 reverted)
https://github.com/hg/tinc/actions/runs/1087167564
https://github.com/hg/tinc/actions/runs/1087131224
https://github.com/hg/tinc/actions/runs/1087042963
https://github.com/hg/tinc/actions/runs/1086990423
https://github.com/hg/tinc/actions/runs/1086632473
https://github.com/hg/tinc/actions/runs/1086801641

These warnings are caused by system headers which we can't do anything about:
...
1184 warnings generated.
1201 warnings generated.
Suppressed 1201 warnings (1104 in non-user code, 97 with check filters).

For comparison, here's an example of a real issue:

FreeBSD
macOS

Linux job won't show this until GitHub update their Ubuntu VMs to clang-tidy 12 or later. It cannot easily be installed manually because of broken dependencies. We can work around this with a separate container, but the best solution IMHO is to simply wait until clang-tidy is updated, and rely on FreeBSD and macOS for now.","Huge thanks for taking the time to review this. I fixed everything except for this (I'll await your judgement on that), plus all calls to functions from ctype and unnecessary casts to unsigned int (instead of %zu).

No thank you for putting in the time to do all these cleanups, it is very much appreciated!",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,296,2021-08-01T11:13:09Z,2021-08-02T10:10:11Z,2021-08-02T10:13:14Z,MERGED,True,647,431,95,https://github.com/hg,"Add clang-tidy to CI, fix reported narrowing conversion warnings",4,[],https://github.com/gsliepen/tinc/pull/296,https://github.com/hg,4,https://github.com/gsliepen/tinc/pull/296#issuecomment-890569028,"This gets rid of all reported narrowing casts (eliminating them whenever possible, and adding explicit casts to silence the useless warning otherwise), and adjusts variable types where it makes sense to do so:

char → uint8_t where memory is expected to contain opaque binary data
ssize_t where it is returned by library functions
size_t for sizeof(..) results, storing array indices, etc.
ptrdiff_t for pointer arithmetic results
and so on

clang-tidy has been added to CI and will fail if it finds anything suspicious. Only narrowing casts are checked for now (see .clang-tidy), we can enable more warning types one by one after fixing them.
The full list for you particular version of clang can be obtained with:
$ clang-tidy --checks='*' --list-checks

or here.
You may also find this page useful.
Cryptographic functions are skipped because they produce a ton of warnings and it's probably best not to mess with them.
Solaris and Windows code is also skipped because clang-tidy requires a fully working translation unit with all included headers present. I couldn't build compilation database on Windows (autotools really doesn't make it easy, and most tools to do it don't work there), and we have no CI for Solaris.
When (if) we switch the build system to something more modern that generates the compilation database without third-party tools, this could be updated.

https://builds.sr.ht/~reducer/job/557195
https://builds.sr.ht/~reducer/job/557202
https://builds.sr.ht/~reducer/job/557201
https://github.com/hg/tinc/actions/runs/1087055817 (with e050753 reverted)
https://github.com/hg/tinc/actions/runs/1087167564
https://github.com/hg/tinc/actions/runs/1087131224
https://github.com/hg/tinc/actions/runs/1087042963
https://github.com/hg/tinc/actions/runs/1086990423
https://github.com/hg/tinc/actions/runs/1086632473
https://github.com/hg/tinc/actions/runs/1086801641

These warnings are caused by system headers which we can't do anything about:
...
1184 warnings generated.
1201 warnings generated.
Suppressed 1201 warnings (1104 in non-user code, 97 with check filters).

For comparison, here's an example of a real issue:

FreeBSD
macOS

Linux job won't show this until GitHub update their Ubuntu VMs to clang-tidy 12 or later. It cannot easily be installed manually because of broken dependencies. We can work around this with a separate container, but the best solution IMHO is to simply wait until clang-tidy is updated, and rely on FreeBSD and macOS for now.","I think this covers everything for now.
diff --git a/src/digest.h b/src/digest.h
index c7ffdf0b..1cebf582 100644
--- a/src/digest.h
+++ b/src/digest.h
@@ -23,13 +23,14 @@
 #include ""system.h""
 
 #define DIGEST_MAX_SIZE 64
+#define DIGEST_ALGO_SIZE ((size_t) -1)
 
 #ifndef DISABLE_LEGACY
 
 typedef struct digest digest_t;
 
-extern digest_t *digest_open_by_name(const char *name, int maclength) __attribute__((__malloc__));
-extern digest_t *digest_open_by_nid(int nid, ssize_t maclength) __attribute__((__malloc__));
+extern digest_t *digest_open_by_name(const char *name, size_t maclength) __attribute__((__malloc__));
+extern digest_t *digest_open_by_nid(int nid, size_t maclength) __attribute__((__malloc__));
 extern void digest_close(digest_t *digest);
 extern bool digest_create(digest_t *digest, const void *indata, size_t inlen, void *outdata) __attribute__((__warn_unused_result__));
 extern bool digest_verify(digest_t *digest, const void *indata, size_t inlen, const void *digestdata) __attribute__((__warn_unused_result__));
@@ -39,6 +40,6 @@ extern size_t digest_keylength(const digest_t *digest);
 extern size_t digest_length(const digest_t *digest);
 extern bool digest_active(const digest_t *digest);
 
-#endif
+#endif // DISABLE_LEGACY
 
-#endif
+#endif // TINC_DIGEST_H
diff --git a/src/gcrypt/digest.c b/src/gcrypt/digest.c
index 383842f6..3333f5f2 100644
--- a/src/gcrypt/digest.c
+++ b/src/gcrypt/digest.c
@@ -24,7 +24,7 @@
 
 static struct {
 	const char *name;
-	int algo;
+	enum gcry_md_algos algo;
 	int nid;
 } digesttable[] = {
 	{""none"", GCRY_MD_NONE, 0},
@@ -34,7 +34,7 @@ static struct {
 	{""sha512"", GCRY_MD_SHA512, 674},
 };
 
-static bool nametodigest(const char *name, int *algo) {
+static bool nametodigest(const char *name, enum gcry_md_algos *algo) {
 	int i;
 
 	for(i = 0; i < sizeof(digesttable) / sizeof(*digesttable); i++) {
@@ -47,10 +47,8 @@ static bool nametodigest(const char *name, int *algo) {
 	return false;
 }
 
-static bool nidtodigest(int nid, int *algo) {
-	int i;
-
-	for(i = 0; i < sizeof(digesttable) / sizeof(*digesttable); i++) {
+static bool nidtodigest(int nid, enum gcry_md_algos *algo) {
+	for(int i = 0; i < sizeof(digesttable) / sizeof(*digesttable); i++) {
 		if(nid == digesttable[i].nid) {
 			*algo = digesttable[i].algo;
 			return true;
@@ -60,10 +58,8 @@ static bool nidtodigest(int nid, int *algo) {
 	return false;
 }
 
-static bool digesttonid(int algo, int *nid) {
-	int i;
-
-	for(i = 0; i < sizeof(digesttable) / sizeof(*digesttable); i++) {
+static bool digesttonid(enum gcry_md_algos algo, int *nid) {
+	for(int i = 0; i < sizeof(digesttable) / sizeof(*digesttable); i++) {
 		if(algo == digesttable[i].algo) {
 			*nid = digesttable[i].nid;
 			return true;
@@ -73,7 +69,7 @@ static bool digesttonid(int algo, int *nid) {
 	return false;
 }
 
-static bool digest_open(digest_t *digest, int algo, int maclength) {
+static bool digest_open(digest_t *digest, enum gcry_md_algos algo, size_t maclength) {
 	if(!digesttonid(algo, &digest->nid)) {
 		logger(DEBUG_ALWAYS, LOG_DEBUG, ""Digest %d has no corresponding nid!"", algo);
 		return false;
@@ -93,8 +89,8 @@ static bool digest_open(digest_t *digest, int algo, int maclength) {
 	return true;
 }
 
-bool digest_open_by_name(digest_t *digest, const char *name, int maclength) {
-	int algo;
+bool digest_open_by_name(digest_t *digest, const char *name, size_t maclength) {
+	enum gcry_md_algos algo;
 
 	if(!nametodigest(name, &algo)) {
 		logger(DEBUG_ALWAYS, LOG_DEBUG, ""Unknown digest name '%s'!"", name);
@@ -104,8 +100,8 @@ bool digest_open_by_name(digest_t *digest, const char *name, int maclength) {
 	return digest_open(digest, algo, maclength);
 }
 
-bool digest_open_by_nid(digest_t *digest, int nid, int maclength) {
-	int algo;
+bool digest_open_by_nid(digest_t *digest, int nid, size_t maclength) {
+	enum gcry_md_algos algo;
 
 	if(!nidtodigest(nid, &algo)) {
 		logger(DEBUG_ALWAYS, LOG_DEBUG, ""Unknown digest ID %d!"", nid);
@@ -115,7 +111,7 @@ bool digest_open_by_nid(digest_t *digest, int nid, int maclength) {
 	return digest_open(digest, algo, maclength);
 }
 
-bool digest_open_sha1(digest_t *digest, int maclength) {
+bool digest_open_sha1(digest_t *digest, size_t maclength) {
 	return digest_open(digest, GCRY_MD_SHA1, maclength);
 }
 
@@ -163,7 +159,7 @@ bool digest_create(digest_t *digest, const void *indata, size_t inlen, void *out
 }
 
 bool digest_verify(digest_t *digest, const void *indata, size_t inlen, const void *cmpdata) {
-	ssize_t len = digest->maclength;
+	size_t len = digest->maclength;
 	uint8_t outdata[len];
 
 	return digest_create(digest, indata, inlen, outdata) && !memcmp(cmpdata, outdata, len);
diff --git a/src/gcrypt/digest.h b/src/gcrypt/digest.h
index 6ba5dd56..9a9c611e 100644
--- a/src/gcrypt/digest.h
+++ b/src/gcrypt/digest.h
@@ -25,15 +25,15 @@
 #define DIGEST_MAX_SIZE 64
 
 typedef struct digest {
-	int algo;
+	enum gcry_md_algos algo;
 	int nid;
-	ssize_t maclength;
+	size_t maclength;
 	gcry_md_hd_t hmac;
 } digest_t;
 
-extern bool digest_open_by_name(struct digest *, const char *name, int maclength);
-extern bool digest_open_by_nid(struct digest *, int nid, int maclength);
-extern bool digest_open_sha1(struct digest *, int maclength);
+extern bool digest_open_by_name(struct digest *, const char *name, size_t maclength);
+extern bool digest_open_by_nid(struct digest *, int nid, size_t maclength);
+extern bool digest_open_sha1(struct digest *, size_t maclength);
 extern void digest_close(struct digest *);
 extern bool digest_create(struct digest *, const void *indata, size_t inlen, void *outdata);
 extern bool digest_verify(struct digest *, const void *indata, size_t inlen, const void *digestdata);
diff --git a/src/net_setup.c b/src/net_setup.c
index 90a78495..02dfd74b 100644
--- a/src/net_setup.c
+++ b/src/net_setup.c
@@ -863,6 +863,8 @@ static bool setup_myself(void) {
 	int compression = COMPRESS_NONE;
 
 	if(get_config_int(lookup_config(config_tree, ""Compression""), &compression)) {
+		myself->incompression = compression;
+
 		switch(myself->incompression) {
 		case COMPRESS_LZ4:
 #ifdef HAVE_LZ4
@@ -908,8 +910,6 @@ static bool setup_myself(void) {
 			logger(DEBUG_ALWAYS, LOG_ERR, ""Compression level %i is unrecognized by this node."", myself->incompression);
 			return false;
 		}
-
-		myself->incompression = compression;
 	} else {
 		myself->incompression = COMPRESS_NONE;
 	}
diff --git a/src/openssl/digest.c b/src/openssl/digest.c
index 2be310d2..82364e71 100644
--- a/src/openssl/digest.c
+++ b/src/openssl/digest.c
@@ -27,13 +27,13 @@
 #include ""../digest.h""
 #include ""../logger.h""
 
-static digest_t *digest_open(const EVP_MD *evp_md, ssize_t maclength) {
+static digest_t *digest_open(const EVP_MD *evp_md, size_t maclength) {
 	digest_t *digest = xzalloc(sizeof(*digest));
 	digest->digest = evp_md;
 
 	size_t digestlen = EVP_MD_size(digest->digest);
 
-	if(maclength < 0 || (size_t) maclength > digestlen) {
+	if(maclength == DIGEST_ALGO_SIZE || maclength > digestlen) {
 		digest->maclength = digestlen;
 	} else {
 		digest->maclength = maclength;
@@ -42,7 +42,7 @@ static digest_t *digest_open(const EVP_MD *evp_md, ssize_t maclength) {
 	return digest;
 }
 
-digest_t *digest_open_by_name(const char *name, int maclength) {
+digest_t *digest_open_by_name(const char *name, size_t maclength) {
 	const EVP_MD *evp_md = EVP_get_digestbyname(name);
 
 	if(!evp_md) {
@@ -53,7 +53,7 @@ digest_t *digest_open_by_name(const char *name, int maclength) {
 	return digest_open(evp_md, maclength);
 }
 
-digest_t *digest_open_by_nid(int nid, ssize_t maclength) {
+digest_t *digest_open_by_nid(int nid, size_t maclength) {
 	const EVP_MD *evp_md = EVP_get_digestbynid(nid);
 
 	if(!evp_md) {
diff --git a/src/openssl/prf.c b/src/openssl/prf.c
index b7a77f99..62770859 100644
--- a/src/openssl/prf.c
+++ b/src/openssl/prf.c
@@ -30,7 +30,7 @@
  */
 
 static bool prf_xor(int nid, const uint8_t *secret, size_t secretlen, uint8_t *seed, size_t seedlen, uint8_t *out, size_t outlen) {
-	digest_t *digest = digest_open_by_nid(nid, -1);
+	digest_t *digest = digest_open_by_nid(nid, DIGEST_ALGO_SIZE);
 
 	if(!digest) {
 		return false;
diff --git a/src/protocol_auth.c b/src/protocol_auth.c
index c5ba071d..e16fe4fc 100644
--- a/src/protocol_auth.c
+++ b/src/protocol_auth.c
@@ -518,13 +518,9 @@ bool send_metakey(connection_t *c) {
 		c->outcipher = cipher_open_by_name(""aes-256-cfb"");
 	}
 
-	if(!c) {
-		return false;
-	}
-
 	c->outbudget = cipher_budget(c->outcipher);
 
-	if(!(c->outdigest = digest_open_by_name(""sha256"", -1))) {
+	if(!(c->outdigest = digest_open_by_name(""sha256"", DIGEST_ALGO_SIZE))) {
 		return false;
 	}
 
@@ -639,7 +635,7 @@ bool metakey_h(connection_t *c, const char *request) {
 	c->inbudget = cipher_budget(c->incipher);
 
 	if(digest) {
-		if(!(c->indigest = digest_open_by_nid(digest, -1))) {
+		if(!(c->indigest = digest_open_by_nid(digest, DIGEST_ALGO_SIZE))) {
 			logger(DEBUG_ALWAYS, LOG_ERR, ""Error during initialisation of digest from %s (%s)"", c->name, c->hostname);
 			return false;
 		}
diff --git a/src/protocol_key.c b/src/protocol_key.c
index 65fd35ec..012f2267 100644
--- a/src/protocol_key.c
+++ b/src/protocol_key.c
@@ -356,7 +356,7 @@ bool send_ans_key(node_t *to) {
 
 	if(myself->indigest) {
 		to->indigest = digest_open_by_nid(digest_get_nid(myself->indigest),
-		                                  (ssize_t)digest_length(myself->indigest));
+		                                  digest_length(myself->indigest));
 
 		if(!to->indigest) {
 			abort();
@@ -397,11 +397,11 @@ bool ans_key_h(connection_t *c, const char *request) {
 	char address[MAX_STRING_SIZE] = """";
 	char port[MAX_STRING_SIZE] = """";
 	int cipher, digest;
-	ssize_t maclength;
+	size_t maclength;
 	compression_level_t compression;
 	node_t *from, *to;
 
-	if(sscanf(request, ""%*d ""MAX_STRING"" ""MAX_STRING"" ""MAX_STRING"" %d %d %zd %d ""MAX_STRING"" ""MAX_STRING,
+	if(sscanf(request, ""%*d ""MAX_STRING"" ""MAX_STRING"" ""MAX_STRING"" %d %d %zu %d ""MAX_STRING"" ""MAX_STRING,
 	                from_name, to_name, key, &cipher, &digest, &maclength,
 	                &compression, address, port) < 7) {
 		logger(DEBUG_ALWAYS, LOG_ERR, ""Got bad %s from %s (%s)"", ""ANS_KEY"", c->name,
@@ -467,7 +467,7 @@ bool ans_key_h(connection_t *c, const char *request) {
 	}
 
 	switch(compression) {
-	case 12:
+	case COMPRESS_LZ4:
 #ifdef HAVE_LZ4
 		break;
 #else
@@ -476,8 +476,8 @@ bool ans_key_h(connection_t *c, const char *request) {
 		return true;
 #endif
 
-	case 11:
-	case 10:
+	case COMPRESS_LZO_HI:
+	case COMPRESS_LZO_LO:
 #ifdef HAVE_LZO
 		break;
 #else
@@ -486,15 +486,15 @@ bool ans_key_h(connection_t *c, const char *request) {
 		return true;
 #endif
 
-	case 9:
-	case 8:
-	case 7:
-	case 6:
-	case 5:
-	case 4:
-	case 3:
-	case 2:
-	case 1:
+	case COMPRESS_ZLIB_9:
+	case COMPRESS_ZLIB_8:
+	case COMPRESS_ZLIB_7:
+	case COMPRESS_ZLIB_6:
+	case COMPRESS_ZLIB_5:
+	case COMPRESS_ZLIB_4:
+	case COMPRESS_ZLIB_3:
+	case COMPRESS_ZLIB_2:
+	case COMPRESS_ZLIB_1:
 #ifdef HAVE_ZLIB
 		break;
 #else
@@ -503,7 +503,7 @@ bool ans_key_h(connection_t *c, const char *request) {
 		return true;
 #endif
 
-	case 0:
+	case COMPRESS_NONE:
 		break;
 
 	default:",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,297,2021-08-01T18:56:52Z,2021-08-02T10:13:36Z,2021-08-02T10:16:33Z,CLOSED,False,2,1,1,https://github.com/hg,Improve invite-join.test reliability on Alpine Linux.,1,[],https://github.com/gsliepen/tinc/pull/297,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/297,"When joining one tinc to another on Alpine, it seems to be more reliable to receive invitation from one tinc instance and then pass it to another one instead of starting both at the same time and connecting them via a pipe (tinc foo ... | tinc bar ...)
Every time we've seen Alpine fail, it happened here
https://github.com/hg/tinc/blob/317ac584352db2b446e09a10ffb19d0d9f49acff/src/tincctl.c#L465-L473
with this message
Connected to localhost port 30010...
recvline failed: Connection reset by peer
Cannot read greeting from peer
Could not connect to ::1 port 30010: Address not available

This will be improved in due time (I added an item to my todo list and we can probably open a separate issue). In the meantime, we can at least make a failing Alpine job signal something important, before everyone starts ignoring it.
Here's 1200 successful test runs on six different version of Alpine:

https://github.com/hg/tinc/actions/runs/1087334406
https://github.com/hg/tinc/actions/runs/1087337931

Plus the usual:

https://github.com/hg/tinc/actions/runs/1087391861
https://github.com/hg/tinc/actions/runs/1087917968","When joining one tinc to another on Alpine, it seems to be more reliable to receive invitation from one tinc instance and then pass it to another one instead of starting both at the same time and connecting them via a pipe (tinc foo ... | tinc bar ...)
Every time we've seen Alpine fail, it happened here
https://github.com/hg/tinc/blob/317ac584352db2b446e09a10ffb19d0d9f49acff/src/tincctl.c#L465-L473
with this message
Connected to localhost port 30010...
recvline failed: Connection reset by peer
Cannot read greeting from peer
Could not connect to ::1 port 30010: Address not available

This will be improved in due time (I added an item to my todo list and we can probably open a separate issue). In the meantime, we can at least make a failing Alpine job signal something important, before everyone starts ignoring it.
Here's 1200 successful test runs on six different version of Alpine:

https://github.com/hg/tinc/actions/runs/1087334406
https://github.com/hg/tinc/actions/runs/1087337931

Plus the usual:

https://github.com/hg/tinc/actions/runs/1087391861
https://github.com/hg/tinc/actions/runs/1087917968",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,297,2021-08-01T18:56:52Z,2021-08-02T10:13:36Z,2021-08-02T10:16:33Z,CLOSED,False,2,1,1,https://github.com/hg,Improve invite-join.test reliability on Alpine Linux.,1,[],https://github.com/gsliepen/tinc/pull/297,https://github.com/gsliepen,2,https://github.com/gsliepen/tinc/pull/297#issuecomment-890904501,"When joining one tinc to another on Alpine, it seems to be more reliable to receive invitation from one tinc instance and then pass it to another one instead of starting both at the same time and connecting them via a pipe (tinc foo ... | tinc bar ...)
Every time we've seen Alpine fail, it happened here
https://github.com/hg/tinc/blob/317ac584352db2b446e09a10ffb19d0d9f49acff/src/tincctl.c#L465-L473
with this message
Connected to localhost port 30010...
recvline failed: Connection reset by peer
Cannot read greeting from peer
Could not connect to ::1 port 30010: Address not available

This will be improved in due time (I added an item to my todo list and we can probably open a separate issue). In the meantime, we can at least make a failing Alpine job signal something important, before everyone starts ignoring it.
Here's 1200 successful test runs on six different version of Alpine:

https://github.com/hg/tinc/actions/runs/1087334406
https://github.com/hg/tinc/actions/runs/1087337931

Plus the usual:

https://github.com/hg/tinc/actions/runs/1087391861
https://github.com/hg/tinc/actions/runs/1087917968",Cherry-picked as bf7abd5.,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,299,2021-08-08T14:01:39Z,2021-08-10T18:13:12Z,2022-03-13T05:04:24Z,MERGED,True,589,288,29,https://github.com/hg,CI: cross-compilation for MIPS/armv7; build packages on every push,2,"['1.1', 'CI']",https://github.com/gsliepen/tinc/pull/299,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/299,"I propose a few more changes to CI.
Tests:

https://github.com/hg/tinc/actions/runs/1110145524
https://github.com/hg/tinc/actions/runs/1110181726
https://github.com/hg/tinc/actions/runs/1110058391
https://github.com/hg/tinc/actions/runs/1110104752

build more packages
re #289: build deb + rpm + windows packages on every push to the main branch, and on every release:

deb:

Debian stable
Debian testing
Ubuntu LTS (latest)


rpm:

RHEL-ish 7
RHEL-ish 8
Fedora (latest)


and a simple installer for Windows

@fangfufu: did you have any other distributions in mind?
The packages are published as a pre-release on this page, or as a proper release if you use a tag.
The pre-release will always reuse the same tag latest. GitHub does not allow creating releases without tags, so there's not much choice here.
cross-compilation
Add a couple of cross-compilation jobs for two architectures frequently seen in cheap routers: mips and armv7; run tests on resulting binaries using qemu user virtualization.
mips also gives us additional testing on a big-endian architecture.
I also wanted to add s390 (because of this), but it kept failing on key generation with SIGILL (seems to be an omission in qemu).
cleanups
Reuse the same configuration flags and package list as much as possible (by moving them out of the yaml config).
Since the test suite seems to be stable now, I reduced the number of Windows and macOS jobs to one, which is now using the same test script as the Linux jobs (and runs tests both with the default config, and without the legacy protocol). There's not much sense in running multiple jobs: macOS is quickly deprecated after the next release is available, and Windows 2016/2019 are very similar (both use the same msys2 environment).","I propose a few more changes to CI.
Tests:

https://github.com/hg/tinc/actions/runs/1110145524
https://github.com/hg/tinc/actions/runs/1110181726
https://github.com/hg/tinc/actions/runs/1110058391
https://github.com/hg/tinc/actions/runs/1110104752

build more packages
re #289: build deb + rpm + windows packages on every push to the main branch, and on every release:

deb:

Debian stable
Debian testing
Ubuntu LTS (latest)


rpm:

RHEL-ish 7
RHEL-ish 8
Fedora (latest)


and a simple installer for Windows

@fangfufu: did you have any other distributions in mind?
The packages are published as a pre-release on this page, or as a proper release if you use a tag.
The pre-release will always reuse the same tag latest. GitHub does not allow creating releases without tags, so there's not much choice here.
cross-compilation
Add a couple of cross-compilation jobs for two architectures frequently seen in cheap routers: mips and armv7; run tests on resulting binaries using qemu user virtualization.
mips also gives us additional testing on a big-endian architecture.
I also wanted to add s390 (because of this), but it kept failing on key generation with SIGILL (seems to be an omission in qemu).
cleanups
Reuse the same configuration flags and package list as much as possible (by moving them out of the yaml config).
Since the test suite seems to be stable now, I reduced the number of Windows and macOS jobs to one, which is now using the same test script as the Linux jobs (and runs tests both with the default config, and without the legacy protocol). There's not much sense in running multiple jobs: macOS is quickly deprecated after the next release is available, and Windows 2016/2019 are very similar (both use the same msys2 environment).",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,299,2021-08-08T14:01:39Z,2021-08-10T18:13:12Z,2022-03-13T05:04:24Z,MERGED,True,589,288,29,https://github.com/hg,CI: cross-compilation for MIPS/armv7; build packages on every push,2,"['1.1', 'CI']",https://github.com/gsliepen/tinc/pull/299,https://github.com/fangfufu,2,https://github.com/gsliepen/tinc/pull/299#issuecomment-894806770,"I propose a few more changes to CI.
Tests:

https://github.com/hg/tinc/actions/runs/1110145524
https://github.com/hg/tinc/actions/runs/1110181726
https://github.com/hg/tinc/actions/runs/1110058391
https://github.com/hg/tinc/actions/runs/1110104752

build more packages
re #289: build deb + rpm + windows packages on every push to the main branch, and on every release:

deb:

Debian stable
Debian testing
Ubuntu LTS (latest)


rpm:

RHEL-ish 7
RHEL-ish 8
Fedora (latest)


and a simple installer for Windows

@fangfufu: did you have any other distributions in mind?
The packages are published as a pre-release on this page, or as a proper release if you use a tag.
The pre-release will always reuse the same tag latest. GitHub does not allow creating releases without tags, so there's not much choice here.
cross-compilation
Add a couple of cross-compilation jobs for two architectures frequently seen in cheap routers: mips and armv7; run tests on resulting binaries using qemu user virtualization.
mips also gives us additional testing on a big-endian architecture.
I also wanted to add s390 (because of this), but it kept failing on key generation with SIGILL (seems to be an omission in qemu).
cleanups
Reuse the same configuration flags and package list as much as possible (by moving them out of the yaml config).
Since the test suite seems to be stable now, I reduced the number of Windows and macOS jobs to one, which is now using the same test script as the Linux jobs (and runs tests both with the default config, and without the legacy protocol). There's not much sense in running multiple jobs: macOS is quickly deprecated after the next release is available, and Windows 2016/2019 are very similar (both use the same msys2 environment).",Should we add the latest Ubuntu (21.04) as well?,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,299,2021-08-08T14:01:39Z,2021-08-10T18:13:12Z,2022-03-13T05:04:24Z,MERGED,True,589,288,29,https://github.com/hg,CI: cross-compilation for MIPS/armv7; build packages on every push,2,"['1.1', 'CI']",https://github.com/gsliepen/tinc/pull/299,https://github.com/hg,3,https://github.com/gsliepen/tinc/pull/299#issuecomment-894826523,"I propose a few more changes to CI.
Tests:

https://github.com/hg/tinc/actions/runs/1110145524
https://github.com/hg/tinc/actions/runs/1110181726
https://github.com/hg/tinc/actions/runs/1110058391
https://github.com/hg/tinc/actions/runs/1110104752

build more packages
re #289: build deb + rpm + windows packages on every push to the main branch, and on every release:

deb:

Debian stable
Debian testing
Ubuntu LTS (latest)


rpm:

RHEL-ish 7
RHEL-ish 8
Fedora (latest)


and a simple installer for Windows

@fangfufu: did you have any other distributions in mind?
The packages are published as a pre-release on this page, or as a proper release if you use a tag.
The pre-release will always reuse the same tag latest. GitHub does not allow creating releases without tags, so there's not much choice here.
cross-compilation
Add a couple of cross-compilation jobs for two architectures frequently seen in cheap routers: mips and armv7; run tests on resulting binaries using qemu user virtualization.
mips also gives us additional testing on a big-endian architecture.
I also wanted to add s390 (because of this), but it kept failing on key generation with SIGILL (seems to be an omission in qemu).
cleanups
Reuse the same configuration flags and package list as much as possible (by moving them out of the yaml config).
Since the test suite seems to be stable now, I reduced the number of Windows and macOS jobs to one, which is now using the same test script as the Linux jobs (and runs tests both with the default config, and without the legacy protocol). There's not much sense in running multiple jobs: macOS is quickly deprecated after the next release is available, and Windows 2016/2019 are very similar (both use the same msys2 environment).","Should we add the latest Ubuntu (21.04) as well?

Makes sense, added. The tag misleadingly says ""rolling"", but in reality it's the latest official release.

21.04 doesn't seem to ship libvdeplug_dyn.h, just like Debian sid. Tinc will probably have to be updated to support this, I'll look into it later.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,299,2021-08-08T14:01:39Z,2021-08-10T18:13:12Z,2022-03-13T05:04:24Z,MERGED,True,589,288,29,https://github.com/hg,CI: cross-compilation for MIPS/armv7; build packages on every push,2,"['1.1', 'CI']",https://github.com/gsliepen/tinc/pull/299,https://github.com/gsliepen,4,https://github.com/gsliepen/tinc/pull/299#issuecomment-894837216,"I propose a few more changes to CI.
Tests:

https://github.com/hg/tinc/actions/runs/1110145524
https://github.com/hg/tinc/actions/runs/1110181726
https://github.com/hg/tinc/actions/runs/1110058391
https://github.com/hg/tinc/actions/runs/1110104752

build more packages
re #289: build deb + rpm + windows packages on every push to the main branch, and on every release:

deb:

Debian stable
Debian testing
Ubuntu LTS (latest)


rpm:

RHEL-ish 7
RHEL-ish 8
Fedora (latest)


and a simple installer for Windows

@fangfufu: did you have any other distributions in mind?
The packages are published as a pre-release on this page, or as a proper release if you use a tag.
The pre-release will always reuse the same tag latest. GitHub does not allow creating releases without tags, so there's not much choice here.
cross-compilation
Add a couple of cross-compilation jobs for two architectures frequently seen in cheap routers: mips and armv7; run tests on resulting binaries using qemu user virtualization.
mips also gives us additional testing on a big-endian architecture.
I also wanted to add s390 (because of this), but it kept failing on key generation with SIGILL (seems to be an omission in qemu).
cleanups
Reuse the same configuration flags and package list as much as possible (by moving them out of the yaml config).
Since the test suite seems to be stable now, I reduced the number of Windows and macOS jobs to one, which is now using the same test script as the Linux jobs (and runs tests both with the default config, and without the legacy protocol). There's not much sense in running multiple jobs: macOS is quickly deprecated after the next release is available, and Windows 2016/2019 are very similar (both use the same msys2 environment).","21.04 doesn't seem to ship libvdeplug_dyn.h, just like Debian sid. Tinc will probably have to be updated to support this, I'll look into it later.

I created issue #300 for this.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,299,2021-08-08T14:01:39Z,2021-08-10T18:13:12Z,2022-03-13T05:04:24Z,MERGED,True,589,288,29,https://github.com/hg,CI: cross-compilation for MIPS/armv7; build packages on every push,2,"['1.1', 'CI']",https://github.com/gsliepen/tinc/pull/299,https://github.com/hg,5,https://github.com/gsliepen/tinc/pull/299#issuecomment-894839035,"I propose a few more changes to CI.
Tests:

https://github.com/hg/tinc/actions/runs/1110145524
https://github.com/hg/tinc/actions/runs/1110181726
https://github.com/hg/tinc/actions/runs/1110058391
https://github.com/hg/tinc/actions/runs/1110104752

build more packages
re #289: build deb + rpm + windows packages on every push to the main branch, and on every release:

deb:

Debian stable
Debian testing
Ubuntu LTS (latest)


rpm:

RHEL-ish 7
RHEL-ish 8
Fedora (latest)


and a simple installer for Windows

@fangfufu: did you have any other distributions in mind?
The packages are published as a pre-release on this page, or as a proper release if you use a tag.
The pre-release will always reuse the same tag latest. GitHub does not allow creating releases without tags, so there's not much choice here.
cross-compilation
Add a couple of cross-compilation jobs for two architectures frequently seen in cheap routers: mips and armv7; run tests on resulting binaries using qemu user virtualization.
mips also gives us additional testing on a big-endian architecture.
I also wanted to add s390 (because of this), but it kept failing on key generation with SIGILL (seems to be an omission in qemu).
cleanups
Reuse the same configuration flags and package list as much as possible (by moving them out of the yaml config).
Since the test suite seems to be stable now, I reduced the number of Windows and macOS jobs to one, which is now using the same test script as the Linux jobs (and runs tests both with the default config, and without the legacy protocol). There's not much sense in running multiple jobs: macOS is quickly deprecated after the next release is available, and Windows 2016/2019 are very similar (both use the same msys2 environment).","This will add a small amount of work to package maintainers, but I think it's time to rename README to README.md to force GitHub and Gitlab to properly render it as a Markdown document.
The releases section is simply not discoverable. Nobody will know about nightly builds unless we direct users to it with big, bold letters:
https://github.com/hg/tinc/tree/ci-test#nightly-builds
Should I push this here?",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,299,2021-08-08T14:01:39Z,2021-08-10T18:13:12Z,2022-03-13T05:04:24Z,MERGED,True,589,288,29,https://github.com/hg,CI: cross-compilation for MIPS/armv7; build packages on every push,2,"['1.1', 'CI']",https://github.com/gsliepen/tinc/pull/299,https://github.com/gsliepen,6,https://github.com/gsliepen/tinc/pull/299#issuecomment-894840103,"I propose a few more changes to CI.
Tests:

https://github.com/hg/tinc/actions/runs/1110145524
https://github.com/hg/tinc/actions/runs/1110181726
https://github.com/hg/tinc/actions/runs/1110058391
https://github.com/hg/tinc/actions/runs/1110104752

build more packages
re #289: build deb + rpm + windows packages on every push to the main branch, and on every release:

deb:

Debian stable
Debian testing
Ubuntu LTS (latest)


rpm:

RHEL-ish 7
RHEL-ish 8
Fedora (latest)


and a simple installer for Windows

@fangfufu: did you have any other distributions in mind?
The packages are published as a pre-release on this page, or as a proper release if you use a tag.
The pre-release will always reuse the same tag latest. GitHub does not allow creating releases without tags, so there's not much choice here.
cross-compilation
Add a couple of cross-compilation jobs for two architectures frequently seen in cheap routers: mips and armv7; run tests on resulting binaries using qemu user virtualization.
mips also gives us additional testing on a big-endian architecture.
I also wanted to add s390 (because of this), but it kept failing on key generation with SIGILL (seems to be an omission in qemu).
cleanups
Reuse the same configuration flags and package list as much as possible (by moving them out of the yaml config).
Since the test suite seems to be stable now, I reduced the number of Windows and macOS jobs to one, which is now using the same test script as the Linux jobs (and runs tests both with the default config, and without the legacy protocol). There's not much sense in running multiple jobs: macOS is quickly deprecated after the next release is available, and Windows 2016/2019 are very similar (both use the same msys2 environment).","Should I push this here?

Sure!",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,299,2021-08-08T14:01:39Z,2021-08-10T18:13:12Z,2022-03-13T05:04:24Z,MERGED,True,589,288,29,https://github.com/hg,CI: cross-compilation for MIPS/armv7; build packages on every push,2,"['1.1', 'CI']",https://github.com/gsliepen/tinc/pull/299,https://github.com/hg,7,https://github.com/gsliepen/tinc/pull/299#issuecomment-895788285,"I propose a few more changes to CI.
Tests:

https://github.com/hg/tinc/actions/runs/1110145524
https://github.com/hg/tinc/actions/runs/1110181726
https://github.com/hg/tinc/actions/runs/1110058391
https://github.com/hg/tinc/actions/runs/1110104752

build more packages
re #289: build deb + rpm + windows packages on every push to the main branch, and on every release:

deb:

Debian stable
Debian testing
Ubuntu LTS (latest)


rpm:

RHEL-ish 7
RHEL-ish 8
Fedora (latest)


and a simple installer for Windows

@fangfufu: did you have any other distributions in mind?
The packages are published as a pre-release on this page, or as a proper release if you use a tag.
The pre-release will always reuse the same tag latest. GitHub does not allow creating releases without tags, so there's not much choice here.
cross-compilation
Add a couple of cross-compilation jobs for two architectures frequently seen in cheap routers: mips and armv7; run tests on resulting binaries using qemu user virtualization.
mips also gives us additional testing on a big-endian architecture.
I also wanted to add s390 (because of this), but it kept failing on key generation with SIGILL (seems to be an omission in qemu).
cleanups
Reuse the same configuration flags and package list as much as possible (by moving them out of the yaml config).
Since the test suite seems to be stable now, I reduced the number of Windows and macOS jobs to one, which is now using the same test script as the Linux jobs (and runs tests both with the default config, and without the legacy protocol). There's not much sense in running multiple jobs: macOS is quickly deprecated after the next release is available, and Windows 2016/2019 are very similar (both use the same msys2 environment).","The scripts in the ci/ directory should never be runi by users directly. It might help to add a README.md in that directory explaining their purpose. Maybe also rename the directory to .ci so it's hidden by default?

I did both. We could keep them in .github/, but the paths are unmanageable, and (strictly speaking) it's a directory for GitHub magic files, so who knows what actions they could auto-trigger in the future.
vde2 is now used on every distribution except RHEL-based ones (where you have to build it from source).",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,302,2021-08-08T23:16:42Z,2021-08-09T20:39:38Z,2021-08-09T20:39:39Z,MERGED,True,24,20,2,https://github.com/fangfufu,Use libvdeplug.h instead of libvdeplug_dyn.h,1,"['bug', 'regression', '1.1']",https://github.com/gsliepen/tinc/pull/302,https://github.com/fangfufu,1,https://github.com/gsliepen/tinc/pull/302,"This is my attempt to address issue #300. I changed include from libvdeplug_dyn.h rather than libvdeplug.h.
The libvdeplug.h from Debian Unstable is almost identical to the one from Debian Buster. I think using the statically linked version of libvdeplug might be the quickest and easiest fix. (This is still dynamic linking, please refer to #302 (comment))","This is my attempt to address issue #300. I changed include from libvdeplug_dyn.h rather than libvdeplug.h.
The libvdeplug.h from Debian Unstable is almost identical to the one from Debian Buster. I think using the statically linked version of libvdeplug might be the quickest and easiest fix. (This is still dynamic linking, please refer to #302 (comment))",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,302,2021-08-08T23:16:42Z,2021-08-09T20:39:38Z,2021-08-09T20:39:39Z,MERGED,True,24,20,2,https://github.com/fangfufu,Use libvdeplug.h instead of libvdeplug_dyn.h,1,"['bug', 'regression', '1.1']",https://github.com/gsliepen/tinc/pull/302,https://github.com/fangfufu,2,https://github.com/gsliepen/tinc/pull/302#issuecomment-894873134,"This is my attempt to address issue #300. I changed include from libvdeplug_dyn.h rather than libvdeplug.h.
The libvdeplug.h from Debian Unstable is almost identical to the one from Debian Buster. I think using the statically linked version of libvdeplug might be the quickest and easiest fix. (This is still dynamic linking, please refer to #302 (comment))","@hg, what do you think of this? I added you as a collaborator to my fork, in case you want to directly commit to what I have done so far. 🙂",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,302,2021-08-08T23:16:42Z,2021-08-09T20:39:38Z,2021-08-09T20:39:39Z,MERGED,True,24,20,2,https://github.com/fangfufu,Use libvdeplug.h instead of libvdeplug_dyn.h,1,"['bug', 'regression', '1.1']",https://github.com/gsliepen/tinc/pull/302,https://github.com/Nable80,3,https://github.com/gsliepen/tinc/pull/302#issuecomment-894913096,"This is my attempt to address issue #300. I changed include from libvdeplug_dyn.h rather than libvdeplug.h.
The libvdeplug.h from Debian Unstable is almost identical to the one from Debian Buster. I think using the statically linked version of libvdeplug might be the quickest and easiest fix. (This is still dynamic linking, please refer to #302 (comment))","non-dynamic loading

Is it just static linking?

	ssize_t lenin = (ssize_t) vde_recv(conn, DATA(packet), MTU, 0);
...
	if((ssize_t)vde_send(conn, DATA(packet), packet->len, 0) < 0) {

https://manpages.debian.org/unstable/libvdeplug-dev/vde_recv.3.en.html tells me that vde_recv and vde_send already return ssize_t, why are these casts needed?",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,302,2021-08-08T23:16:42Z,2021-08-09T20:39:38Z,2021-08-09T20:39:39Z,MERGED,True,24,20,2,https://github.com/fangfufu,Use libvdeplug.h instead of libvdeplug_dyn.h,1,"['bug', 'regression', '1.1']",https://github.com/gsliepen/tinc/pull/302,https://github.com/fangfufu,4,https://github.com/gsliepen/tinc/pull/302#issuecomment-894916854,"This is my attempt to address issue #300. I changed include from libvdeplug_dyn.h rather than libvdeplug.h.
The libvdeplug.h from Debian Unstable is almost identical to the one from Debian Buster. I think using the statically linked version of libvdeplug might be the quickest and easiest fix. (This is still dynamic linking, please refer to #302 (comment))",I think it is basically static linking. My knowledge of the linker isn't great. I have never personally written a dynamically linked C program. I basically just worded it in a conservative way. You are write that (ssize_t) casting is no longer required. It was required due to dynamic linking. I have amended the commit.,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,302,2021-08-08T23:16:42Z,2021-08-09T20:39:38Z,2021-08-09T20:39:39Z,MERGED,True,24,20,2,https://github.com/fangfufu,Use libvdeplug.h instead of libvdeplug_dyn.h,1,"['bug', 'regression', '1.1']",https://github.com/gsliepen/tinc/pull/302,https://github.com/Nable80,5,https://github.com/gsliepen/tinc/pull/302#issuecomment-894921639,"This is my attempt to address issue #300. I changed include from libvdeplug_dyn.h rather than libvdeplug.h.
The libvdeplug.h from Debian Unstable is almost identical to the one from Debian Buster. I think using the statically linked version of libvdeplug might be the quickest and easiest fix. (This is still dynamic linking, please refer to #302 (comment))","You can use ldd tool to see which libraries are loaded dynamically when the binary is executed, e.g.:
ldd ./tincd
        linux-vdso.so.1 (0x00007fff837e1000)
        libcrypto.so.1.1 => /usr/lib/x86_64-linux-gnu/libcrypto.so.1.1 (0x00007fa53e40d000)
        libz.so.1 => /lib/x86_64-linux-gnu/libz.so.1 (0x00007fa53e3f0000)
        liblzo2.so.2 => /lib/x86_64-linux-gnu/liblzo2.so.2 (0x00007fa53e3cb000)
        libc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007fa53e206000)
        libdl.so.2 => /lib/x86_64-linux-gnu/libdl.so.2 (0x00007fa53e200000)
        libpthread.so.0 => /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007fa53e1de000)
        /lib64/ld-linux-x86-64.so.2 (0x00007fa53e7bf000)

FYI: statically-linked libraries won't appear in this list. If you see libvde in this list, it's still linked dynamically (and it's not a problem) but it happens when process is started (regular dynamic library behavior) instead of later run-time (plugin style).",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,302,2021-08-08T23:16:42Z,2021-08-09T20:39:38Z,2021-08-09T20:39:39Z,MERGED,True,24,20,2,https://github.com/fangfufu,Use libvdeplug.h instead of libvdeplug_dyn.h,1,"['bug', 'regression', '1.1']",https://github.com/gsliepen/tinc/pull/302,https://github.com/hg,6,https://github.com/gsliepen/tinc/pull/302#issuecomment-894950250,"This is my attempt to address issue #300. I changed include from libvdeplug_dyn.h rather than libvdeplug.h.
The libvdeplug.h from Debian Unstable is almost identical to the one from Debian Buster. I think using the statically linked version of libvdeplug might be the quickest and easiest fix. (This is still dynamic linking, please refer to #302 (comment))","It still uses dynamic linking. It's just that the task of linking the library is passed to the system dynamic linker at tincd start time, instead of doing it manually with libvdeplug_dynopen when vde functionality is actually needed. This is probably the best solution in any case IMHO.
I tested it on Ubuntu 21.04 and Debian Sid, and manually on FreeBSD 11, NetBSD 8, and DragonflyBSD 6. Works fine.
This should probably go in before #299, I will need to adjust build scripts some more.


... tells me that vde_recv and vde_send already return ssize_t, why are these casts needed?

It made sense for the old header because of a bug in declarations there. See this. This header seems to be fine everywhere I checked.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,302,2021-08-08T23:16:42Z,2021-08-09T20:39:38Z,2021-08-09T20:39:39Z,MERGED,True,24,20,2,https://github.com/fangfufu,Use libvdeplug.h instead of libvdeplug_dyn.h,1,"['bug', 'regression', '1.1']",https://github.com/gsliepen/tinc/pull/302,https://github.com/fangfufu,7,https://github.com/gsliepen/tinc/pull/302#issuecomment-895098733,"This is my attempt to address issue #300. I changed include from libvdeplug_dyn.h rather than libvdeplug.h.
The libvdeplug.h from Debian Unstable is almost identical to the one from Debian Buster. I think using the statically linked version of libvdeplug might be the quickest and easiest fix. (This is still dynamic linking, please refer to #302 (comment))","By the way, @gsliepen / @hg, which linter command should I be using?",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,302,2021-08-08T23:16:42Z,2021-08-09T20:39:38Z,2021-08-09T20:39:39Z,MERGED,True,24,20,2,https://github.com/fangfufu,Use libvdeplug.h instead of libvdeplug_dyn.h,1,"['bug', 'regression', '1.1']",https://github.com/gsliepen/tinc/pull/302,https://github.com/hg,8,https://github.com/gsliepen/tinc/pull/302#issuecomment-895107112,"This is my attempt to address issue #300. I changed include from libvdeplug_dyn.h rather than libvdeplug.h.
The libvdeplug.h from Debian Unstable is almost identical to the one from Debian Buster. I think using the statically linked version of libvdeplug might be the quickest and easiest fix. (This is still dynamic linking, please refer to #302 (comment))","I use compilers with sanitizers (both clang and gcc), valgrind to look for memory leaks, clang-tidy, and cppcheck (which breaks on some things because it uses its own parser instead of a compiler backend like clang-tidy does, but it's still useful).
Use this as a starting point:

  
    
      tinc/.github/workflows/test.yml
    
    
        Lines 63 to 68
      in
      bf7abd5
    
  
  
    

        
          
                     find src \ 
        

        
          
                       ! '(' -path src/solaris -prune ')' \ 
        

        
          
                       ! '(' -path src/mingw   -prune ')' \ 
        

        
          
                       ! '(' -path src/bsd     -prune ')' \ 
        

        
          
                       -name '*.c' \ 
        

        
          
                       -exec clang-tidy --header-filter='.*' '{}' + 
        
    
  


and
https://github.com/gsliepen/tinc/tree/1.1/.github/workflows/sanitizers",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,302,2021-08-08T23:16:42Z,2021-08-09T20:39:38Z,2021-08-09T20:39:39Z,MERGED,True,24,20,2,https://github.com/fangfufu,Use libvdeplug.h instead of libvdeplug_dyn.h,1,"['bug', 'regression', '1.1']",https://github.com/gsliepen/tinc/pull/302,https://github.com/hg,9,https://github.com/gsliepen/tinc/pull/302#issuecomment-895115803,"This is my attempt to address issue #300. I changed include from libvdeplug_dyn.h rather than libvdeplug.h.
The libvdeplug.h from Debian Unstable is almost identical to the one from Debian Buster. I think using the statically linked version of libvdeplug might be the quickest and easiest fix. (This is still dynamic linking, please refer to #302 (comment))","Ah, yes, and you need this to reformat C
$ astyle -r --options=.astylerc  --formatted '*.c' '*.h'

and
$ shellcheck -x script.sh
$ shfmt -d -i 2 -s script.sh

if  any scripts were changed.",True,{'THUMBS_UP': ['https://github.com/fangfufu']}
gsliepen/tinc,https://github.com/gsliepen/tinc,302,2021-08-08T23:16:42Z,2021-08-09T20:39:38Z,2021-08-09T20:39:39Z,MERGED,True,24,20,2,https://github.com/fangfufu,Use libvdeplug.h instead of libvdeplug_dyn.h,1,"['bug', 'regression', '1.1']",https://github.com/gsliepen/tinc/pull/302,https://github.com/fangfufu,10,https://github.com/gsliepen/tinc/pull/302#issuecomment-895123209,"This is my attempt to address issue #300. I changed include from libvdeplug_dyn.h rather than libvdeplug.h.
The libvdeplug.h from Debian Unstable is almost identical to the one from Debian Buster. I think using the statically linked version of libvdeplug might be the quickest and easiest fix. (This is still dynamic linking, please refer to #302 (comment))",Ah apologies. I meant formatter rather than linter. I will leave linting / santizing to you CI scripts. Thanks for recognising that I was probably confused. 🙂,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,302,2021-08-08T23:16:42Z,2021-08-09T20:39:38Z,2021-08-09T20:39:39Z,MERGED,True,24,20,2,https://github.com/fangfufu,Use libvdeplug.h instead of libvdeplug_dyn.h,1,"['bug', 'regression', '1.1']",https://github.com/gsliepen/tinc/pull/302,https://github.com/gsliepen,11,https://github.com/gsliepen/tinc/pull/302#issuecomment-895148444,"This is my attempt to address issue #300. I changed include from libvdeplug_dyn.h rather than libvdeplug.h.
The libvdeplug.h from Debian Unstable is almost identical to the one from Debian Buster. I think using the statically linked version of libvdeplug might be the quickest and easiest fix. (This is still dynamic linking, please refer to #302 (comment))","You can run make astyle from the top level build directory. Maybe I should add a ""precommit"" rule or something like that that calls a bunch of stuff to reformat and do some simple checks.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,302,2021-08-08T23:16:42Z,2021-08-09T20:39:38Z,2021-08-09T20:39:39Z,MERGED,True,24,20,2,https://github.com/fangfufu,Use libvdeplug.h instead of libvdeplug_dyn.h,1,"['bug', 'regression', '1.1']",https://github.com/gsliepen/tinc/pull/302,https://github.com/fangfufu,12,https://github.com/gsliepen/tinc/pull/302#issuecomment-895377518,"This is my attempt to address issue #300. I changed include from libvdeplug_dyn.h rather than libvdeplug.h.
The libvdeplug.h from Debian Unstable is almost identical to the one from Debian Buster. I think using the statically linked version of libvdeplug might be the quickest and easiest fix. (This is still dynamic linking, please refer to #302 (comment))","I am pretty sure you have to set up pre-commit hooks manually after you clone the repository. But I suppose it would be nice to provide a script for everyone to use, that can be inside the repository. You can symlink the scrpt as a pre-commit hook.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,303,2021-08-10T00:02:12Z,2021-08-10T01:30:52Z,2021-08-10T01:30:53Z,CLOSED,False,0,0,0,https://github.com/fangfufu,Fix -Wsign-compare error in keys.c,0,[],https://github.com/gsliepen/tinc/pull/303,https://github.com/fangfufu,1,https://github.com/gsliepen/tinc/pull/303,"When compiling with -Wall -Wextra under Debian Buster, I get the following error message:
keys.c: In function ‘disable_old_keys’:
keys.c:26:12: warning: comparison of integer expressions of different signedness: ‘int’ and ‘long unsigned int’ [-Wsign-compare]
  if(result < sizeof(tmpfile)) {

snprintf returns a negative value on output error. In the current implementation, there is no error handling for negative return
values. Therefore in this context, it is acceptable to convert int to size_t.","When compiling with -Wall -Wextra under Debian Buster, I get the following error message:
keys.c: In function ‘disable_old_keys’:
keys.c:26:12: warning: comparison of integer expressions of different signedness: ‘int’ and ‘long unsigned int’ [-Wsign-compare]
  if(result < sizeof(tmpfile)) {

snprintf returns a negative value on output error. In the current implementation, there is no error handling for negative return
values. Therefore in this context, it is acceptable to convert int to size_t.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,304,2021-08-10T01:26:05Z,2021-08-10T19:04:49Z,2021-08-10T19:54:15Z,CLOSED,False,82,70,19,https://github.com/fangfufu,Reduce pointer indirection for global list_t variables,1,"['1.1', 'janitorial']",https://github.com/gsliepen/tinc/pull/304,https://github.com/fangfufu,1,https://github.com/gsliepen/tinc/pull/304,"Converted cmdline_conf, connection_list, outgoing_list from
pointer-to-structs to structs.
Created list_empty_list for these structs. This is necessary,
because list_delete_list frees the supplied list_t pointer.
Part of #294","Converted cmdline_conf, connection_list, outgoing_list from
pointer-to-structs to structs.
Created list_empty_list for these structs. This is necessary,
because list_delete_list frees the supplied list_t pointer.
Part of #294",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,304,2021-08-10T01:26:05Z,2021-08-10T19:04:49Z,2021-08-10T19:54:15Z,CLOSED,False,82,70,19,https://github.com/fangfufu,Reduce pointer indirection for global list_t variables,1,"['1.1', 'janitorial']",https://github.com/gsliepen/tinc/pull/304,https://github.com/fangfufu,2,https://github.com/gsliepen/tinc/pull/304#issuecomment-895663529,"Converted cmdline_conf, connection_list, outgoing_list from
pointer-to-structs to structs.
Created list_empty_list for these structs. This is necessary,
because list_delete_list frees the supplied list_t pointer.
Part of #294",The tests fail for some reason. It would be helpful if someone provides a bit of feedback on this.,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,304,2021-08-10T01:26:05Z,2021-08-10T19:04:49Z,2021-08-10T19:54:15Z,CLOSED,False,82,70,19,https://github.com/fangfufu,Reduce pointer indirection for global list_t variables,1,"['1.1', 'janitorial']",https://github.com/gsliepen/tinc/pull/304,https://github.com/hg,3,https://github.com/gsliepen/tinc/pull/304#issuecomment-895794978,"Converted cmdline_conf, connection_list, outgoing_list from
pointer-to-structs to structs.
Created list_empty_list for these structs. This is necessary,
because list_delete_list frees the supplied list_t pointer.
Part of #294","Try this patch.
diff --git a/src/conf.c b/src/conf.c
index 6b5f1093..90bd3697 100644
--- a/src/conf.c
+++ b/src/conf.c
@@ -44,7 +44,7 @@ list_t cmdline_conf = {
 	.head = NULL,
 	.tail = NULL,
 	.count = 0,
-	.delete = NULL,
+	.delete = (list_action_t)free_config,
 };
 
 static int config_compare(const config_t *a, const config_t *b) {
diff --git a/src/connection.c b/src/connection.c
index 20dc5de7..0c5e7ef0 100644
--- a/src/connection.c
+++ b/src/connection.c
@@ -35,7 +35,7 @@ list_t connection_list = {
 	.head = NULL,
 	.tail = NULL,
 	.count = 0,
-	.delete = NULL,
+	.delete = (list_action_t) free_connection,
 };
 
 connection_t *everyone;",True,{'THUMBS_UP': ['https://github.com/fangfufu']}
gsliepen/tinc,https://github.com/gsliepen/tinc,304,2021-08-10T01:26:05Z,2021-08-10T19:04:49Z,2021-08-10T19:54:15Z,CLOSED,False,82,70,19,https://github.com/fangfufu,Reduce pointer indirection for global list_t variables,1,"['1.1', 'janitorial']",https://github.com/gsliepen/tinc/pull/304,https://github.com/fangfufu,4,https://github.com/gsliepen/tinc/pull/304#issuecomment-895904581,"Converted cmdline_conf, connection_list, outgoing_list from
pointer-to-structs to structs.
Created list_empty_list for these structs. This is necessary,
because list_delete_list frees the supplied list_t pointer.
Part of #294","Thanks, @hg.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,304,2021-08-10T01:26:05Z,2021-08-10T19:04:49Z,2021-08-10T19:54:15Z,CLOSED,False,82,70,19,https://github.com/fangfufu,Reduce pointer indirection for global list_t variables,1,"['1.1', 'janitorial']",https://github.com/gsliepen/tinc/pull/304,https://github.com/fangfufu,5,https://github.com/gsliepen/tinc/pull/304#issuecomment-896229787,"Converted cmdline_conf, connection_list, outgoing_list from
pointer-to-structs to structs.
Created list_empty_list for these structs. This is necessary,
because list_delete_list frees the supplied list_t pointer.
Part of #294","Resolving the conversation does not appear to get rid off the ""change requested"", @splitice. On a side note, I miss the ""Done"" button in Gerrit. 😛",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,304,2021-08-10T01:26:05Z,2021-08-10T19:04:49Z,2021-08-10T19:54:15Z,CLOSED,False,82,70,19,https://github.com/fangfufu,Reduce pointer indirection for global list_t variables,1,"['1.1', 'janitorial']",https://github.com/gsliepen/tinc/pull/304,https://github.com/gsliepen,6,https://github.com/gsliepen/tinc/pull/304#issuecomment-896241621,"Converted cmdline_conf, connection_list, outgoing_list from
pointer-to-structs to structs.
Created list_empty_list for these structs. This is necessary,
because list_delete_list frees the supplied list_t pointer.
Part of #294",Cherry-picked as 0871c30.,True,{'THUMBS_UP': ['https://github.com/fangfufu']}
gsliepen/tinc,https://github.com/gsliepen/tinc,305,2021-08-10T01:31:38Z,2021-08-10T18:36:50Z,2021-08-10T18:48:03Z,CLOSED,False,1,1,1,https://github.com/fangfufu,Fix -Wsign-compare error in keys.c,1,"['1.1', 'janitorial']",https://github.com/gsliepen/tinc/pull/305,https://github.com/fangfufu,1,https://github.com/gsliepen/tinc/pull/305,"When compiling with -Wall -Wextra under Debian Buster, I get the following error message:
keys.c: In function ‘disable_old_keys’:
keys.c:26:12: warning: comparison of integer expressions of different signedness: ‘int’ and ‘long unsigned int’ [-Wsign-compare]
  if(result < sizeof(tmpfile)) {

snprintf returns a negative value on output error. In the current implementation, there is no error handling for negative return
values. Therefore in this context, it is acceptable to convert int to size_t.","When compiling with -Wall -Wextra under Debian Buster, I get the following error message:
keys.c: In function ‘disable_old_keys’:
keys.c:26:12: warning: comparison of integer expressions of different signedness: ‘int’ and ‘long unsigned int’ [-Wsign-compare]
  if(result < sizeof(tmpfile)) {

snprintf returns a negative value on output error. In the current implementation, there is no error handling for negative return
values. Therefore in this context, it is acceptable to convert int to size_t.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,305,2021-08-10T01:31:38Z,2021-08-10T18:36:50Z,2021-08-10T18:48:03Z,CLOSED,False,1,1,1,https://github.com/fangfufu,Fix -Wsign-compare error in keys.c,1,"['1.1', 'janitorial']",https://github.com/gsliepen/tinc/pull/305,https://github.com/gsliepen,2,https://github.com/gsliepen/tinc/pull/305#issuecomment-896223340,"When compiling with -Wall -Wextra under Debian Buster, I get the following error message:
keys.c: In function ‘disable_old_keys’:
keys.c:26:12: warning: comparison of integer expressions of different signedness: ‘int’ and ‘long unsigned int’ [-Wsign-compare]
  if(result < sizeof(tmpfile)) {

snprintf returns a negative value on output error. In the current implementation, there is no error handling for negative return
values. Therefore in this context, it is acceptable to convert int to size_t.",Cherry-picked as 9e917cc. Thanks!,True,{'THUMBS_UP': ['https://github.com/fangfufu']}
gsliepen/tinc,https://github.com/gsliepen/tinc,307,2021-08-10T15:09:17Z,2021-08-11T18:24:18Z,2022-03-13T05:04:42Z,CLOSED,False,294,295,36,https://github.com/hg,Replace pointers to global splay trees with structs.,2,"['1.1', 'janitorial']",https://github.com/gsliepen/tinc/pull/307,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/307,"Related to #294
This gets rid of global pointers to splay trees.
In addition to this, I also wanted to replace pointers in struct members, but it's more difficult and will take some time. In light of #304 I'll PR this now so we could avoid repeating the same work.","Related to #294
This gets rid of global pointers to splay trees.
In addition to this, I also wanted to replace pointers in struct members, but it's more difficult and will take some time. In light of #304 I'll PR this now so we could avoid repeating the same work.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,307,2021-08-10T15:09:17Z,2021-08-11T18:24:18Z,2022-03-13T05:04:42Z,CLOSED,False,294,295,36,https://github.com/hg,Replace pointers to global splay trees with structs.,2,"['1.1', 'janitorial']",https://github.com/gsliepen/tinc/pull/307,https://github.com/gsliepen,2,https://github.com/gsliepen/tinc/pull/307#issuecomment-897050987,"Related to #294
This gets rid of global pointers to splay trees.
In addition to this, I also wanted to replace pointers in struct members, but it's more difficult and will take some time. In light of #304 I'll PR this now so we could avoid repeating the same work.",Rebased and merged. Thanks!,True,"{'THUMBS_UP': ['https://github.com/hg', 'https://github.com/fangfufu']}"
gsliepen/tinc,https://github.com/gsliepen/tinc,308,2021-08-10T20:38:47Z,2021-08-10T20:40:40Z,2021-08-10T20:40:40Z,CLOSED,False,1,1,1,https://github.com/fangfufu,Windows CI test pull request,1,[],https://github.com/gsliepen/tinc/pull/308,https://github.com/fangfufu,1,https://github.com/gsliepen/tinc/pull/308,"I can't seem to trigger CI runs on my own forks, without creating a pull request.","I can't seem to trigger CI runs on my own forks, without creating a pull request.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,309,2021-08-10T20:42:02Z,2021-08-10T23:15:45Z,2021-08-10T23:15:45Z,CLOSED,False,0,0,0,https://github.com/fangfufu,Test pull request to see if windows CI works (do not merge) ,0,"['1.1', 'CI']",https://github.com/gsliepen/tinc/pull/309,https://github.com/fangfufu,1,https://github.com/gsliepen/tinc/pull/309,"Do not merge
I can't seem to trigger CI runs on my own forks, without creating a pull request.","Do not merge
I can't seem to trigger CI runs on my own forks, without creating a pull request.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,309,2021-08-10T20:42:02Z,2021-08-10T23:15:45Z,2021-08-10T23:15:45Z,CLOSED,False,0,0,0,https://github.com/fangfufu,Test pull request to see if windows CI works (do not merge) ,0,"['1.1', 'CI']",https://github.com/gsliepen/tinc/pull/309,https://github.com/fangfufu,2,https://github.com/gsliepen/tinc/pull/309#issuecomment-896304214,"Do not merge
I can't seem to trigger CI runs on my own forks, without creating a pull request.",It appears that CI is broken right now... The Github workflow isn't running at all.,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,309,2021-08-10T20:42:02Z,2021-08-10T23:15:45Z,2021-08-10T23:15:45Z,CLOSED,False,0,0,0,https://github.com/fangfufu,Test pull request to see if windows CI works (do not merge) ,0,"['1.1', 'CI']",https://github.com/gsliepen/tinc/pull/309,https://github.com/gsliepen,3,https://github.com/gsliepen/tinc/pull/309#issuecomment-896307569,"Do not merge
I can't seem to trigger CI runs on my own forks, without creating a pull request.",It's because you pushed exactly the same commit as in #308. I think GitHub notices it's not a new commit hash and thus skips checks.,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,309,2021-08-10T20:42:02Z,2021-08-10T23:15:45Z,2021-08-10T23:15:45Z,CLOSED,False,0,0,0,https://github.com/fangfufu,Test pull request to see if windows CI works (do not merge) ,0,"['1.1', 'CI']",https://github.com/gsliepen/tinc/pull/309,https://github.com/fangfufu,4,https://github.com/gsliepen/tinc/pull/309#issuecomment-896310216,"Do not merge
I can't seem to trigger CI runs on my own forks, without creating a pull request.","@gsliepen , I created this new pull request because the old one was only running the workflows outside of Github. I have just created a new commit with a dummy file, and it is still not running the workflows from Github itself.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,309,2021-08-10T20:42:02Z,2021-08-10T23:15:45Z,2021-08-10T23:15:45Z,CLOSED,False,0,0,0,https://github.com/fangfufu,Test pull request to see if windows CI works (do not merge) ,0,"['1.1', 'CI']",https://github.com/gsliepen/tinc/pull/309,https://github.com/fangfufu,5,https://github.com/gsliepen/tinc/pull/309#issuecomment-896313671,"Do not merge
I can't seem to trigger CI runs on my own forks, without creating a pull request.",I recommend continuing the discussion of Github workflows not running at issue #310,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,309,2021-08-10T20:42:02Z,2021-08-10T23:15:45Z,2021-08-10T23:15:45Z,CLOSED,False,0,0,0,https://github.com/fangfufu,Test pull request to see if windows CI works (do not merge) ,0,"['1.1', 'CI']",https://github.com/gsliepen/tinc/pull/309,https://github.com/fangfufu,6,https://github.com/gsliepen/tinc/pull/309#issuecomment-896364475,"Do not merge
I can't seem to trigger CI runs on my own forks, without creating a pull request.","Okay, Github workflow issue was due to Github infrastructure. I am still investigating the problem with Windows CI workflow.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,312,2021-08-11T05:01:31Z,2021-08-11T17:10:14Z,2021-08-11T17:10:14Z,MERGED,True,2,0,1,https://github.com/hg,Make apt stop asking questions when building deb package.,1,[],https://github.com/gsliepen/tinc/pull/312,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/312,"I don't know what changed in the last couple of days, but it didn't ask anything before.
Tests:

https://github.com/hg/tinc/actions/runs/1118758437
https://github.com/hg/tinc/actions/runs/1118769237

Packages:

https://github.com/hg/tinc/releases/tag/latest
https://github.com/hg/tinc/releases/tag/release-1.420

I wonder why apt doesn't detect if it's on a tty or not, and acts accordingly.
Thanks @fangfufu for reporting it (#311).","I don't know what changed in the last couple of days, but it didn't ask anything before.
Tests:

https://github.com/hg/tinc/actions/runs/1118758437
https://github.com/hg/tinc/actions/runs/1118769237

Packages:

https://github.com/hg/tinc/releases/tag/latest
https://github.com/hg/tinc/releases/tag/release-1.420

I wonder why apt doesn't detect if it's on a tty or not, and acts accordingly.
Thanks @fangfufu for reporting it (#311).",True,{'THUMBS_UP': ['https://github.com/fangfufu']}
gsliepen/tinc,https://github.com/gsliepen/tinc,313,2021-08-12T09:46:53Z,2021-08-12T11:28:02Z,2021-08-14T18:12:46Z,CLOSED,False,6821,1327,87,https://github.com/hg,Add localization support using gettext,5,[],https://github.com/gsliepen/tinc/pull/313,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/313,"Is there any interest in having tinc available in multiple languages, not just English?
This PR adds gettext support and wraps every (I think) user-facing translatable string with the _() macro.
Incidentally, it also fixes a couple of logging bugs in Solaris-specific code.
Man pages were not changed. It's a huge job that could be done next.
I know it's a huge diff, but the vast majority of it is the auto-generated .pot template which does not require much attention.
Tests:

https://github.com/hg/tinc/actions/runs/1123359114
https://github.com/hg/tinc/actions/runs/1123297098
https://github.com/hg/tinc/actions/runs/1123134191
https://builds.sr.ht/~reducer/job/565004
https://builds.sr.ht/~reducer/job/565005
https://builds.sr.ht/~reducer/job/565006


If you do merge this, I'll start translating tinc into Russian. For other languages we can use one of these services:

https://weblate.org/
https://translationproject.org/

and rely on the community for help.
For example:

https://hosted.weblate.org/projects/tinc/

(I'll remove this project after this PR is merged to let you register the name.)
Another example from the sssd project:

https://github.com/SSSD/sssd
https://translate.fedoraproject.org/projects/sssd/


I translated a few strings just to show that it works:
https://github.com/hg/tinc/tree/l10n
Usage: tincd [option]...

  -c, --config=DIR              Читать настройки из директории DIR.
  -D, --no-detach               Не отключаться от терминала и не переходить в фон.
  -d, --debug[=LEVEL]           Увеличить подробность журналирования или установить уровень на LEVEL.
  -n, --net=NETNAME             Подключиться к сети NETNAME.
  -L, --mlock                   Запретить сброс tinc в файл подкачки.
      --logfile[=FILENAME]      Включить журналирование в файл.
  -s  --syslog                  Use syslog instead of stderr with --no-detach.
      --pidfile=FILENAME        Write PID and control socket cookie to FILENAME.
      --bypass-security         Отключает проверки безопасности в протоколе (для отладки).
  -o, --option[HOST.]KEY=VALUE  Set global/host configuration value.
  -R, --chroot                  Выполнить chroot в директорию NET при запуске.
  -U, --user=USER               Запускать под пользователем USER.
      --help                    Показать справку и выйти.
      --version                 Показать информацию о версии и выйти.

Сообщайте о проблемах на tinc@tinc-vpn.org.","Is there any interest in having tinc available in multiple languages, not just English?
This PR adds gettext support and wraps every (I think) user-facing translatable string with the _() macro.
Incidentally, it also fixes a couple of logging bugs in Solaris-specific code.
Man pages were not changed. It's a huge job that could be done next.
I know it's a huge diff, but the vast majority of it is the auto-generated .pot template which does not require much attention.
Tests:

https://github.com/hg/tinc/actions/runs/1123359114
https://github.com/hg/tinc/actions/runs/1123297098
https://github.com/hg/tinc/actions/runs/1123134191
https://builds.sr.ht/~reducer/job/565004
https://builds.sr.ht/~reducer/job/565005
https://builds.sr.ht/~reducer/job/565006


If you do merge this, I'll start translating tinc into Russian. For other languages we can use one of these services:

https://weblate.org/
https://translationproject.org/

and rely on the community for help.
For example:

https://hosted.weblate.org/projects/tinc/

(I'll remove this project after this PR is merged to let you register the name.)
Another example from the sssd project:

https://github.com/SSSD/sssd
https://translate.fedoraproject.org/projects/sssd/


I translated a few strings just to show that it works:
https://github.com/hg/tinc/tree/l10n
Usage: tincd [option]...

  -c, --config=DIR              Читать настройки из директории DIR.
  -D, --no-detach               Не отключаться от терминала и не переходить в фон.
  -d, --debug[=LEVEL]           Увеличить подробность журналирования или установить уровень на LEVEL.
  -n, --net=NETNAME             Подключиться к сети NETNAME.
  -L, --mlock                   Запретить сброс tinc в файл подкачки.
      --logfile[=FILENAME]      Включить журналирование в файл.
  -s  --syslog                  Use syslog instead of stderr with --no-detach.
      --pidfile=FILENAME        Write PID and control socket cookie to FILENAME.
      --bypass-security         Отключает проверки безопасности в протоколе (для отладки).
  -o, --option[HOST.]KEY=VALUE  Set global/host configuration value.
  -R, --chroot                  Выполнить chroot в директорию NET при запуске.
  -U, --user=USER               Запускать под пользователем USER.
      --help                    Показать справку и выйти.
      --version                 Показать информацию о версии и выйти.

Сообщайте о проблемах на tinc@tinc-vpn.org.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,313,2021-08-12T09:46:53Z,2021-08-12T11:28:02Z,2021-08-14T18:12:46Z,CLOSED,False,6821,1327,87,https://github.com/hg,Add localization support using gettext,5,[],https://github.com/gsliepen/tinc/pull/313,https://github.com/gsliepen,2,https://github.com/gsliepen/tinc/pull/313#issuecomment-897529965,"Is there any interest in having tinc available in multiple languages, not just English?
This PR adds gettext support and wraps every (I think) user-facing translatable string with the _() macro.
Incidentally, it also fixes a couple of logging bugs in Solaris-specific code.
Man pages were not changed. It's a huge job that could be done next.
I know it's a huge diff, but the vast majority of it is the auto-generated .pot template which does not require much attention.
Tests:

https://github.com/hg/tinc/actions/runs/1123359114
https://github.com/hg/tinc/actions/runs/1123297098
https://github.com/hg/tinc/actions/runs/1123134191
https://builds.sr.ht/~reducer/job/565004
https://builds.sr.ht/~reducer/job/565005
https://builds.sr.ht/~reducer/job/565006


If you do merge this, I'll start translating tinc into Russian. For other languages we can use one of these services:

https://weblate.org/
https://translationproject.org/

and rely on the community for help.
For example:

https://hosted.weblate.org/projects/tinc/

(I'll remove this project after this PR is merged to let you register the name.)
Another example from the sssd project:

https://github.com/SSSD/sssd
https://translate.fedoraproject.org/projects/sssd/


I translated a few strings just to show that it works:
https://github.com/hg/tinc/tree/l10n
Usage: tincd [option]...

  -c, --config=DIR              Читать настройки из директории DIR.
  -D, --no-detach               Не отключаться от терминала и не переходить в фон.
  -d, --debug[=LEVEL]           Увеличить подробность журналирования или установить уровень на LEVEL.
  -n, --net=NETNAME             Подключиться к сети NETNAME.
  -L, --mlock                   Запретить сброс tinc в файл подкачки.
      --logfile[=FILENAME]      Включить журналирование в файл.
  -s  --syslog                  Use syslog instead of stderr with --no-detach.
      --pidfile=FILENAME        Write PID and control socket cookie to FILENAME.
      --bypass-security         Отключает проверки безопасности в протоколе (для отладки).
  -o, --option[HOST.]KEY=VALUE  Set global/host configuration value.
  -R, --chroot                  Выполнить chroot в директорию NET при запуске.
  -U, --user=USER               Запускать под пользователем USER.
      --help                    Показать справку и выйти.
      --version                 Показать информацию о версии и выйти.

Сообщайте о проблемах на tinc@tinc-vpn.org.","Is there any interest in having tinc available in multiple languages, not just English?

Well, tinc used to support gettext, but this was dropped in commit 4c85542 because there was not much effort in actually maintaining translations. So giving this past experience, I think it doesn't make sense unless we have some way to incentivize translations being made and maintained.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,313,2021-08-12T09:46:53Z,2021-08-12T11:28:02Z,2021-08-14T18:12:46Z,CLOSED,False,6821,1327,87,https://github.com/hg,Add localization support using gettext,5,[],https://github.com/gsliepen/tinc/pull/313,https://github.com/hg,3,https://github.com/gsliepen/tinc/pull/313#issuecomment-897560846,"Is there any interest in having tinc available in multiple languages, not just English?
This PR adds gettext support and wraps every (I think) user-facing translatable string with the _() macro.
Incidentally, it also fixes a couple of logging bugs in Solaris-specific code.
Man pages were not changed. It's a huge job that could be done next.
I know it's a huge diff, but the vast majority of it is the auto-generated .pot template which does not require much attention.
Tests:

https://github.com/hg/tinc/actions/runs/1123359114
https://github.com/hg/tinc/actions/runs/1123297098
https://github.com/hg/tinc/actions/runs/1123134191
https://builds.sr.ht/~reducer/job/565004
https://builds.sr.ht/~reducer/job/565005
https://builds.sr.ht/~reducer/job/565006


If you do merge this, I'll start translating tinc into Russian. For other languages we can use one of these services:

https://weblate.org/
https://translationproject.org/

and rely on the community for help.
For example:

https://hosted.weblate.org/projects/tinc/

(I'll remove this project after this PR is merged to let you register the name.)
Another example from the sssd project:

https://github.com/SSSD/sssd
https://translate.fedoraproject.org/projects/sssd/


I translated a few strings just to show that it works:
https://github.com/hg/tinc/tree/l10n
Usage: tincd [option]...

  -c, --config=DIR              Читать настройки из директории DIR.
  -D, --no-detach               Не отключаться от терминала и не переходить в фон.
  -d, --debug[=LEVEL]           Увеличить подробность журналирования или установить уровень на LEVEL.
  -n, --net=NETNAME             Подключиться к сети NETNAME.
  -L, --mlock                   Запретить сброс tinc в файл подкачки.
      --logfile[=FILENAME]      Включить журналирование в файл.
  -s  --syslog                  Use syslog instead of stderr with --no-detach.
      --pidfile=FILENAME        Write PID and control socket cookie to FILENAME.
      --bypass-security         Отключает проверки безопасности в протоколе (для отладки).
  -o, --option[HOST.]KEY=VALUE  Set global/host configuration value.
  -R, --chroot                  Выполнить chroot в директорию NET при запуске.
  -U, --user=USER               Запускать под пользователем USER.
      --help                    Показать справку и выйти.
      --version                 Показать информацию о версии и выйти.

Сообщайте о проблемах на tinc@tinc-vpn.org.","Ah, sorry, I didn't know about that. I can maintain one translation, and from looking at other projects, even pretty low-level components like sssd, I've been thinking along ""build and they will come"" lines, but with this history in mind it's probably not worth it.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,313,2021-08-12T09:46:53Z,2021-08-12T11:28:02Z,2021-08-14T18:12:46Z,CLOSED,False,6821,1327,87,https://github.com/hg,Add localization support using gettext,5,[],https://github.com/gsliepen/tinc/pull/313,https://github.com/fangfufu,4,https://github.com/gsliepen/tinc/pull/313#issuecomment-898068645,"Is there any interest in having tinc available in multiple languages, not just English?
This PR adds gettext support and wraps every (I think) user-facing translatable string with the _() macro.
Incidentally, it also fixes a couple of logging bugs in Solaris-specific code.
Man pages were not changed. It's a huge job that could be done next.
I know it's a huge diff, but the vast majority of it is the auto-generated .pot template which does not require much attention.
Tests:

https://github.com/hg/tinc/actions/runs/1123359114
https://github.com/hg/tinc/actions/runs/1123297098
https://github.com/hg/tinc/actions/runs/1123134191
https://builds.sr.ht/~reducer/job/565004
https://builds.sr.ht/~reducer/job/565005
https://builds.sr.ht/~reducer/job/565006


If you do merge this, I'll start translating tinc into Russian. For other languages we can use one of these services:

https://weblate.org/
https://translationproject.org/

and rely on the community for help.
For example:

https://hosted.weblate.org/projects/tinc/

(I'll remove this project after this PR is merged to let you register the name.)
Another example from the sssd project:

https://github.com/SSSD/sssd
https://translate.fedoraproject.org/projects/sssd/


I translated a few strings just to show that it works:
https://github.com/hg/tinc/tree/l10n
Usage: tincd [option]...

  -c, --config=DIR              Читать настройки из директории DIR.
  -D, --no-detach               Не отключаться от терминала и не переходить в фон.
  -d, --debug[=LEVEL]           Увеличить подробность журналирования или установить уровень на LEVEL.
  -n, --net=NETNAME             Подключиться к сети NETNAME.
  -L, --mlock                   Запретить сброс tinc в файл подкачки.
      --logfile[=FILENAME]      Включить журналирование в файл.
  -s  --syslog                  Use syslog instead of stderr with --no-detach.
      --pidfile=FILENAME        Write PID and control socket cookie to FILENAME.
      --bypass-security         Отключает проверки безопасности в протоколе (для отладки).
  -o, --option[HOST.]KEY=VALUE  Set global/host configuration value.
  -R, --chroot                  Выполнить chroot в директорию NET при запуске.
  -U, --user=USER               Запускать под пользователем USER.
      --help                    Показать справку и выйти.
      --version                 Показать информацию о версии и выйти.

Сообщайте о проблемах на tinc@tinc-vpn.org.","Well, if we ever want to work on issue #118, then we have to revisit this pull request.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,313,2021-08-12T09:46:53Z,2021-08-12T11:28:02Z,2021-08-14T18:12:46Z,CLOSED,False,6821,1327,87,https://github.com/hg,Add localization support using gettext,5,[],https://github.com/gsliepen/tinc/pull/313,https://github.com/hg,5,https://github.com/gsliepen/tinc/pull/313#issuecomment-898939897,"Is there any interest in having tinc available in multiple languages, not just English?
This PR adds gettext support and wraps every (I think) user-facing translatable string with the _() macro.
Incidentally, it also fixes a couple of logging bugs in Solaris-specific code.
Man pages were not changed. It's a huge job that could be done next.
I know it's a huge diff, but the vast majority of it is the auto-generated .pot template which does not require much attention.
Tests:

https://github.com/hg/tinc/actions/runs/1123359114
https://github.com/hg/tinc/actions/runs/1123297098
https://github.com/hg/tinc/actions/runs/1123134191
https://builds.sr.ht/~reducer/job/565004
https://builds.sr.ht/~reducer/job/565005
https://builds.sr.ht/~reducer/job/565006


If you do merge this, I'll start translating tinc into Russian. For other languages we can use one of these services:

https://weblate.org/
https://translationproject.org/

and rely on the community for help.
For example:

https://hosted.weblate.org/projects/tinc/

(I'll remove this project after this PR is merged to let you register the name.)
Another example from the sssd project:

https://github.com/SSSD/sssd
https://translate.fedoraproject.org/projects/sssd/


I translated a few strings just to show that it works:
https://github.com/hg/tinc/tree/l10n
Usage: tincd [option]...

  -c, --config=DIR              Читать настройки из директории DIR.
  -D, --no-detach               Не отключаться от терминала и не переходить в фон.
  -d, --debug[=LEVEL]           Увеличить подробность журналирования или установить уровень на LEVEL.
  -n, --net=NETNAME             Подключиться к сети NETNAME.
  -L, --mlock                   Запретить сброс tinc в файл подкачки.
      --logfile[=FILENAME]      Включить журналирование в файл.
  -s  --syslog                  Use syslog instead of stderr with --no-detach.
      --pidfile=FILENAME        Write PID and control socket cookie to FILENAME.
      --bypass-security         Отключает проверки безопасности в протоколе (для отладки).
  -o, --option[HOST.]KEY=VALUE  Set global/host configuration value.
  -R, --chroot                  Выполнить chroot в директорию NET при запуске.
  -U, --user=USER               Запускать под пользователем USER.
      --help                    Показать справку и выйти.
      --version                 Показать информацию о версии и выйти.

Сообщайте о проблемах на tinc@tinc-vpn.org.","I forgot to delete the project and somebody has started translating it into Norwegian.
https://hosted.weblate.org/projects/tinc/tinc/nb_NO/
I'll see how it goes and will keep working on the Russian translation for the time being.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,314,2021-08-12T12:59:15Z,2021-08-18T08:49:36Z,2021-08-18T08:49:39Z,CLOSED,False,4,4,2,https://github.com/hg,RFC7539-related changes to ChaCha20,2,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/314,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/314,"This is an attempt to align the ChaCha20 implementation with RFC7539 (related to #301).
It seems to be the right thing to do to increment the major protocol version. I don't think we can reset the minor version, though? It's compared with magic values 1 and 2 all over the place.
A large part of RFC7539 is the AEAD construction, which doesn't seem to be used in tinc. Instead we simply encrypt the plaintext and append the MAC to it. Were you planning to modify the protocol to add AEAD?

Because we don't have unit testing yet, I threw together a small program to check the algorithm against RFC test vectors:
$ cd src/chacha-poly1305/
$ cat >test.c
$ gcc poly1305.c chacha.c test.c
$ ./a.out

#include <stdint.h>
#include <string.h>
#include <stdlib.h>
#include <stdio.h>
#include ""chacha.h""
#include ""poly1305.h""

#define U8C(v) (v##U)
#define U32C(v) (v##U)

#define U8V(v) ((uint8_t)(v)&U8C(0xFF))
#define U32V(v) ((uint32_t)(v)&U32C(0xFFFFFFFF))

#define ROTL32(v, n) \
	(U32V((v) << (n)) | ((v) >> (32 - (n))))

#define U8TO32_LITTLE(p)              \
	(((uint32_t)((p)[0])) |       \
	 ((uint32_t)((p)[1]) << 8) |  \
	 ((uint32_t)((p)[2]) << 16) | \
	 ((uint32_t)((p)[3]) << 24))

#define U32TO8_LITTLE(p, v)              \
	do {                             \
		(p)[0] = U8V((v));       \
		(p)[1] = U8V((v) >> 8);  \
		(p)[2] = U8V((v) >> 16); \
		(p)[3] = U8V((v) >> 24); \
	} while(0)

#define ROTATE(v, c) (ROTL32(v, c))
#define XOR(v, w) ((v) ^ (w))
#define PLUS(v, w) (U32V((v) + (w)))
#define PLUSONE(v) (PLUS((v), 1))

#define QUARTERROUND(a, b, c, d)   \
	a = PLUS(a, b);            \
	d = ROTATE(XOR(d, a), 16); \
	c = PLUS(c, d);            \
	b = ROTATE(XOR(b, c), 12); \
	a = PLUS(a, b);            \
	d = ROTATE(XOR(d, a), 8);  \
	c = PLUS(c, d);            \
	b = ROTATE(XOR(b, c), 7);

static const uint8_t key[] = {
	0x00, 0x01, 0x02, 0x03, 0x04, 0x05, 0x06, 0x07, 0x08, 0x09, 0x0a, 0x0b, 0x0c, 0x0d, 0x0e, 0x0f,
	0x10, 0x11, 0x12, 0x13, 0x14, 0x15, 0x16, 0x17, 0x18, 0x19, 0x1a, 0x1b, 0x1c, 0x1d, 0x1e, 0x1f,
};

static const uint8_t one[8] = {1, 0, 0, 0, 0, 0, 0, 0};

static const uint32_t expected_initial_state[] = {
	0x61707865, 0x3320646e, 0x79622d32, 0x6b206574,
	0x03020100, 0x07060504, 0x0b0a0908, 0x0f0e0d0c,
	0x13121110, 0x17161514, 0x1b1a1918, 0x1f1e1d1c,
	0x00000001, 0x09000000, 0x4a000000, 0x00000000,
};

static const uint32_t expected_after_20_rounds[] = {
	0x837778ab, 0xe238d763, 0xa67ae21e, 0x5950bb2f,
	0xc4f2d0c7, 0xfc62bb2f, 0x8fa018fc, 0x3f5ec7b7,
	0x335271c2, 0xf29489f3, 0xeabda8fc, 0x82e46ebd,
	0xd19c12b4, 0xb04e16de, 0x9e83d0cb, 0x4e3c50a2,
};

static void check_state(const void *expected, const void *real, const char *kind) {
	if(memcmp(expected, real, sizeof(struct chacha_ctx))) {
		fprintf(stderr, ""invalid %s state\n"", kind);
		exit(1);
	}
}

// copy-pasted from chacha.c
static void run_20_rounds(struct chacha_ctx *ctx) {
	uint32_t x0 = ctx->input[0];
	uint32_t x1 = ctx->input[1];
	uint32_t x2 = ctx->input[2];
	uint32_t x3 = ctx->input[3];
	uint32_t x4 = ctx->input[4];
	uint32_t x5 = ctx->input[5];
	uint32_t x6 = ctx->input[6];
	uint32_t x7 = ctx->input[7];
	uint32_t x8 = ctx->input[8];
	uint32_t x9 = ctx->input[9];
	uint32_t x10 = ctx->input[10];
	uint32_t x11 = ctx->input[11];
	uint32_t x12 = ctx->input[12];
	uint32_t x13 = ctx->input[13];
	uint32_t x14 = ctx->input[14];
	uint32_t x15 = ctx->input[15];

	for(size_t i = 20; i > 0; i -= 2) {
		QUARTERROUND(x0, x4, x8, x12)
		QUARTERROUND(x1, x5, x9, x13)
		QUARTERROUND(x2, x6, x10, x14)
		QUARTERROUND(x3, x7, x11, x15)
		QUARTERROUND(x0, x5, x10, x15)
		QUARTERROUND(x1, x6, x11, x12)
		QUARTERROUND(x2, x7, x8, x13)
		QUARTERROUND(x3, x4, x9, x14)
	}

	U32TO8_LITTLE((uint8_t *) ctx + 0, x0);
	U32TO8_LITTLE((uint8_t *) ctx + 4, x1);
	U32TO8_LITTLE((uint8_t *) ctx + 8, x2);
	U32TO8_LITTLE((uint8_t *) ctx + 12, x3);
	U32TO8_LITTLE((uint8_t *) ctx + 16, x4);
	U32TO8_LITTLE((uint8_t *) ctx + 20, x5);
	U32TO8_LITTLE((uint8_t *) ctx + 24, x6);
	U32TO8_LITTLE((uint8_t *) ctx + 28, x7);
	U32TO8_LITTLE((uint8_t *) ctx + 32, x8);
	U32TO8_LITTLE((uint8_t *) ctx + 36, x9);
	U32TO8_LITTLE((uint8_t *) ctx + 40, x10);
	U32TO8_LITTLE((uint8_t *) ctx + 44, x11);
	U32TO8_LITTLE((uint8_t *) ctx + 48, x12);
	U32TO8_LITTLE((uint8_t *) ctx + 52, x13);
	U32TO8_LITTLE((uint8_t *) ctx + 56, x14);
	U32TO8_LITTLE((uint8_t *) ctx + 60, x15);
}

static void test_initialization() {
	static const uint8_t nonce[] = {
		0x00, 0x00, 0x00, 0x09, 0x00, 0x00, 0x00, 0x4a, 0x00, 0x00, 0x00, 0x00,
	};

	struct chacha_ctx ctx = {0};

	chacha_keysetup(&ctx, key, 256);
	chacha_ivsetup(&ctx, nonce, one);
	check_state(&expected_initial_state, &ctx, ""initial"");

	run_20_rounds(&ctx);
	check_state(&expected_after_20_rounds, &ctx, ""20 rounds"");
}

static void test_entryption() {
	const uint8_t plaintext[] = {
		0x4c, 0x61, 0x64, 0x69, 0x65, 0x73, 0x20, 0x61, 0x6e, 0x64, 0x20, 0x47, 0x65, 0x6e, 0x74, 0x6c,
		0x65, 0x6d, 0x65, 0x6e, 0x20, 0x6f, 0x66, 0x20, 0x74, 0x68, 0x65, 0x20, 0x63, 0x6c, 0x61, 0x73,
		0x73, 0x20, 0x6f, 0x66, 0x20, 0x27, 0x39, 0x39, 0x3a, 0x20, 0x49, 0x66, 0x20, 0x49, 0x20, 0x63,
		0x6f, 0x75, 0x6c, 0x64, 0x20, 0x6f, 0x66, 0x66, 0x65, 0x72, 0x20, 0x79, 0x6f, 0x75, 0x20, 0x6f,
		0x6e, 0x6c, 0x79, 0x20, 0x6f, 0x6e, 0x65, 0x20, 0x74, 0x69, 0x70, 0x20, 0x66, 0x6f, 0x72, 0x20,
		0x74, 0x68, 0x65, 0x20, 0x66, 0x75, 0x74, 0x75, 0x72, 0x65, 0x2c, 0x20, 0x73, 0x75, 0x6e, 0x73,
		0x63, 0x72, 0x65, 0x65, 0x6e, 0x20, 0x77, 0x6f, 0x75, 0x6c, 0x64, 0x20, 0x62, 0x65, 0x20, 0x69,
		0x74, 0x2e,
	};

	const uint8_t expected_ciphertext[] = {
		0x6e, 0x2e, 0x35, 0x9a, 0x25, 0x68, 0xf9, 0x80, 0x41, 0xba, 0x07, 0x28, 0xdd, 0x0d, 0x69, 0x81,
		0xe9, 0x7e, 0x7a, 0xec, 0x1d, 0x43, 0x60, 0xc2, 0x0a, 0x27, 0xaf, 0xcc, 0xfd, 0x9f, 0xae, 0x0b,
		0xf9, 0x1b, 0x65, 0xc5, 0x52, 0x47, 0x33, 0xab, 0x8f, 0x59, 0x3d, 0xab, 0xcd, 0x62, 0xb3, 0x57,
		0x16, 0x39, 0xd6, 0x24, 0xe6, 0x51, 0x52, 0xab, 0x8f, 0x53, 0x0c, 0x35, 0x9f, 0x08, 0x61, 0xd8,
		0x07, 0xca, 0x0d, 0xbf, 0x50, 0x0d, 0x6a, 0x61, 0x56, 0xa3, 0x8e, 0x08, 0x8a, 0x22, 0xb6, 0x5e,
		0x52, 0xbc, 0x51, 0x4d, 0x16, 0xcc, 0xf8, 0x06, 0x81, 0x8c, 0xe9, 0x1a, 0xb7, 0x79, 0x37, 0x36,
		0x5a, 0xf9, 0x0b, 0xbf, 0x74, 0xa3, 0x5b, 0xe6, 0xb4, 0x0b, 0x8e, 0xed, 0xf2, 0x78, 0x5e, 0x42,
		0x87, 0x4d,
	};

	static const uint8_t enc_nonce[] = {
		0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x4a, 0x00, 0x00, 0x00, 0x00,
	};

	uint8_t ciphertext[sizeof(expected_ciphertext)];

	struct chacha_ctx ctx = {0};
	chacha_keysetup(&ctx, key, 256);
	chacha_ivsetup(&ctx, enc_nonce, one);

	chacha_encrypt_bytes(&ctx, (uint8_t *) plaintext, ciphertext, sizeof(ciphertext));

	if(memcmp(expected_ciphertext, ciphertext, sizeof(ciphertext))) {
		fprintf(stderr, ""invalid ciphertext\n"");
		exit(2);
	}
}

static void test_auth() {
	const uint8_t key[] = {
		0x85, 0xd6, 0xbe, 0x78, 0x57, 0x55, 0x6d, 0x33, 0x7f, 0x44, 0x52, 0xfe, 0x42, 0xd5, 0x06, 0xa8,
		0x01, 0x03, 0x80, 0x8a, 0xfb, 0x0d, 0xb2, 0xfd, 0x4a, 0xbf, 0xf6, 0xaf, 0x41, 0x49, 0xf5, 0x1b,
	};

	const uint8_t msg[] = {
		0x43, 0x72, 0x79, 0x70, 0x74, 0x6f, 0x67, 0x72, 0x61, 0x70, 0x68, 0x69, 0x63, 0x20, 0x46, 0x6f,
		0x72, 0x75, 0x6d, 0x20, 0x52, 0x65, 0x73, 0x65, 0x61, 0x72, 0x63, 0x68, 0x20, 0x47, 0x72, 0x6f,
		0x75, 0x70,
	};

	const uint8_t  expected_tag[] = {
		0xa8, 0x06, 0x1d, 0xc1, 0x30, 0x51, 0x36, 0xc6, 0xc2, 0x2b, 0x8b, 0xaf, 0x0c, 0x01, 0x27, 0xa9,
	};

	uint8_t tag[POLY1305_TAGLEN];
	poly1305_auth(tag, msg, sizeof(msg), key);

	if(memcmp(expected_tag, tag, sizeof(tag))) {
		fprintf(stderr, ""invalid MAC\n"");
		exit(3);
	}
}

int main() {
	test_initialization();
	test_entryption();
	test_auth();
}","This is an attempt to align the ChaCha20 implementation with RFC7539 (related to #301).
It seems to be the right thing to do to increment the major protocol version. I don't think we can reset the minor version, though? It's compared with magic values 1 and 2 all over the place.
A large part of RFC7539 is the AEAD construction, which doesn't seem to be used in tinc. Instead we simply encrypt the plaintext and append the MAC to it. Were you planning to modify the protocol to add AEAD?

Because we don't have unit testing yet, I threw together a small program to check the algorithm against RFC test vectors:
$ cd src/chacha-poly1305/
$ cat >test.c
$ gcc poly1305.c chacha.c test.c
$ ./a.out

#include <stdint.h>
#include <string.h>
#include <stdlib.h>
#include <stdio.h>
#include ""chacha.h""
#include ""poly1305.h""

#define U8C(v) (v##U)
#define U32C(v) (v##U)

#define U8V(v) ((uint8_t)(v)&U8C(0xFF))
#define U32V(v) ((uint32_t)(v)&U32C(0xFFFFFFFF))

#define ROTL32(v, n) \
	(U32V((v) << (n)) | ((v) >> (32 - (n))))

#define U8TO32_LITTLE(p)              \
	(((uint32_t)((p)[0])) |       \
	 ((uint32_t)((p)[1]) << 8) |  \
	 ((uint32_t)((p)[2]) << 16) | \
	 ((uint32_t)((p)[3]) << 24))

#define U32TO8_LITTLE(p, v)              \
	do {                             \
		(p)[0] = U8V((v));       \
		(p)[1] = U8V((v) >> 8);  \
		(p)[2] = U8V((v) >> 16); \
		(p)[3] = U8V((v) >> 24); \
	} while(0)

#define ROTATE(v, c) (ROTL32(v, c))
#define XOR(v, w) ((v) ^ (w))
#define PLUS(v, w) (U32V((v) + (w)))
#define PLUSONE(v) (PLUS((v), 1))

#define QUARTERROUND(a, b, c, d)   \
	a = PLUS(a, b);            \
	d = ROTATE(XOR(d, a), 16); \
	c = PLUS(c, d);            \
	b = ROTATE(XOR(b, c), 12); \
	a = PLUS(a, b);            \
	d = ROTATE(XOR(d, a), 8);  \
	c = PLUS(c, d);            \
	b = ROTATE(XOR(b, c), 7);

static const uint8_t key[] = {
	0x00, 0x01, 0x02, 0x03, 0x04, 0x05, 0x06, 0x07, 0x08, 0x09, 0x0a, 0x0b, 0x0c, 0x0d, 0x0e, 0x0f,
	0x10, 0x11, 0x12, 0x13, 0x14, 0x15, 0x16, 0x17, 0x18, 0x19, 0x1a, 0x1b, 0x1c, 0x1d, 0x1e, 0x1f,
};

static const uint8_t one[8] = {1, 0, 0, 0, 0, 0, 0, 0};

static const uint32_t expected_initial_state[] = {
	0x61707865, 0x3320646e, 0x79622d32, 0x6b206574,
	0x03020100, 0x07060504, 0x0b0a0908, 0x0f0e0d0c,
	0x13121110, 0x17161514, 0x1b1a1918, 0x1f1e1d1c,
	0x00000001, 0x09000000, 0x4a000000, 0x00000000,
};

static const uint32_t expected_after_20_rounds[] = {
	0x837778ab, 0xe238d763, 0xa67ae21e, 0x5950bb2f,
	0xc4f2d0c7, 0xfc62bb2f, 0x8fa018fc, 0x3f5ec7b7,
	0x335271c2, 0xf29489f3, 0xeabda8fc, 0x82e46ebd,
	0xd19c12b4, 0xb04e16de, 0x9e83d0cb, 0x4e3c50a2,
};

static void check_state(const void *expected, const void *real, const char *kind) {
	if(memcmp(expected, real, sizeof(struct chacha_ctx))) {
		fprintf(stderr, ""invalid %s state\n"", kind);
		exit(1);
	}
}

// copy-pasted from chacha.c
static void run_20_rounds(struct chacha_ctx *ctx) {
	uint32_t x0 = ctx->input[0];
	uint32_t x1 = ctx->input[1];
	uint32_t x2 = ctx->input[2];
	uint32_t x3 = ctx->input[3];
	uint32_t x4 = ctx->input[4];
	uint32_t x5 = ctx->input[5];
	uint32_t x6 = ctx->input[6];
	uint32_t x7 = ctx->input[7];
	uint32_t x8 = ctx->input[8];
	uint32_t x9 = ctx->input[9];
	uint32_t x10 = ctx->input[10];
	uint32_t x11 = ctx->input[11];
	uint32_t x12 = ctx->input[12];
	uint32_t x13 = ctx->input[13];
	uint32_t x14 = ctx->input[14];
	uint32_t x15 = ctx->input[15];

	for(size_t i = 20; i > 0; i -= 2) {
		QUARTERROUND(x0, x4, x8, x12)
		QUARTERROUND(x1, x5, x9, x13)
		QUARTERROUND(x2, x6, x10, x14)
		QUARTERROUND(x3, x7, x11, x15)
		QUARTERROUND(x0, x5, x10, x15)
		QUARTERROUND(x1, x6, x11, x12)
		QUARTERROUND(x2, x7, x8, x13)
		QUARTERROUND(x3, x4, x9, x14)
	}

	U32TO8_LITTLE((uint8_t *) ctx + 0, x0);
	U32TO8_LITTLE((uint8_t *) ctx + 4, x1);
	U32TO8_LITTLE((uint8_t *) ctx + 8, x2);
	U32TO8_LITTLE((uint8_t *) ctx + 12, x3);
	U32TO8_LITTLE((uint8_t *) ctx + 16, x4);
	U32TO8_LITTLE((uint8_t *) ctx + 20, x5);
	U32TO8_LITTLE((uint8_t *) ctx + 24, x6);
	U32TO8_LITTLE((uint8_t *) ctx + 28, x7);
	U32TO8_LITTLE((uint8_t *) ctx + 32, x8);
	U32TO8_LITTLE((uint8_t *) ctx + 36, x9);
	U32TO8_LITTLE((uint8_t *) ctx + 40, x10);
	U32TO8_LITTLE((uint8_t *) ctx + 44, x11);
	U32TO8_LITTLE((uint8_t *) ctx + 48, x12);
	U32TO8_LITTLE((uint8_t *) ctx + 52, x13);
	U32TO8_LITTLE((uint8_t *) ctx + 56, x14);
	U32TO8_LITTLE((uint8_t *) ctx + 60, x15);
}

static void test_initialization() {
	static const uint8_t nonce[] = {
		0x00, 0x00, 0x00, 0x09, 0x00, 0x00, 0x00, 0x4a, 0x00, 0x00, 0x00, 0x00,
	};

	struct chacha_ctx ctx = {0};

	chacha_keysetup(&ctx, key, 256);
	chacha_ivsetup(&ctx, nonce, one);
	check_state(&expected_initial_state, &ctx, ""initial"");

	run_20_rounds(&ctx);
	check_state(&expected_after_20_rounds, &ctx, ""20 rounds"");
}

static void test_entryption() {
	const uint8_t plaintext[] = {
		0x4c, 0x61, 0x64, 0x69, 0x65, 0x73, 0x20, 0x61, 0x6e, 0x64, 0x20, 0x47, 0x65, 0x6e, 0x74, 0x6c,
		0x65, 0x6d, 0x65, 0x6e, 0x20, 0x6f, 0x66, 0x20, 0x74, 0x68, 0x65, 0x20, 0x63, 0x6c, 0x61, 0x73,
		0x73, 0x20, 0x6f, 0x66, 0x20, 0x27, 0x39, 0x39, 0x3a, 0x20, 0x49, 0x66, 0x20, 0x49, 0x20, 0x63,
		0x6f, 0x75, 0x6c, 0x64, 0x20, 0x6f, 0x66, 0x66, 0x65, 0x72, 0x20, 0x79, 0x6f, 0x75, 0x20, 0x6f,
		0x6e, 0x6c, 0x79, 0x20, 0x6f, 0x6e, 0x65, 0x20, 0x74, 0x69, 0x70, 0x20, 0x66, 0x6f, 0x72, 0x20,
		0x74, 0x68, 0x65, 0x20, 0x66, 0x75, 0x74, 0x75, 0x72, 0x65, 0x2c, 0x20, 0x73, 0x75, 0x6e, 0x73,
		0x63, 0x72, 0x65, 0x65, 0x6e, 0x20, 0x77, 0x6f, 0x75, 0x6c, 0x64, 0x20, 0x62, 0x65, 0x20, 0x69,
		0x74, 0x2e,
	};

	const uint8_t expected_ciphertext[] = {
		0x6e, 0x2e, 0x35, 0x9a, 0x25, 0x68, 0xf9, 0x80, 0x41, 0xba, 0x07, 0x28, 0xdd, 0x0d, 0x69, 0x81,
		0xe9, 0x7e, 0x7a, 0xec, 0x1d, 0x43, 0x60, 0xc2, 0x0a, 0x27, 0xaf, 0xcc, 0xfd, 0x9f, 0xae, 0x0b,
		0xf9, 0x1b, 0x65, 0xc5, 0x52, 0x47, 0x33, 0xab, 0x8f, 0x59, 0x3d, 0xab, 0xcd, 0x62, 0xb3, 0x57,
		0x16, 0x39, 0xd6, 0x24, 0xe6, 0x51, 0x52, 0xab, 0x8f, 0x53, 0x0c, 0x35, 0x9f, 0x08, 0x61, 0xd8,
		0x07, 0xca, 0x0d, 0xbf, 0x50, 0x0d, 0x6a, 0x61, 0x56, 0xa3, 0x8e, 0x08, 0x8a, 0x22, 0xb6, 0x5e,
		0x52, 0xbc, 0x51, 0x4d, 0x16, 0xcc, 0xf8, 0x06, 0x81, 0x8c, 0xe9, 0x1a, 0xb7, 0x79, 0x37, 0x36,
		0x5a, 0xf9, 0x0b, 0xbf, 0x74, 0xa3, 0x5b, 0xe6, 0xb4, 0x0b, 0x8e, 0xed, 0xf2, 0x78, 0x5e, 0x42,
		0x87, 0x4d,
	};

	static const uint8_t enc_nonce[] = {
		0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x4a, 0x00, 0x00, 0x00, 0x00,
	};

	uint8_t ciphertext[sizeof(expected_ciphertext)];

	struct chacha_ctx ctx = {0};
	chacha_keysetup(&ctx, key, 256);
	chacha_ivsetup(&ctx, enc_nonce, one);

	chacha_encrypt_bytes(&ctx, (uint8_t *) plaintext, ciphertext, sizeof(ciphertext));

	if(memcmp(expected_ciphertext, ciphertext, sizeof(ciphertext))) {
		fprintf(stderr, ""invalid ciphertext\n"");
		exit(2);
	}
}

static void test_auth() {
	const uint8_t key[] = {
		0x85, 0xd6, 0xbe, 0x78, 0x57, 0x55, 0x6d, 0x33, 0x7f, 0x44, 0x52, 0xfe, 0x42, 0xd5, 0x06, 0xa8,
		0x01, 0x03, 0x80, 0x8a, 0xfb, 0x0d, 0xb2, 0xfd, 0x4a, 0xbf, 0xf6, 0xaf, 0x41, 0x49, 0xf5, 0x1b,
	};

	const uint8_t msg[] = {
		0x43, 0x72, 0x79, 0x70, 0x74, 0x6f, 0x67, 0x72, 0x61, 0x70, 0x68, 0x69, 0x63, 0x20, 0x46, 0x6f,
		0x72, 0x75, 0x6d, 0x20, 0x52, 0x65, 0x73, 0x65, 0x61, 0x72, 0x63, 0x68, 0x20, 0x47, 0x72, 0x6f,
		0x75, 0x70,
	};

	const uint8_t  expected_tag[] = {
		0xa8, 0x06, 0x1d, 0xc1, 0x30, 0x51, 0x36, 0xc6, 0xc2, 0x2b, 0x8b, 0xaf, 0x0c, 0x01, 0x27, 0xa9,
	};

	uint8_t tag[POLY1305_TAGLEN];
	poly1305_auth(tag, msg, sizeof(msg), key);

	if(memcmp(expected_tag, tag, sizeof(tag))) {
		fprintf(stderr, ""invalid MAC\n"");
		exit(3);
	}
}

int main() {
	test_initialization();
	test_entryption();
	test_auth();
}",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,314,2021-08-12T12:59:15Z,2021-08-18T08:49:36Z,2021-08-18T08:49:39Z,CLOSED,False,4,4,2,https://github.com/hg,RFC7539-related changes to ChaCha20,2,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/314,https://github.com/gsliepen,2,https://github.com/gsliepen/tinc/pull/314#issuecomment-897756890,"This is an attempt to align the ChaCha20 implementation with RFC7539 (related to #301).
It seems to be the right thing to do to increment the major protocol version. I don't think we can reset the minor version, though? It's compared with magic values 1 and 2 all over the place.
A large part of RFC7539 is the AEAD construction, which doesn't seem to be used in tinc. Instead we simply encrypt the plaintext and append the MAC to it. Were you planning to modify the protocol to add AEAD?

Because we don't have unit testing yet, I threw together a small program to check the algorithm against RFC test vectors:
$ cd src/chacha-poly1305/
$ cat >test.c
$ gcc poly1305.c chacha.c test.c
$ ./a.out

#include <stdint.h>
#include <string.h>
#include <stdlib.h>
#include <stdio.h>
#include ""chacha.h""
#include ""poly1305.h""

#define U8C(v) (v##U)
#define U32C(v) (v##U)

#define U8V(v) ((uint8_t)(v)&U8C(0xFF))
#define U32V(v) ((uint32_t)(v)&U32C(0xFFFFFFFF))

#define ROTL32(v, n) \
	(U32V((v) << (n)) | ((v) >> (32 - (n))))

#define U8TO32_LITTLE(p)              \
	(((uint32_t)((p)[0])) |       \
	 ((uint32_t)((p)[1]) << 8) |  \
	 ((uint32_t)((p)[2]) << 16) | \
	 ((uint32_t)((p)[3]) << 24))

#define U32TO8_LITTLE(p, v)              \
	do {                             \
		(p)[0] = U8V((v));       \
		(p)[1] = U8V((v) >> 8);  \
		(p)[2] = U8V((v) >> 16); \
		(p)[3] = U8V((v) >> 24); \
	} while(0)

#define ROTATE(v, c) (ROTL32(v, c))
#define XOR(v, w) ((v) ^ (w))
#define PLUS(v, w) (U32V((v) + (w)))
#define PLUSONE(v) (PLUS((v), 1))

#define QUARTERROUND(a, b, c, d)   \
	a = PLUS(a, b);            \
	d = ROTATE(XOR(d, a), 16); \
	c = PLUS(c, d);            \
	b = ROTATE(XOR(b, c), 12); \
	a = PLUS(a, b);            \
	d = ROTATE(XOR(d, a), 8);  \
	c = PLUS(c, d);            \
	b = ROTATE(XOR(b, c), 7);

static const uint8_t key[] = {
	0x00, 0x01, 0x02, 0x03, 0x04, 0x05, 0x06, 0x07, 0x08, 0x09, 0x0a, 0x0b, 0x0c, 0x0d, 0x0e, 0x0f,
	0x10, 0x11, 0x12, 0x13, 0x14, 0x15, 0x16, 0x17, 0x18, 0x19, 0x1a, 0x1b, 0x1c, 0x1d, 0x1e, 0x1f,
};

static const uint8_t one[8] = {1, 0, 0, 0, 0, 0, 0, 0};

static const uint32_t expected_initial_state[] = {
	0x61707865, 0x3320646e, 0x79622d32, 0x6b206574,
	0x03020100, 0x07060504, 0x0b0a0908, 0x0f0e0d0c,
	0x13121110, 0x17161514, 0x1b1a1918, 0x1f1e1d1c,
	0x00000001, 0x09000000, 0x4a000000, 0x00000000,
};

static const uint32_t expected_after_20_rounds[] = {
	0x837778ab, 0xe238d763, 0xa67ae21e, 0x5950bb2f,
	0xc4f2d0c7, 0xfc62bb2f, 0x8fa018fc, 0x3f5ec7b7,
	0x335271c2, 0xf29489f3, 0xeabda8fc, 0x82e46ebd,
	0xd19c12b4, 0xb04e16de, 0x9e83d0cb, 0x4e3c50a2,
};

static void check_state(const void *expected, const void *real, const char *kind) {
	if(memcmp(expected, real, sizeof(struct chacha_ctx))) {
		fprintf(stderr, ""invalid %s state\n"", kind);
		exit(1);
	}
}

// copy-pasted from chacha.c
static void run_20_rounds(struct chacha_ctx *ctx) {
	uint32_t x0 = ctx->input[0];
	uint32_t x1 = ctx->input[1];
	uint32_t x2 = ctx->input[2];
	uint32_t x3 = ctx->input[3];
	uint32_t x4 = ctx->input[4];
	uint32_t x5 = ctx->input[5];
	uint32_t x6 = ctx->input[6];
	uint32_t x7 = ctx->input[7];
	uint32_t x8 = ctx->input[8];
	uint32_t x9 = ctx->input[9];
	uint32_t x10 = ctx->input[10];
	uint32_t x11 = ctx->input[11];
	uint32_t x12 = ctx->input[12];
	uint32_t x13 = ctx->input[13];
	uint32_t x14 = ctx->input[14];
	uint32_t x15 = ctx->input[15];

	for(size_t i = 20; i > 0; i -= 2) {
		QUARTERROUND(x0, x4, x8, x12)
		QUARTERROUND(x1, x5, x9, x13)
		QUARTERROUND(x2, x6, x10, x14)
		QUARTERROUND(x3, x7, x11, x15)
		QUARTERROUND(x0, x5, x10, x15)
		QUARTERROUND(x1, x6, x11, x12)
		QUARTERROUND(x2, x7, x8, x13)
		QUARTERROUND(x3, x4, x9, x14)
	}

	U32TO8_LITTLE((uint8_t *) ctx + 0, x0);
	U32TO8_LITTLE((uint8_t *) ctx + 4, x1);
	U32TO8_LITTLE((uint8_t *) ctx + 8, x2);
	U32TO8_LITTLE((uint8_t *) ctx + 12, x3);
	U32TO8_LITTLE((uint8_t *) ctx + 16, x4);
	U32TO8_LITTLE((uint8_t *) ctx + 20, x5);
	U32TO8_LITTLE((uint8_t *) ctx + 24, x6);
	U32TO8_LITTLE((uint8_t *) ctx + 28, x7);
	U32TO8_LITTLE((uint8_t *) ctx + 32, x8);
	U32TO8_LITTLE((uint8_t *) ctx + 36, x9);
	U32TO8_LITTLE((uint8_t *) ctx + 40, x10);
	U32TO8_LITTLE((uint8_t *) ctx + 44, x11);
	U32TO8_LITTLE((uint8_t *) ctx + 48, x12);
	U32TO8_LITTLE((uint8_t *) ctx + 52, x13);
	U32TO8_LITTLE((uint8_t *) ctx + 56, x14);
	U32TO8_LITTLE((uint8_t *) ctx + 60, x15);
}

static void test_initialization() {
	static const uint8_t nonce[] = {
		0x00, 0x00, 0x00, 0x09, 0x00, 0x00, 0x00, 0x4a, 0x00, 0x00, 0x00, 0x00,
	};

	struct chacha_ctx ctx = {0};

	chacha_keysetup(&ctx, key, 256);
	chacha_ivsetup(&ctx, nonce, one);
	check_state(&expected_initial_state, &ctx, ""initial"");

	run_20_rounds(&ctx);
	check_state(&expected_after_20_rounds, &ctx, ""20 rounds"");
}

static void test_entryption() {
	const uint8_t plaintext[] = {
		0x4c, 0x61, 0x64, 0x69, 0x65, 0x73, 0x20, 0x61, 0x6e, 0x64, 0x20, 0x47, 0x65, 0x6e, 0x74, 0x6c,
		0x65, 0x6d, 0x65, 0x6e, 0x20, 0x6f, 0x66, 0x20, 0x74, 0x68, 0x65, 0x20, 0x63, 0x6c, 0x61, 0x73,
		0x73, 0x20, 0x6f, 0x66, 0x20, 0x27, 0x39, 0x39, 0x3a, 0x20, 0x49, 0x66, 0x20, 0x49, 0x20, 0x63,
		0x6f, 0x75, 0x6c, 0x64, 0x20, 0x6f, 0x66, 0x66, 0x65, 0x72, 0x20, 0x79, 0x6f, 0x75, 0x20, 0x6f,
		0x6e, 0x6c, 0x79, 0x20, 0x6f, 0x6e, 0x65, 0x20, 0x74, 0x69, 0x70, 0x20, 0x66, 0x6f, 0x72, 0x20,
		0x74, 0x68, 0x65, 0x20, 0x66, 0x75, 0x74, 0x75, 0x72, 0x65, 0x2c, 0x20, 0x73, 0x75, 0x6e, 0x73,
		0x63, 0x72, 0x65, 0x65, 0x6e, 0x20, 0x77, 0x6f, 0x75, 0x6c, 0x64, 0x20, 0x62, 0x65, 0x20, 0x69,
		0x74, 0x2e,
	};

	const uint8_t expected_ciphertext[] = {
		0x6e, 0x2e, 0x35, 0x9a, 0x25, 0x68, 0xf9, 0x80, 0x41, 0xba, 0x07, 0x28, 0xdd, 0x0d, 0x69, 0x81,
		0xe9, 0x7e, 0x7a, 0xec, 0x1d, 0x43, 0x60, 0xc2, 0x0a, 0x27, 0xaf, 0xcc, 0xfd, 0x9f, 0xae, 0x0b,
		0xf9, 0x1b, 0x65, 0xc5, 0x52, 0x47, 0x33, 0xab, 0x8f, 0x59, 0x3d, 0xab, 0xcd, 0x62, 0xb3, 0x57,
		0x16, 0x39, 0xd6, 0x24, 0xe6, 0x51, 0x52, 0xab, 0x8f, 0x53, 0x0c, 0x35, 0x9f, 0x08, 0x61, 0xd8,
		0x07, 0xca, 0x0d, 0xbf, 0x50, 0x0d, 0x6a, 0x61, 0x56, 0xa3, 0x8e, 0x08, 0x8a, 0x22, 0xb6, 0x5e,
		0x52, 0xbc, 0x51, 0x4d, 0x16, 0xcc, 0xf8, 0x06, 0x81, 0x8c, 0xe9, 0x1a, 0xb7, 0x79, 0x37, 0x36,
		0x5a, 0xf9, 0x0b, 0xbf, 0x74, 0xa3, 0x5b, 0xe6, 0xb4, 0x0b, 0x8e, 0xed, 0xf2, 0x78, 0x5e, 0x42,
		0x87, 0x4d,
	};

	static const uint8_t enc_nonce[] = {
		0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x4a, 0x00, 0x00, 0x00, 0x00,
	};

	uint8_t ciphertext[sizeof(expected_ciphertext)];

	struct chacha_ctx ctx = {0};
	chacha_keysetup(&ctx, key, 256);
	chacha_ivsetup(&ctx, enc_nonce, one);

	chacha_encrypt_bytes(&ctx, (uint8_t *) plaintext, ciphertext, sizeof(ciphertext));

	if(memcmp(expected_ciphertext, ciphertext, sizeof(ciphertext))) {
		fprintf(stderr, ""invalid ciphertext\n"");
		exit(2);
	}
}

static void test_auth() {
	const uint8_t key[] = {
		0x85, 0xd6, 0xbe, 0x78, 0x57, 0x55, 0x6d, 0x33, 0x7f, 0x44, 0x52, 0xfe, 0x42, 0xd5, 0x06, 0xa8,
		0x01, 0x03, 0x80, 0x8a, 0xfb, 0x0d, 0xb2, 0xfd, 0x4a, 0xbf, 0xf6, 0xaf, 0x41, 0x49, 0xf5, 0x1b,
	};

	const uint8_t msg[] = {
		0x43, 0x72, 0x79, 0x70, 0x74, 0x6f, 0x67, 0x72, 0x61, 0x70, 0x68, 0x69, 0x63, 0x20, 0x46, 0x6f,
		0x72, 0x75, 0x6d, 0x20, 0x52, 0x65, 0x73, 0x65, 0x61, 0x72, 0x63, 0x68, 0x20, 0x47, 0x72, 0x6f,
		0x75, 0x70,
	};

	const uint8_t  expected_tag[] = {
		0xa8, 0x06, 0x1d, 0xc1, 0x30, 0x51, 0x36, 0xc6, 0xc2, 0x2b, 0x8b, 0xaf, 0x0c, 0x01, 0x27, 0xa9,
	};

	uint8_t tag[POLY1305_TAGLEN];
	poly1305_auth(tag, msg, sizeof(msg), key);

	if(memcmp(expected_tag, tag, sizeof(tag))) {
		fprintf(stderr, ""invalid MAC\n"");
		exit(3);
	}
}

int main() {
	test_initialization();
	test_entryption();
	test_auth();
}","This is an attempt to align the ChaCha20 implementation with RFC7539 (related to #301).

I thought it would just be the IV but there are some other subtle differences that make it incompatible. I've actually already finished using RFC7539-compliant Chacha20-Poly1305 in commit 4b44259 in the feature/alt-ciphersuite branch. I should probably have mentioned that in #301, sorry!

It seems to be the right thing to do to increment the major protocol version. I don't think we can reset the minor version, though? It's compared with magic values 1 and 2 all over the place.

Well we're still in the -pre phase and we also still want compatibility with tinc 1.0 to ensure we can incrementally upgrade a VPN from 1.0 to 1.1 without having to synchronize all nodes at the same time. So the major version should stay 17 I think, the minor version can be bumped so a node using the fixed Chacha20-Poly1305 implementation can detect that an older node wants to connect and then report an error message.

A large part of RFC7539 is the AEAD construction, which doesn't seem to be used in tinc. Instead we simply encrypt the plaintext and append the MAC to it. Were you planning to modify the protocol to add AEAD?

I'm not planning to use the associated data part of AEAD.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,314,2021-08-12T12:59:15Z,2021-08-18T08:49:36Z,2021-08-18T08:49:39Z,CLOSED,False,4,4,2,https://github.com/hg,RFC7539-related changes to ChaCha20,2,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/314,https://github.com/fangfufu,3,https://github.com/gsliepen/tinc/pull/314#issuecomment-897768901,"This is an attempt to align the ChaCha20 implementation with RFC7539 (related to #301).
It seems to be the right thing to do to increment the major protocol version. I don't think we can reset the minor version, though? It's compared with magic values 1 and 2 all over the place.
A large part of RFC7539 is the AEAD construction, which doesn't seem to be used in tinc. Instead we simply encrypt the plaintext and append the MAC to it. Were you planning to modify the protocol to add AEAD?

Because we don't have unit testing yet, I threw together a small program to check the algorithm against RFC test vectors:
$ cd src/chacha-poly1305/
$ cat >test.c
$ gcc poly1305.c chacha.c test.c
$ ./a.out

#include <stdint.h>
#include <string.h>
#include <stdlib.h>
#include <stdio.h>
#include ""chacha.h""
#include ""poly1305.h""

#define U8C(v) (v##U)
#define U32C(v) (v##U)

#define U8V(v) ((uint8_t)(v)&U8C(0xFF))
#define U32V(v) ((uint32_t)(v)&U32C(0xFFFFFFFF))

#define ROTL32(v, n) \
	(U32V((v) << (n)) | ((v) >> (32 - (n))))

#define U8TO32_LITTLE(p)              \
	(((uint32_t)((p)[0])) |       \
	 ((uint32_t)((p)[1]) << 8) |  \
	 ((uint32_t)((p)[2]) << 16) | \
	 ((uint32_t)((p)[3]) << 24))

#define U32TO8_LITTLE(p, v)              \
	do {                             \
		(p)[0] = U8V((v));       \
		(p)[1] = U8V((v) >> 8);  \
		(p)[2] = U8V((v) >> 16); \
		(p)[3] = U8V((v) >> 24); \
	} while(0)

#define ROTATE(v, c) (ROTL32(v, c))
#define XOR(v, w) ((v) ^ (w))
#define PLUS(v, w) (U32V((v) + (w)))
#define PLUSONE(v) (PLUS((v), 1))

#define QUARTERROUND(a, b, c, d)   \
	a = PLUS(a, b);            \
	d = ROTATE(XOR(d, a), 16); \
	c = PLUS(c, d);            \
	b = ROTATE(XOR(b, c), 12); \
	a = PLUS(a, b);            \
	d = ROTATE(XOR(d, a), 8);  \
	c = PLUS(c, d);            \
	b = ROTATE(XOR(b, c), 7);

static const uint8_t key[] = {
	0x00, 0x01, 0x02, 0x03, 0x04, 0x05, 0x06, 0x07, 0x08, 0x09, 0x0a, 0x0b, 0x0c, 0x0d, 0x0e, 0x0f,
	0x10, 0x11, 0x12, 0x13, 0x14, 0x15, 0x16, 0x17, 0x18, 0x19, 0x1a, 0x1b, 0x1c, 0x1d, 0x1e, 0x1f,
};

static const uint8_t one[8] = {1, 0, 0, 0, 0, 0, 0, 0};

static const uint32_t expected_initial_state[] = {
	0x61707865, 0x3320646e, 0x79622d32, 0x6b206574,
	0x03020100, 0x07060504, 0x0b0a0908, 0x0f0e0d0c,
	0x13121110, 0x17161514, 0x1b1a1918, 0x1f1e1d1c,
	0x00000001, 0x09000000, 0x4a000000, 0x00000000,
};

static const uint32_t expected_after_20_rounds[] = {
	0x837778ab, 0xe238d763, 0xa67ae21e, 0x5950bb2f,
	0xc4f2d0c7, 0xfc62bb2f, 0x8fa018fc, 0x3f5ec7b7,
	0x335271c2, 0xf29489f3, 0xeabda8fc, 0x82e46ebd,
	0xd19c12b4, 0xb04e16de, 0x9e83d0cb, 0x4e3c50a2,
};

static void check_state(const void *expected, const void *real, const char *kind) {
	if(memcmp(expected, real, sizeof(struct chacha_ctx))) {
		fprintf(stderr, ""invalid %s state\n"", kind);
		exit(1);
	}
}

// copy-pasted from chacha.c
static void run_20_rounds(struct chacha_ctx *ctx) {
	uint32_t x0 = ctx->input[0];
	uint32_t x1 = ctx->input[1];
	uint32_t x2 = ctx->input[2];
	uint32_t x3 = ctx->input[3];
	uint32_t x4 = ctx->input[4];
	uint32_t x5 = ctx->input[5];
	uint32_t x6 = ctx->input[6];
	uint32_t x7 = ctx->input[7];
	uint32_t x8 = ctx->input[8];
	uint32_t x9 = ctx->input[9];
	uint32_t x10 = ctx->input[10];
	uint32_t x11 = ctx->input[11];
	uint32_t x12 = ctx->input[12];
	uint32_t x13 = ctx->input[13];
	uint32_t x14 = ctx->input[14];
	uint32_t x15 = ctx->input[15];

	for(size_t i = 20; i > 0; i -= 2) {
		QUARTERROUND(x0, x4, x8, x12)
		QUARTERROUND(x1, x5, x9, x13)
		QUARTERROUND(x2, x6, x10, x14)
		QUARTERROUND(x3, x7, x11, x15)
		QUARTERROUND(x0, x5, x10, x15)
		QUARTERROUND(x1, x6, x11, x12)
		QUARTERROUND(x2, x7, x8, x13)
		QUARTERROUND(x3, x4, x9, x14)
	}

	U32TO8_LITTLE((uint8_t *) ctx + 0, x0);
	U32TO8_LITTLE((uint8_t *) ctx + 4, x1);
	U32TO8_LITTLE((uint8_t *) ctx + 8, x2);
	U32TO8_LITTLE((uint8_t *) ctx + 12, x3);
	U32TO8_LITTLE((uint8_t *) ctx + 16, x4);
	U32TO8_LITTLE((uint8_t *) ctx + 20, x5);
	U32TO8_LITTLE((uint8_t *) ctx + 24, x6);
	U32TO8_LITTLE((uint8_t *) ctx + 28, x7);
	U32TO8_LITTLE((uint8_t *) ctx + 32, x8);
	U32TO8_LITTLE((uint8_t *) ctx + 36, x9);
	U32TO8_LITTLE((uint8_t *) ctx + 40, x10);
	U32TO8_LITTLE((uint8_t *) ctx + 44, x11);
	U32TO8_LITTLE((uint8_t *) ctx + 48, x12);
	U32TO8_LITTLE((uint8_t *) ctx + 52, x13);
	U32TO8_LITTLE((uint8_t *) ctx + 56, x14);
	U32TO8_LITTLE((uint8_t *) ctx + 60, x15);
}

static void test_initialization() {
	static const uint8_t nonce[] = {
		0x00, 0x00, 0x00, 0x09, 0x00, 0x00, 0x00, 0x4a, 0x00, 0x00, 0x00, 0x00,
	};

	struct chacha_ctx ctx = {0};

	chacha_keysetup(&ctx, key, 256);
	chacha_ivsetup(&ctx, nonce, one);
	check_state(&expected_initial_state, &ctx, ""initial"");

	run_20_rounds(&ctx);
	check_state(&expected_after_20_rounds, &ctx, ""20 rounds"");
}

static void test_entryption() {
	const uint8_t plaintext[] = {
		0x4c, 0x61, 0x64, 0x69, 0x65, 0x73, 0x20, 0x61, 0x6e, 0x64, 0x20, 0x47, 0x65, 0x6e, 0x74, 0x6c,
		0x65, 0x6d, 0x65, 0x6e, 0x20, 0x6f, 0x66, 0x20, 0x74, 0x68, 0x65, 0x20, 0x63, 0x6c, 0x61, 0x73,
		0x73, 0x20, 0x6f, 0x66, 0x20, 0x27, 0x39, 0x39, 0x3a, 0x20, 0x49, 0x66, 0x20, 0x49, 0x20, 0x63,
		0x6f, 0x75, 0x6c, 0x64, 0x20, 0x6f, 0x66, 0x66, 0x65, 0x72, 0x20, 0x79, 0x6f, 0x75, 0x20, 0x6f,
		0x6e, 0x6c, 0x79, 0x20, 0x6f, 0x6e, 0x65, 0x20, 0x74, 0x69, 0x70, 0x20, 0x66, 0x6f, 0x72, 0x20,
		0x74, 0x68, 0x65, 0x20, 0x66, 0x75, 0x74, 0x75, 0x72, 0x65, 0x2c, 0x20, 0x73, 0x75, 0x6e, 0x73,
		0x63, 0x72, 0x65, 0x65, 0x6e, 0x20, 0x77, 0x6f, 0x75, 0x6c, 0x64, 0x20, 0x62, 0x65, 0x20, 0x69,
		0x74, 0x2e,
	};

	const uint8_t expected_ciphertext[] = {
		0x6e, 0x2e, 0x35, 0x9a, 0x25, 0x68, 0xf9, 0x80, 0x41, 0xba, 0x07, 0x28, 0xdd, 0x0d, 0x69, 0x81,
		0xe9, 0x7e, 0x7a, 0xec, 0x1d, 0x43, 0x60, 0xc2, 0x0a, 0x27, 0xaf, 0xcc, 0xfd, 0x9f, 0xae, 0x0b,
		0xf9, 0x1b, 0x65, 0xc5, 0x52, 0x47, 0x33, 0xab, 0x8f, 0x59, 0x3d, 0xab, 0xcd, 0x62, 0xb3, 0x57,
		0x16, 0x39, 0xd6, 0x24, 0xe6, 0x51, 0x52, 0xab, 0x8f, 0x53, 0x0c, 0x35, 0x9f, 0x08, 0x61, 0xd8,
		0x07, 0xca, 0x0d, 0xbf, 0x50, 0x0d, 0x6a, 0x61, 0x56, 0xa3, 0x8e, 0x08, 0x8a, 0x22, 0xb6, 0x5e,
		0x52, 0xbc, 0x51, 0x4d, 0x16, 0xcc, 0xf8, 0x06, 0x81, 0x8c, 0xe9, 0x1a, 0xb7, 0x79, 0x37, 0x36,
		0x5a, 0xf9, 0x0b, 0xbf, 0x74, 0xa3, 0x5b, 0xe6, 0xb4, 0x0b, 0x8e, 0xed, 0xf2, 0x78, 0x5e, 0x42,
		0x87, 0x4d,
	};

	static const uint8_t enc_nonce[] = {
		0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x4a, 0x00, 0x00, 0x00, 0x00,
	};

	uint8_t ciphertext[sizeof(expected_ciphertext)];

	struct chacha_ctx ctx = {0};
	chacha_keysetup(&ctx, key, 256);
	chacha_ivsetup(&ctx, enc_nonce, one);

	chacha_encrypt_bytes(&ctx, (uint8_t *) plaintext, ciphertext, sizeof(ciphertext));

	if(memcmp(expected_ciphertext, ciphertext, sizeof(ciphertext))) {
		fprintf(stderr, ""invalid ciphertext\n"");
		exit(2);
	}
}

static void test_auth() {
	const uint8_t key[] = {
		0x85, 0xd6, 0xbe, 0x78, 0x57, 0x55, 0x6d, 0x33, 0x7f, 0x44, 0x52, 0xfe, 0x42, 0xd5, 0x06, 0xa8,
		0x01, 0x03, 0x80, 0x8a, 0xfb, 0x0d, 0xb2, 0xfd, 0x4a, 0xbf, 0xf6, 0xaf, 0x41, 0x49, 0xf5, 0x1b,
	};

	const uint8_t msg[] = {
		0x43, 0x72, 0x79, 0x70, 0x74, 0x6f, 0x67, 0x72, 0x61, 0x70, 0x68, 0x69, 0x63, 0x20, 0x46, 0x6f,
		0x72, 0x75, 0x6d, 0x20, 0x52, 0x65, 0x73, 0x65, 0x61, 0x72, 0x63, 0x68, 0x20, 0x47, 0x72, 0x6f,
		0x75, 0x70,
	};

	const uint8_t  expected_tag[] = {
		0xa8, 0x06, 0x1d, 0xc1, 0x30, 0x51, 0x36, 0xc6, 0xc2, 0x2b, 0x8b, 0xaf, 0x0c, 0x01, 0x27, 0xa9,
	};

	uint8_t tag[POLY1305_TAGLEN];
	poly1305_auth(tag, msg, sizeof(msg), key);

	if(memcmp(expected_tag, tag, sizeof(tag))) {
		fprintf(stderr, ""invalid MAC\n"");
		exit(3);
	}
}

int main() {
	test_initialization();
	test_entryption();
	test_auth();
}","Well we're still in the -pre phase and we also still want compatibility with tinc 1.0 to ensure we can incrementally upgrade a VPN from 1.0 to 1.1 without having to synchronize all nodes at the same time.

It would be nice if users of tinc 1.1 can do upgrade without having to synchronise all nodes at the same time.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,314,2021-08-12T12:59:15Z,2021-08-18T08:49:36Z,2021-08-18T08:49:39Z,CLOSED,False,4,4,2,https://github.com/hg,RFC7539-related changes to ChaCha20,2,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/314,https://github.com/gsliepen,4,https://github.com/gsliepen/tinc/pull/314#issuecomment-897826686,"This is an attempt to align the ChaCha20 implementation with RFC7539 (related to #301).
It seems to be the right thing to do to increment the major protocol version. I don't think we can reset the minor version, though? It's compared with magic values 1 and 2 all over the place.
A large part of RFC7539 is the AEAD construction, which doesn't seem to be used in tinc. Instead we simply encrypt the plaintext and append the MAC to it. Were you planning to modify the protocol to add AEAD?

Because we don't have unit testing yet, I threw together a small program to check the algorithm against RFC test vectors:
$ cd src/chacha-poly1305/
$ cat >test.c
$ gcc poly1305.c chacha.c test.c
$ ./a.out

#include <stdint.h>
#include <string.h>
#include <stdlib.h>
#include <stdio.h>
#include ""chacha.h""
#include ""poly1305.h""

#define U8C(v) (v##U)
#define U32C(v) (v##U)

#define U8V(v) ((uint8_t)(v)&U8C(0xFF))
#define U32V(v) ((uint32_t)(v)&U32C(0xFFFFFFFF))

#define ROTL32(v, n) \
	(U32V((v) << (n)) | ((v) >> (32 - (n))))

#define U8TO32_LITTLE(p)              \
	(((uint32_t)((p)[0])) |       \
	 ((uint32_t)((p)[1]) << 8) |  \
	 ((uint32_t)((p)[2]) << 16) | \
	 ((uint32_t)((p)[3]) << 24))

#define U32TO8_LITTLE(p, v)              \
	do {                             \
		(p)[0] = U8V((v));       \
		(p)[1] = U8V((v) >> 8);  \
		(p)[2] = U8V((v) >> 16); \
		(p)[3] = U8V((v) >> 24); \
	} while(0)

#define ROTATE(v, c) (ROTL32(v, c))
#define XOR(v, w) ((v) ^ (w))
#define PLUS(v, w) (U32V((v) + (w)))
#define PLUSONE(v) (PLUS((v), 1))

#define QUARTERROUND(a, b, c, d)   \
	a = PLUS(a, b);            \
	d = ROTATE(XOR(d, a), 16); \
	c = PLUS(c, d);            \
	b = ROTATE(XOR(b, c), 12); \
	a = PLUS(a, b);            \
	d = ROTATE(XOR(d, a), 8);  \
	c = PLUS(c, d);            \
	b = ROTATE(XOR(b, c), 7);

static const uint8_t key[] = {
	0x00, 0x01, 0x02, 0x03, 0x04, 0x05, 0x06, 0x07, 0x08, 0x09, 0x0a, 0x0b, 0x0c, 0x0d, 0x0e, 0x0f,
	0x10, 0x11, 0x12, 0x13, 0x14, 0x15, 0x16, 0x17, 0x18, 0x19, 0x1a, 0x1b, 0x1c, 0x1d, 0x1e, 0x1f,
};

static const uint8_t one[8] = {1, 0, 0, 0, 0, 0, 0, 0};

static const uint32_t expected_initial_state[] = {
	0x61707865, 0x3320646e, 0x79622d32, 0x6b206574,
	0x03020100, 0x07060504, 0x0b0a0908, 0x0f0e0d0c,
	0x13121110, 0x17161514, 0x1b1a1918, 0x1f1e1d1c,
	0x00000001, 0x09000000, 0x4a000000, 0x00000000,
};

static const uint32_t expected_after_20_rounds[] = {
	0x837778ab, 0xe238d763, 0xa67ae21e, 0x5950bb2f,
	0xc4f2d0c7, 0xfc62bb2f, 0x8fa018fc, 0x3f5ec7b7,
	0x335271c2, 0xf29489f3, 0xeabda8fc, 0x82e46ebd,
	0xd19c12b4, 0xb04e16de, 0x9e83d0cb, 0x4e3c50a2,
};

static void check_state(const void *expected, const void *real, const char *kind) {
	if(memcmp(expected, real, sizeof(struct chacha_ctx))) {
		fprintf(stderr, ""invalid %s state\n"", kind);
		exit(1);
	}
}

// copy-pasted from chacha.c
static void run_20_rounds(struct chacha_ctx *ctx) {
	uint32_t x0 = ctx->input[0];
	uint32_t x1 = ctx->input[1];
	uint32_t x2 = ctx->input[2];
	uint32_t x3 = ctx->input[3];
	uint32_t x4 = ctx->input[4];
	uint32_t x5 = ctx->input[5];
	uint32_t x6 = ctx->input[6];
	uint32_t x7 = ctx->input[7];
	uint32_t x8 = ctx->input[8];
	uint32_t x9 = ctx->input[9];
	uint32_t x10 = ctx->input[10];
	uint32_t x11 = ctx->input[11];
	uint32_t x12 = ctx->input[12];
	uint32_t x13 = ctx->input[13];
	uint32_t x14 = ctx->input[14];
	uint32_t x15 = ctx->input[15];

	for(size_t i = 20; i > 0; i -= 2) {
		QUARTERROUND(x0, x4, x8, x12)
		QUARTERROUND(x1, x5, x9, x13)
		QUARTERROUND(x2, x6, x10, x14)
		QUARTERROUND(x3, x7, x11, x15)
		QUARTERROUND(x0, x5, x10, x15)
		QUARTERROUND(x1, x6, x11, x12)
		QUARTERROUND(x2, x7, x8, x13)
		QUARTERROUND(x3, x4, x9, x14)
	}

	U32TO8_LITTLE((uint8_t *) ctx + 0, x0);
	U32TO8_LITTLE((uint8_t *) ctx + 4, x1);
	U32TO8_LITTLE((uint8_t *) ctx + 8, x2);
	U32TO8_LITTLE((uint8_t *) ctx + 12, x3);
	U32TO8_LITTLE((uint8_t *) ctx + 16, x4);
	U32TO8_LITTLE((uint8_t *) ctx + 20, x5);
	U32TO8_LITTLE((uint8_t *) ctx + 24, x6);
	U32TO8_LITTLE((uint8_t *) ctx + 28, x7);
	U32TO8_LITTLE((uint8_t *) ctx + 32, x8);
	U32TO8_LITTLE((uint8_t *) ctx + 36, x9);
	U32TO8_LITTLE((uint8_t *) ctx + 40, x10);
	U32TO8_LITTLE((uint8_t *) ctx + 44, x11);
	U32TO8_LITTLE((uint8_t *) ctx + 48, x12);
	U32TO8_LITTLE((uint8_t *) ctx + 52, x13);
	U32TO8_LITTLE((uint8_t *) ctx + 56, x14);
	U32TO8_LITTLE((uint8_t *) ctx + 60, x15);
}

static void test_initialization() {
	static const uint8_t nonce[] = {
		0x00, 0x00, 0x00, 0x09, 0x00, 0x00, 0x00, 0x4a, 0x00, 0x00, 0x00, 0x00,
	};

	struct chacha_ctx ctx = {0};

	chacha_keysetup(&ctx, key, 256);
	chacha_ivsetup(&ctx, nonce, one);
	check_state(&expected_initial_state, &ctx, ""initial"");

	run_20_rounds(&ctx);
	check_state(&expected_after_20_rounds, &ctx, ""20 rounds"");
}

static void test_entryption() {
	const uint8_t plaintext[] = {
		0x4c, 0x61, 0x64, 0x69, 0x65, 0x73, 0x20, 0x61, 0x6e, 0x64, 0x20, 0x47, 0x65, 0x6e, 0x74, 0x6c,
		0x65, 0x6d, 0x65, 0x6e, 0x20, 0x6f, 0x66, 0x20, 0x74, 0x68, 0x65, 0x20, 0x63, 0x6c, 0x61, 0x73,
		0x73, 0x20, 0x6f, 0x66, 0x20, 0x27, 0x39, 0x39, 0x3a, 0x20, 0x49, 0x66, 0x20, 0x49, 0x20, 0x63,
		0x6f, 0x75, 0x6c, 0x64, 0x20, 0x6f, 0x66, 0x66, 0x65, 0x72, 0x20, 0x79, 0x6f, 0x75, 0x20, 0x6f,
		0x6e, 0x6c, 0x79, 0x20, 0x6f, 0x6e, 0x65, 0x20, 0x74, 0x69, 0x70, 0x20, 0x66, 0x6f, 0x72, 0x20,
		0x74, 0x68, 0x65, 0x20, 0x66, 0x75, 0x74, 0x75, 0x72, 0x65, 0x2c, 0x20, 0x73, 0x75, 0x6e, 0x73,
		0x63, 0x72, 0x65, 0x65, 0x6e, 0x20, 0x77, 0x6f, 0x75, 0x6c, 0x64, 0x20, 0x62, 0x65, 0x20, 0x69,
		0x74, 0x2e,
	};

	const uint8_t expected_ciphertext[] = {
		0x6e, 0x2e, 0x35, 0x9a, 0x25, 0x68, 0xf9, 0x80, 0x41, 0xba, 0x07, 0x28, 0xdd, 0x0d, 0x69, 0x81,
		0xe9, 0x7e, 0x7a, 0xec, 0x1d, 0x43, 0x60, 0xc2, 0x0a, 0x27, 0xaf, 0xcc, 0xfd, 0x9f, 0xae, 0x0b,
		0xf9, 0x1b, 0x65, 0xc5, 0x52, 0x47, 0x33, 0xab, 0x8f, 0x59, 0x3d, 0xab, 0xcd, 0x62, 0xb3, 0x57,
		0x16, 0x39, 0xd6, 0x24, 0xe6, 0x51, 0x52, 0xab, 0x8f, 0x53, 0x0c, 0x35, 0x9f, 0x08, 0x61, 0xd8,
		0x07, 0xca, 0x0d, 0xbf, 0x50, 0x0d, 0x6a, 0x61, 0x56, 0xa3, 0x8e, 0x08, 0x8a, 0x22, 0xb6, 0x5e,
		0x52, 0xbc, 0x51, 0x4d, 0x16, 0xcc, 0xf8, 0x06, 0x81, 0x8c, 0xe9, 0x1a, 0xb7, 0x79, 0x37, 0x36,
		0x5a, 0xf9, 0x0b, 0xbf, 0x74, 0xa3, 0x5b, 0xe6, 0xb4, 0x0b, 0x8e, 0xed, 0xf2, 0x78, 0x5e, 0x42,
		0x87, 0x4d,
	};

	static const uint8_t enc_nonce[] = {
		0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x4a, 0x00, 0x00, 0x00, 0x00,
	};

	uint8_t ciphertext[sizeof(expected_ciphertext)];

	struct chacha_ctx ctx = {0};
	chacha_keysetup(&ctx, key, 256);
	chacha_ivsetup(&ctx, enc_nonce, one);

	chacha_encrypt_bytes(&ctx, (uint8_t *) plaintext, ciphertext, sizeof(ciphertext));

	if(memcmp(expected_ciphertext, ciphertext, sizeof(ciphertext))) {
		fprintf(stderr, ""invalid ciphertext\n"");
		exit(2);
	}
}

static void test_auth() {
	const uint8_t key[] = {
		0x85, 0xd6, 0xbe, 0x78, 0x57, 0x55, 0x6d, 0x33, 0x7f, 0x44, 0x52, 0xfe, 0x42, 0xd5, 0x06, 0xa8,
		0x01, 0x03, 0x80, 0x8a, 0xfb, 0x0d, 0xb2, 0xfd, 0x4a, 0xbf, 0xf6, 0xaf, 0x41, 0x49, 0xf5, 0x1b,
	};

	const uint8_t msg[] = {
		0x43, 0x72, 0x79, 0x70, 0x74, 0x6f, 0x67, 0x72, 0x61, 0x70, 0x68, 0x69, 0x63, 0x20, 0x46, 0x6f,
		0x72, 0x75, 0x6d, 0x20, 0x52, 0x65, 0x73, 0x65, 0x61, 0x72, 0x63, 0x68, 0x20, 0x47, 0x72, 0x6f,
		0x75, 0x70,
	};

	const uint8_t  expected_tag[] = {
		0xa8, 0x06, 0x1d, 0xc1, 0x30, 0x51, 0x36, 0xc6, 0xc2, 0x2b, 0x8b, 0xaf, 0x0c, 0x01, 0x27, 0xa9,
	};

	uint8_t tag[POLY1305_TAGLEN];
	poly1305_auth(tag, msg, sizeof(msg), key);

	if(memcmp(expected_tag, tag, sizeof(tag))) {
		fprintf(stderr, ""invalid MAC\n"");
		exit(3);
	}
}

int main() {
	test_initialization();
	test_entryption();
	test_auth();
}","I guess we could keep a copy of the ""wrong"" Chacha20-Poly1305 and only use that for old nodes 1.1, and then remove that at some point.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,314,2021-08-12T12:59:15Z,2021-08-18T08:49:36Z,2021-08-18T08:49:39Z,CLOSED,False,4,4,2,https://github.com/hg,RFC7539-related changes to ChaCha20,2,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/314,https://github.com/fangfufu,5,https://github.com/gsliepen/tinc/pull/314#issuecomment-897958176,"This is an attempt to align the ChaCha20 implementation with RFC7539 (related to #301).
It seems to be the right thing to do to increment the major protocol version. I don't think we can reset the minor version, though? It's compared with magic values 1 and 2 all over the place.
A large part of RFC7539 is the AEAD construction, which doesn't seem to be used in tinc. Instead we simply encrypt the plaintext and append the MAC to it. Were you planning to modify the protocol to add AEAD?

Because we don't have unit testing yet, I threw together a small program to check the algorithm against RFC test vectors:
$ cd src/chacha-poly1305/
$ cat >test.c
$ gcc poly1305.c chacha.c test.c
$ ./a.out

#include <stdint.h>
#include <string.h>
#include <stdlib.h>
#include <stdio.h>
#include ""chacha.h""
#include ""poly1305.h""

#define U8C(v) (v##U)
#define U32C(v) (v##U)

#define U8V(v) ((uint8_t)(v)&U8C(0xFF))
#define U32V(v) ((uint32_t)(v)&U32C(0xFFFFFFFF))

#define ROTL32(v, n) \
	(U32V((v) << (n)) | ((v) >> (32 - (n))))

#define U8TO32_LITTLE(p)              \
	(((uint32_t)((p)[0])) |       \
	 ((uint32_t)((p)[1]) << 8) |  \
	 ((uint32_t)((p)[2]) << 16) | \
	 ((uint32_t)((p)[3]) << 24))

#define U32TO8_LITTLE(p, v)              \
	do {                             \
		(p)[0] = U8V((v));       \
		(p)[1] = U8V((v) >> 8);  \
		(p)[2] = U8V((v) >> 16); \
		(p)[3] = U8V((v) >> 24); \
	} while(0)

#define ROTATE(v, c) (ROTL32(v, c))
#define XOR(v, w) ((v) ^ (w))
#define PLUS(v, w) (U32V((v) + (w)))
#define PLUSONE(v) (PLUS((v), 1))

#define QUARTERROUND(a, b, c, d)   \
	a = PLUS(a, b);            \
	d = ROTATE(XOR(d, a), 16); \
	c = PLUS(c, d);            \
	b = ROTATE(XOR(b, c), 12); \
	a = PLUS(a, b);            \
	d = ROTATE(XOR(d, a), 8);  \
	c = PLUS(c, d);            \
	b = ROTATE(XOR(b, c), 7);

static const uint8_t key[] = {
	0x00, 0x01, 0x02, 0x03, 0x04, 0x05, 0x06, 0x07, 0x08, 0x09, 0x0a, 0x0b, 0x0c, 0x0d, 0x0e, 0x0f,
	0x10, 0x11, 0x12, 0x13, 0x14, 0x15, 0x16, 0x17, 0x18, 0x19, 0x1a, 0x1b, 0x1c, 0x1d, 0x1e, 0x1f,
};

static const uint8_t one[8] = {1, 0, 0, 0, 0, 0, 0, 0};

static const uint32_t expected_initial_state[] = {
	0x61707865, 0x3320646e, 0x79622d32, 0x6b206574,
	0x03020100, 0x07060504, 0x0b0a0908, 0x0f0e0d0c,
	0x13121110, 0x17161514, 0x1b1a1918, 0x1f1e1d1c,
	0x00000001, 0x09000000, 0x4a000000, 0x00000000,
};

static const uint32_t expected_after_20_rounds[] = {
	0x837778ab, 0xe238d763, 0xa67ae21e, 0x5950bb2f,
	0xc4f2d0c7, 0xfc62bb2f, 0x8fa018fc, 0x3f5ec7b7,
	0x335271c2, 0xf29489f3, 0xeabda8fc, 0x82e46ebd,
	0xd19c12b4, 0xb04e16de, 0x9e83d0cb, 0x4e3c50a2,
};

static void check_state(const void *expected, const void *real, const char *kind) {
	if(memcmp(expected, real, sizeof(struct chacha_ctx))) {
		fprintf(stderr, ""invalid %s state\n"", kind);
		exit(1);
	}
}

// copy-pasted from chacha.c
static void run_20_rounds(struct chacha_ctx *ctx) {
	uint32_t x0 = ctx->input[0];
	uint32_t x1 = ctx->input[1];
	uint32_t x2 = ctx->input[2];
	uint32_t x3 = ctx->input[3];
	uint32_t x4 = ctx->input[4];
	uint32_t x5 = ctx->input[5];
	uint32_t x6 = ctx->input[6];
	uint32_t x7 = ctx->input[7];
	uint32_t x8 = ctx->input[8];
	uint32_t x9 = ctx->input[9];
	uint32_t x10 = ctx->input[10];
	uint32_t x11 = ctx->input[11];
	uint32_t x12 = ctx->input[12];
	uint32_t x13 = ctx->input[13];
	uint32_t x14 = ctx->input[14];
	uint32_t x15 = ctx->input[15];

	for(size_t i = 20; i > 0; i -= 2) {
		QUARTERROUND(x0, x4, x8, x12)
		QUARTERROUND(x1, x5, x9, x13)
		QUARTERROUND(x2, x6, x10, x14)
		QUARTERROUND(x3, x7, x11, x15)
		QUARTERROUND(x0, x5, x10, x15)
		QUARTERROUND(x1, x6, x11, x12)
		QUARTERROUND(x2, x7, x8, x13)
		QUARTERROUND(x3, x4, x9, x14)
	}

	U32TO8_LITTLE((uint8_t *) ctx + 0, x0);
	U32TO8_LITTLE((uint8_t *) ctx + 4, x1);
	U32TO8_LITTLE((uint8_t *) ctx + 8, x2);
	U32TO8_LITTLE((uint8_t *) ctx + 12, x3);
	U32TO8_LITTLE((uint8_t *) ctx + 16, x4);
	U32TO8_LITTLE((uint8_t *) ctx + 20, x5);
	U32TO8_LITTLE((uint8_t *) ctx + 24, x6);
	U32TO8_LITTLE((uint8_t *) ctx + 28, x7);
	U32TO8_LITTLE((uint8_t *) ctx + 32, x8);
	U32TO8_LITTLE((uint8_t *) ctx + 36, x9);
	U32TO8_LITTLE((uint8_t *) ctx + 40, x10);
	U32TO8_LITTLE((uint8_t *) ctx + 44, x11);
	U32TO8_LITTLE((uint8_t *) ctx + 48, x12);
	U32TO8_LITTLE((uint8_t *) ctx + 52, x13);
	U32TO8_LITTLE((uint8_t *) ctx + 56, x14);
	U32TO8_LITTLE((uint8_t *) ctx + 60, x15);
}

static void test_initialization() {
	static const uint8_t nonce[] = {
		0x00, 0x00, 0x00, 0x09, 0x00, 0x00, 0x00, 0x4a, 0x00, 0x00, 0x00, 0x00,
	};

	struct chacha_ctx ctx = {0};

	chacha_keysetup(&ctx, key, 256);
	chacha_ivsetup(&ctx, nonce, one);
	check_state(&expected_initial_state, &ctx, ""initial"");

	run_20_rounds(&ctx);
	check_state(&expected_after_20_rounds, &ctx, ""20 rounds"");
}

static void test_entryption() {
	const uint8_t plaintext[] = {
		0x4c, 0x61, 0x64, 0x69, 0x65, 0x73, 0x20, 0x61, 0x6e, 0x64, 0x20, 0x47, 0x65, 0x6e, 0x74, 0x6c,
		0x65, 0x6d, 0x65, 0x6e, 0x20, 0x6f, 0x66, 0x20, 0x74, 0x68, 0x65, 0x20, 0x63, 0x6c, 0x61, 0x73,
		0x73, 0x20, 0x6f, 0x66, 0x20, 0x27, 0x39, 0x39, 0x3a, 0x20, 0x49, 0x66, 0x20, 0x49, 0x20, 0x63,
		0x6f, 0x75, 0x6c, 0x64, 0x20, 0x6f, 0x66, 0x66, 0x65, 0x72, 0x20, 0x79, 0x6f, 0x75, 0x20, 0x6f,
		0x6e, 0x6c, 0x79, 0x20, 0x6f, 0x6e, 0x65, 0x20, 0x74, 0x69, 0x70, 0x20, 0x66, 0x6f, 0x72, 0x20,
		0x74, 0x68, 0x65, 0x20, 0x66, 0x75, 0x74, 0x75, 0x72, 0x65, 0x2c, 0x20, 0x73, 0x75, 0x6e, 0x73,
		0x63, 0x72, 0x65, 0x65, 0x6e, 0x20, 0x77, 0x6f, 0x75, 0x6c, 0x64, 0x20, 0x62, 0x65, 0x20, 0x69,
		0x74, 0x2e,
	};

	const uint8_t expected_ciphertext[] = {
		0x6e, 0x2e, 0x35, 0x9a, 0x25, 0x68, 0xf9, 0x80, 0x41, 0xba, 0x07, 0x28, 0xdd, 0x0d, 0x69, 0x81,
		0xe9, 0x7e, 0x7a, 0xec, 0x1d, 0x43, 0x60, 0xc2, 0x0a, 0x27, 0xaf, 0xcc, 0xfd, 0x9f, 0xae, 0x0b,
		0xf9, 0x1b, 0x65, 0xc5, 0x52, 0x47, 0x33, 0xab, 0x8f, 0x59, 0x3d, 0xab, 0xcd, 0x62, 0xb3, 0x57,
		0x16, 0x39, 0xd6, 0x24, 0xe6, 0x51, 0x52, 0xab, 0x8f, 0x53, 0x0c, 0x35, 0x9f, 0x08, 0x61, 0xd8,
		0x07, 0xca, 0x0d, 0xbf, 0x50, 0x0d, 0x6a, 0x61, 0x56, 0xa3, 0x8e, 0x08, 0x8a, 0x22, 0xb6, 0x5e,
		0x52, 0xbc, 0x51, 0x4d, 0x16, 0xcc, 0xf8, 0x06, 0x81, 0x8c, 0xe9, 0x1a, 0xb7, 0x79, 0x37, 0x36,
		0x5a, 0xf9, 0x0b, 0xbf, 0x74, 0xa3, 0x5b, 0xe6, 0xb4, 0x0b, 0x8e, 0xed, 0xf2, 0x78, 0x5e, 0x42,
		0x87, 0x4d,
	};

	static const uint8_t enc_nonce[] = {
		0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x4a, 0x00, 0x00, 0x00, 0x00,
	};

	uint8_t ciphertext[sizeof(expected_ciphertext)];

	struct chacha_ctx ctx = {0};
	chacha_keysetup(&ctx, key, 256);
	chacha_ivsetup(&ctx, enc_nonce, one);

	chacha_encrypt_bytes(&ctx, (uint8_t *) plaintext, ciphertext, sizeof(ciphertext));

	if(memcmp(expected_ciphertext, ciphertext, sizeof(ciphertext))) {
		fprintf(stderr, ""invalid ciphertext\n"");
		exit(2);
	}
}

static void test_auth() {
	const uint8_t key[] = {
		0x85, 0xd6, 0xbe, 0x78, 0x57, 0x55, 0x6d, 0x33, 0x7f, 0x44, 0x52, 0xfe, 0x42, 0xd5, 0x06, 0xa8,
		0x01, 0x03, 0x80, 0x8a, 0xfb, 0x0d, 0xb2, 0xfd, 0x4a, 0xbf, 0xf6, 0xaf, 0x41, 0x49, 0xf5, 0x1b,
	};

	const uint8_t msg[] = {
		0x43, 0x72, 0x79, 0x70, 0x74, 0x6f, 0x67, 0x72, 0x61, 0x70, 0x68, 0x69, 0x63, 0x20, 0x46, 0x6f,
		0x72, 0x75, 0x6d, 0x20, 0x52, 0x65, 0x73, 0x65, 0x61, 0x72, 0x63, 0x68, 0x20, 0x47, 0x72, 0x6f,
		0x75, 0x70,
	};

	const uint8_t  expected_tag[] = {
		0xa8, 0x06, 0x1d, 0xc1, 0x30, 0x51, 0x36, 0xc6, 0xc2, 0x2b, 0x8b, 0xaf, 0x0c, 0x01, 0x27, 0xa9,
	};

	uint8_t tag[POLY1305_TAGLEN];
	poly1305_auth(tag, msg, sizeof(msg), key);

	if(memcmp(expected_tag, tag, sizeof(tag))) {
		fprintf(stderr, ""invalid MAC\n"");
		exit(3);
	}
}

int main() {
	test_initialization();
	test_entryption();
	test_auth();
}","I guess we could keep a copy of the ""wrong"" Chacha20-Poly1305 and only use that for old nodes 1.1, and then remove that at some point.

Can we get the new 1.1 node to fall back to 1.0 protocol, if the other 1.1 node is using an outdated 1.1 protocol?",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,314,2021-08-12T12:59:15Z,2021-08-18T08:49:36Z,2021-08-18T08:49:39Z,CLOSED,False,4,4,2,https://github.com/hg,RFC7539-related changes to ChaCha20,2,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/314,https://github.com/gsliepen,6,https://github.com/gsliepen/tinc/pull/314#issuecomment-897965556,"This is an attempt to align the ChaCha20 implementation with RFC7539 (related to #301).
It seems to be the right thing to do to increment the major protocol version. I don't think we can reset the minor version, though? It's compared with magic values 1 and 2 all over the place.
A large part of RFC7539 is the AEAD construction, which doesn't seem to be used in tinc. Instead we simply encrypt the plaintext and append the MAC to it. Were you planning to modify the protocol to add AEAD?

Because we don't have unit testing yet, I threw together a small program to check the algorithm against RFC test vectors:
$ cd src/chacha-poly1305/
$ cat >test.c
$ gcc poly1305.c chacha.c test.c
$ ./a.out

#include <stdint.h>
#include <string.h>
#include <stdlib.h>
#include <stdio.h>
#include ""chacha.h""
#include ""poly1305.h""

#define U8C(v) (v##U)
#define U32C(v) (v##U)

#define U8V(v) ((uint8_t)(v)&U8C(0xFF))
#define U32V(v) ((uint32_t)(v)&U32C(0xFFFFFFFF))

#define ROTL32(v, n) \
	(U32V((v) << (n)) | ((v) >> (32 - (n))))

#define U8TO32_LITTLE(p)              \
	(((uint32_t)((p)[0])) |       \
	 ((uint32_t)((p)[1]) << 8) |  \
	 ((uint32_t)((p)[2]) << 16) | \
	 ((uint32_t)((p)[3]) << 24))

#define U32TO8_LITTLE(p, v)              \
	do {                             \
		(p)[0] = U8V((v));       \
		(p)[1] = U8V((v) >> 8);  \
		(p)[2] = U8V((v) >> 16); \
		(p)[3] = U8V((v) >> 24); \
	} while(0)

#define ROTATE(v, c) (ROTL32(v, c))
#define XOR(v, w) ((v) ^ (w))
#define PLUS(v, w) (U32V((v) + (w)))
#define PLUSONE(v) (PLUS((v), 1))

#define QUARTERROUND(a, b, c, d)   \
	a = PLUS(a, b);            \
	d = ROTATE(XOR(d, a), 16); \
	c = PLUS(c, d);            \
	b = ROTATE(XOR(b, c), 12); \
	a = PLUS(a, b);            \
	d = ROTATE(XOR(d, a), 8);  \
	c = PLUS(c, d);            \
	b = ROTATE(XOR(b, c), 7);

static const uint8_t key[] = {
	0x00, 0x01, 0x02, 0x03, 0x04, 0x05, 0x06, 0x07, 0x08, 0x09, 0x0a, 0x0b, 0x0c, 0x0d, 0x0e, 0x0f,
	0x10, 0x11, 0x12, 0x13, 0x14, 0x15, 0x16, 0x17, 0x18, 0x19, 0x1a, 0x1b, 0x1c, 0x1d, 0x1e, 0x1f,
};

static const uint8_t one[8] = {1, 0, 0, 0, 0, 0, 0, 0};

static const uint32_t expected_initial_state[] = {
	0x61707865, 0x3320646e, 0x79622d32, 0x6b206574,
	0x03020100, 0x07060504, 0x0b0a0908, 0x0f0e0d0c,
	0x13121110, 0x17161514, 0x1b1a1918, 0x1f1e1d1c,
	0x00000001, 0x09000000, 0x4a000000, 0x00000000,
};

static const uint32_t expected_after_20_rounds[] = {
	0x837778ab, 0xe238d763, 0xa67ae21e, 0x5950bb2f,
	0xc4f2d0c7, 0xfc62bb2f, 0x8fa018fc, 0x3f5ec7b7,
	0x335271c2, 0xf29489f3, 0xeabda8fc, 0x82e46ebd,
	0xd19c12b4, 0xb04e16de, 0x9e83d0cb, 0x4e3c50a2,
};

static void check_state(const void *expected, const void *real, const char *kind) {
	if(memcmp(expected, real, sizeof(struct chacha_ctx))) {
		fprintf(stderr, ""invalid %s state\n"", kind);
		exit(1);
	}
}

// copy-pasted from chacha.c
static void run_20_rounds(struct chacha_ctx *ctx) {
	uint32_t x0 = ctx->input[0];
	uint32_t x1 = ctx->input[1];
	uint32_t x2 = ctx->input[2];
	uint32_t x3 = ctx->input[3];
	uint32_t x4 = ctx->input[4];
	uint32_t x5 = ctx->input[5];
	uint32_t x6 = ctx->input[6];
	uint32_t x7 = ctx->input[7];
	uint32_t x8 = ctx->input[8];
	uint32_t x9 = ctx->input[9];
	uint32_t x10 = ctx->input[10];
	uint32_t x11 = ctx->input[11];
	uint32_t x12 = ctx->input[12];
	uint32_t x13 = ctx->input[13];
	uint32_t x14 = ctx->input[14];
	uint32_t x15 = ctx->input[15];

	for(size_t i = 20; i > 0; i -= 2) {
		QUARTERROUND(x0, x4, x8, x12)
		QUARTERROUND(x1, x5, x9, x13)
		QUARTERROUND(x2, x6, x10, x14)
		QUARTERROUND(x3, x7, x11, x15)
		QUARTERROUND(x0, x5, x10, x15)
		QUARTERROUND(x1, x6, x11, x12)
		QUARTERROUND(x2, x7, x8, x13)
		QUARTERROUND(x3, x4, x9, x14)
	}

	U32TO8_LITTLE((uint8_t *) ctx + 0, x0);
	U32TO8_LITTLE((uint8_t *) ctx + 4, x1);
	U32TO8_LITTLE((uint8_t *) ctx + 8, x2);
	U32TO8_LITTLE((uint8_t *) ctx + 12, x3);
	U32TO8_LITTLE((uint8_t *) ctx + 16, x4);
	U32TO8_LITTLE((uint8_t *) ctx + 20, x5);
	U32TO8_LITTLE((uint8_t *) ctx + 24, x6);
	U32TO8_LITTLE((uint8_t *) ctx + 28, x7);
	U32TO8_LITTLE((uint8_t *) ctx + 32, x8);
	U32TO8_LITTLE((uint8_t *) ctx + 36, x9);
	U32TO8_LITTLE((uint8_t *) ctx + 40, x10);
	U32TO8_LITTLE((uint8_t *) ctx + 44, x11);
	U32TO8_LITTLE((uint8_t *) ctx + 48, x12);
	U32TO8_LITTLE((uint8_t *) ctx + 52, x13);
	U32TO8_LITTLE((uint8_t *) ctx + 56, x14);
	U32TO8_LITTLE((uint8_t *) ctx + 60, x15);
}

static void test_initialization() {
	static const uint8_t nonce[] = {
		0x00, 0x00, 0x00, 0x09, 0x00, 0x00, 0x00, 0x4a, 0x00, 0x00, 0x00, 0x00,
	};

	struct chacha_ctx ctx = {0};

	chacha_keysetup(&ctx, key, 256);
	chacha_ivsetup(&ctx, nonce, one);
	check_state(&expected_initial_state, &ctx, ""initial"");

	run_20_rounds(&ctx);
	check_state(&expected_after_20_rounds, &ctx, ""20 rounds"");
}

static void test_entryption() {
	const uint8_t plaintext[] = {
		0x4c, 0x61, 0x64, 0x69, 0x65, 0x73, 0x20, 0x61, 0x6e, 0x64, 0x20, 0x47, 0x65, 0x6e, 0x74, 0x6c,
		0x65, 0x6d, 0x65, 0x6e, 0x20, 0x6f, 0x66, 0x20, 0x74, 0x68, 0x65, 0x20, 0x63, 0x6c, 0x61, 0x73,
		0x73, 0x20, 0x6f, 0x66, 0x20, 0x27, 0x39, 0x39, 0x3a, 0x20, 0x49, 0x66, 0x20, 0x49, 0x20, 0x63,
		0x6f, 0x75, 0x6c, 0x64, 0x20, 0x6f, 0x66, 0x66, 0x65, 0x72, 0x20, 0x79, 0x6f, 0x75, 0x20, 0x6f,
		0x6e, 0x6c, 0x79, 0x20, 0x6f, 0x6e, 0x65, 0x20, 0x74, 0x69, 0x70, 0x20, 0x66, 0x6f, 0x72, 0x20,
		0x74, 0x68, 0x65, 0x20, 0x66, 0x75, 0x74, 0x75, 0x72, 0x65, 0x2c, 0x20, 0x73, 0x75, 0x6e, 0x73,
		0x63, 0x72, 0x65, 0x65, 0x6e, 0x20, 0x77, 0x6f, 0x75, 0x6c, 0x64, 0x20, 0x62, 0x65, 0x20, 0x69,
		0x74, 0x2e,
	};

	const uint8_t expected_ciphertext[] = {
		0x6e, 0x2e, 0x35, 0x9a, 0x25, 0x68, 0xf9, 0x80, 0x41, 0xba, 0x07, 0x28, 0xdd, 0x0d, 0x69, 0x81,
		0xe9, 0x7e, 0x7a, 0xec, 0x1d, 0x43, 0x60, 0xc2, 0x0a, 0x27, 0xaf, 0xcc, 0xfd, 0x9f, 0xae, 0x0b,
		0xf9, 0x1b, 0x65, 0xc5, 0x52, 0x47, 0x33, 0xab, 0x8f, 0x59, 0x3d, 0xab, 0xcd, 0x62, 0xb3, 0x57,
		0x16, 0x39, 0xd6, 0x24, 0xe6, 0x51, 0x52, 0xab, 0x8f, 0x53, 0x0c, 0x35, 0x9f, 0x08, 0x61, 0xd8,
		0x07, 0xca, 0x0d, 0xbf, 0x50, 0x0d, 0x6a, 0x61, 0x56, 0xa3, 0x8e, 0x08, 0x8a, 0x22, 0xb6, 0x5e,
		0x52, 0xbc, 0x51, 0x4d, 0x16, 0xcc, 0xf8, 0x06, 0x81, 0x8c, 0xe9, 0x1a, 0xb7, 0x79, 0x37, 0x36,
		0x5a, 0xf9, 0x0b, 0xbf, 0x74, 0xa3, 0x5b, 0xe6, 0xb4, 0x0b, 0x8e, 0xed, 0xf2, 0x78, 0x5e, 0x42,
		0x87, 0x4d,
	};

	static const uint8_t enc_nonce[] = {
		0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x4a, 0x00, 0x00, 0x00, 0x00,
	};

	uint8_t ciphertext[sizeof(expected_ciphertext)];

	struct chacha_ctx ctx = {0};
	chacha_keysetup(&ctx, key, 256);
	chacha_ivsetup(&ctx, enc_nonce, one);

	chacha_encrypt_bytes(&ctx, (uint8_t *) plaintext, ciphertext, sizeof(ciphertext));

	if(memcmp(expected_ciphertext, ciphertext, sizeof(ciphertext))) {
		fprintf(stderr, ""invalid ciphertext\n"");
		exit(2);
	}
}

static void test_auth() {
	const uint8_t key[] = {
		0x85, 0xd6, 0xbe, 0x78, 0x57, 0x55, 0x6d, 0x33, 0x7f, 0x44, 0x52, 0xfe, 0x42, 0xd5, 0x06, 0xa8,
		0x01, 0x03, 0x80, 0x8a, 0xfb, 0x0d, 0xb2, 0xfd, 0x4a, 0xbf, 0xf6, 0xaf, 0x41, 0x49, 0xf5, 0x1b,
	};

	const uint8_t msg[] = {
		0x43, 0x72, 0x79, 0x70, 0x74, 0x6f, 0x67, 0x72, 0x61, 0x70, 0x68, 0x69, 0x63, 0x20, 0x46, 0x6f,
		0x72, 0x75, 0x6d, 0x20, 0x52, 0x65, 0x73, 0x65, 0x61, 0x72, 0x63, 0x68, 0x20, 0x47, 0x72, 0x6f,
		0x75, 0x70,
	};

	const uint8_t  expected_tag[] = {
		0xa8, 0x06, 0x1d, 0xc1, 0x30, 0x51, 0x36, 0xc6, 0xc2, 0x2b, 0x8b, 0xaf, 0x0c, 0x01, 0x27, 0xa9,
	};

	uint8_t tag[POLY1305_TAGLEN];
	poly1305_auth(tag, msg, sizeof(msg), key);

	if(memcmp(expected_tag, tag, sizeof(tag))) {
		fprintf(stderr, ""invalid MAC\n"");
		exit(3);
	}
}

int main() {
	test_initialization();
	test_entryption();
	test_auth();
}","Can we get the new 1.1 node to fall back to 1.0 protocol, if the other 1.1 node is using an outdated 1.1 protocol?

Good idea, but currently nodes don't allow falling back to 1.0 if they have each other's Ed25519 key to prevent version rollback attacks. So while we could make the new 1.1 nodes fall back, the old ones wouldn't allow it.
I'll have a look this weekend at seeing if making it be backwards compatible is feasible.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,314,2021-08-12T12:59:15Z,2021-08-18T08:49:36Z,2021-08-18T08:49:39Z,CLOSED,False,4,4,2,https://github.com/hg,RFC7539-related changes to ChaCha20,2,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/314,https://github.com/fangfufu,7,https://github.com/gsliepen/tinc/pull/314#issuecomment-897969773,"This is an attempt to align the ChaCha20 implementation with RFC7539 (related to #301).
It seems to be the right thing to do to increment the major protocol version. I don't think we can reset the minor version, though? It's compared with magic values 1 and 2 all over the place.
A large part of RFC7539 is the AEAD construction, which doesn't seem to be used in tinc. Instead we simply encrypt the plaintext and append the MAC to it. Were you planning to modify the protocol to add AEAD?

Because we don't have unit testing yet, I threw together a small program to check the algorithm against RFC test vectors:
$ cd src/chacha-poly1305/
$ cat >test.c
$ gcc poly1305.c chacha.c test.c
$ ./a.out

#include <stdint.h>
#include <string.h>
#include <stdlib.h>
#include <stdio.h>
#include ""chacha.h""
#include ""poly1305.h""

#define U8C(v) (v##U)
#define U32C(v) (v##U)

#define U8V(v) ((uint8_t)(v)&U8C(0xFF))
#define U32V(v) ((uint32_t)(v)&U32C(0xFFFFFFFF))

#define ROTL32(v, n) \
	(U32V((v) << (n)) | ((v) >> (32 - (n))))

#define U8TO32_LITTLE(p)              \
	(((uint32_t)((p)[0])) |       \
	 ((uint32_t)((p)[1]) << 8) |  \
	 ((uint32_t)((p)[2]) << 16) | \
	 ((uint32_t)((p)[3]) << 24))

#define U32TO8_LITTLE(p, v)              \
	do {                             \
		(p)[0] = U8V((v));       \
		(p)[1] = U8V((v) >> 8);  \
		(p)[2] = U8V((v) >> 16); \
		(p)[3] = U8V((v) >> 24); \
	} while(0)

#define ROTATE(v, c) (ROTL32(v, c))
#define XOR(v, w) ((v) ^ (w))
#define PLUS(v, w) (U32V((v) + (w)))
#define PLUSONE(v) (PLUS((v), 1))

#define QUARTERROUND(a, b, c, d)   \
	a = PLUS(a, b);            \
	d = ROTATE(XOR(d, a), 16); \
	c = PLUS(c, d);            \
	b = ROTATE(XOR(b, c), 12); \
	a = PLUS(a, b);            \
	d = ROTATE(XOR(d, a), 8);  \
	c = PLUS(c, d);            \
	b = ROTATE(XOR(b, c), 7);

static const uint8_t key[] = {
	0x00, 0x01, 0x02, 0x03, 0x04, 0x05, 0x06, 0x07, 0x08, 0x09, 0x0a, 0x0b, 0x0c, 0x0d, 0x0e, 0x0f,
	0x10, 0x11, 0x12, 0x13, 0x14, 0x15, 0x16, 0x17, 0x18, 0x19, 0x1a, 0x1b, 0x1c, 0x1d, 0x1e, 0x1f,
};

static const uint8_t one[8] = {1, 0, 0, 0, 0, 0, 0, 0};

static const uint32_t expected_initial_state[] = {
	0x61707865, 0x3320646e, 0x79622d32, 0x6b206574,
	0x03020100, 0x07060504, 0x0b0a0908, 0x0f0e0d0c,
	0x13121110, 0x17161514, 0x1b1a1918, 0x1f1e1d1c,
	0x00000001, 0x09000000, 0x4a000000, 0x00000000,
};

static const uint32_t expected_after_20_rounds[] = {
	0x837778ab, 0xe238d763, 0xa67ae21e, 0x5950bb2f,
	0xc4f2d0c7, 0xfc62bb2f, 0x8fa018fc, 0x3f5ec7b7,
	0x335271c2, 0xf29489f3, 0xeabda8fc, 0x82e46ebd,
	0xd19c12b4, 0xb04e16de, 0x9e83d0cb, 0x4e3c50a2,
};

static void check_state(const void *expected, const void *real, const char *kind) {
	if(memcmp(expected, real, sizeof(struct chacha_ctx))) {
		fprintf(stderr, ""invalid %s state\n"", kind);
		exit(1);
	}
}

// copy-pasted from chacha.c
static void run_20_rounds(struct chacha_ctx *ctx) {
	uint32_t x0 = ctx->input[0];
	uint32_t x1 = ctx->input[1];
	uint32_t x2 = ctx->input[2];
	uint32_t x3 = ctx->input[3];
	uint32_t x4 = ctx->input[4];
	uint32_t x5 = ctx->input[5];
	uint32_t x6 = ctx->input[6];
	uint32_t x7 = ctx->input[7];
	uint32_t x8 = ctx->input[8];
	uint32_t x9 = ctx->input[9];
	uint32_t x10 = ctx->input[10];
	uint32_t x11 = ctx->input[11];
	uint32_t x12 = ctx->input[12];
	uint32_t x13 = ctx->input[13];
	uint32_t x14 = ctx->input[14];
	uint32_t x15 = ctx->input[15];

	for(size_t i = 20; i > 0; i -= 2) {
		QUARTERROUND(x0, x4, x8, x12)
		QUARTERROUND(x1, x5, x9, x13)
		QUARTERROUND(x2, x6, x10, x14)
		QUARTERROUND(x3, x7, x11, x15)
		QUARTERROUND(x0, x5, x10, x15)
		QUARTERROUND(x1, x6, x11, x12)
		QUARTERROUND(x2, x7, x8, x13)
		QUARTERROUND(x3, x4, x9, x14)
	}

	U32TO8_LITTLE((uint8_t *) ctx + 0, x0);
	U32TO8_LITTLE((uint8_t *) ctx + 4, x1);
	U32TO8_LITTLE((uint8_t *) ctx + 8, x2);
	U32TO8_LITTLE((uint8_t *) ctx + 12, x3);
	U32TO8_LITTLE((uint8_t *) ctx + 16, x4);
	U32TO8_LITTLE((uint8_t *) ctx + 20, x5);
	U32TO8_LITTLE((uint8_t *) ctx + 24, x6);
	U32TO8_LITTLE((uint8_t *) ctx + 28, x7);
	U32TO8_LITTLE((uint8_t *) ctx + 32, x8);
	U32TO8_LITTLE((uint8_t *) ctx + 36, x9);
	U32TO8_LITTLE((uint8_t *) ctx + 40, x10);
	U32TO8_LITTLE((uint8_t *) ctx + 44, x11);
	U32TO8_LITTLE((uint8_t *) ctx + 48, x12);
	U32TO8_LITTLE((uint8_t *) ctx + 52, x13);
	U32TO8_LITTLE((uint8_t *) ctx + 56, x14);
	U32TO8_LITTLE((uint8_t *) ctx + 60, x15);
}

static void test_initialization() {
	static const uint8_t nonce[] = {
		0x00, 0x00, 0x00, 0x09, 0x00, 0x00, 0x00, 0x4a, 0x00, 0x00, 0x00, 0x00,
	};

	struct chacha_ctx ctx = {0};

	chacha_keysetup(&ctx, key, 256);
	chacha_ivsetup(&ctx, nonce, one);
	check_state(&expected_initial_state, &ctx, ""initial"");

	run_20_rounds(&ctx);
	check_state(&expected_after_20_rounds, &ctx, ""20 rounds"");
}

static void test_entryption() {
	const uint8_t plaintext[] = {
		0x4c, 0x61, 0x64, 0x69, 0x65, 0x73, 0x20, 0x61, 0x6e, 0x64, 0x20, 0x47, 0x65, 0x6e, 0x74, 0x6c,
		0x65, 0x6d, 0x65, 0x6e, 0x20, 0x6f, 0x66, 0x20, 0x74, 0x68, 0x65, 0x20, 0x63, 0x6c, 0x61, 0x73,
		0x73, 0x20, 0x6f, 0x66, 0x20, 0x27, 0x39, 0x39, 0x3a, 0x20, 0x49, 0x66, 0x20, 0x49, 0x20, 0x63,
		0x6f, 0x75, 0x6c, 0x64, 0x20, 0x6f, 0x66, 0x66, 0x65, 0x72, 0x20, 0x79, 0x6f, 0x75, 0x20, 0x6f,
		0x6e, 0x6c, 0x79, 0x20, 0x6f, 0x6e, 0x65, 0x20, 0x74, 0x69, 0x70, 0x20, 0x66, 0x6f, 0x72, 0x20,
		0x74, 0x68, 0x65, 0x20, 0x66, 0x75, 0x74, 0x75, 0x72, 0x65, 0x2c, 0x20, 0x73, 0x75, 0x6e, 0x73,
		0x63, 0x72, 0x65, 0x65, 0x6e, 0x20, 0x77, 0x6f, 0x75, 0x6c, 0x64, 0x20, 0x62, 0x65, 0x20, 0x69,
		0x74, 0x2e,
	};

	const uint8_t expected_ciphertext[] = {
		0x6e, 0x2e, 0x35, 0x9a, 0x25, 0x68, 0xf9, 0x80, 0x41, 0xba, 0x07, 0x28, 0xdd, 0x0d, 0x69, 0x81,
		0xe9, 0x7e, 0x7a, 0xec, 0x1d, 0x43, 0x60, 0xc2, 0x0a, 0x27, 0xaf, 0xcc, 0xfd, 0x9f, 0xae, 0x0b,
		0xf9, 0x1b, 0x65, 0xc5, 0x52, 0x47, 0x33, 0xab, 0x8f, 0x59, 0x3d, 0xab, 0xcd, 0x62, 0xb3, 0x57,
		0x16, 0x39, 0xd6, 0x24, 0xe6, 0x51, 0x52, 0xab, 0x8f, 0x53, 0x0c, 0x35, 0x9f, 0x08, 0x61, 0xd8,
		0x07, 0xca, 0x0d, 0xbf, 0x50, 0x0d, 0x6a, 0x61, 0x56, 0xa3, 0x8e, 0x08, 0x8a, 0x22, 0xb6, 0x5e,
		0x52, 0xbc, 0x51, 0x4d, 0x16, 0xcc, 0xf8, 0x06, 0x81, 0x8c, 0xe9, 0x1a, 0xb7, 0x79, 0x37, 0x36,
		0x5a, 0xf9, 0x0b, 0xbf, 0x74, 0xa3, 0x5b, 0xe6, 0xb4, 0x0b, 0x8e, 0xed, 0xf2, 0x78, 0x5e, 0x42,
		0x87, 0x4d,
	};

	static const uint8_t enc_nonce[] = {
		0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x4a, 0x00, 0x00, 0x00, 0x00,
	};

	uint8_t ciphertext[sizeof(expected_ciphertext)];

	struct chacha_ctx ctx = {0};
	chacha_keysetup(&ctx, key, 256);
	chacha_ivsetup(&ctx, enc_nonce, one);

	chacha_encrypt_bytes(&ctx, (uint8_t *) plaintext, ciphertext, sizeof(ciphertext));

	if(memcmp(expected_ciphertext, ciphertext, sizeof(ciphertext))) {
		fprintf(stderr, ""invalid ciphertext\n"");
		exit(2);
	}
}

static void test_auth() {
	const uint8_t key[] = {
		0x85, 0xd6, 0xbe, 0x78, 0x57, 0x55, 0x6d, 0x33, 0x7f, 0x44, 0x52, 0xfe, 0x42, 0xd5, 0x06, 0xa8,
		0x01, 0x03, 0x80, 0x8a, 0xfb, 0x0d, 0xb2, 0xfd, 0x4a, 0xbf, 0xf6, 0xaf, 0x41, 0x49, 0xf5, 0x1b,
	};

	const uint8_t msg[] = {
		0x43, 0x72, 0x79, 0x70, 0x74, 0x6f, 0x67, 0x72, 0x61, 0x70, 0x68, 0x69, 0x63, 0x20, 0x46, 0x6f,
		0x72, 0x75, 0x6d, 0x20, 0x52, 0x65, 0x73, 0x65, 0x61, 0x72, 0x63, 0x68, 0x20, 0x47, 0x72, 0x6f,
		0x75, 0x70,
	};

	const uint8_t  expected_tag[] = {
		0xa8, 0x06, 0x1d, 0xc1, 0x30, 0x51, 0x36, 0xc6, 0xc2, 0x2b, 0x8b, 0xaf, 0x0c, 0x01, 0x27, 0xa9,
	};

	uint8_t tag[POLY1305_TAGLEN];
	poly1305_auth(tag, msg, sizeof(msg), key);

	if(memcmp(expected_tag, tag, sizeof(tag))) {
		fprintf(stderr, ""invalid MAC\n"");
		exit(3);
	}
}

int main() {
	test_initialization();
	test_entryption();
	test_auth();
}","we could make the new 1.1 nodes fall back, the old ones wouldn't allow it

We only have to change the behaviour of the new 1.1 nodes, right? We have to make them compatible with the old version of the 1.1 protocol, and print out some sort of warning messages. I think there is no way to change the behaviour of old nodes anyway
I recommend we have a --strict-rfc7539-chacha20 option, so we can turn the fallback behaviour of the new 1.1 nodes off. We should also print some sort of error messages indicating that some nodes are incompatible.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,314,2021-08-12T12:59:15Z,2021-08-18T08:49:36Z,2021-08-18T08:49:39Z,CLOSED,False,4,4,2,https://github.com/hg,RFC7539-related changes to ChaCha20,2,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/314,https://github.com/splitice,8,https://github.com/gsliepen/tinc/pull/314#issuecomment-899156852,"This is an attempt to align the ChaCha20 implementation with RFC7539 (related to #301).
It seems to be the right thing to do to increment the major protocol version. I don't think we can reset the minor version, though? It's compared with magic values 1 and 2 all over the place.
A large part of RFC7539 is the AEAD construction, which doesn't seem to be used in tinc. Instead we simply encrypt the plaintext and append the MAC to it. Were you planning to modify the protocol to add AEAD?

Because we don't have unit testing yet, I threw together a small program to check the algorithm against RFC test vectors:
$ cd src/chacha-poly1305/
$ cat >test.c
$ gcc poly1305.c chacha.c test.c
$ ./a.out

#include <stdint.h>
#include <string.h>
#include <stdlib.h>
#include <stdio.h>
#include ""chacha.h""
#include ""poly1305.h""

#define U8C(v) (v##U)
#define U32C(v) (v##U)

#define U8V(v) ((uint8_t)(v)&U8C(0xFF))
#define U32V(v) ((uint32_t)(v)&U32C(0xFFFFFFFF))

#define ROTL32(v, n) \
	(U32V((v) << (n)) | ((v) >> (32 - (n))))

#define U8TO32_LITTLE(p)              \
	(((uint32_t)((p)[0])) |       \
	 ((uint32_t)((p)[1]) << 8) |  \
	 ((uint32_t)((p)[2]) << 16) | \
	 ((uint32_t)((p)[3]) << 24))

#define U32TO8_LITTLE(p, v)              \
	do {                             \
		(p)[0] = U8V((v));       \
		(p)[1] = U8V((v) >> 8);  \
		(p)[2] = U8V((v) >> 16); \
		(p)[3] = U8V((v) >> 24); \
	} while(0)

#define ROTATE(v, c) (ROTL32(v, c))
#define XOR(v, w) ((v) ^ (w))
#define PLUS(v, w) (U32V((v) + (w)))
#define PLUSONE(v) (PLUS((v), 1))

#define QUARTERROUND(a, b, c, d)   \
	a = PLUS(a, b);            \
	d = ROTATE(XOR(d, a), 16); \
	c = PLUS(c, d);            \
	b = ROTATE(XOR(b, c), 12); \
	a = PLUS(a, b);            \
	d = ROTATE(XOR(d, a), 8);  \
	c = PLUS(c, d);            \
	b = ROTATE(XOR(b, c), 7);

static const uint8_t key[] = {
	0x00, 0x01, 0x02, 0x03, 0x04, 0x05, 0x06, 0x07, 0x08, 0x09, 0x0a, 0x0b, 0x0c, 0x0d, 0x0e, 0x0f,
	0x10, 0x11, 0x12, 0x13, 0x14, 0x15, 0x16, 0x17, 0x18, 0x19, 0x1a, 0x1b, 0x1c, 0x1d, 0x1e, 0x1f,
};

static const uint8_t one[8] = {1, 0, 0, 0, 0, 0, 0, 0};

static const uint32_t expected_initial_state[] = {
	0x61707865, 0x3320646e, 0x79622d32, 0x6b206574,
	0x03020100, 0x07060504, 0x0b0a0908, 0x0f0e0d0c,
	0x13121110, 0x17161514, 0x1b1a1918, 0x1f1e1d1c,
	0x00000001, 0x09000000, 0x4a000000, 0x00000000,
};

static const uint32_t expected_after_20_rounds[] = {
	0x837778ab, 0xe238d763, 0xa67ae21e, 0x5950bb2f,
	0xc4f2d0c7, 0xfc62bb2f, 0x8fa018fc, 0x3f5ec7b7,
	0x335271c2, 0xf29489f3, 0xeabda8fc, 0x82e46ebd,
	0xd19c12b4, 0xb04e16de, 0x9e83d0cb, 0x4e3c50a2,
};

static void check_state(const void *expected, const void *real, const char *kind) {
	if(memcmp(expected, real, sizeof(struct chacha_ctx))) {
		fprintf(stderr, ""invalid %s state\n"", kind);
		exit(1);
	}
}

// copy-pasted from chacha.c
static void run_20_rounds(struct chacha_ctx *ctx) {
	uint32_t x0 = ctx->input[0];
	uint32_t x1 = ctx->input[1];
	uint32_t x2 = ctx->input[2];
	uint32_t x3 = ctx->input[3];
	uint32_t x4 = ctx->input[4];
	uint32_t x5 = ctx->input[5];
	uint32_t x6 = ctx->input[6];
	uint32_t x7 = ctx->input[7];
	uint32_t x8 = ctx->input[8];
	uint32_t x9 = ctx->input[9];
	uint32_t x10 = ctx->input[10];
	uint32_t x11 = ctx->input[11];
	uint32_t x12 = ctx->input[12];
	uint32_t x13 = ctx->input[13];
	uint32_t x14 = ctx->input[14];
	uint32_t x15 = ctx->input[15];

	for(size_t i = 20; i > 0; i -= 2) {
		QUARTERROUND(x0, x4, x8, x12)
		QUARTERROUND(x1, x5, x9, x13)
		QUARTERROUND(x2, x6, x10, x14)
		QUARTERROUND(x3, x7, x11, x15)
		QUARTERROUND(x0, x5, x10, x15)
		QUARTERROUND(x1, x6, x11, x12)
		QUARTERROUND(x2, x7, x8, x13)
		QUARTERROUND(x3, x4, x9, x14)
	}

	U32TO8_LITTLE((uint8_t *) ctx + 0, x0);
	U32TO8_LITTLE((uint8_t *) ctx + 4, x1);
	U32TO8_LITTLE((uint8_t *) ctx + 8, x2);
	U32TO8_LITTLE((uint8_t *) ctx + 12, x3);
	U32TO8_LITTLE((uint8_t *) ctx + 16, x4);
	U32TO8_LITTLE((uint8_t *) ctx + 20, x5);
	U32TO8_LITTLE((uint8_t *) ctx + 24, x6);
	U32TO8_LITTLE((uint8_t *) ctx + 28, x7);
	U32TO8_LITTLE((uint8_t *) ctx + 32, x8);
	U32TO8_LITTLE((uint8_t *) ctx + 36, x9);
	U32TO8_LITTLE((uint8_t *) ctx + 40, x10);
	U32TO8_LITTLE((uint8_t *) ctx + 44, x11);
	U32TO8_LITTLE((uint8_t *) ctx + 48, x12);
	U32TO8_LITTLE((uint8_t *) ctx + 52, x13);
	U32TO8_LITTLE((uint8_t *) ctx + 56, x14);
	U32TO8_LITTLE((uint8_t *) ctx + 60, x15);
}

static void test_initialization() {
	static const uint8_t nonce[] = {
		0x00, 0x00, 0x00, 0x09, 0x00, 0x00, 0x00, 0x4a, 0x00, 0x00, 0x00, 0x00,
	};

	struct chacha_ctx ctx = {0};

	chacha_keysetup(&ctx, key, 256);
	chacha_ivsetup(&ctx, nonce, one);
	check_state(&expected_initial_state, &ctx, ""initial"");

	run_20_rounds(&ctx);
	check_state(&expected_after_20_rounds, &ctx, ""20 rounds"");
}

static void test_entryption() {
	const uint8_t plaintext[] = {
		0x4c, 0x61, 0x64, 0x69, 0x65, 0x73, 0x20, 0x61, 0x6e, 0x64, 0x20, 0x47, 0x65, 0x6e, 0x74, 0x6c,
		0x65, 0x6d, 0x65, 0x6e, 0x20, 0x6f, 0x66, 0x20, 0x74, 0x68, 0x65, 0x20, 0x63, 0x6c, 0x61, 0x73,
		0x73, 0x20, 0x6f, 0x66, 0x20, 0x27, 0x39, 0x39, 0x3a, 0x20, 0x49, 0x66, 0x20, 0x49, 0x20, 0x63,
		0x6f, 0x75, 0x6c, 0x64, 0x20, 0x6f, 0x66, 0x66, 0x65, 0x72, 0x20, 0x79, 0x6f, 0x75, 0x20, 0x6f,
		0x6e, 0x6c, 0x79, 0x20, 0x6f, 0x6e, 0x65, 0x20, 0x74, 0x69, 0x70, 0x20, 0x66, 0x6f, 0x72, 0x20,
		0x74, 0x68, 0x65, 0x20, 0x66, 0x75, 0x74, 0x75, 0x72, 0x65, 0x2c, 0x20, 0x73, 0x75, 0x6e, 0x73,
		0x63, 0x72, 0x65, 0x65, 0x6e, 0x20, 0x77, 0x6f, 0x75, 0x6c, 0x64, 0x20, 0x62, 0x65, 0x20, 0x69,
		0x74, 0x2e,
	};

	const uint8_t expected_ciphertext[] = {
		0x6e, 0x2e, 0x35, 0x9a, 0x25, 0x68, 0xf9, 0x80, 0x41, 0xba, 0x07, 0x28, 0xdd, 0x0d, 0x69, 0x81,
		0xe9, 0x7e, 0x7a, 0xec, 0x1d, 0x43, 0x60, 0xc2, 0x0a, 0x27, 0xaf, 0xcc, 0xfd, 0x9f, 0xae, 0x0b,
		0xf9, 0x1b, 0x65, 0xc5, 0x52, 0x47, 0x33, 0xab, 0x8f, 0x59, 0x3d, 0xab, 0xcd, 0x62, 0xb3, 0x57,
		0x16, 0x39, 0xd6, 0x24, 0xe6, 0x51, 0x52, 0xab, 0x8f, 0x53, 0x0c, 0x35, 0x9f, 0x08, 0x61, 0xd8,
		0x07, 0xca, 0x0d, 0xbf, 0x50, 0x0d, 0x6a, 0x61, 0x56, 0xa3, 0x8e, 0x08, 0x8a, 0x22, 0xb6, 0x5e,
		0x52, 0xbc, 0x51, 0x4d, 0x16, 0xcc, 0xf8, 0x06, 0x81, 0x8c, 0xe9, 0x1a, 0xb7, 0x79, 0x37, 0x36,
		0x5a, 0xf9, 0x0b, 0xbf, 0x74, 0xa3, 0x5b, 0xe6, 0xb4, 0x0b, 0x8e, 0xed, 0xf2, 0x78, 0x5e, 0x42,
		0x87, 0x4d,
	};

	static const uint8_t enc_nonce[] = {
		0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x4a, 0x00, 0x00, 0x00, 0x00,
	};

	uint8_t ciphertext[sizeof(expected_ciphertext)];

	struct chacha_ctx ctx = {0};
	chacha_keysetup(&ctx, key, 256);
	chacha_ivsetup(&ctx, enc_nonce, one);

	chacha_encrypt_bytes(&ctx, (uint8_t *) plaintext, ciphertext, sizeof(ciphertext));

	if(memcmp(expected_ciphertext, ciphertext, sizeof(ciphertext))) {
		fprintf(stderr, ""invalid ciphertext\n"");
		exit(2);
	}
}

static void test_auth() {
	const uint8_t key[] = {
		0x85, 0xd6, 0xbe, 0x78, 0x57, 0x55, 0x6d, 0x33, 0x7f, 0x44, 0x52, 0xfe, 0x42, 0xd5, 0x06, 0xa8,
		0x01, 0x03, 0x80, 0x8a, 0xfb, 0x0d, 0xb2, 0xfd, 0x4a, 0xbf, 0xf6, 0xaf, 0x41, 0x49, 0xf5, 0x1b,
	};

	const uint8_t msg[] = {
		0x43, 0x72, 0x79, 0x70, 0x74, 0x6f, 0x67, 0x72, 0x61, 0x70, 0x68, 0x69, 0x63, 0x20, 0x46, 0x6f,
		0x72, 0x75, 0x6d, 0x20, 0x52, 0x65, 0x73, 0x65, 0x61, 0x72, 0x63, 0x68, 0x20, 0x47, 0x72, 0x6f,
		0x75, 0x70,
	};

	const uint8_t  expected_tag[] = {
		0xa8, 0x06, 0x1d, 0xc1, 0x30, 0x51, 0x36, 0xc6, 0xc2, 0x2b, 0x8b, 0xaf, 0x0c, 0x01, 0x27, 0xa9,
	};

	uint8_t tag[POLY1305_TAGLEN];
	poly1305_auth(tag, msg, sizeof(msg), key);

	if(memcmp(expected_tag, tag, sizeof(tag))) {
		fprintf(stderr, ""invalid MAC\n"");
		exit(3);
	}
}

int main() {
	test_initialization();
	test_entryption();
	test_auth();
}",Given that 1.1 is prerelease perhaps breaking changes can be considered unfortunate but acceptable?,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,314,2021-08-12T12:59:15Z,2021-08-18T08:49:36Z,2021-08-18T08:49:39Z,CLOSED,False,4,4,2,https://github.com/hg,RFC7539-related changes to ChaCha20,2,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/314,https://github.com/fangfufu,9,https://github.com/gsliepen/tinc/pull/314#issuecomment-900338706,"This is an attempt to align the ChaCha20 implementation with RFC7539 (related to #301).
It seems to be the right thing to do to increment the major protocol version. I don't think we can reset the minor version, though? It's compared with magic values 1 and 2 all over the place.
A large part of RFC7539 is the AEAD construction, which doesn't seem to be used in tinc. Instead we simply encrypt the plaintext and append the MAC to it. Were you planning to modify the protocol to add AEAD?

Because we don't have unit testing yet, I threw together a small program to check the algorithm against RFC test vectors:
$ cd src/chacha-poly1305/
$ cat >test.c
$ gcc poly1305.c chacha.c test.c
$ ./a.out

#include <stdint.h>
#include <string.h>
#include <stdlib.h>
#include <stdio.h>
#include ""chacha.h""
#include ""poly1305.h""

#define U8C(v) (v##U)
#define U32C(v) (v##U)

#define U8V(v) ((uint8_t)(v)&U8C(0xFF))
#define U32V(v) ((uint32_t)(v)&U32C(0xFFFFFFFF))

#define ROTL32(v, n) \
	(U32V((v) << (n)) | ((v) >> (32 - (n))))

#define U8TO32_LITTLE(p)              \
	(((uint32_t)((p)[0])) |       \
	 ((uint32_t)((p)[1]) << 8) |  \
	 ((uint32_t)((p)[2]) << 16) | \
	 ((uint32_t)((p)[3]) << 24))

#define U32TO8_LITTLE(p, v)              \
	do {                             \
		(p)[0] = U8V((v));       \
		(p)[1] = U8V((v) >> 8);  \
		(p)[2] = U8V((v) >> 16); \
		(p)[3] = U8V((v) >> 24); \
	} while(0)

#define ROTATE(v, c) (ROTL32(v, c))
#define XOR(v, w) ((v) ^ (w))
#define PLUS(v, w) (U32V((v) + (w)))
#define PLUSONE(v) (PLUS((v), 1))

#define QUARTERROUND(a, b, c, d)   \
	a = PLUS(a, b);            \
	d = ROTATE(XOR(d, a), 16); \
	c = PLUS(c, d);            \
	b = ROTATE(XOR(b, c), 12); \
	a = PLUS(a, b);            \
	d = ROTATE(XOR(d, a), 8);  \
	c = PLUS(c, d);            \
	b = ROTATE(XOR(b, c), 7);

static const uint8_t key[] = {
	0x00, 0x01, 0x02, 0x03, 0x04, 0x05, 0x06, 0x07, 0x08, 0x09, 0x0a, 0x0b, 0x0c, 0x0d, 0x0e, 0x0f,
	0x10, 0x11, 0x12, 0x13, 0x14, 0x15, 0x16, 0x17, 0x18, 0x19, 0x1a, 0x1b, 0x1c, 0x1d, 0x1e, 0x1f,
};

static const uint8_t one[8] = {1, 0, 0, 0, 0, 0, 0, 0};

static const uint32_t expected_initial_state[] = {
	0x61707865, 0x3320646e, 0x79622d32, 0x6b206574,
	0x03020100, 0x07060504, 0x0b0a0908, 0x0f0e0d0c,
	0x13121110, 0x17161514, 0x1b1a1918, 0x1f1e1d1c,
	0x00000001, 0x09000000, 0x4a000000, 0x00000000,
};

static const uint32_t expected_after_20_rounds[] = {
	0x837778ab, 0xe238d763, 0xa67ae21e, 0x5950bb2f,
	0xc4f2d0c7, 0xfc62bb2f, 0x8fa018fc, 0x3f5ec7b7,
	0x335271c2, 0xf29489f3, 0xeabda8fc, 0x82e46ebd,
	0xd19c12b4, 0xb04e16de, 0x9e83d0cb, 0x4e3c50a2,
};

static void check_state(const void *expected, const void *real, const char *kind) {
	if(memcmp(expected, real, sizeof(struct chacha_ctx))) {
		fprintf(stderr, ""invalid %s state\n"", kind);
		exit(1);
	}
}

// copy-pasted from chacha.c
static void run_20_rounds(struct chacha_ctx *ctx) {
	uint32_t x0 = ctx->input[0];
	uint32_t x1 = ctx->input[1];
	uint32_t x2 = ctx->input[2];
	uint32_t x3 = ctx->input[3];
	uint32_t x4 = ctx->input[4];
	uint32_t x5 = ctx->input[5];
	uint32_t x6 = ctx->input[6];
	uint32_t x7 = ctx->input[7];
	uint32_t x8 = ctx->input[8];
	uint32_t x9 = ctx->input[9];
	uint32_t x10 = ctx->input[10];
	uint32_t x11 = ctx->input[11];
	uint32_t x12 = ctx->input[12];
	uint32_t x13 = ctx->input[13];
	uint32_t x14 = ctx->input[14];
	uint32_t x15 = ctx->input[15];

	for(size_t i = 20; i > 0; i -= 2) {
		QUARTERROUND(x0, x4, x8, x12)
		QUARTERROUND(x1, x5, x9, x13)
		QUARTERROUND(x2, x6, x10, x14)
		QUARTERROUND(x3, x7, x11, x15)
		QUARTERROUND(x0, x5, x10, x15)
		QUARTERROUND(x1, x6, x11, x12)
		QUARTERROUND(x2, x7, x8, x13)
		QUARTERROUND(x3, x4, x9, x14)
	}

	U32TO8_LITTLE((uint8_t *) ctx + 0, x0);
	U32TO8_LITTLE((uint8_t *) ctx + 4, x1);
	U32TO8_LITTLE((uint8_t *) ctx + 8, x2);
	U32TO8_LITTLE((uint8_t *) ctx + 12, x3);
	U32TO8_LITTLE((uint8_t *) ctx + 16, x4);
	U32TO8_LITTLE((uint8_t *) ctx + 20, x5);
	U32TO8_LITTLE((uint8_t *) ctx + 24, x6);
	U32TO8_LITTLE((uint8_t *) ctx + 28, x7);
	U32TO8_LITTLE((uint8_t *) ctx + 32, x8);
	U32TO8_LITTLE((uint8_t *) ctx + 36, x9);
	U32TO8_LITTLE((uint8_t *) ctx + 40, x10);
	U32TO8_LITTLE((uint8_t *) ctx + 44, x11);
	U32TO8_LITTLE((uint8_t *) ctx + 48, x12);
	U32TO8_LITTLE((uint8_t *) ctx + 52, x13);
	U32TO8_LITTLE((uint8_t *) ctx + 56, x14);
	U32TO8_LITTLE((uint8_t *) ctx + 60, x15);
}

static void test_initialization() {
	static const uint8_t nonce[] = {
		0x00, 0x00, 0x00, 0x09, 0x00, 0x00, 0x00, 0x4a, 0x00, 0x00, 0x00, 0x00,
	};

	struct chacha_ctx ctx = {0};

	chacha_keysetup(&ctx, key, 256);
	chacha_ivsetup(&ctx, nonce, one);
	check_state(&expected_initial_state, &ctx, ""initial"");

	run_20_rounds(&ctx);
	check_state(&expected_after_20_rounds, &ctx, ""20 rounds"");
}

static void test_entryption() {
	const uint8_t plaintext[] = {
		0x4c, 0x61, 0x64, 0x69, 0x65, 0x73, 0x20, 0x61, 0x6e, 0x64, 0x20, 0x47, 0x65, 0x6e, 0x74, 0x6c,
		0x65, 0x6d, 0x65, 0x6e, 0x20, 0x6f, 0x66, 0x20, 0x74, 0x68, 0x65, 0x20, 0x63, 0x6c, 0x61, 0x73,
		0x73, 0x20, 0x6f, 0x66, 0x20, 0x27, 0x39, 0x39, 0x3a, 0x20, 0x49, 0x66, 0x20, 0x49, 0x20, 0x63,
		0x6f, 0x75, 0x6c, 0x64, 0x20, 0x6f, 0x66, 0x66, 0x65, 0x72, 0x20, 0x79, 0x6f, 0x75, 0x20, 0x6f,
		0x6e, 0x6c, 0x79, 0x20, 0x6f, 0x6e, 0x65, 0x20, 0x74, 0x69, 0x70, 0x20, 0x66, 0x6f, 0x72, 0x20,
		0x74, 0x68, 0x65, 0x20, 0x66, 0x75, 0x74, 0x75, 0x72, 0x65, 0x2c, 0x20, 0x73, 0x75, 0x6e, 0x73,
		0x63, 0x72, 0x65, 0x65, 0x6e, 0x20, 0x77, 0x6f, 0x75, 0x6c, 0x64, 0x20, 0x62, 0x65, 0x20, 0x69,
		0x74, 0x2e,
	};

	const uint8_t expected_ciphertext[] = {
		0x6e, 0x2e, 0x35, 0x9a, 0x25, 0x68, 0xf9, 0x80, 0x41, 0xba, 0x07, 0x28, 0xdd, 0x0d, 0x69, 0x81,
		0xe9, 0x7e, 0x7a, 0xec, 0x1d, 0x43, 0x60, 0xc2, 0x0a, 0x27, 0xaf, 0xcc, 0xfd, 0x9f, 0xae, 0x0b,
		0xf9, 0x1b, 0x65, 0xc5, 0x52, 0x47, 0x33, 0xab, 0x8f, 0x59, 0x3d, 0xab, 0xcd, 0x62, 0xb3, 0x57,
		0x16, 0x39, 0xd6, 0x24, 0xe6, 0x51, 0x52, 0xab, 0x8f, 0x53, 0x0c, 0x35, 0x9f, 0x08, 0x61, 0xd8,
		0x07, 0xca, 0x0d, 0xbf, 0x50, 0x0d, 0x6a, 0x61, 0x56, 0xa3, 0x8e, 0x08, 0x8a, 0x22, 0xb6, 0x5e,
		0x52, 0xbc, 0x51, 0x4d, 0x16, 0xcc, 0xf8, 0x06, 0x81, 0x8c, 0xe9, 0x1a, 0xb7, 0x79, 0x37, 0x36,
		0x5a, 0xf9, 0x0b, 0xbf, 0x74, 0xa3, 0x5b, 0xe6, 0xb4, 0x0b, 0x8e, 0xed, 0xf2, 0x78, 0x5e, 0x42,
		0x87, 0x4d,
	};

	static const uint8_t enc_nonce[] = {
		0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x4a, 0x00, 0x00, 0x00, 0x00,
	};

	uint8_t ciphertext[sizeof(expected_ciphertext)];

	struct chacha_ctx ctx = {0};
	chacha_keysetup(&ctx, key, 256);
	chacha_ivsetup(&ctx, enc_nonce, one);

	chacha_encrypt_bytes(&ctx, (uint8_t *) plaintext, ciphertext, sizeof(ciphertext));

	if(memcmp(expected_ciphertext, ciphertext, sizeof(ciphertext))) {
		fprintf(stderr, ""invalid ciphertext\n"");
		exit(2);
	}
}

static void test_auth() {
	const uint8_t key[] = {
		0x85, 0xd6, 0xbe, 0x78, 0x57, 0x55, 0x6d, 0x33, 0x7f, 0x44, 0x52, 0xfe, 0x42, 0xd5, 0x06, 0xa8,
		0x01, 0x03, 0x80, 0x8a, 0xfb, 0x0d, 0xb2, 0xfd, 0x4a, 0xbf, 0xf6, 0xaf, 0x41, 0x49, 0xf5, 0x1b,
	};

	const uint8_t msg[] = {
		0x43, 0x72, 0x79, 0x70, 0x74, 0x6f, 0x67, 0x72, 0x61, 0x70, 0x68, 0x69, 0x63, 0x20, 0x46, 0x6f,
		0x72, 0x75, 0x6d, 0x20, 0x52, 0x65, 0x73, 0x65, 0x61, 0x72, 0x63, 0x68, 0x20, 0x47, 0x72, 0x6f,
		0x75, 0x70,
	};

	const uint8_t  expected_tag[] = {
		0xa8, 0x06, 0x1d, 0xc1, 0x30, 0x51, 0x36, 0xc6, 0xc2, 0x2b, 0x8b, 0xaf, 0x0c, 0x01, 0x27, 0xa9,
	};

	uint8_t tag[POLY1305_TAGLEN];
	poly1305_auth(tag, msg, sizeof(msg), key);

	if(memcmp(expected_tag, tag, sizeof(tag))) {
		fprintf(stderr, ""invalid MAC\n"");
		exit(3);
	}
}

int main() {
	test_initialization();
	test_entryption();
	test_auth();
}","Given that 1.1 is prerelease perhaps breaking changes can be considered unfortunate but acceptable?

Personally, I don't think so, tinc-1.1 has been around since 2011 (https://github.com/gsliepen/tinc/releases/tag/release-1.1pre1), so it is about 10 years old.
Having said that, rather than group legacy 1.1 protocol and 1.0 protocol separately, perhaps we can just group the old 1.1 protocol with the 1.0 protocol together as the ""legacy-protocol""",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,314,2021-08-12T12:59:15Z,2021-08-18T08:49:36Z,2021-08-18T08:49:39Z,CLOSED,False,4,4,2,https://github.com/hg,RFC7539-related changes to ChaCha20,2,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/314,https://github.com/splitice,10,https://github.com/gsliepen/tinc/pull/314#issuecomment-900358559,"This is an attempt to align the ChaCha20 implementation with RFC7539 (related to #301).
It seems to be the right thing to do to increment the major protocol version. I don't think we can reset the minor version, though? It's compared with magic values 1 and 2 all over the place.
A large part of RFC7539 is the AEAD construction, which doesn't seem to be used in tinc. Instead we simply encrypt the plaintext and append the MAC to it. Were you planning to modify the protocol to add AEAD?

Because we don't have unit testing yet, I threw together a small program to check the algorithm against RFC test vectors:
$ cd src/chacha-poly1305/
$ cat >test.c
$ gcc poly1305.c chacha.c test.c
$ ./a.out

#include <stdint.h>
#include <string.h>
#include <stdlib.h>
#include <stdio.h>
#include ""chacha.h""
#include ""poly1305.h""

#define U8C(v) (v##U)
#define U32C(v) (v##U)

#define U8V(v) ((uint8_t)(v)&U8C(0xFF))
#define U32V(v) ((uint32_t)(v)&U32C(0xFFFFFFFF))

#define ROTL32(v, n) \
	(U32V((v) << (n)) | ((v) >> (32 - (n))))

#define U8TO32_LITTLE(p)              \
	(((uint32_t)((p)[0])) |       \
	 ((uint32_t)((p)[1]) << 8) |  \
	 ((uint32_t)((p)[2]) << 16) | \
	 ((uint32_t)((p)[3]) << 24))

#define U32TO8_LITTLE(p, v)              \
	do {                             \
		(p)[0] = U8V((v));       \
		(p)[1] = U8V((v) >> 8);  \
		(p)[2] = U8V((v) >> 16); \
		(p)[3] = U8V((v) >> 24); \
	} while(0)

#define ROTATE(v, c) (ROTL32(v, c))
#define XOR(v, w) ((v) ^ (w))
#define PLUS(v, w) (U32V((v) + (w)))
#define PLUSONE(v) (PLUS((v), 1))

#define QUARTERROUND(a, b, c, d)   \
	a = PLUS(a, b);            \
	d = ROTATE(XOR(d, a), 16); \
	c = PLUS(c, d);            \
	b = ROTATE(XOR(b, c), 12); \
	a = PLUS(a, b);            \
	d = ROTATE(XOR(d, a), 8);  \
	c = PLUS(c, d);            \
	b = ROTATE(XOR(b, c), 7);

static const uint8_t key[] = {
	0x00, 0x01, 0x02, 0x03, 0x04, 0x05, 0x06, 0x07, 0x08, 0x09, 0x0a, 0x0b, 0x0c, 0x0d, 0x0e, 0x0f,
	0x10, 0x11, 0x12, 0x13, 0x14, 0x15, 0x16, 0x17, 0x18, 0x19, 0x1a, 0x1b, 0x1c, 0x1d, 0x1e, 0x1f,
};

static const uint8_t one[8] = {1, 0, 0, 0, 0, 0, 0, 0};

static const uint32_t expected_initial_state[] = {
	0x61707865, 0x3320646e, 0x79622d32, 0x6b206574,
	0x03020100, 0x07060504, 0x0b0a0908, 0x0f0e0d0c,
	0x13121110, 0x17161514, 0x1b1a1918, 0x1f1e1d1c,
	0x00000001, 0x09000000, 0x4a000000, 0x00000000,
};

static const uint32_t expected_after_20_rounds[] = {
	0x837778ab, 0xe238d763, 0xa67ae21e, 0x5950bb2f,
	0xc4f2d0c7, 0xfc62bb2f, 0x8fa018fc, 0x3f5ec7b7,
	0x335271c2, 0xf29489f3, 0xeabda8fc, 0x82e46ebd,
	0xd19c12b4, 0xb04e16de, 0x9e83d0cb, 0x4e3c50a2,
};

static void check_state(const void *expected, const void *real, const char *kind) {
	if(memcmp(expected, real, sizeof(struct chacha_ctx))) {
		fprintf(stderr, ""invalid %s state\n"", kind);
		exit(1);
	}
}

// copy-pasted from chacha.c
static void run_20_rounds(struct chacha_ctx *ctx) {
	uint32_t x0 = ctx->input[0];
	uint32_t x1 = ctx->input[1];
	uint32_t x2 = ctx->input[2];
	uint32_t x3 = ctx->input[3];
	uint32_t x4 = ctx->input[4];
	uint32_t x5 = ctx->input[5];
	uint32_t x6 = ctx->input[6];
	uint32_t x7 = ctx->input[7];
	uint32_t x8 = ctx->input[8];
	uint32_t x9 = ctx->input[9];
	uint32_t x10 = ctx->input[10];
	uint32_t x11 = ctx->input[11];
	uint32_t x12 = ctx->input[12];
	uint32_t x13 = ctx->input[13];
	uint32_t x14 = ctx->input[14];
	uint32_t x15 = ctx->input[15];

	for(size_t i = 20; i > 0; i -= 2) {
		QUARTERROUND(x0, x4, x8, x12)
		QUARTERROUND(x1, x5, x9, x13)
		QUARTERROUND(x2, x6, x10, x14)
		QUARTERROUND(x3, x7, x11, x15)
		QUARTERROUND(x0, x5, x10, x15)
		QUARTERROUND(x1, x6, x11, x12)
		QUARTERROUND(x2, x7, x8, x13)
		QUARTERROUND(x3, x4, x9, x14)
	}

	U32TO8_LITTLE((uint8_t *) ctx + 0, x0);
	U32TO8_LITTLE((uint8_t *) ctx + 4, x1);
	U32TO8_LITTLE((uint8_t *) ctx + 8, x2);
	U32TO8_LITTLE((uint8_t *) ctx + 12, x3);
	U32TO8_LITTLE((uint8_t *) ctx + 16, x4);
	U32TO8_LITTLE((uint8_t *) ctx + 20, x5);
	U32TO8_LITTLE((uint8_t *) ctx + 24, x6);
	U32TO8_LITTLE((uint8_t *) ctx + 28, x7);
	U32TO8_LITTLE((uint8_t *) ctx + 32, x8);
	U32TO8_LITTLE((uint8_t *) ctx + 36, x9);
	U32TO8_LITTLE((uint8_t *) ctx + 40, x10);
	U32TO8_LITTLE((uint8_t *) ctx + 44, x11);
	U32TO8_LITTLE((uint8_t *) ctx + 48, x12);
	U32TO8_LITTLE((uint8_t *) ctx + 52, x13);
	U32TO8_LITTLE((uint8_t *) ctx + 56, x14);
	U32TO8_LITTLE((uint8_t *) ctx + 60, x15);
}

static void test_initialization() {
	static const uint8_t nonce[] = {
		0x00, 0x00, 0x00, 0x09, 0x00, 0x00, 0x00, 0x4a, 0x00, 0x00, 0x00, 0x00,
	};

	struct chacha_ctx ctx = {0};

	chacha_keysetup(&ctx, key, 256);
	chacha_ivsetup(&ctx, nonce, one);
	check_state(&expected_initial_state, &ctx, ""initial"");

	run_20_rounds(&ctx);
	check_state(&expected_after_20_rounds, &ctx, ""20 rounds"");
}

static void test_entryption() {
	const uint8_t plaintext[] = {
		0x4c, 0x61, 0x64, 0x69, 0x65, 0x73, 0x20, 0x61, 0x6e, 0x64, 0x20, 0x47, 0x65, 0x6e, 0x74, 0x6c,
		0x65, 0x6d, 0x65, 0x6e, 0x20, 0x6f, 0x66, 0x20, 0x74, 0x68, 0x65, 0x20, 0x63, 0x6c, 0x61, 0x73,
		0x73, 0x20, 0x6f, 0x66, 0x20, 0x27, 0x39, 0x39, 0x3a, 0x20, 0x49, 0x66, 0x20, 0x49, 0x20, 0x63,
		0x6f, 0x75, 0x6c, 0x64, 0x20, 0x6f, 0x66, 0x66, 0x65, 0x72, 0x20, 0x79, 0x6f, 0x75, 0x20, 0x6f,
		0x6e, 0x6c, 0x79, 0x20, 0x6f, 0x6e, 0x65, 0x20, 0x74, 0x69, 0x70, 0x20, 0x66, 0x6f, 0x72, 0x20,
		0x74, 0x68, 0x65, 0x20, 0x66, 0x75, 0x74, 0x75, 0x72, 0x65, 0x2c, 0x20, 0x73, 0x75, 0x6e, 0x73,
		0x63, 0x72, 0x65, 0x65, 0x6e, 0x20, 0x77, 0x6f, 0x75, 0x6c, 0x64, 0x20, 0x62, 0x65, 0x20, 0x69,
		0x74, 0x2e,
	};

	const uint8_t expected_ciphertext[] = {
		0x6e, 0x2e, 0x35, 0x9a, 0x25, 0x68, 0xf9, 0x80, 0x41, 0xba, 0x07, 0x28, 0xdd, 0x0d, 0x69, 0x81,
		0xe9, 0x7e, 0x7a, 0xec, 0x1d, 0x43, 0x60, 0xc2, 0x0a, 0x27, 0xaf, 0xcc, 0xfd, 0x9f, 0xae, 0x0b,
		0xf9, 0x1b, 0x65, 0xc5, 0x52, 0x47, 0x33, 0xab, 0x8f, 0x59, 0x3d, 0xab, 0xcd, 0x62, 0xb3, 0x57,
		0x16, 0x39, 0xd6, 0x24, 0xe6, 0x51, 0x52, 0xab, 0x8f, 0x53, 0x0c, 0x35, 0x9f, 0x08, 0x61, 0xd8,
		0x07, 0xca, 0x0d, 0xbf, 0x50, 0x0d, 0x6a, 0x61, 0x56, 0xa3, 0x8e, 0x08, 0x8a, 0x22, 0xb6, 0x5e,
		0x52, 0xbc, 0x51, 0x4d, 0x16, 0xcc, 0xf8, 0x06, 0x81, 0x8c, 0xe9, 0x1a, 0xb7, 0x79, 0x37, 0x36,
		0x5a, 0xf9, 0x0b, 0xbf, 0x74, 0xa3, 0x5b, 0xe6, 0xb4, 0x0b, 0x8e, 0xed, 0xf2, 0x78, 0x5e, 0x42,
		0x87, 0x4d,
	};

	static const uint8_t enc_nonce[] = {
		0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x4a, 0x00, 0x00, 0x00, 0x00,
	};

	uint8_t ciphertext[sizeof(expected_ciphertext)];

	struct chacha_ctx ctx = {0};
	chacha_keysetup(&ctx, key, 256);
	chacha_ivsetup(&ctx, enc_nonce, one);

	chacha_encrypt_bytes(&ctx, (uint8_t *) plaintext, ciphertext, sizeof(ciphertext));

	if(memcmp(expected_ciphertext, ciphertext, sizeof(ciphertext))) {
		fprintf(stderr, ""invalid ciphertext\n"");
		exit(2);
	}
}

static void test_auth() {
	const uint8_t key[] = {
		0x85, 0xd6, 0xbe, 0x78, 0x57, 0x55, 0x6d, 0x33, 0x7f, 0x44, 0x52, 0xfe, 0x42, 0xd5, 0x06, 0xa8,
		0x01, 0x03, 0x80, 0x8a, 0xfb, 0x0d, 0xb2, 0xfd, 0x4a, 0xbf, 0xf6, 0xaf, 0x41, 0x49, 0xf5, 0x1b,
	};

	const uint8_t msg[] = {
		0x43, 0x72, 0x79, 0x70, 0x74, 0x6f, 0x67, 0x72, 0x61, 0x70, 0x68, 0x69, 0x63, 0x20, 0x46, 0x6f,
		0x72, 0x75, 0x6d, 0x20, 0x52, 0x65, 0x73, 0x65, 0x61, 0x72, 0x63, 0x68, 0x20, 0x47, 0x72, 0x6f,
		0x75, 0x70,
	};

	const uint8_t  expected_tag[] = {
		0xa8, 0x06, 0x1d, 0xc1, 0x30, 0x51, 0x36, 0xc6, 0xc2, 0x2b, 0x8b, 0xaf, 0x0c, 0x01, 0x27, 0xa9,
	};

	uint8_t tag[POLY1305_TAGLEN];
	poly1305_auth(tag, msg, sizeof(msg), key);

	if(memcmp(expected_tag, tag, sizeof(tag))) {
		fprintf(stderr, ""invalid MAC\n"");
		exit(3);
	}
}

int main() {
	test_initialization();
	test_entryption();
	test_auth();
}","@fangfufu I'm not sure how that grouping would work. A protocol version number bump at least is going to be required. This just concerns me, there's already it of legacy protocol to maintain.
Perhaps it could be implemented as a third cipher (along side aes) and eventually the old cipher removed?",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,314,2021-08-12T12:59:15Z,2021-08-18T08:49:36Z,2021-08-18T08:49:39Z,CLOSED,False,4,4,2,https://github.com/hg,RFC7539-related changes to ChaCha20,2,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/314,https://github.com/gsliepen,11,https://github.com/gsliepen/tinc/pull/314#issuecomment-900519696,"This is an attempt to align the ChaCha20 implementation with RFC7539 (related to #301).
It seems to be the right thing to do to increment the major protocol version. I don't think we can reset the minor version, though? It's compared with magic values 1 and 2 all over the place.
A large part of RFC7539 is the AEAD construction, which doesn't seem to be used in tinc. Instead we simply encrypt the plaintext and append the MAC to it. Were you planning to modify the protocol to add AEAD?

Because we don't have unit testing yet, I threw together a small program to check the algorithm against RFC test vectors:
$ cd src/chacha-poly1305/
$ cat >test.c
$ gcc poly1305.c chacha.c test.c
$ ./a.out

#include <stdint.h>
#include <string.h>
#include <stdlib.h>
#include <stdio.h>
#include ""chacha.h""
#include ""poly1305.h""

#define U8C(v) (v##U)
#define U32C(v) (v##U)

#define U8V(v) ((uint8_t)(v)&U8C(0xFF))
#define U32V(v) ((uint32_t)(v)&U32C(0xFFFFFFFF))

#define ROTL32(v, n) \
	(U32V((v) << (n)) | ((v) >> (32 - (n))))

#define U8TO32_LITTLE(p)              \
	(((uint32_t)((p)[0])) |       \
	 ((uint32_t)((p)[1]) << 8) |  \
	 ((uint32_t)((p)[2]) << 16) | \
	 ((uint32_t)((p)[3]) << 24))

#define U32TO8_LITTLE(p, v)              \
	do {                             \
		(p)[0] = U8V((v));       \
		(p)[1] = U8V((v) >> 8);  \
		(p)[2] = U8V((v) >> 16); \
		(p)[3] = U8V((v) >> 24); \
	} while(0)

#define ROTATE(v, c) (ROTL32(v, c))
#define XOR(v, w) ((v) ^ (w))
#define PLUS(v, w) (U32V((v) + (w)))
#define PLUSONE(v) (PLUS((v), 1))

#define QUARTERROUND(a, b, c, d)   \
	a = PLUS(a, b);            \
	d = ROTATE(XOR(d, a), 16); \
	c = PLUS(c, d);            \
	b = ROTATE(XOR(b, c), 12); \
	a = PLUS(a, b);            \
	d = ROTATE(XOR(d, a), 8);  \
	c = PLUS(c, d);            \
	b = ROTATE(XOR(b, c), 7);

static const uint8_t key[] = {
	0x00, 0x01, 0x02, 0x03, 0x04, 0x05, 0x06, 0x07, 0x08, 0x09, 0x0a, 0x0b, 0x0c, 0x0d, 0x0e, 0x0f,
	0x10, 0x11, 0x12, 0x13, 0x14, 0x15, 0x16, 0x17, 0x18, 0x19, 0x1a, 0x1b, 0x1c, 0x1d, 0x1e, 0x1f,
};

static const uint8_t one[8] = {1, 0, 0, 0, 0, 0, 0, 0};

static const uint32_t expected_initial_state[] = {
	0x61707865, 0x3320646e, 0x79622d32, 0x6b206574,
	0x03020100, 0x07060504, 0x0b0a0908, 0x0f0e0d0c,
	0x13121110, 0x17161514, 0x1b1a1918, 0x1f1e1d1c,
	0x00000001, 0x09000000, 0x4a000000, 0x00000000,
};

static const uint32_t expected_after_20_rounds[] = {
	0x837778ab, 0xe238d763, 0xa67ae21e, 0x5950bb2f,
	0xc4f2d0c7, 0xfc62bb2f, 0x8fa018fc, 0x3f5ec7b7,
	0x335271c2, 0xf29489f3, 0xeabda8fc, 0x82e46ebd,
	0xd19c12b4, 0xb04e16de, 0x9e83d0cb, 0x4e3c50a2,
};

static void check_state(const void *expected, const void *real, const char *kind) {
	if(memcmp(expected, real, sizeof(struct chacha_ctx))) {
		fprintf(stderr, ""invalid %s state\n"", kind);
		exit(1);
	}
}

// copy-pasted from chacha.c
static void run_20_rounds(struct chacha_ctx *ctx) {
	uint32_t x0 = ctx->input[0];
	uint32_t x1 = ctx->input[1];
	uint32_t x2 = ctx->input[2];
	uint32_t x3 = ctx->input[3];
	uint32_t x4 = ctx->input[4];
	uint32_t x5 = ctx->input[5];
	uint32_t x6 = ctx->input[6];
	uint32_t x7 = ctx->input[7];
	uint32_t x8 = ctx->input[8];
	uint32_t x9 = ctx->input[9];
	uint32_t x10 = ctx->input[10];
	uint32_t x11 = ctx->input[11];
	uint32_t x12 = ctx->input[12];
	uint32_t x13 = ctx->input[13];
	uint32_t x14 = ctx->input[14];
	uint32_t x15 = ctx->input[15];

	for(size_t i = 20; i > 0; i -= 2) {
		QUARTERROUND(x0, x4, x8, x12)
		QUARTERROUND(x1, x5, x9, x13)
		QUARTERROUND(x2, x6, x10, x14)
		QUARTERROUND(x3, x7, x11, x15)
		QUARTERROUND(x0, x5, x10, x15)
		QUARTERROUND(x1, x6, x11, x12)
		QUARTERROUND(x2, x7, x8, x13)
		QUARTERROUND(x3, x4, x9, x14)
	}

	U32TO8_LITTLE((uint8_t *) ctx + 0, x0);
	U32TO8_LITTLE((uint8_t *) ctx + 4, x1);
	U32TO8_LITTLE((uint8_t *) ctx + 8, x2);
	U32TO8_LITTLE((uint8_t *) ctx + 12, x3);
	U32TO8_LITTLE((uint8_t *) ctx + 16, x4);
	U32TO8_LITTLE((uint8_t *) ctx + 20, x5);
	U32TO8_LITTLE((uint8_t *) ctx + 24, x6);
	U32TO8_LITTLE((uint8_t *) ctx + 28, x7);
	U32TO8_LITTLE((uint8_t *) ctx + 32, x8);
	U32TO8_LITTLE((uint8_t *) ctx + 36, x9);
	U32TO8_LITTLE((uint8_t *) ctx + 40, x10);
	U32TO8_LITTLE((uint8_t *) ctx + 44, x11);
	U32TO8_LITTLE((uint8_t *) ctx + 48, x12);
	U32TO8_LITTLE((uint8_t *) ctx + 52, x13);
	U32TO8_LITTLE((uint8_t *) ctx + 56, x14);
	U32TO8_LITTLE((uint8_t *) ctx + 60, x15);
}

static void test_initialization() {
	static const uint8_t nonce[] = {
		0x00, 0x00, 0x00, 0x09, 0x00, 0x00, 0x00, 0x4a, 0x00, 0x00, 0x00, 0x00,
	};

	struct chacha_ctx ctx = {0};

	chacha_keysetup(&ctx, key, 256);
	chacha_ivsetup(&ctx, nonce, one);
	check_state(&expected_initial_state, &ctx, ""initial"");

	run_20_rounds(&ctx);
	check_state(&expected_after_20_rounds, &ctx, ""20 rounds"");
}

static void test_entryption() {
	const uint8_t plaintext[] = {
		0x4c, 0x61, 0x64, 0x69, 0x65, 0x73, 0x20, 0x61, 0x6e, 0x64, 0x20, 0x47, 0x65, 0x6e, 0x74, 0x6c,
		0x65, 0x6d, 0x65, 0x6e, 0x20, 0x6f, 0x66, 0x20, 0x74, 0x68, 0x65, 0x20, 0x63, 0x6c, 0x61, 0x73,
		0x73, 0x20, 0x6f, 0x66, 0x20, 0x27, 0x39, 0x39, 0x3a, 0x20, 0x49, 0x66, 0x20, 0x49, 0x20, 0x63,
		0x6f, 0x75, 0x6c, 0x64, 0x20, 0x6f, 0x66, 0x66, 0x65, 0x72, 0x20, 0x79, 0x6f, 0x75, 0x20, 0x6f,
		0x6e, 0x6c, 0x79, 0x20, 0x6f, 0x6e, 0x65, 0x20, 0x74, 0x69, 0x70, 0x20, 0x66, 0x6f, 0x72, 0x20,
		0x74, 0x68, 0x65, 0x20, 0x66, 0x75, 0x74, 0x75, 0x72, 0x65, 0x2c, 0x20, 0x73, 0x75, 0x6e, 0x73,
		0x63, 0x72, 0x65, 0x65, 0x6e, 0x20, 0x77, 0x6f, 0x75, 0x6c, 0x64, 0x20, 0x62, 0x65, 0x20, 0x69,
		0x74, 0x2e,
	};

	const uint8_t expected_ciphertext[] = {
		0x6e, 0x2e, 0x35, 0x9a, 0x25, 0x68, 0xf9, 0x80, 0x41, 0xba, 0x07, 0x28, 0xdd, 0x0d, 0x69, 0x81,
		0xe9, 0x7e, 0x7a, 0xec, 0x1d, 0x43, 0x60, 0xc2, 0x0a, 0x27, 0xaf, 0xcc, 0xfd, 0x9f, 0xae, 0x0b,
		0xf9, 0x1b, 0x65, 0xc5, 0x52, 0x47, 0x33, 0xab, 0x8f, 0x59, 0x3d, 0xab, 0xcd, 0x62, 0xb3, 0x57,
		0x16, 0x39, 0xd6, 0x24, 0xe6, 0x51, 0x52, 0xab, 0x8f, 0x53, 0x0c, 0x35, 0x9f, 0x08, 0x61, 0xd8,
		0x07, 0xca, 0x0d, 0xbf, 0x50, 0x0d, 0x6a, 0x61, 0x56, 0xa3, 0x8e, 0x08, 0x8a, 0x22, 0xb6, 0x5e,
		0x52, 0xbc, 0x51, 0x4d, 0x16, 0xcc, 0xf8, 0x06, 0x81, 0x8c, 0xe9, 0x1a, 0xb7, 0x79, 0x37, 0x36,
		0x5a, 0xf9, 0x0b, 0xbf, 0x74, 0xa3, 0x5b, 0xe6, 0xb4, 0x0b, 0x8e, 0xed, 0xf2, 0x78, 0x5e, 0x42,
		0x87, 0x4d,
	};

	static const uint8_t enc_nonce[] = {
		0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x4a, 0x00, 0x00, 0x00, 0x00,
	};

	uint8_t ciphertext[sizeof(expected_ciphertext)];

	struct chacha_ctx ctx = {0};
	chacha_keysetup(&ctx, key, 256);
	chacha_ivsetup(&ctx, enc_nonce, one);

	chacha_encrypt_bytes(&ctx, (uint8_t *) plaintext, ciphertext, sizeof(ciphertext));

	if(memcmp(expected_ciphertext, ciphertext, sizeof(ciphertext))) {
		fprintf(stderr, ""invalid ciphertext\n"");
		exit(2);
	}
}

static void test_auth() {
	const uint8_t key[] = {
		0x85, 0xd6, 0xbe, 0x78, 0x57, 0x55, 0x6d, 0x33, 0x7f, 0x44, 0x52, 0xfe, 0x42, 0xd5, 0x06, 0xa8,
		0x01, 0x03, 0x80, 0x8a, 0xfb, 0x0d, 0xb2, 0xfd, 0x4a, 0xbf, 0xf6, 0xaf, 0x41, 0x49, 0xf5, 0x1b,
	};

	const uint8_t msg[] = {
		0x43, 0x72, 0x79, 0x70, 0x74, 0x6f, 0x67, 0x72, 0x61, 0x70, 0x68, 0x69, 0x63, 0x20, 0x46, 0x6f,
		0x72, 0x75, 0x6d, 0x20, 0x52, 0x65, 0x73, 0x65, 0x61, 0x72, 0x63, 0x68, 0x20, 0x47, 0x72, 0x6f,
		0x75, 0x70,
	};

	const uint8_t  expected_tag[] = {
		0xa8, 0x06, 0x1d, 0xc1, 0x30, 0x51, 0x36, 0xc6, 0xc2, 0x2b, 0x8b, 0xaf, 0x0c, 0x01, 0x27, 0xa9,
	};

	uint8_t tag[POLY1305_TAGLEN];
	poly1305_auth(tag, msg, sizeof(msg), key);

	if(memcmp(expected_tag, tag, sizeof(tag))) {
		fprintf(stderr, ""invalid MAC\n"");
		exit(3);
	}
}

int main() {
	test_initialization();
	test_entryption();
	test_auth();
}","Perhaps it could be implemented as a third cipher (along side aes) and eventually the old cipher removed?

I think that's the best option. It provides both 1.0 and older 1.1 versions with an upgrade path.",True,{'THUMBS_UP': ['https://github.com/fangfufu']}
gsliepen/tinc,https://github.com/gsliepen/tinc,316,2021-08-14T15:31:26Z,2021-08-14T17:32:46Z,2021-08-14T17:32:46Z,MERGED,True,9,5,2,https://github.com/splitice,hash table fix,1,[],https://github.com/gsliepen/tinc/pull/316,https://github.com/splitice,1,https://github.com/gsliepen/tinc/pull/316,"Clears keys during hash_clear
Explicitly clears memory during subnet init (bug introduced during merge)
Fixes memcmp read past bounds (read size 8, not 4/6/8)","Clears keys during hash_clear
Explicitly clears memory during subnet init (bug introduced during merge)
Fixes memcmp read past bounds (read size 8, not 4/6/8)",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,316,2021-08-14T15:31:26Z,2021-08-14T17:32:46Z,2021-08-14T17:32:46Z,MERGED,True,9,5,2,https://github.com/splitice,hash table fix,1,[],https://github.com/gsliepen/tinc/pull/316,https://github.com/splitice,2,https://github.com/gsliepen/tinc/pull/316#issuecomment-898908899,"Clears keys during hash_clear
Explicitly clears memory during subnet init (bug introduced during merge)
Fixes memcmp read past bounds (read size 8, not 4/6/8)",Note: Not yet real world tested. Currently setting up a new test environment (with OpenSSL 1.1.1),True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,317,2021-08-14T15:43:44Z,2021-08-14T23:37:30Z,2021-08-15T17:19:28Z,MERGED,True,13,24,4,https://github.com/hg,Improve failure detection in the test suite.,2,[],https://github.com/gsliepen/tinc/pull/317,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/317,"Improve detection of tinc failures in the test suite — it should now report failures as failures instead of hanging indefinitely.
Prompted by #315.
The reason behind --foreground was to put the time limit only on the, em, foreground process, ignoring anything that it might start and leave running in the background (like tinc). After rewriting the test library so many times I don't believe it's actually needed anymore, any it's best to throw it away in any case because it's not supported by most timeouts.
Things that should have failed (and did):

https://github.com/hg/tinc/runs/3329650122
https://github.com/hg/tinc/runs/3329650316


A bit of a rant: it's way too late for that, but after bashing my head against so many pointless differences in Unix utilities I am of the opinion that the test suite for cross-platform projects should be written in something like Python, or maybe even C. Diversity is good when there is actual diversity, but not when you have ten sets of utilities that are pretty much the same, except for tiny little differences like: this tail does X on SIGPIPE, that tail doesn't; this wc prints whitespace around the number, that one doesn't, this shell waits for all child jobs to finish, that one doesn't, and so on and so forth.
Autotools developers deserve a monument for their efforts.","Improve detection of tinc failures in the test suite — it should now report failures as failures instead of hanging indefinitely.
Prompted by #315.
The reason behind --foreground was to put the time limit only on the, em, foreground process, ignoring anything that it might start and leave running in the background (like tinc). After rewriting the test library so many times I don't believe it's actually needed anymore, any it's best to throw it away in any case because it's not supported by most timeouts.
Things that should have failed (and did):

https://github.com/hg/tinc/runs/3329650122
https://github.com/hg/tinc/runs/3329650316


A bit of a rant: it's way too late for that, but after bashing my head against so many pointless differences in Unix utilities I am of the opinion that the test suite for cross-platform projects should be written in something like Python, or maybe even C. Diversity is good when there is actual diversity, but not when you have ten sets of utilities that are pretty much the same, except for tiny little differences like: this tail does X on SIGPIPE, that tail doesn't; this wc prints whitespace around the number, that one doesn't, this shell waits for all child jobs to finish, that one doesn't, and so on and so forth.
Autotools developers deserve a monument for their efforts.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,317,2021-08-14T15:43:44Z,2021-08-14T23:37:30Z,2021-08-15T17:19:28Z,MERGED,True,13,24,4,https://github.com/hg,Improve failure detection in the test suite.,2,[],https://github.com/gsliepen/tinc/pull/317,https://github.com/hg,2,https://github.com/gsliepen/tinc/pull/317#issuecomment-898911262,"Improve detection of tinc failures in the test suite — it should now report failures as failures instead of hanging indefinitely.
Prompted by #315.
The reason behind --foreground was to put the time limit only on the, em, foreground process, ignoring anything that it might start and leave running in the background (like tinc). After rewriting the test library so many times I don't believe it's actually needed anymore, any it's best to throw it away in any case because it's not supported by most timeouts.
Things that should have failed (and did):

https://github.com/hg/tinc/runs/3329650122
https://github.com/hg/tinc/runs/3329650316


A bit of a rant: it's way too late for that, but after bashing my head against so many pointless differences in Unix utilities I am of the opinion that the test suite for cross-platform projects should be written in something like Python, or maybe even C. Diversity is good when there is actual diversity, but not when you have ten sets of utilities that are pretty much the same, except for tiny little differences like: this tail does X on SIGPIPE, that tail doesn't; this wc prints whitespace around the number, that one doesn't, this shell waits for all child jobs to finish, that one doesn't, and so on and so forth.
Autotools developers deserve a monument for their efforts.","UBSAN failure is triggered by hash table changes. I am less sure about FreeBSD weirdness. I'll wait for hash table fixes, then rebase and investigate.",True,{'THUMBS_UP': ['https://github.com/gsliepen']}
gsliepen/tinc,https://github.com/gsliepen/tinc,317,2021-08-14T15:43:44Z,2021-08-14T23:37:30Z,2021-08-15T17:19:28Z,MERGED,True,13,24,4,https://github.com/hg,Improve failure detection in the test suite.,2,[],https://github.com/gsliepen/tinc/pull/317,https://github.com/hg,3,https://github.com/gsliepen/tinc/pull/317#issuecomment-898947928,"Improve detection of tinc failures in the test suite — it should now report failures as failures instead of hanging indefinitely.
Prompted by #315.
The reason behind --foreground was to put the time limit only on the, em, foreground process, ignoring anything that it might start and leave running in the background (like tinc). After rewriting the test library so many times I don't believe it's actually needed anymore, any it's best to throw it away in any case because it's not supported by most timeouts.
Things that should have failed (and did):

https://github.com/hg/tinc/runs/3329650122
https://github.com/hg/tinc/runs/3329650316


A bit of a rant: it's way too late for that, but after bashing my head against so many pointless differences in Unix utilities I am of the opinion that the test suite for cross-platform projects should be written in something like Python, or maybe even C. Diversity is good when there is actual diversity, but not when you have ten sets of utilities that are pretty much the same, except for tiny little differences like: this tail does X on SIGPIPE, that tail doesn't; this wc prints whitespace around the number, that one doesn't, this shell waits for all child jobs to finish, that one doesn't, and so on and so forth.
Autotools developers deserve a monument for their efforts.","OK, the FreeBSD issue will have to be fixed by switching to GNU timeout. I don't want to further complicate the test suite. Its timeout behaves completely differently to GNU timeout and even other BSDs, and requires --foreground to cover our use case properly (and that flag is harmful everywhere else).

https://github.com/hg/tinc/actions/runs/1131065003
https://github.com/hg/tinc/actions/runs/1131080266
https://github.com/hg/tinc/actions/runs/1131107368
https://github.com/hg/tinc/actions/runs/1131126302
https://builds.sr.ht/~reducer/job/566469
https://builds.sr.ht/~reducer/job/566470

For some magical reason, compiledb recently stopped generating proper compile_commands.json on FreeBSD (see first sourcehut link), probably because of some compatibility weirdness with FreeBSD make. I pushed a drive-by fix for this (see the second link). It's still fine on Linux.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,317,2021-08-14T15:43:44Z,2021-08-14T23:37:30Z,2021-08-15T17:19:28Z,MERGED,True,13,24,4,https://github.com/hg,Improve failure detection in the test suite.,2,[],https://github.com/gsliepen/tinc/pull/317,https://github.com/fangfufu,4,https://github.com/gsliepen/tinc/pull/317#issuecomment-898959701,"Improve detection of tinc failures in the test suite — it should now report failures as failures instead of hanging indefinitely.
Prompted by #315.
The reason behind --foreground was to put the time limit only on the, em, foreground process, ignoring anything that it might start and leave running in the background (like tinc). After rewriting the test library so many times I don't believe it's actually needed anymore, any it's best to throw it away in any case because it's not supported by most timeouts.
Things that should have failed (and did):

https://github.com/hg/tinc/runs/3329650122
https://github.com/hg/tinc/runs/3329650316


A bit of a rant: it's way too late for that, but after bashing my head against so many pointless differences in Unix utilities I am of the opinion that the test suite for cross-platform projects should be written in something like Python, or maybe even C. Diversity is good when there is actual diversity, but not when you have ten sets of utilities that are pretty much the same, except for tiny little differences like: this tail does X on SIGPIPE, that tail doesn't; this wc prints whitespace around the number, that one doesn't, this shell waits for all child jobs to finish, that one doesn't, and so on and so forth.
Autotools developers deserve a monument for their efforts.",Will this help with issue #306?,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,318,2021-08-15T05:50:22Z,2021-08-15T18:50:03Z,2021-08-15T18:50:03Z,CLOSED,False,12,15,2,https://github.com/splitice,simplify signal handling,2,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/318,https://github.com/splitice,1,https://github.com/gsliepen/tinc/pull/318,The splay tree for signal handling is unnecessary.,The splay tree for signal handling is unnecessary.,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,318,2021-08-15T05:50:22Z,2021-08-15T18:50:03Z,2021-08-15T18:50:03Z,CLOSED,False,12,15,2,https://github.com/splitice,simplify signal handling,2,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/318,https://github.com/gsliepen,2,https://github.com/gsliepen/tinc/pull/318#issuecomment-899094685,The splay tree for signal handling is unnecessary.,Squashed & rebased as 290ca7a. Thanks!,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,320,2021-08-15T12:57:16Z,2021-08-15T14:08:42Z,2021-08-15T23:29:56Z,MERGED,True,3,2,1,https://github.com/hg,Reinit pseudo-random state in tincd service on Windows,1,[],https://github.com/gsliepen/tinc/pull/320,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/320,"https://github.com/hg/tinc/runs/3333383171
This should fix #306. Here's what I believe was happening:

tincd service on Windows is always initialized to the same pseudo-random sequence
bar connects to foo, sends its subnet information (using ""random"" numbers in meta commands)
foo configures bar's edges, subnets, etc, and remembers the commands it received
bar disconnects from foo and restarts
bar connects again (repeat step 1)
foo sees the exact same commands and rejects them outright
bar gets ignored and there's no connection anymore

Sometimes a timer would go off somewhere, rand() would be called before it's used in send_add_edge, and the job would pass successfully.

Considering how bad MS's pseudo-random number generator is (RAND_MAX is 0xFFFF and collisions are relatively likely), maybe it's best to throw it away and use one of:

call it twice and build a proper 32-bit integer out of both results
set the first result to getpid()
roll our own algorithm
or maybe even CryptGenRandom(), at least for anything that goes through the network to other nodes


By the way, CI breakage is caused by the new Debian release. We'll have to wait until container images are updated, probably another day or two. We can hardcode version numbers instead of tags like stable, but then you'll have to update them every couple of years.","https://github.com/hg/tinc/runs/3333383171
This should fix #306. Here's what I believe was happening:

tincd service on Windows is always initialized to the same pseudo-random sequence
bar connects to foo, sends its subnet information (using ""random"" numbers in meta commands)
foo configures bar's edges, subnets, etc, and remembers the commands it received
bar disconnects from foo and restarts
bar connects again (repeat step 1)
foo sees the exact same commands and rejects them outright
bar gets ignored and there's no connection anymore

Sometimes a timer would go off somewhere, rand() would be called before it's used in send_add_edge, and the job would pass successfully.

Considering how bad MS's pseudo-random number generator is (RAND_MAX is 0xFFFF and collisions are relatively likely), maybe it's best to throw it away and use one of:

call it twice and build a proper 32-bit integer out of both results
set the first result to getpid()
roll our own algorithm
or maybe even CryptGenRandom(), at least for anything that goes through the network to other nodes


By the way, CI breakage is caused by the new Debian release. We'll have to wait until container images are updated, probably another day or two. We can hardcode version numbers instead of tags like stable, but then you'll have to update them every couple of years.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,320,2021-08-15T12:57:16Z,2021-08-15T14:08:42Z,2021-08-15T23:29:56Z,MERGED,True,3,2,1,https://github.com/hg,Reinit pseudo-random state in tincd service on Windows,1,[],https://github.com/gsliepen/tinc/pull/320,https://github.com/fangfufu,2,https://github.com/gsliepen/tinc/pull/320#issuecomment-899125973,"https://github.com/hg/tinc/runs/3333383171
This should fix #306. Here's what I believe was happening:

tincd service on Windows is always initialized to the same pseudo-random sequence
bar connects to foo, sends its subnet information (using ""random"" numbers in meta commands)
foo configures bar's edges, subnets, etc, and remembers the commands it received
bar disconnects from foo and restarts
bar connects again (repeat step 1)
foo sees the exact same commands and rejects them outright
bar gets ignored and there's no connection anymore

Sometimes a timer would go off somewhere, rand() would be called before it's used in send_add_edge, and the job would pass successfully.

Considering how bad MS's pseudo-random number generator is (RAND_MAX is 0xFFFF and collisions are relatively likely), maybe it's best to throw it away and use one of:

call it twice and build a proper 32-bit integer out of both results
set the first result to getpid()
roll our own algorithm
or maybe even CryptGenRandom(), at least for anything that goes through the network to other nodes


By the way, CI breakage is caused by the new Debian release. We'll have to wait until container images are updated, probably another day or two. We can hardcode version numbers instead of tags like stable, but then you'll have to update them every couple of years.","By the way, CI breakage is caused by the new Debian release. We'll have to wait until container images are updated, probably another day or two. We can hardcode version numbers instead of tags like stable, but then you'll have to update them every couple of years.

Personally I think it is better to hardcode the version numbers. I use Debian on my personal computer. I used to use tags like stable or testing, a few years ago I read somewhere that it is recommended for people to use the actual version codename, to avoid unexpected upgrades. I then switched to the actual codename.
I think it is also reasonable to expect modification the files between major Debian upgrades, because there might be dependency changes.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,320,2021-08-15T12:57:16Z,2021-08-15T14:08:42Z,2021-08-15T23:29:56Z,MERGED,True,3,2,1,https://github.com/hg,Reinit pseudo-random state in tincd service on Windows,1,[],https://github.com/gsliepen/tinc/pull/320,https://github.com/gsliepen,3,https://github.com/gsliepen/tinc/pull/320#issuecomment-899127053,"https://github.com/hg/tinc/runs/3333383171
This should fix #306. Here's what I believe was happening:

tincd service on Windows is always initialized to the same pseudo-random sequence
bar connects to foo, sends its subnet information (using ""random"" numbers in meta commands)
foo configures bar's edges, subnets, etc, and remembers the commands it received
bar disconnects from foo and restarts
bar connects again (repeat step 1)
foo sees the exact same commands and rejects them outright
bar gets ignored and there's no connection anymore

Sometimes a timer would go off somewhere, rand() would be called before it's used in send_add_edge, and the job would pass successfully.

Considering how bad MS's pseudo-random number generator is (RAND_MAX is 0xFFFF and collisions are relatively likely), maybe it's best to throw it away and use one of:

call it twice and build a proper 32-bit integer out of both results
set the first result to getpid()
roll our own algorithm
or maybe even CryptGenRandom(), at least for anything that goes through the network to other nodes


By the way, CI breakage is caused by the new Debian release. We'll have to wait until container images are updated, probably another day or two. We can hardcode version numbers instead of tags like stable, but then you'll have to update them every couple of years.","Personally I think it is better to hardcode the version numbers.

I think it would have been fine if Docker Hub's debian:stable would just be an alias for the latest stable release, but instead it is (or was by the time you read it, they are going to fix it) a copy of buster bit with stable in the sources.list file.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,321,2021-08-15T18:05:52Z,2021-08-15T18:16:51Z,2022-03-13T05:05:17Z,CLOSED,False,3,3,2,https://github.com/hg,Fix UBSAN warnings about conversions and overflows.,1,[],https://github.com/gsliepen/tinc/pull/321,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/321,"A couple of fixes for yet another batch of UBSAN warnings.
before:

https://github.com/hg/tinc/runs/3334263546
plus local testing

after:

https://github.com/hg/tinc/actions/runs/1133163095
https://github.com/hg/tinc/actions/runs/1133164880

route.c:488:30: runtime error: implicit conversion from type 'uint32_t' (aka 'unsigned int') of value 62357 (32-bit, unsigned) to type 'uint8_t' (aka 'unsigned char') changed the value to 149 (8-bit, unsigned)
SUMMARY: UndefinedBehaviorSanitizer: undefined-behavior route.c:488:30 in

subnet.c:86:8: runtime error: unsigned integer overflow: 4273296874 + 33554432 cannot be represented in type 'unsigned int'
    #0 0x55d3879f6337 in hash_function_ipv6_t src/subnet.c:86:8
    #1 0x55d3879f6388 in hash_search_ipv6_t src/subnet.c:106:1
    #2 0x55d3879f8e16 in lookup_subnet_ipv6 src/subnet.c:293:10
    #3 0x55d3879cb4fb in route_ipv6 src/route.c:722:11
    #4 0x55d3879c7b19 in route src/route.c:1160:4
    #5 0x55d38797db2e in handle_device_data src/net_packet.c:1910:3
    #6 0x55d387950780 in event_loop src/event.c:355:5
    #7 0x55d387968c02 in main_loop src/net.c:505:6
    #8 0x55d3879ff471 in main src/tincd.c:614:11
    #9 0x7efd65c8f0b2 in __libc_start_main (/lib/x86_64-linux-gnu/libc.so.6+0x270b2)
    #10 0x55d387919dcd in _start (src/tincd+0x9adcd)

SUMMARY: UndefinedBehaviorSanitizer: undefined-behavior subnet.c:86:8 in","A couple of fixes for yet another batch of UBSAN warnings.
before:

https://github.com/hg/tinc/runs/3334263546
plus local testing

after:

https://github.com/hg/tinc/actions/runs/1133163095
https://github.com/hg/tinc/actions/runs/1133164880

route.c:488:30: runtime error: implicit conversion from type 'uint32_t' (aka 'unsigned int') of value 62357 (32-bit, unsigned) to type 'uint8_t' (aka 'unsigned char') changed the value to 149 (8-bit, unsigned)
SUMMARY: UndefinedBehaviorSanitizer: undefined-behavior route.c:488:30 in

subnet.c:86:8: runtime error: unsigned integer overflow: 4273296874 + 33554432 cannot be represented in type 'unsigned int'
    #0 0x55d3879f6337 in hash_function_ipv6_t src/subnet.c:86:8
    #1 0x55d3879f6388 in hash_search_ipv6_t src/subnet.c:106:1
    #2 0x55d3879f8e16 in lookup_subnet_ipv6 src/subnet.c:293:10
    #3 0x55d3879cb4fb in route_ipv6 src/route.c:722:11
    #4 0x55d3879c7b19 in route src/route.c:1160:4
    #5 0x55d38797db2e in handle_device_data src/net_packet.c:1910:3
    #6 0x55d387950780 in event_loop src/event.c:355:5
    #7 0x55d387968c02 in main_loop src/net.c:505:6
    #8 0x55d3879ff471 in main src/tincd.c:614:11
    #9 0x7efd65c8f0b2 in __libc_start_main (/lib/x86_64-linux-gnu/libc.so.6+0x270b2)
    #10 0x55d387919dcd in _start (src/tincd+0x9adcd)

SUMMARY: UndefinedBehaviorSanitizer: undefined-behavior subnet.c:86:8 in",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,321,2021-08-15T18:05:52Z,2021-08-15T18:16:51Z,2022-03-13T05:05:17Z,CLOSED,False,3,3,2,https://github.com/hg,Fix UBSAN warnings about conversions and overflows.,1,[],https://github.com/gsliepen/tinc/pull/321,https://github.com/gsliepen,2,https://github.com/gsliepen/tinc/pull/321#issuecomment-899091167,"A couple of fixes for yet another batch of UBSAN warnings.
before:

https://github.com/hg/tinc/runs/3334263546
plus local testing

after:

https://github.com/hg/tinc/actions/runs/1133163095
https://github.com/hg/tinc/actions/runs/1133164880

route.c:488:30: runtime error: implicit conversion from type 'uint32_t' (aka 'unsigned int') of value 62357 (32-bit, unsigned) to type 'uint8_t' (aka 'unsigned char') changed the value to 149 (8-bit, unsigned)
SUMMARY: UndefinedBehaviorSanitizer: undefined-behavior route.c:488:30 in

subnet.c:86:8: runtime error: unsigned integer overflow: 4273296874 + 33554432 cannot be represented in type 'unsigned int'
    #0 0x55d3879f6337 in hash_function_ipv6_t src/subnet.c:86:8
    #1 0x55d3879f6388 in hash_search_ipv6_t src/subnet.c:106:1
    #2 0x55d3879f8e16 in lookup_subnet_ipv6 src/subnet.c:293:10
    #3 0x55d3879cb4fb in route_ipv6 src/route.c:722:11
    #4 0x55d3879c7b19 in route src/route.c:1160:4
    #5 0x55d38797db2e in handle_device_data src/net_packet.c:1910:3
    #6 0x55d387950780 in event_loop src/event.c:355:5
    #7 0x55d387968c02 in main_loop src/net.c:505:6
    #8 0x55d3879ff471 in main src/tincd.c:614:11
    #9 0x7efd65c8f0b2 in __libc_start_main (/lib/x86_64-linux-gnu/libc.so.6+0x270b2)
    #10 0x55d387919dcd in _start (src/tincd+0x9adcd)

SUMMARY: UndefinedBehaviorSanitizer: undefined-behavior subnet.c:86:8 in",Cherry-picked as 04d8a8e. Thanks!,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,322,2021-08-15T18:09:36Z,2021-08-15T19:16:50Z,2022-03-13T05:05:19Z,MERGED,True,190,97,19,https://github.com/hg,Replace pointers to cipher_t/digest_t in connection_t with structs.,2,[],https://github.com/gsliepen/tinc/pull/322,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/322,"This is a part of #294 (replacing pointers to cipher_t and digest_t inside connection_t with structs themselves).
CI for this PR will fail until #321 is merged and this rebased on top.
I am not sure about changes to gcrypt. It is impossible to test because it hasn't been working for quite a while. I'll look into fixing it next.","This is a part of #294 (replacing pointers to cipher_t and digest_t inside connection_t with structs themselves).
CI for this PR will fail until #321 is merged and this rebased on top.
I am not sure about changes to gcrypt. It is impossible to test because it hasn't been working for quite a while. I'll look into fixing it next.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,322,2021-08-15T18:09:36Z,2021-08-15T19:16:50Z,2022-03-13T05:05:19Z,MERGED,True,190,97,19,https://github.com/hg,Replace pointers to cipher_t/digest_t in connection_t with structs.,2,[],https://github.com/gsliepen/tinc/pull/322,https://github.com/hg,2,https://github.com/gsliepen/tinc/pull/322#issuecomment-899096240,"This is a part of #294 (replacing pointers to cipher_t and digest_t inside connection_t with structs themselves).
CI for this PR will fail until #321 is merged and this rebased on top.
I am not sure about changes to gcrypt. It is impossible to test because it hasn't been working for quite a while. I'll look into fixing it next.","Thank you, fixed.
https://github.com/hg/tinc/actions/runs/1133263859
I moved cross-compilation jobs to buster for now. They don't work on bullseye anymore. There have been some major changes to supported architectures IIRC. I'll look into it tomorrow.
It's a tiny change and does not warrant a separate pull request IMHO.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,322,2021-08-15T18:09:36Z,2021-08-15T19:16:50Z,2022-03-13T05:05:19Z,MERGED,True,190,97,19,https://github.com/hg,Replace pointers to cipher_t/digest_t in connection_t with structs.,2,[],https://github.com/gsliepen/tinc/pull/322,https://github.com/gsliepen,3,https://github.com/gsliepen/tinc/pull/322#issuecomment-899097610,"This is a part of #294 (replacing pointers to cipher_t and digest_t inside connection_t with structs themselves).
CI for this PR will fail until #321 is merged and this rebased on top.
I am not sure about changes to gcrypt. It is impossible to test because it hasn't been working for quite a while. I'll look into fixing it next.",Ooooh all green!,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,323,2021-08-16T02:24:39Z,2021-08-17T21:37:11Z,2021-08-17T21:37:12Z,CLOSED,False,127,13,3,https://github.com/splitice,epoll patch v2,2,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/323,https://github.com/splitice,1,https://github.com/gsliepen/tinc/pull/323,Version 2 of the epoll patch,Version 2 of the epoll patch,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,323,2021-08-16T02:24:39Z,2021-08-17T21:37:11Z,2021-08-17T21:37:12Z,CLOSED,False,127,13,3,https://github.com/splitice,epoll patch v2,2,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/323,https://github.com/splitice,2,https://github.com/gsliepen/tinc/pull/323#issuecomment-900370571,Version 2 of the epoll patch,Fyi from my end I am happy with the state post review.,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,323,2021-08-16T02:24:39Z,2021-08-17T21:37:11Z,2021-08-17T21:37:12Z,CLOSED,False,127,13,3,https://github.com/splitice,epoll patch v2,2,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/323,https://github.com/gsliepen,3,https://github.com/gsliepen/tinc/pull/323#issuecomment-900648304,Version 2 of the epoll patch,Squashed and rebased as b322126. Thanks!,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,324,2021-08-17T08:11:33Z,2021-08-17T21:36:37Z,2022-03-13T05:04:57Z,MERGED,True,23,12,3,https://github.com/hg,Leaks in `invitation.c` + minor Solaris fixes,3,"['bug', '1.1']",https://github.com/gsliepen/tinc/pull/324,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/324,"https://github.com/hg/tinc/actions/runs/1138466183
https://github.com/hg/tinc/actions/runs/1138456174

Found in the process of making libgcrypt work. Cryptographic library failures were pushing invitation.c into previously untested error handling paths.
Fuzz testing could help with that, probably. I am not sure how to implement it, though: tincd networking code seems to require a lot of state being set up to function properly, so there has to be a network connection of some sort.
Running two separate tincd processes and sending fuzz data between them won't work — fuzzers monitor the very same process they're writing data into and expect it to fail.
I'm thinking of trying to create a separate thread, connect() to the same process, send data there, and see what happens.

For Solaris CI we could try this:
https://github.com/vmactions/solaris-vm
I'm getting the idea that if the code is not being regularly tested, then it quickly bitrots and probably does not work. Does it make sense to spend time on a pretty much dead OS?","https://github.com/hg/tinc/actions/runs/1138466183
https://github.com/hg/tinc/actions/runs/1138456174

Found in the process of making libgcrypt work. Cryptographic library failures were pushing invitation.c into previously untested error handling paths.
Fuzz testing could help with that, probably. I am not sure how to implement it, though: tincd networking code seems to require a lot of state being set up to function properly, so there has to be a network connection of some sort.
Running two separate tincd processes and sending fuzz data between them won't work — fuzzers monitor the very same process they're writing data into and expect it to fail.
I'm thinking of trying to create a separate thread, connect() to the same process, send data there, and see what happens.

For Solaris CI we could try this:
https://github.com/vmactions/solaris-vm
I'm getting the idea that if the code is not being regularly tested, then it quickly bitrots and probably does not work. Does it make sense to spend time on a pretty much dead OS?",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,324,2021-08-17T08:11:33Z,2021-08-17T21:36:37Z,2022-03-13T05:04:57Z,MERGED,True,23,12,3,https://github.com/hg,Leaks in `invitation.c` + minor Solaris fixes,3,"['bug', '1.1']",https://github.com/gsliepen/tinc/pull/324,https://github.com/hg,2,https://github.com/gsliepen/tinc/pull/324#issuecomment-900100632,"https://github.com/hg/tinc/actions/runs/1138466183
https://github.com/hg/tinc/actions/runs/1138456174

Found in the process of making libgcrypt work. Cryptographic library failures were pushing invitation.c into previously untested error handling paths.
Fuzz testing could help with that, probably. I am not sure how to implement it, though: tincd networking code seems to require a lot of state being set up to function properly, so there has to be a network connection of some sort.
Running two separate tincd processes and sending fuzz data between them won't work — fuzzers monitor the very same process they're writing data into and expect it to fail.
I'm thinking of trying to create a separate thread, connect() to the same process, send data there, and see what happens.

For Solaris CI we could try this:
https://github.com/vmactions/solaris-vm
I'm getting the idea that if the code is not being regularly tested, then it quickly bitrots and probably does not work. Does it make sense to spend time on a pretty much dead OS?","Hmm, I ran it locally on a Windows VM for a few dozen times before publishing this, and it was fine. I'll do more testing to determine if it's a spurious failure, or if there are new regressions.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,324,2021-08-17T08:11:33Z,2021-08-17T21:36:37Z,2022-03-13T05:04:57Z,MERGED,True,23,12,3,https://github.com/hg,Leaks in `invitation.c` + minor Solaris fixes,3,"['bug', '1.1']",https://github.com/gsliepen/tinc/pull/324,https://github.com/hg,3,https://github.com/gsliepen/tinc/pull/324#issuecomment-900190600,"https://github.com/hg/tinc/actions/runs/1138466183
https://github.com/hg/tinc/actions/runs/1138456174

Found in the process of making libgcrypt work. Cryptographic library failures were pushing invitation.c into previously untested error handling paths.
Fuzz testing could help with that, probably. I am not sure how to implement it, though: tincd networking code seems to require a lot of state being set up to function properly, so there has to be a network connection of some sort.
Running two separate tincd processes and sending fuzz data between them won't work — fuzzers monitor the very same process they're writing data into and expect it to fail.
I'm thinking of trying to create a separate thread, connect() to the same process, send data there, and see what happens.

For Solaris CI we could try this:
https://github.com/vmactions/solaris-vm
I'm getting the idea that if the code is not being regularly tested, then it quickly bitrots and probably does not work. Does it make sense to spend time on a pretty much dead OS?","After looping the test suite for two more hours, I think this was a one-off failure unrelated to these changes, unless I am missing something very obvious.
I also threw in a fix for this for good measure (triggered by pure chance in #326 and caused by a recent refactoring). My bad.
https://github.com/hg/tinc/actions/runs/1138918466",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,324,2021-08-17T08:11:33Z,2021-08-17T21:36:37Z,2022-03-13T05:04:57Z,MERGED,True,23,12,3,https://github.com/hg,Leaks in `invitation.c` + minor Solaris fixes,3,"['bug', '1.1']",https://github.com/gsliepen/tinc/pull/324,https://github.com/fangfufu,4,https://github.com/gsliepen/tinc/pull/324#issuecomment-900343460,"https://github.com/hg/tinc/actions/runs/1138466183
https://github.com/hg/tinc/actions/runs/1138456174

Found in the process of making libgcrypt work. Cryptographic library failures were pushing invitation.c into previously untested error handling paths.
Fuzz testing could help with that, probably. I am not sure how to implement it, though: tincd networking code seems to require a lot of state being set up to function properly, so there has to be a network connection of some sort.
Running two separate tincd processes and sending fuzz data between them won't work — fuzzers monitor the very same process they're writing data into and expect it to fail.
I'm thinking of trying to create a separate thread, connect() to the same process, send data there, and see what happens.

For Solaris CI we could try this:
https://github.com/vmactions/solaris-vm
I'm getting the idea that if the code is not being regularly tested, then it quickly bitrots and probably does not work. Does it make sense to spend time on a pretty much dead OS?","Btw, @gsliepen, I noticed that you put ""approved"" on this pull request. What does that actually mean for us? I don't think @hg can merge the pull request himself, because he is not a ""collaborator"".",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,324,2021-08-17T08:11:33Z,2021-08-17T21:36:37Z,2022-03-13T05:04:57Z,MERGED,True,23,12,3,https://github.com/hg,Leaks in `invitation.c` + minor Solaris fixes,3,"['bug', '1.1']",https://github.com/gsliepen/tinc/pull/324,https://github.com/gsliepen,5,https://github.com/gsliepen/tinc/pull/324#issuecomment-900413229,"https://github.com/hg/tinc/actions/runs/1138466183
https://github.com/hg/tinc/actions/runs/1138456174

Found in the process of making libgcrypt work. Cryptographic library failures were pushing invitation.c into previously untested error handling paths.
Fuzz testing could help with that, probably. I am not sure how to implement it, though: tincd networking code seems to require a lot of state being set up to function properly, so there has to be a network connection of some sort.
Running two separate tincd processes and sending fuzz data between them won't work — fuzzers monitor the very same process they're writing data into and expect it to fail.
I'm thinking of trying to create a separate thread, connect() to the same process, send data there, and see what happens.

For Solaris CI we could try this:
https://github.com/vmactions/solaris-vm
I'm getting the idea that if the code is not being regularly tested, then it quickly bitrots and probably does not work. Does it make sense to spend time on a pretty much dead OS?","Btw, @gsliepen, I noticed that you put ""approved"" on this pull request. What does that actually mean for us? I don't think @hg can merge the pull request himself, because he is not a ""collaborator"".

I'll merge it later today!",True,{'THUMBS_UP': ['https://github.com/fangfufu']}
gsliepen/tinc,https://github.com/gsliepen/tinc,325,2021-08-17T09:46:02Z,2021-09-18T18:33:36Z,2021-09-18T18:33:36Z,CLOSED,False,4,1,1,https://github.com/fangfufu,Wait for the network to be online before starting tinc. (1.0),1,"['enhancement', '1.0']",https://github.com/gsliepen/tinc/pull/325,https://github.com/fangfufu,1,https://github.com/gsliepen/tinc/pull/325,"Basically the same as pull request #326, but for tinc 1.0.","Basically the same as pull request #326, but for tinc 1.0.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,325,2021-08-17T09:46:02Z,2021-09-18T18:33:36Z,2021-09-18T18:33:36Z,CLOSED,False,4,1,1,https://github.com/fangfufu,Wait for the network to be online before starting tinc. (1.0),1,"['enhancement', '1.0']",https://github.com/gsliepen/tinc/pull/325,https://github.com/fangfufu,2,https://github.com/gsliepen/tinc/pull/325#issuecomment-900207241,"Basically the same as pull request #326, but for tinc 1.0.","@hg , I get these when I put the DynamicUser in:
Aug 17 12:12:24 gabriel systemd[1]: Started Tinc net tinc.
Aug 17 12:12:24 gabriel tincd[446858]: Couldn't write pid file /run/tinc.tinc.pid: Read-only file system
Aug 17 12:12:24 gabriel systemd[1]: tinc@tinc.service: Main process exited, code=exited, status=1/FAILURE
Aug 17 12:12:24 gabriel systemd[1]: tinc@tinc.service: Failed with result 'exit-code'.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,325,2021-08-17T09:46:02Z,2021-09-18T18:33:36Z,2021-09-18T18:33:36Z,CLOSED,False,4,1,1,https://github.com/fangfufu,Wait for the network to be online before starting tinc. (1.0),1,"['enhancement', '1.0']",https://github.com/gsliepen/tinc/pull/325,https://github.com/fangfufu,3,https://github.com/gsliepen/tinc/pull/325#issuecomment-900220257,"Basically the same as pull request #326, but for tinc 1.0.","@hg, I tried your kludge (#326 (comment)) ExecStartPre=+/usr/bin/chown -R tinc:tinc @sysconfdir@/tinc/%i, I get the followings:
Aug 17 12:34:05 gabriel systemd[12845]: tinc@tinc.service: Failed to determine user credentials: No such process
Aug 17 12:34:05 gabriel systemd[12845]: tinc@tinc.service: Failed at step USER spawning /usr/bin/chown: No such process
Aug 17 12:34:05 gabriel systemd[1]: tinc@tinc.service: Control process exited, code=exited, status=217/USER
Aug 17 12:34:05 gabriel systemd[1]: tinc@tinc.service: Failed with result 'exit-code'.
Aug 17 12:34:05 gabriel systemd[1]: Failed to start Tinc net tinc.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,325,2021-08-17T09:46:02Z,2021-09-18T18:33:36Z,2021-09-18T18:33:36Z,CLOSED,False,4,1,1,https://github.com/fangfufu,Wait for the network to be online before starting tinc. (1.0),1,"['enhancement', '1.0']",https://github.com/gsliepen/tinc/pull/325,https://github.com/hg,4,https://github.com/gsliepen/tinc/pull/325#issuecomment-900224172,"Basically the same as pull request #326, but for tinc 1.0.",Try adding ProtectSystem=no.,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,325,2021-08-17T09:46:02Z,2021-09-18T18:33:36Z,2021-09-18T18:33:36Z,CLOSED,False,4,1,1,https://github.com/fangfufu,Wait for the network to be online before starting tinc. (1.0),1,"['enhancement', '1.0']",https://github.com/gsliepen/tinc/pull/325,https://github.com/fangfufu,5,https://github.com/gsliepen/tinc/pull/325#issuecomment-900227426,"Basically the same as pull request #326, but for tinc 1.0.","With ProtectSystem=no, I get:
Aug 17 12:47:27 gabriel systemd[1]: Starting Tinc net tinc...
Aug 17 12:47:27 gabriel chown[61888]: /usr/bin/chown: invalid user: ‘tinc:tinc’
Aug 17 12:47:27 gabriel systemd[1]: tinc@tinc.service: Control process exited, code=exited, status=1/FAILURE
Aug 17 12:47:27 gabriel systemd[1]: tinc@tinc.service: Failed with result 'exit-code'.
Aug 17 12:47:27 gabriel systemd[1]: Failed to start Tinc net tinc.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,325,2021-08-17T09:46:02Z,2021-09-18T18:33:36Z,2021-09-18T18:33:36Z,CLOSED,False,4,1,1,https://github.com/fangfufu,Wait for the network to be online before starting tinc. (1.0),1,"['enhancement', '1.0']",https://github.com/gsliepen/tinc/pull/325,https://github.com/fangfufu,6,https://github.com/gsliepen/tinc/pull/325#issuecomment-900228871,"Basically the same as pull request #326, but for tinc 1.0.","I suppose I could fix it by adding the user and group tinc:tinc, but then that requires changes to the installation script.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,325,2021-08-17T09:46:02Z,2021-09-18T18:33:36Z,2021-09-18T18:33:36Z,CLOSED,False,4,1,1,https://github.com/fangfufu,Wait for the network to be online before starting tinc. (1.0),1,"['enhancement', '1.0']",https://github.com/gsliepen/tinc/pull/325,https://github.com/hg,7,https://github.com/gsliepen/tinc/pull/325#issuecomment-900264385,"Basically the same as pull request #326, but for tinc 1.0.","Then it's running chown before creating the user, or maybe with a separate mount atop of /etc/passwd.
It's not worth it in any case, we'll have to adjust installation scripts first.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,325,2021-08-17T09:46:02Z,2021-09-18T18:33:36Z,2021-09-18T18:33:36Z,CLOSED,False,4,1,1,https://github.com/fangfufu,Wait for the network to be online before starting tinc. (1.0),1,"['enhancement', '1.0']",https://github.com/gsliepen/tinc/pull/325,https://github.com/fangfufu,8,https://github.com/gsliepen/tinc/pull/325#issuecomment-922352775,"Basically the same as pull request #326, but for tinc 1.0.",Closing as per #326 (comment),True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,326,2021-08-17T09:52:04Z,2021-09-18T18:32:47Z,2021-09-19T09:18:57Z,CLOSED,False,4,1,1,https://github.com/fangfufu,Wait for the network to be online before starting tinc. (1.1),1,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/326,https://github.com/fangfufu,1,https://github.com/gsliepen/tinc/pull/326,"I found it super annoying that tinc starts before any of my other network interfaces come online. I made this change locally, so tinc starts up after the network comes online. OpenVPN has similar behaviour. I think it might be useful for others.
Note that the behaviour of tinc not waiting until the network comes online is mentioned in issue #133.
There is also a similar pull request for tinc 1.0. (pull request #325)","I found it super annoying that tinc starts before any of my other network interfaces come online. I made this change locally, so tinc starts up after the network comes online. OpenVPN has similar behaviour. I think it might be useful for others.
Note that the behaviour of tinc not waiting until the network comes online is mentioned in issue #133.
There is also a similar pull request for tinc 1.0. (pull request #325)",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,326,2021-08-17T09:52:04Z,2021-09-18T18:32:47Z,2021-09-19T09:18:57Z,CLOSED,False,4,1,1,https://github.com/fangfufu,Wait for the network to be online before starting tinc. (1.1),1,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/326,https://github.com/hg,2,https://github.com/gsliepen/tinc/pull/326#issuecomment-900177806,"I found it super annoying that tinc starts before any of my other network interfaces come online. I made this change locally, so tinc starts up after the network comes online. OpenVPN has similar behaviour. I think it might be useful for others.
Note that the behaviour of tinc not waiting until the network comes online is mentioned in issue #133.
There is also a similar pull request for tinc 1.0. (pull request #325)","By the way, I also find these changes useful:
[Service]
User = tinc
Group = tinc
AmbientCapabilities = CAP_NET_ADMIN CAP_NET_BIND_SERVICE
tinc does not really require root in most circumstances. CAP_NET_BIND_SERVICE allows it to bind to 655, and CAP_NET_ADMIN to configure network interfaces (including processes started through tincd scripts). The second one is a very powerful capability, but it's still better than root.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,326,2021-08-17T09:52:04Z,2021-09-18T18:32:47Z,2021-09-19T09:18:57Z,CLOSED,False,4,1,1,https://github.com/fangfufu,Wait for the network to be online before starting tinc. (1.1),1,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/326,https://github.com/fangfufu,3,https://github.com/gsliepen/tinc/pull/326#issuecomment-900187262,"I found it super annoying that tinc starts before any of my other network interfaces come online. I made this change locally, so tinc starts up after the network comes online. OpenVPN has similar behaviour. I think it might be useful for others.
Note that the behaviour of tinc not waiting until the network comes online is mentioned in issue #133.
There is also a similar pull request for tinc 1.0. (pull request #325)","By default tinc doesn't create its own user. At least not under Debian. If we want this in, then we should really create new user and new group as a part of the installation.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,326,2021-08-17T09:52:04Z,2021-09-18T18:32:47Z,2021-09-19T09:18:57Z,CLOSED,False,4,1,1,https://github.com/fangfufu,Wait for the network to be online before starting tinc. (1.1),1,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/326,https://github.com/hg,4,https://github.com/gsliepen/tinc/pull/326#issuecomment-900188925,"I found it super annoying that tinc starts before any of my other network interfaces come online. I made this change locally, so tinc starts up after the network comes online. OpenVPN has similar behaviour. I think it might be useful for others.
Note that the behaviour of tinc not waiting until the network comes online is mentioned in issue #133.
There is also a similar pull request for tinc 1.0. (pull request #325)","Well, there's DynamicUser when systemd is recent enough.
http://0pointer.net/blog/dynamic-users-with-systemd.html
It's probably worth getting in before 1.1 is finally released, which is the best time for breaking changes. tinc is written in C, after all, we need all the hardening we can get.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,326,2021-08-17T09:52:04Z,2021-09-18T18:32:47Z,2021-09-19T09:18:57Z,CLOSED,False,4,1,1,https://github.com/fangfufu,Wait for the network to be online before starting tinc. (1.1),1,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/326,https://github.com/hg,5,https://github.com/gsliepen/tinc/pull/326#issuecomment-900190077,"I found it super annoying that tinc starts before any of my other network interfaces come online. I made this change locally, so tinc starts up after the network comes online. OpenVPN has similar behaviour. I think it might be useful for others.
Note that the behaviour of tinc not waiting until the network comes online is mentioned in issue #133.
There is also a similar pull request for tinc 1.0. (pull request #325)","I also suggest looking at
$ systemd-analyze security tinc@

if your systemd is not very ancient. There are a ton of isolation options (many of those are used by various container engines). I've been doing this with work-related stuff for many years.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,326,2021-08-17T09:52:04Z,2021-09-18T18:32:47Z,2021-09-19T09:18:57Z,CLOSED,False,4,1,1,https://github.com/fangfufu,Wait for the network to be online before starting tinc. (1.1),1,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/326,https://github.com/fangfufu,6,https://github.com/gsliepen/tinc/pull/326#issuecomment-900192668,"I found it super annoying that tinc starts before any of my other network interfaces come online. I made this change locally, so tinc starts up after the network comes online. OpenVPN has similar behaviour. I think it might be useful for others.
Note that the behaviour of tinc not waiting until the network comes online is mentioned in issue #133.
There is also a similar pull request for tinc 1.0. (pull request #325)","DynamicUser requires at least Debian Buster, which is now the OldStable. So I think we should put it in.
https://packages.debian.org/search?suite=all&searchon=names&keywords=systemd",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,326,2021-08-17T09:52:04Z,2021-09-18T18:32:47Z,2021-09-19T09:18:57Z,CLOSED,False,4,1,1,https://github.com/fangfufu,Wait for the network to be online before starting tinc. (1.1),1,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/326,https://github.com/fangfufu,7,https://github.com/gsliepen/tinc/pull/326#issuecomment-900196785,"I found it super annoying that tinc starts before any of my other network interfaces come online. I made this change locally, so tinc starts up after the network comes online. OpenVPN has similar behaviour. I think it might be useful for others.
Note that the behaviour of tinc not waiting until the network comes online is mentioned in issue #133.
There is also a similar pull request for tinc 1.0. (pull request #325)","By the way, I also find these changes useful:
[Service]
User = tinc
Group = tinc
AmbientCapabilities = CAP_NET_ADMIN CAP_NET_BIND_SERVICE
tinc does not really require root in most circumstances. CAP_NET_BIND_SERVICE allows it to bind to 655, and CAP_NET_ADMIN to configure network interfaces (including processes started through tincd scripts). The second one is a very powerful capability, but it's still better than root.

Added",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,326,2021-08-17T09:52:04Z,2021-09-18T18:32:47Z,2021-09-19T09:18:57Z,CLOSED,False,4,1,1,https://github.com/fangfufu,Wait for the network to be online before starting tinc. (1.1),1,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/326,https://github.com/hg,8,https://github.com/gsliepen/tinc/pull/326#issuecomment-900203979,"I found it super annoying that tinc starts before any of my other network interfaces come online. I made this change locally, so tinc starts up after the network comes online. OpenVPN has similar behaviour. I think it might be useful for others.
Note that the behaviour of tinc not waiting until the network comes online is mentioned in issue #133.
There is also a similar pull request for tinc 1.0. (pull request #325)","This probably won't work as it's currently written, because by default tinc config directory belongs to root, and blocks access to keys to users others than root.
This kludge should fix it:
ExecStartPre=+/usr/bin/chown -R tinc:tinc @sysconfdir@/tinc/%i
but the best solution would be changing installation (and upgrade) scripts and doing it there.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,326,2021-08-17T09:52:04Z,2021-09-18T18:32:47Z,2021-09-19T09:18:57Z,CLOSED,False,4,1,1,https://github.com/fangfufu,Wait for the network to be online before starting tinc. (1.1),1,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/326,https://github.com/fangfufu,9,https://github.com/gsliepen/tinc/pull/326#issuecomment-900208725,"I found it super annoying that tinc starts before any of my other network interfaces come online. I made this change locally, so tinc starts up after the network comes online. OpenVPN has similar behaviour. I think it might be useful for others.
Note that the behaviour of tinc not waiting until the network comes online is mentioned in issue #133.
There is also a similar pull request for tinc 1.0. (pull request #325)","but the best solution would be changing installation (and upgrade) scripts and doing it there.

Personally I think this should be split into two pull requests - one to add my original proposed changes, the second one does the DynamicUser and the directory/file ownership changes.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,326,2021-08-17T09:52:04Z,2021-09-18T18:32:47Z,2021-09-19T09:18:57Z,CLOSED,False,4,1,1,https://github.com/fangfufu,Wait for the network to be online before starting tinc. (1.1),1,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/326,https://github.com/fangfufu,10,https://github.com/gsliepen/tinc/pull/326#issuecomment-900222527,"I found it super annoying that tinc starts before any of my other network interfaces come online. I made this change locally, so tinc starts up after the network comes online. OpenVPN has similar behaviour. I think it might be useful for others.
Note that the behaviour of tinc not waiting until the network comes online is mentioned in issue #133.
There is also a similar pull request for tinc 1.0. (pull request #325)","By the way, I also find these changes useful:
[Service]
User = tinc
Group = tinc
AmbientCapabilities = CAP_NET_ADMIN CAP_NET_BIND_SERVICE
tinc does not really require root in most circumstances. CAP_NET_BIND_SERVICE allows it to bind to 655, and CAP_NET_ADMIN to configure network interfaces (including processes started through tincd scripts). The second one is a very powerful capability, but it's still better than root.

I think I am not going to add these in this pull request, as I cannot get it them working locally for my tinc 1.0. (Yes, I know this is pull request is for tinc 1.1) We need to change the installation script, as you stated in #326 (comment).
The results of my attempts are documented in #325 (comment) and #325 (comment).
We should have a separate pull request which changes the installation script. I am not sure what to do right now, so I am not adding them in this pull request.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,326,2021-08-17T09:52:04Z,2021-09-18T18:32:47Z,2021-09-19T09:18:57Z,CLOSED,False,4,1,1,https://github.com/fangfufu,Wait for the network to be online before starting tinc. (1.1),1,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/326,https://github.com/gsliepen,11,https://github.com/gsliepen/tinc/pull/326#issuecomment-900286554,"I found it super annoying that tinc starts before any of my other network interfaces come online. I made this change locally, so tinc starts up after the network comes online. OpenVPN has similar behaviour. I think it might be useful for others.
Note that the behaviour of tinc not waiting until the network comes online is mentioned in issue #133.
There is also a similar pull request for tinc 1.0. (pull request #325)","Ah, the dreaded network-online target. For some people, the network isn't online until the VPN is up and running, and they could've configured their systemd setup so! Also, tinc should not have to depend on the network being online, as it's supposed to handle network outages to begin with, so the network not being available the first few seconds after it starts should be fine.

I found it super annoying that tinc starts before any of my other network interfaces come online.

Why is this annoying exactly? Just in case there is a better solution that addresses the issues you are getting because of this.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,326,2021-08-17T09:52:04Z,2021-09-18T18:32:47Z,2021-09-19T09:18:57Z,CLOSED,False,4,1,1,https://github.com/fangfufu,Wait for the network to be online before starting tinc. (1.1),1,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/326,https://github.com/fangfufu,12,https://github.com/gsliepen/tinc/pull/326#issuecomment-900335884,"I found it super annoying that tinc starts before any of my other network interfaces come online. I made this change locally, so tinc starts up after the network comes online. OpenVPN has similar behaviour. I think it might be useful for others.
Note that the behaviour of tinc not waiting until the network comes online is mentioned in issue #133.
There is also a similar pull request for tinc 1.0. (pull request #325)","For some people, the network isn't online until the VPN is up and running, and they could've configured their systemd setup so!
Now you mentioned it, the network-online target does sound a bit ambiguous. However surely the physical network should be up and running before VPN starts up?


Why is this annoying exactly? Just in case there is a better solution that addresses the issues you are getting because of this.

I basically have a bridge which bridge my different layer-2 VPN interfaces together. There is no easy way to add tinc to the bridge if tinc starts before /etc/network/interfaces gets configured.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,326,2021-08-17T09:52:04Z,2021-09-18T18:32:47Z,2021-09-19T09:18:57Z,CLOSED,False,4,1,1,https://github.com/fangfufu,Wait for the network to be online before starting tinc. (1.1),1,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/326,https://github.com/splitice,13,https://github.com/gsliepen/tinc/pull/326#issuecomment-900369595,"I found it super annoying that tinc starts before any of my other network interfaces come online. I made this change locally, so tinc starts up after the network comes online. OpenVPN has similar behaviour. I think it might be useful for others.
Note that the behaviour of tinc not waiting until the network comes online is mentioned in issue #133.
There is also a similar pull request for tinc 1.0. (pull request #325)",Support for systemd notify (on tinc ready) would also be nice (seperate). That's what I first thought when I read the title.,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,326,2021-08-17T09:52:04Z,2021-09-18T18:32:47Z,2021-09-19T09:18:57Z,CLOSED,False,4,1,1,https://github.com/fangfufu,Wait for the network to be online before starting tinc. (1.1),1,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/326,https://github.com/gsliepen,14,https://github.com/gsliepen/tinc/pull/326#issuecomment-900371361,"I found it super annoying that tinc starts before any of my other network interfaces come online. I made this change locally, so tinc starts up after the network comes online. OpenVPN has similar behaviour. I think it might be useful for others.
Note that the behaviour of tinc not waiting until the network comes online is mentioned in issue #133.
There is also a similar pull request for tinc 1.0. (pull request #325)","There is no easy way to add tinc to the bridge if tinc starts before /etc/network/interfaces gets configured.

How about adding tinc's interface to the bridge in the host-up script instead? But yes, in that case a dependency on whatever brings the bridge up would be nice.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,326,2021-08-17T09:52:04Z,2021-09-18T18:32:47Z,2021-09-19T09:18:57Z,CLOSED,False,4,1,1,https://github.com/fangfufu,Wait for the network to be online before starting tinc. (1.1),1,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/326,https://github.com/gsliepen,15,https://github.com/gsliepen/tinc/pull/326#issuecomment-900373400,"I found it super annoying that tinc starts before any of my other network interfaces come online. I made this change locally, so tinc starts up after the network comes online. OpenVPN has similar behaviour. I think it might be useful for others.
Note that the behaviour of tinc not waiting until the network comes online is mentioned in issue #133.
There is also a similar pull request for tinc 1.0. (pull request #325)","Support for systemd notify (on tinc ready) would also be nice (seperate).

This could be put in the tinc-up script, or also in a host-up script if you want the notification to happen only when tinc has actually connected to another node.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,326,2021-08-17T09:52:04Z,2021-09-18T18:32:47Z,2021-09-19T09:18:57Z,CLOSED,False,4,1,1,https://github.com/fangfufu,Wait for the network to be online before starting tinc. (1.1),1,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/326,https://github.com/splitice,16,https://github.com/gsliepen/tinc/pull/326#issuecomment-900380608,"I found it super annoying that tinc starts before any of my other network interfaces come online. I made this change locally, so tinc starts up after the network comes online. OpenVPN has similar behaviour. I think it might be useful for others.
Note that the behaviour of tinc not waiting until the network comes online is mentioned in issue #133.
There is also a similar pull request for tinc 1.0. (pull request #325)","Interesting idea, it could work. There can be pid issues with approaches like that but I think uid 0 has a pass.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,326,2021-08-17T09:52:04Z,2021-09-18T18:32:47Z,2021-09-19T09:18:57Z,CLOSED,False,4,1,1,https://github.com/fangfufu,Wait for the network to be online before starting tinc. (1.1),1,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/326,https://github.com/gsliepen,17,https://github.com/gsliepen/tinc/pull/326#issuecomment-900416021,"I found it super annoying that tinc starts before any of my other network interfaces come online. I made this change locally, so tinc starts up after the network comes online. OpenVPN has similar behaviour. I think it might be useful for others.
Note that the behaviour of tinc not waiting until the network comes online is mentioned in issue #133.
There is also a similar pull request for tinc 1.0. (pull request #325)","tinc does not really require root in most circumstances. CAP_NET_BIND_SERVICE allows it to bind to 655, and CAP_NET_ADMIN to configure network interfaces (including processes started through tincd scripts). The second one is a very powerful capability, but it's still better than root.

It really depends on what people put in their scripts. That said, safer defaults for tinc 1.1 might be a good idea. I wouldn't use this for tinc 1.0, as that will just upset users that do need the extra capabilities and that expect it to be stable.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,326,2021-08-17T09:52:04Z,2021-09-18T18:32:47Z,2021-09-19T09:18:57Z,CLOSED,False,4,1,1,https://github.com/fangfufu,Wait for the network to be online before starting tinc. (1.1),1,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/326,https://github.com/hg,18,https://github.com/gsliepen/tinc/pull/326#issuecomment-900420809,"I found it super annoying that tinc starts before any of my other network interfaces come online. I made this change locally, so tinc starts up after the network comes online. OpenVPN has similar behaviour. I think it might be useful for others.
Note that the behaviour of tinc not waiting until the network comes online is mentioned in issue #133.
There is also a similar pull request for tinc 1.0. (pull request #325)","It really depends on what people put in their scripts.

I've been using it everywhere. If tincd requires root access to configure something on one machine, I throw it into a separate script (owned by root), and give the tinc user the appropriate sudo privileges:
tinc ALL = (ALL) NOPASSWD: /etc/tinc/net/tinc-up

This script then checks the UID it's running under and sudos itself if necessary.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,326,2021-08-17T09:52:04Z,2021-09-18T18:32:47Z,2021-09-19T09:18:57Z,CLOSED,False,4,1,1,https://github.com/fangfufu,Wait for the network to be online before starting tinc. (1.1),1,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/326,https://github.com/fangfufu,19,https://github.com/gsliepen/tinc/pull/326#issuecomment-900436337,"I found it super annoying that tinc starts before any of my other network interfaces come online. I made this change locally, so tinc starts up after the network comes online. OpenVPN has similar behaviour. I think it might be useful for others.
Note that the behaviour of tinc not waiting until the network comes online is mentioned in issue #133.
There is also a similar pull request for tinc 1.0. (pull request #325)","There is no easy way to add tinc to the bridge if tinc starts before /etc/network/interfaces gets configured.

How about adding tinc's interface to the bridge in the host-up script instead? But yes, in that case a dependency on whatever brings the bridge up would be nice.

That's a good idea. Maybe I should just close this PR. One last question thing though, would it be a good idea if we align our behaviour with OpenVPN?",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,326,2021-08-17T09:52:04Z,2021-09-18T18:32:47Z,2021-09-19T09:18:57Z,CLOSED,False,4,1,1,https://github.com/fangfufu,Wait for the network to be online before starting tinc. (1.1),1,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/326,https://github.com/gsliepen,20,https://github.com/gsliepen/tinc/pull/326#issuecomment-901447036,"I found it super annoying that tinc starts before any of my other network interfaces come online. I made this change locally, so tinc starts up after the network comes online. OpenVPN has similar behaviour. I think it might be useful for others.
Note that the behaviour of tinc not waiting until the network comes online is mentioned in issue #133.
There is also a similar pull request for tinc 1.0. (pull request #325)","I see that OpenVPN's service file has some useful things, like DeviceAllow=/dev/net/tun, but it's missing a Wants+After=modprobe@tun.service then.
I also wonder what the best way is to run tinc as non-root under systemd. I guess systemd.networkd could be used to create and configure a tun or tap device that can be accessed by a non-root user, and then let tincd use that one, and not have up/down scripts. But I don't see how this could work together with DynamicUser.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,326,2021-08-17T09:52:04Z,2021-09-18T18:32:47Z,2021-09-19T09:18:57Z,CLOSED,False,4,1,1,https://github.com/fangfufu,Wait for the network to be online before starting tinc. (1.1),1,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/326,https://github.com/fangfufu,21,https://github.com/gsliepen/tinc/pull/326#issuecomment-901517977,"I found it super annoying that tinc starts before any of my other network interfaces come online. I made this change locally, so tinc starts up after the network comes online. OpenVPN has similar behaviour. I think it might be useful for others.
Note that the behaviour of tinc not waiting until the network comes online is mentioned in issue #133.
There is also a similar pull request for tinc 1.0. (pull request #325)","I kind of like having up/down scripts. This allows the end users to do more advanced configurations, like adding the tun/tap device to a bridge.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,326,2021-08-17T09:52:04Z,2021-09-18T18:32:47Z,2021-09-19T09:18:57Z,CLOSED,False,4,1,1,https://github.com/fangfufu,Wait for the network to be online before starting tinc. (1.1),1,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/326,https://github.com/hg,22,https://github.com/gsliepen/tinc/pull/326#issuecomment-901612563,"I found it super annoying that tinc starts before any of my other network interfaces come online. I made this change locally, so tinc starts up after the network comes online. OpenVPN has similar behaviour. I think it might be useful for others.
Note that the behaviour of tinc not waiting until the network comes online is mentioned in issue #133.
There is also a similar pull request for tinc 1.0. (pull request #325)","I guess systemd.networkd could be used to create and configure a tun or tap device that can be accessed by a non-root user

That's what I've been using, although the device is still being created by tinc (using CAP_NET_ADMIN).
$ cat /etc/systemd/network/tinc@tinc0.network

[Match]
Name = tinc0

[Network]
Address = 10.99.0.1/16
LinkLocalAddressing = no

[Route]
Destination = 10.10.19.0/24
Destination = 192.168.50.0/24
DynamicUser is not really required, we could use a regular user as has been done for the past 40 years. Every other isolation option that it enables (like ProtectSystem) can be (and should be) enabled separately. I am using this, which is not the strictest possible policy and can be improved further (but prevents access to almost the whole system, including all user files, and should prevent RCEs):
UMask                   = 0077
LockPersonality         = yes
NoNewPrivileges         = yes
PrivateMounts           = yes
PrivateTmp              = yes
ProtectClock            = yes
ProtectControlGroups    = yes
ProtectHome             = yes
ProtectHostname         = yes
ProtectKernelLogs       = yes
ProtectKernelModules    = yes
ProtectKernelTunables   = yes
ProtectSystem           = strict
ReadWritePaths          = /etc/tinc
MemoryDenyWriteExecute  = yes
DevicePolicy            = closed
DeviceAllow             = /dev/net/tun
RestrictAddressFamilies = AF_UNIX AF_INET AF_INET6
RestrictNamespaces      = yes
RestrictRealtime        = yes
RestrictSUIDSGID        = yes
SystemCallArchitectures = native
ProtectProc             = invisible
CapabilityBoundingSet   = CAP_NET_ADMIN CAP_NET_BIND_SERVICE
SystemCallFilter        = ~@clock @module @mount @reboot @swap @privileged @cpu-emulation @obsolete
Because you have full control over the code base and know every system call that tinc could possibly make unless overtaken by script kiddies, the seccomp-bpf system call filter in SystemCallFilter can be trimmed down to absolute necessities instead of using broad groups like I'm doing above.


like adding the tun/tap device to a bridge.

This can be done through systemd-networkd. Some pointers here, and also take a look at man systemd.network → / Example 4..",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,326,2021-08-17T09:52:04Z,2021-09-18T18:32:47Z,2021-09-19T09:18:57Z,CLOSED,False,4,1,1,https://github.com/fangfufu,Wait for the network to be online before starting tinc. (1.1),1,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/326,https://github.com/SilverBut,23,https://github.com/gsliepen/tinc/pull/326#issuecomment-913054782,"I found it super annoying that tinc starts before any of my other network interfaces come online. I made this change locally, so tinc starts up after the network comes online. OpenVPN has similar behaviour. I think it might be useful for others.
Note that the behaviour of tinc not waiting until the network comes online is mentioned in issue #133.
There is also a similar pull request for tinc 1.0. (pull request #325)","Maybe not the best way to implement this feature, as network-online.target might mean ""tinc is up"" for some users, and it's changing behaviors for current service. Also, I'm not sure this would result in same behavior under both systemd and sysvinit.
If users really want tinc start triggered by network-online, what about using drop-in files, and add this into the manual?",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,326,2021-08-17T09:52:04Z,2021-09-18T18:32:47Z,2021-09-19T09:18:57Z,CLOSED,False,4,1,1,https://github.com/fangfufu,Wait for the network to be online before starting tinc. (1.1),1,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/326,https://github.com/Mic92,24,https://github.com/gsliepen/tinc/pull/326#issuecomment-922266050,"I found it super annoying that tinc starts before any of my other network interfaces come online. I made this change locally, so tinc starts up after the network comes online. OpenVPN has similar behaviour. I think it might be useful for others.
Note that the behaviour of tinc not waiting until the network comes online is mentioned in issue #133.
There is also a similar pull request for tinc 1.0. (pull request #325)","For some people, the network isn't online until the VPN is up and running, and they could've configured their systemd setup so!
Now you mentioned it, the network-online target does sound a bit ambiguous. However surely the physical network should be up and running before VPN starts up?


Why is this annoying exactly? Just in case there is a better solution that addresses the issues you are getting because of this.

I basically have a bridge which bridge my different layer-2 VPN interfaces together. There is no easy way to add tinc to the bridge if tinc starts before /etc/network/interfaces gets configured.

Use device units for this.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,326,2021-08-17T09:52:04Z,2021-09-18T18:32:47Z,2021-09-19T09:18:57Z,CLOSED,False,4,1,1,https://github.com/fangfufu,Wait for the network to be online before starting tinc. (1.1),1,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/326,https://github.com/fangfufu,25,https://github.com/gsliepen/tinc/pull/326#issuecomment-922352678,"I found it super annoying that tinc starts before any of my other network interfaces come online. I made this change locally, so tinc starts up after the network comes online. OpenVPN has similar behaviour. I think it might be useful for others.
Note that the behaviour of tinc not waiting until the network comes online is mentioned in issue #133.
There is also a similar pull request for tinc 1.0. (pull request #325)","@Mic92 , is there a good example for the unit file?
Also, closing this pull request, because I am convinced that this is probably not a great idea.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,326,2021-08-17T09:52:04Z,2021-09-18T18:32:47Z,2021-09-19T09:18:57Z,CLOSED,False,4,1,1,https://github.com/fangfufu,Wait for the network to be online before starting tinc. (1.1),1,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/326,https://github.com/Mic92,26,https://github.com/gsliepen/tinc/pull/326#issuecomment-922442230,"I found it super annoying that tinc starts before any of my other network interfaces come online. I made this change locally, so tinc starts up after the network comes online. OpenVPN has similar behaviour. I think it might be useful for others.
Note that the behaviour of tinc not waiting until the network comes online is mentioned in issue #133.
There is also a similar pull request for tinc 1.0. (pull request #325)","@fangfufu
You can get device units created like this:
$ systemctl list-units | grep sys-subsystem-net-devices-
  sys-subsystem-net-devices-enp0s31f6.device                                             loaded active plugged   Ethernet Connection (10) I219-V
  sys-subsystem-net-devices-tinc.retiolum.device                                         loaded active plugged   /sys/subsystem/net/devices/tinc.retiolum
  sys-subsystem-net-devices-wlan0.device                                                 loaded active plugged   Comet Lake PCH-LP CNVi WiFi (Wi-Fi 6 AX201 160MHz)
You tinc service should than contain the wanted device:
After = sys-subsystem-net-devices-tinc.retiolum.device
Requires = sys-subsystem-net-devices-tinc.retiolum.device",True,{'THUMBS_UP': ['https://github.com/fangfufu']}
gsliepen/tinc,https://github.com/gsliepen/tinc,328,2021-08-17T19:12:33Z,2021-08-22T13:08:32Z,2022-03-13T05:04:47Z,MERGED,True,566,372,27,https://github.com/hg,Restore support for libgcrypt,4,['1.1'],https://github.com/gsliepen/tinc/pull/328,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/328,"This is an attempt to restore support for libgcrypt as an alternative crypto backend.
By ""99% done"" I meant ""I am not seeing any more issues"", of course, so it's probably 50% done. Although it's been working fine for me for the past day, I'll be testing it more heavily tomorrow on real systems.
CI jobs now do an additional libgcrypt run, although not with sanitizers. If you run it locally with sanitizers, it will fail without changes from #324. I'll add libgcrypt support to sanitizer runs later, as it requires some relatively big changes.
I sliced it into separate commits for easier review. The meat is in 2309610.

https://github.com/hg/tinc/actions/runs/1140511821
https://github.com/hg/tinc/actions/runs/1140348419
https://github.com/hg/tinc/actions/runs/1138226100 (pretty much the same code, but with a different base64 encoder)


Just for fun, using default settings:
libgcrypt
$ iperf3 -c 10.1.1.1
Connecting to host 10.1.1.1, port 5201
[  5] local 192.168.122.224 port 22580 connected to 10.1.1.1 port 5201
[ ID] Interval           Transfer     Bitrate         Retr  Cwnd
[  5]   0.00-1.00   sec  3.69 GBytes  31.7 Gbits/sec    0   3.00 MBytes
[  5]   1.00-2.00   sec  4.00 GBytes  34.4 Gbits/sec    0   3.00 MBytes
[  5]   2.00-3.00   sec  3.67 GBytes  31.5 Gbits/sec    0   3.00 MBytes
[  5]   3.00-4.00   sec  3.50 GBytes  30.0 Gbits/sec    0   3.00 MBytes
[  5]   4.00-5.00   sec  3.66 GBytes  31.3 Gbits/sec    0   3.00 MBytes
[  5]   5.00-6.00   sec  3.89 GBytes  33.4 Gbits/sec    0   3.00 MBytes
[  5]   6.00-7.00   sec  3.59 GBytes  30.9 Gbits/sec    0   3.00 MBytes
[  5]   7.00-8.00   sec  3.87 GBytes  33.2 Gbits/sec    0   3.00 MBytes
[  5]   8.00-9.00   sec  3.87 GBytes  33.2 Gbits/sec    0   3.00 MBytes
[  5]   9.00-10.00  sec  2.72 GBytes  23.4 Gbits/sec    0   3.00 MBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-10.00  sec  36.4 GBytes  31.3 Gbits/sec    0             sender
[  5]   0.00-10.12  sec  36.4 GBytes  30.9 Gbits/sec                  receiver

OpenSSL
$ iperf3 -c 10.1.1.1
Connecting to host 10.1.1.1, port 5201
[  5] local 192.168.122.224 port 56179 connected to 10.1.1.1 port 5201
[ ID] Interval           Transfer     Bitrate         Retr  Cwnd
[  5]   0.00-1.00   sec  3.94 GBytes  33.8 Gbits/sec    0   3.00 MBytes
[  5]   1.00-2.00   sec  3.86 GBytes  33.1 Gbits/sec    0   3.00 MBytes
[  5]   2.00-3.00   sec  3.88 GBytes  33.2 Gbits/sec    0   3.00 MBytes
[  5]   3.00-4.00   sec  3.93 GBytes  33.9 Gbits/sec    0   3.00 MBytes
[  5]   4.00-5.00   sec  3.90 GBytes  33.5 Gbits/sec    0   3.00 MBytes
[  5]   5.00-6.00   sec  3.91 GBytes  33.6 Gbits/sec    0   3.00 MBytes
[  5]   6.00-7.00   sec  3.94 GBytes  33.9 Gbits/sec    0   3.00 MBytes
[  5]   7.00-8.00   sec  3.86 GBytes  33.2 Gbits/sec    0   3.00 MBytes
[  5]   8.00-9.00   sec  3.90 GBytes  33.5 Gbits/sec    0   3.00 MBytes
[  5]   9.00-10.00  sec  3.88 GBytes  33.3 Gbits/sec    0   3.00 MBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-10.00  sec  39.0 GBytes  33.5 Gbits/sec    0             sender
[  5]   0.00-10.12  sec  39.0 GBytes  33.1 Gbits/sec                  receiver","This is an attempt to restore support for libgcrypt as an alternative crypto backend.
By ""99% done"" I meant ""I am not seeing any more issues"", of course, so it's probably 50% done. Although it's been working fine for me for the past day, I'll be testing it more heavily tomorrow on real systems.
CI jobs now do an additional libgcrypt run, although not with sanitizers. If you run it locally with sanitizers, it will fail without changes from #324. I'll add libgcrypt support to sanitizer runs later, as it requires some relatively big changes.
I sliced it into separate commits for easier review. The meat is in 2309610.

https://github.com/hg/tinc/actions/runs/1140511821
https://github.com/hg/tinc/actions/runs/1140348419
https://github.com/hg/tinc/actions/runs/1138226100 (pretty much the same code, but with a different base64 encoder)


Just for fun, using default settings:
libgcrypt
$ iperf3 -c 10.1.1.1
Connecting to host 10.1.1.1, port 5201
[  5] local 192.168.122.224 port 22580 connected to 10.1.1.1 port 5201
[ ID] Interval           Transfer     Bitrate         Retr  Cwnd
[  5]   0.00-1.00   sec  3.69 GBytes  31.7 Gbits/sec    0   3.00 MBytes
[  5]   1.00-2.00   sec  4.00 GBytes  34.4 Gbits/sec    0   3.00 MBytes
[  5]   2.00-3.00   sec  3.67 GBytes  31.5 Gbits/sec    0   3.00 MBytes
[  5]   3.00-4.00   sec  3.50 GBytes  30.0 Gbits/sec    0   3.00 MBytes
[  5]   4.00-5.00   sec  3.66 GBytes  31.3 Gbits/sec    0   3.00 MBytes
[  5]   5.00-6.00   sec  3.89 GBytes  33.4 Gbits/sec    0   3.00 MBytes
[  5]   6.00-7.00   sec  3.59 GBytes  30.9 Gbits/sec    0   3.00 MBytes
[  5]   7.00-8.00   sec  3.87 GBytes  33.2 Gbits/sec    0   3.00 MBytes
[  5]   8.00-9.00   sec  3.87 GBytes  33.2 Gbits/sec    0   3.00 MBytes
[  5]   9.00-10.00  sec  2.72 GBytes  23.4 Gbits/sec    0   3.00 MBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-10.00  sec  36.4 GBytes  31.3 Gbits/sec    0             sender
[  5]   0.00-10.12  sec  36.4 GBytes  30.9 Gbits/sec                  receiver

OpenSSL
$ iperf3 -c 10.1.1.1
Connecting to host 10.1.1.1, port 5201
[  5] local 192.168.122.224 port 56179 connected to 10.1.1.1 port 5201
[ ID] Interval           Transfer     Bitrate         Retr  Cwnd
[  5]   0.00-1.00   sec  3.94 GBytes  33.8 Gbits/sec    0   3.00 MBytes
[  5]   1.00-2.00   sec  3.86 GBytes  33.1 Gbits/sec    0   3.00 MBytes
[  5]   2.00-3.00   sec  3.88 GBytes  33.2 Gbits/sec    0   3.00 MBytes
[  5]   3.00-4.00   sec  3.93 GBytes  33.9 Gbits/sec    0   3.00 MBytes
[  5]   4.00-5.00   sec  3.90 GBytes  33.5 Gbits/sec    0   3.00 MBytes
[  5]   5.00-6.00   sec  3.91 GBytes  33.6 Gbits/sec    0   3.00 MBytes
[  5]   6.00-7.00   sec  3.94 GBytes  33.9 Gbits/sec    0   3.00 MBytes
[  5]   7.00-8.00   sec  3.86 GBytes  33.2 Gbits/sec    0   3.00 MBytes
[  5]   8.00-9.00   sec  3.90 GBytes  33.5 Gbits/sec    0   3.00 MBytes
[  5]   9.00-10.00  sec  3.88 GBytes  33.3 Gbits/sec    0   3.00 MBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-10.00  sec  39.0 GBytes  33.5 Gbits/sec    0             sender
[  5]   0.00-10.12  sec  39.0 GBytes  33.1 Gbits/sec                  receiver",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,328,2021-08-17T19:12:33Z,2021-08-22T13:08:32Z,2022-03-13T05:04:47Z,MERGED,True,566,372,27,https://github.com/hg,Restore support for libgcrypt,4,['1.1'],https://github.com/gsliepen/tinc/pull/328,https://github.com/hg,2,https://github.com/gsliepen/tinc/pull/328#issuecomment-903278863,"This is an attempt to restore support for libgcrypt as an alternative crypto backend.
By ""99% done"" I meant ""I am not seeing any more issues"", of course, so it's probably 50% done. Although it's been working fine for me for the past day, I'll be testing it more heavily tomorrow on real systems.
CI jobs now do an additional libgcrypt run, although not with sanitizers. If you run it locally with sanitizers, it will fail without changes from #324. I'll add libgcrypt support to sanitizer runs later, as it requires some relatively big changes.
I sliced it into separate commits for easier review. The meat is in 2309610.

https://github.com/hg/tinc/actions/runs/1140511821
https://github.com/hg/tinc/actions/runs/1140348419
https://github.com/hg/tinc/actions/runs/1138226100 (pretty much the same code, but with a different base64 encoder)


Just for fun, using default settings:
libgcrypt
$ iperf3 -c 10.1.1.1
Connecting to host 10.1.1.1, port 5201
[  5] local 192.168.122.224 port 22580 connected to 10.1.1.1 port 5201
[ ID] Interval           Transfer     Bitrate         Retr  Cwnd
[  5]   0.00-1.00   sec  3.69 GBytes  31.7 Gbits/sec    0   3.00 MBytes
[  5]   1.00-2.00   sec  4.00 GBytes  34.4 Gbits/sec    0   3.00 MBytes
[  5]   2.00-3.00   sec  3.67 GBytes  31.5 Gbits/sec    0   3.00 MBytes
[  5]   3.00-4.00   sec  3.50 GBytes  30.0 Gbits/sec    0   3.00 MBytes
[  5]   4.00-5.00   sec  3.66 GBytes  31.3 Gbits/sec    0   3.00 MBytes
[  5]   5.00-6.00   sec  3.89 GBytes  33.4 Gbits/sec    0   3.00 MBytes
[  5]   6.00-7.00   sec  3.59 GBytes  30.9 Gbits/sec    0   3.00 MBytes
[  5]   7.00-8.00   sec  3.87 GBytes  33.2 Gbits/sec    0   3.00 MBytes
[  5]   8.00-9.00   sec  3.87 GBytes  33.2 Gbits/sec    0   3.00 MBytes
[  5]   9.00-10.00  sec  2.72 GBytes  23.4 Gbits/sec    0   3.00 MBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-10.00  sec  36.4 GBytes  31.3 Gbits/sec    0             sender
[  5]   0.00-10.12  sec  36.4 GBytes  30.9 Gbits/sec                  receiver

OpenSSL
$ iperf3 -c 10.1.1.1
Connecting to host 10.1.1.1, port 5201
[  5] local 192.168.122.224 port 56179 connected to 10.1.1.1 port 5201
[ ID] Interval           Transfer     Bitrate         Retr  Cwnd
[  5]   0.00-1.00   sec  3.94 GBytes  33.8 Gbits/sec    0   3.00 MBytes
[  5]   1.00-2.00   sec  3.86 GBytes  33.1 Gbits/sec    0   3.00 MBytes
[  5]   2.00-3.00   sec  3.88 GBytes  33.2 Gbits/sec    0   3.00 MBytes
[  5]   3.00-4.00   sec  3.93 GBytes  33.9 Gbits/sec    0   3.00 MBytes
[  5]   4.00-5.00   sec  3.90 GBytes  33.5 Gbits/sec    0   3.00 MBytes
[  5]   5.00-6.00   sec  3.91 GBytes  33.6 Gbits/sec    0   3.00 MBytes
[  5]   6.00-7.00   sec  3.94 GBytes  33.9 Gbits/sec    0   3.00 MBytes
[  5]   7.00-8.00   sec  3.86 GBytes  33.2 Gbits/sec    0   3.00 MBytes
[  5]   8.00-9.00   sec  3.90 GBytes  33.5 Gbits/sec    0   3.00 MBytes
[  5]   9.00-10.00  sec  3.88 GBytes  33.3 Gbits/sec    0   3.00 MBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-10.00  sec  39.0 GBytes  33.5 Gbits/sec    0             sender
[  5]   0.00-10.12  sec  39.0 GBytes  33.1 Gbits/sec                  receiver","Oops. I've been very busy for the past few days and haven't really managed to finish this yet. It works fine though (at least in my personal experience), and the remaining changes are not very important. I'll send them separately a bit later:

update docs to mention libgcrypt as an alternative to openssl
disable ECB modes (see diff below)
a few other bits and pieces

I should have mentioned this here, sorry.
diff --git a/src/gcrypt/cipher.c b/src/gcrypt/cipher.c
index 0f7b008d..eb17f7d0 100644
--- a/src/gcrypt/cipher.c
+++ b/src/gcrypt/cipher.c
@@ -31,22 +31,18 @@ static struct {
 } ciphertable[] = {
        {""none"", GCRY_CIPHER_NONE, GCRY_CIPHER_MODE_NONE, 0},

-       {NULL, GCRY_CIPHER_BLOWFISH, GCRY_CIPHER_MODE_ECB, 92},
        {""blowfish"", GCRY_CIPHER_BLOWFISH, GCRY_CIPHER_MODE_CBC, 91},
        {NULL, GCRY_CIPHER_BLOWFISH, GCRY_CIPHER_MODE_CFB, 93},
        {NULL, GCRY_CIPHER_BLOWFISH, GCRY_CIPHER_MODE_OFB, 94},

-       {""aes-128-ecb"", GCRY_CIPHER_AES, GCRY_CIPHER_MODE_ECB, 418},
        {""aes-128-cbc"", GCRY_CIPHER_AES, GCRY_CIPHER_MODE_CBC, 419},
        {""aes-128-cfb"", GCRY_CIPHER_AES, GCRY_CIPHER_MODE_CFB, 421},
        {""aes-128-ofb"", GCRY_CIPHER_AES, GCRY_CIPHER_MODE_OFB, 420},

-       {""aes-192-ecb"", GCRY_CIPHER_AES192, GCRY_CIPHER_MODE_ECB, 422},
        {""aes-192-cbc"", GCRY_CIPHER_AES192, GCRY_CIPHER_MODE_CBC, 423},
        {""aes-192-cfb"", GCRY_CIPHER_AES192, GCRY_CIPHER_MODE_CFB, 425},
        {""aes-192-ofb"", GCRY_CIPHER_AES192, GCRY_CIPHER_MODE_OFB, 424},

-       {""aes-256-ecb"", GCRY_CIPHER_AES256, GCRY_CIPHER_MODE_ECB, 426},
        {""aes-256-cbc"", GCRY_CIPHER_AES256, GCRY_CIPHER_MODE_CBC, 427},
        {""aes-256-cfb"", GCRY_CIPHER_AES256, GCRY_CIPHER_MODE_CFB, 429},
        {""aes-256-ofb"", GCRY_CIPHER_AES256, GCRY_CIPHER_MODE_OFB, 428},
@@ -109,7 +105,7 @@ static bool cipher_open(cipher_t *cipher, int algo, int mode) {
        cipher->keylen = gcry_cipher_get_algo_keylen(algo);
        cipher->blklen = gcry_cipher_get_algo_blklen(algo);
        cipher->key = xmalloc(cipher->keylen + cipher->blklen);
-       cipher->padding = mode == GCRY_CIPHER_MODE_ECB || mode == GCRY_CIPHER_MODE_CBC;
+       cipher->padding = mode == GCRY_CIPHER_MODE_CBC;

        return true;
 }",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,330,2021-08-18T04:09:43Z,2021-08-18T12:35:24Z,2021-08-18T12:35:24Z,CLOSED,False,89,9,4,https://github.com/splitice,remove full subnet cache clear on graph update,3,[],https://github.com/gsliepen/tinc/pull/330,https://github.com/splitice,1,https://github.com/gsliepen/tinc/pull/330,"I wrote this, seemed like it would be a good idea. Thought I would add weight checks next, but I seem to have got my head in a loop in this graph code.
So I'm taking a break grom the graph code.
Effectively the goal would be to only clear from the hash cache if the incoming subnets have a lower weight than the currently cached item
This current version over clears, it doesnt do weight comparisons.","I wrote this, seemed like it would be a good idea. Thought I would add weight checks next, but I seem to have got my head in a loop in this graph code.
So I'm taking a break grom the graph code.
Effectively the goal would be to only clear from the hash cache if the incoming subnets have a lower weight than the currently cached item
This current version over clears, it doesnt do weight comparisons.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,330,2021-08-18T04:09:43Z,2021-08-18T12:35:24Z,2021-08-18T12:35:24Z,CLOSED,False,89,9,4,https://github.com/splitice,remove full subnet cache clear on graph update,3,[],https://github.com/gsliepen/tinc/pull/330,https://github.com/splitice,2,https://github.com/gsliepen/tinc/pull/330#issuecomment-900803412,"I wrote this, seemed like it would be a good idea. Thought I would add weight checks next, but I seem to have got my head in a loop in this graph code.
So I'm taking a break grom the graph code.
Effectively the goal would be to only clear from the hash cache if the incoming subnets have a lower weight than the currently cached item
This current version over clears, it doesnt do weight comparisons.","Ergh, this is quite difficult to get right.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,331,2021-08-18T14:52:38Z,2021-08-22T13:08:52Z,2022-03-13T05:04:34Z,CLOSED,False,34,58,5,https://github.com/hg,CI: improve sanitizer runs; update cross-compilation jobs to Debian bullseye,1,"['1.1', 'CI']",https://github.com/gsliepen/tinc/pull/331,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/331,"https://github.com/hg/tinc/actions/runs/1143479443
and a failing run to show it actually works:
https://github.com/hg/tinc/runs/3362255572


sanitizers now do the full test run, as in every other job.

I would really like to merge this before libgcrypt, because there were a lot of sanitizer failures there. That's what prompted this change.


run all test flavors even if one of them fails.
move cross-compilation jobs to Debian Bullseye

big-endian MIPS is no more. I changed it to little-endian MIPS.
bullseye still ships the cross-compilation toolkit, but it's pretty useless for our purposes without pre-built libraries.




I think CI can finally be left alone after this. Maybe I'll add repositories as per #329, although I don't feel comfortable putting even more eggs in one basket (GitHub).
We could probably host them anywhere, and you could configure a subdomain to point it to GitHub for the time being, then easily move if Microsoft pulls a fast one.
To do this properly, we should use each distribution's own service:

https://copr.fedorainfracloud.org
https://launchpad.net/ubuntu/+ppas
https://build.opensuse.org/

although TBH I don't have time to support this many.","https://github.com/hg/tinc/actions/runs/1143479443
and a failing run to show it actually works:
https://github.com/hg/tinc/runs/3362255572


sanitizers now do the full test run, as in every other job.

I would really like to merge this before libgcrypt, because there were a lot of sanitizer failures there. That's what prompted this change.


run all test flavors even if one of them fails.
move cross-compilation jobs to Debian Bullseye

big-endian MIPS is no more. I changed it to little-endian MIPS.
bullseye still ships the cross-compilation toolkit, but it's pretty useless for our purposes without pre-built libraries.




I think CI can finally be left alone after this. Maybe I'll add repositories as per #329, although I don't feel comfortable putting even more eggs in one basket (GitHub).
We could probably host them anywhere, and you could configure a subdomain to point it to GitHub for the time being, then easily move if Microsoft pulls a fast one.
To do this properly, we should use each distribution's own service:

https://copr.fedorainfracloud.org
https://launchpad.net/ubuntu/+ppas
https://build.opensuse.org/

although TBH I don't have time to support this many.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,331,2021-08-18T14:52:38Z,2021-08-22T13:08:52Z,2022-03-13T05:04:34Z,CLOSED,False,34,58,5,https://github.com/hg,CI: improve sanitizer runs; update cross-compilation jobs to Debian bullseye,1,"['1.1', 'CI']",https://github.com/gsliepen/tinc/pull/331,https://github.com/fangfufu,2,https://github.com/gsliepen/tinc/pull/331#issuecomment-901531610,"https://github.com/hg/tinc/actions/runs/1143479443
and a failing run to show it actually works:
https://github.com/hg/tinc/runs/3362255572


sanitizers now do the full test run, as in every other job.

I would really like to merge this before libgcrypt, because there were a lot of sanitizer failures there. That's what prompted this change.


run all test flavors even if one of them fails.
move cross-compilation jobs to Debian Bullseye

big-endian MIPS is no more. I changed it to little-endian MIPS.
bullseye still ships the cross-compilation toolkit, but it's pretty useless for our purposes without pre-built libraries.




I think CI can finally be left alone after this. Maybe I'll add repositories as per #329, although I don't feel comfortable putting even more eggs in one basket (GitHub).
We could probably host them anywhere, and you could configure a subdomain to point it to GitHub for the time being, then easily move if Microsoft pulls a fast one.
To do this properly, we should use each distribution's own service:

https://copr.fedorainfracloud.org
https://launchpad.net/ubuntu/+ppas
https://build.opensuse.org/

although TBH I don't have time to support this many.","We should just use openSUSE Build Service. On https://build.opensuse.org/, it says

The openSUSE Build Service is the public instance of the Open Build Service (OBS) used for development of the openSUSE distribution and to offer packages from same source for Fedora, Debian, Ubuntu, SUSE Linux Enterprise and other distributions..

I get the official Wine Debian packages from openSUSE Build Service.
Anyways, I am more than happy to provide my own Kimsufi servers for hosting the repository, if required.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,331,2021-08-18T14:52:38Z,2021-08-22T13:08:52Z,2022-03-13T05:04:34Z,CLOSED,False,34,58,5,https://github.com/hg,CI: improve sanitizer runs; update cross-compilation jobs to Debian bullseye,1,"['1.1', 'CI']",https://github.com/gsliepen/tinc/pull/331,https://github.com/hg,3,https://github.com/gsliepen/tinc/pull/331#issuecomment-901725375,"https://github.com/hg/tinc/actions/runs/1143479443
and a failing run to show it actually works:
https://github.com/hg/tinc/runs/3362255572


sanitizers now do the full test run, as in every other job.

I would really like to merge this before libgcrypt, because there were a lot of sanitizer failures there. That's what prompted this change.


run all test flavors even if one of them fails.
move cross-compilation jobs to Debian Bullseye

big-endian MIPS is no more. I changed it to little-endian MIPS.
bullseye still ships the cross-compilation toolkit, but it's pretty useless for our purposes without pre-built libraries.




I think CI can finally be left alone after this. Maybe I'll add repositories as per #329, although I don't feel comfortable putting even more eggs in one basket (GitHub).
We could probably host them anywhere, and you could configure a subdomain to point it to GitHub for the time being, then easily move if Microsoft pulls a fast one.
To do this properly, we should use each distribution's own service:

https://copr.fedorainfracloud.org
https://launchpad.net/ubuntu/+ppas
https://build.opensuse.org/

although TBH I don't have time to support this many.","We should just use openSUSE Build Service

I think you're supposed to provide the source code and use their service to do the build (which is the right thing to do in any case). I'll probably look into doing it later. It doesn't seem to require any changes to CI.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,331,2021-08-18T14:52:38Z,2021-08-22T13:08:52Z,2022-03-13T05:04:34Z,CLOSED,False,34,58,5,https://github.com/hg,CI: improve sanitizer runs; update cross-compilation jobs to Debian bullseye,1,"['1.1', 'CI']",https://github.com/gsliepen/tinc/pull/331,https://github.com/gsliepen,4,https://github.com/gsliepen/tinc/pull/331#issuecomment-903266733,"https://github.com/hg/tinc/actions/runs/1143479443
and a failing run to show it actually works:
https://github.com/hg/tinc/runs/3362255572


sanitizers now do the full test run, as in every other job.

I would really like to merge this before libgcrypt, because there were a lot of sanitizer failures there. That's what prompted this change.


run all test flavors even if one of them fails.
move cross-compilation jobs to Debian Bullseye

big-endian MIPS is no more. I changed it to little-endian MIPS.
bullseye still ships the cross-compilation toolkit, but it's pretty useless for our purposes without pre-built libraries.




I think CI can finally be left alone after this. Maybe I'll add repositories as per #329, although I don't feel comfortable putting even more eggs in one basket (GitHub).
We could probably host them anywhere, and you could configure a subdomain to point it to GitHub for the time being, then easily move if Microsoft pulls a fast one.
To do this properly, we should use each distribution's own service:

https://copr.fedorainfracloud.org
https://launchpad.net/ubuntu/+ppas
https://build.opensuse.org/

although TBH I don't have time to support this many.",Cherry-picked as 53b2398.,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,334,2021-08-23T07:04:03Z,2021-08-23T16:27:31Z,2022-03-13T05:04:27Z,MERGED,True,1,1,1,https://github.com/hg,CI: fix archive name for sanitizer results.,1,[],https://github.com/gsliepen/tinc/pull/334,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/334,"#333
All sanitizer jobs were writing to the same name and overwriting each other.

Success:
https://github.com/hg/tinc/actions/runs/1157587095

The same fix with xoshiro changes applied on top:
https://github.com/hg/tinc/actions/runs/1157593127
UBSAN results (or see the link above):
https://github.com/hg/tinc/suites/3566773997/artifacts/85630898","#333
All sanitizer jobs were writing to the same name and overwriting each other.

Success:
https://github.com/hg/tinc/actions/runs/1157587095

The same fix with xoshiro changes applied on top:
https://github.com/hg/tinc/actions/runs/1157593127
UBSAN results (or see the link above):
https://github.com/hg/tinc/suites/3566773997/artifacts/85630898",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,334,2021-08-23T07:04:03Z,2021-08-23T16:27:31Z,2022-03-13T05:04:27Z,MERGED,True,1,1,1,https://github.com/hg,CI: fix archive name for sanitizer results.,1,[],https://github.com/gsliepen/tinc/pull/334,https://github.com/hg,2,https://github.com/gsliepen/tinc/pull/334#issuecomment-903501194,"#333
All sanitizer jobs were writing to the same name and overwriting each other.

Success:
https://github.com/hg/tinc/actions/runs/1157587095

The same fix with xoshiro changes applied on top:
https://github.com/hg/tinc/actions/runs/1157593127
UBSAN results (or see the link above):
https://github.com/hg/tinc/suites/3566773997/artifacts/85630898","Some minor leaks remain in libgcrypt code, so it's not currently being sanitized. They are of constant size and have very short stack traces that point to initialization code in the library itself. I couldn't find any better solution than ignoring them (yet), I'll try to fix that until the end of the week.",True,{'THUMBS_UP': ['https://github.com/gsliepen']}
gsliepen/tinc,https://github.com/gsliepen/tinc,352,2022-03-12T06:39:47Z,2022-03-12T15:07:33Z,2022-03-12T15:14:15Z,CLOSED,False,38,15,8,https://github.com/hg,Fix `make distcheck`,2,[],https://github.com/gsliepen/tinc/pull/352,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/352,"Here's what automake is doing:
bad=0; pid=$$; list=""tincd tinc""; for p in $list; do \
  case '  ' in \
   *"" $p ""* | *"" ../../../src/$p ""*) continue;; \
  esac; \
  f=`echo ""$p"" | \
     sed 's,^.*/,,;s/$//;s,x,x,;s/$//'`; \
  for opt in --help --version; do \
    if ""/home/neko/src/pub/tinc/tinc-1.1pre18-116-ge856b04f/_inst/sbin/$f"" $opt >c${pid}_.out \
         2>c${pid}_.err </dev/null \
	&& test -n ""`cat c${pid}_.out`"" \
	&& test -z ""`cat c${pid}_.err`""; then :; \
    else echo ""$f does not support $opt"" 1>&2; bad=1; fi; \
  done; \
done; rm -f c${pid}_.???; exit $bad
tincd does not support --help
make[2]: *** [Makefile:807: installcheck-sbinPROGRAMS] Error 1
make[2]: Leaving directory '/home/neko/src/pub/tinc/tinc-1.1pre18-116-ge856b04f/_build/sub/src'
make[1]: *** [Makefile:392: installcheck-recursive] Error 1
make[1]: Leaving directory '/home/neko/src/pub/tinc/tinc-1.1pre18-116-ge856b04f/_build/sub'
make: *** [Makefile:609: distcheck] Error 1

Since 28b7a53 tincd is printing its usage information to stderr, and automake scripts are not happy about this.
This reverts to previous behavior. Or we can disable this check for tincd by using this (tinc should still work fine).

I also added distcheck to CI so this won't happen again (Linux only, because installing a full TeX suite in other jobs takes a lot of time).","Here's what automake is doing:
bad=0; pid=$$; list=""tincd tinc""; for p in $list; do \
  case '  ' in \
   *"" $p ""* | *"" ../../../src/$p ""*) continue;; \
  esac; \
  f=`echo ""$p"" | \
     sed 's,^.*/,,;s/$//;s,x,x,;s/$//'`; \
  for opt in --help --version; do \
    if ""/home/neko/src/pub/tinc/tinc-1.1pre18-116-ge856b04f/_inst/sbin/$f"" $opt >c${pid}_.out \
         2>c${pid}_.err </dev/null \
	&& test -n ""`cat c${pid}_.out`"" \
	&& test -z ""`cat c${pid}_.err`""; then :; \
    else echo ""$f does not support $opt"" 1>&2; bad=1; fi; \
  done; \
done; rm -f c${pid}_.???; exit $bad
tincd does not support --help
make[2]: *** [Makefile:807: installcheck-sbinPROGRAMS] Error 1
make[2]: Leaving directory '/home/neko/src/pub/tinc/tinc-1.1pre18-116-ge856b04f/_build/sub/src'
make[1]: *** [Makefile:392: installcheck-recursive] Error 1
make[1]: Leaving directory '/home/neko/src/pub/tinc/tinc-1.1pre18-116-ge856b04f/_build/sub'
make: *** [Makefile:609: distcheck] Error 1

Since 28b7a53 tincd is printing its usage information to stderr, and automake scripts are not happy about this.
This reverts to previous behavior. Or we can disable this check for tincd by using this (tinc should still work fine).

I also added distcheck to CI so this won't happen again (Linux only, because installing a full TeX suite in other jobs takes a lot of time).",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,352,2022-03-12T06:39:47Z,2022-03-12T15:07:33Z,2022-03-12T15:14:15Z,CLOSED,False,38,15,8,https://github.com/hg,Fix `make distcheck`,2,[],https://github.com/gsliepen/tinc/pull/352,https://github.com/hg,2,https://github.com/gsliepen/tinc/pull/352#issuecomment-1065863117,"Here's what automake is doing:
bad=0; pid=$$; list=""tincd tinc""; for p in $list; do \
  case '  ' in \
   *"" $p ""* | *"" ../../../src/$p ""*) continue;; \
  esac; \
  f=`echo ""$p"" | \
     sed 's,^.*/,,;s/$//;s,x,x,;s/$//'`; \
  for opt in --help --version; do \
    if ""/home/neko/src/pub/tinc/tinc-1.1pre18-116-ge856b04f/_inst/sbin/$f"" $opt >c${pid}_.out \
         2>c${pid}_.err </dev/null \
	&& test -n ""`cat c${pid}_.out`"" \
	&& test -z ""`cat c${pid}_.err`""; then :; \
    else echo ""$f does not support $opt"" 1>&2; bad=1; fi; \
  done; \
done; rm -f c${pid}_.???; exit $bad
tincd does not support --help
make[2]: *** [Makefile:807: installcheck-sbinPROGRAMS] Error 1
make[2]: Leaving directory '/home/neko/src/pub/tinc/tinc-1.1pre18-116-ge856b04f/_build/sub/src'
make[1]: *** [Makefile:392: installcheck-recursive] Error 1
make[1]: Leaving directory '/home/neko/src/pub/tinc/tinc-1.1pre18-116-ge856b04f/_build/sub'
make: *** [Makefile:609: distcheck] Error 1

Since 28b7a53 tincd is printing its usage information to stderr, and automake scripts are not happy about this.
This reverts to previous behavior. Or we can disable this check for tincd by using this (tinc should still work fine).

I also added distcheck to CI so this won't happen again (Linux only, because installing a full TeX suite in other jobs takes a lot of time).",FreeBSD's clang-tidy nags about narrowing conversions. It's not really related to distcheck and I think it's better to fix them separately a bit later.,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,352,2022-03-12T06:39:47Z,2022-03-12T15:07:33Z,2022-03-12T15:14:15Z,CLOSED,False,38,15,8,https://github.com/hg,Fix `make distcheck`,2,[],https://github.com/gsliepen/tinc/pull/352,https://github.com/gsliepen,3,https://github.com/gsliepen/tinc/pull/352#issuecomment-1065899062,"Here's what automake is doing:
bad=0; pid=$$; list=""tincd tinc""; for p in $list; do \
  case '  ' in \
   *"" $p ""* | *"" ../../../src/$p ""*) continue;; \
  esac; \
  f=`echo ""$p"" | \
     sed 's,^.*/,,;s/$//;s,x,x,;s/$//'`; \
  for opt in --help --version; do \
    if ""/home/neko/src/pub/tinc/tinc-1.1pre18-116-ge856b04f/_inst/sbin/$f"" $opt >c${pid}_.out \
         2>c${pid}_.err </dev/null \
	&& test -n ""`cat c${pid}_.out`"" \
	&& test -z ""`cat c${pid}_.err`""; then :; \
    else echo ""$f does not support $opt"" 1>&2; bad=1; fi; \
  done; \
done; rm -f c${pid}_.???; exit $bad
tincd does not support --help
make[2]: *** [Makefile:807: installcheck-sbinPROGRAMS] Error 1
make[2]: Leaving directory '/home/neko/src/pub/tinc/tinc-1.1pre18-116-ge856b04f/_build/sub/src'
make[1]: *** [Makefile:392: installcheck-recursive] Error 1
make[1]: Leaving directory '/home/neko/src/pub/tinc/tinc-1.1pre18-116-ge856b04f/_build/sub'
make: *** [Makefile:609: distcheck] Error 1

Since 28b7a53 tincd is printing its usage information to stderr, and automake scripts are not happy about this.
This reverts to previous behavior. Or we can disable this check for tincd by using this (tinc should still work fine).

I also added distcheck to CI so this won't happen again (Linux only, because installing a full TeX suite in other jobs takes a lot of time).",Cherry-picked onto 1.1. Thanks!,True,{'THUMBS_UP': ['https://github.com/hg']}
gsliepen/tinc,https://github.com/gsliepen/tinc,353,2022-03-14T17:22:58Z,2022-03-15T07:45:15Z,2022-03-15T07:45:15Z,MERGED,True,37,30,3,https://github.com/hg,Silence remaining 'bugprone-narrowing-conversions',2,[],https://github.com/gsliepen/tinc/pull/353,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/353,"It's not the most important thing in the world, but it's probably best to fix these warnings instead of turning off the check completely.
Note that it only shows up with clang-tidy 12 or newer.
Are you fine with JavaScript-ish casts !! or should I replace them with proper (bool)foobar?","It's not the most important thing in the world, but it's probably best to fix these warnings instead of turning off the check completely.
Note that it only shows up with clang-tidy 12 or newer.
Are you fine with JavaScript-ish casts !! or should I replace them with proper (bool)foobar?",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,353,2022-03-14T17:22:58Z,2022-03-15T07:45:15Z,2022-03-15T07:45:15Z,MERGED,True,37,30,3,https://github.com/hg,Silence remaining 'bugprone-narrowing-conversions',2,[],https://github.com/gsliepen/tinc/pull/353,https://github.com/gsliepen,2,https://github.com/gsliepen/tinc/pull/353#issuecomment-1067117845,"It's not the most important thing in the world, but it's probably best to fix these warnings instead of turning off the check completely.
Note that it only shows up with clang-tidy 12 or newer.
Are you fine with JavaScript-ish casts !! or should I replace them with proper (bool)foobar?","Even better would be not to need to cast at all. Perhaps we can solve this more elegantly by moving to C11 (if Linus can, so can we). Then we can replace the bitfields, that need to have a well-defined width in order to serialize them, with unions containing unnamed structs, like so:
typedef union connection_status_t {
    struct {
        bool pinged: 1;
        bool unused_active: 1;
        ...
    };
    uint32_t value;
} connection_status_t;

This should avoid warnings from clang-tidy, and will make accessing it as a 32-bit int much cleaner as well.",True,{'THUMBS_UP': ['https://github.com/hg']}
gsliepen/tinc,https://github.com/gsliepen/tinc,353,2022-03-14T17:22:58Z,2022-03-15T07:45:15Z,2022-03-15T07:45:15Z,MERGED,True,37,30,3,https://github.com/hg,Silence remaining 'bugprone-narrowing-conversions',2,[],https://github.com/gsliepen/tinc/pull/353,https://github.com/hg,3,https://github.com/gsliepen/tinc/pull/353#issuecomment-1067176001,"It's not the most important thing in the world, but it's probably best to fix these warnings instead of turning off the check completely.
Note that it only shows up with clang-tidy 12 or newer.
Are you fine with JavaScript-ish casts !! or should I replace them with proper (bool)foobar?","Thanks, that's definitely much better.
I don't think there's a decent way to ask autoconf for anything newer than C99, even though it seems to have had support for C11 since 2.70. We probably can't rely on magic that only been out for 1.5 years?
The check in configure.ac doesn't seem to be strictly necessary and gcc compiles the code even with -std=c99 -Wpedantic (loudly protesting along the way).
If you'd rather not have it, I'll remove it. FWIW, meson has proper support for setting the C standard.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,353,2022-03-14T17:22:58Z,2022-03-15T07:45:15Z,2022-03-15T07:45:15Z,MERGED,True,37,30,3,https://github.com/hg,Silence remaining 'bugprone-narrowing-conversions',2,[],https://github.com/gsliepen/tinc/pull/353,https://github.com/lancethepants,4,https://github.com/gsliepen/tinc/pull/353#issuecomment-1067188735,"It's not the most important thing in the world, but it's probably best to fix these warnings instead of turning off the check completely.
Note that it only shows up with clang-tidy 12 or newer.
Are you fine with JavaScript-ish casts !! or should I replace them with proper (bool)foobar?","So I know that tomato firmware which has tinc integration (with a nice gui I made) is using pre gcc-4.6 toolchains, which as far as I can tell, pre-dates c11. One of the toolchains is 4.2.4 (stupid old I know), so I'm not sure it'd even have -std=c1x experimental support . I know there are people using tinc with tomato. Trust me, I really hate being that guy that pipes up and is resistant to change.
If it's any consolation I finally was forced to work with meson, and although I don't care for having to create cross files, it is workable.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,353,2022-03-14T17:22:58Z,2022-03-15T07:45:15Z,2022-03-15T07:45:15Z,MERGED,True,37,30,3,https://github.com/hg,Silence remaining 'bugprone-narrowing-conversions',2,[],https://github.com/gsliepen/tinc/pull/353,https://github.com/lancethepants,5,https://github.com/gsliepen/tinc/pull/353#issuecomment-1067201443,"It's not the most important thing in the world, but it's probably best to fix these warnings instead of turning off the check completely.
Note that it only shows up with clang-tidy 12 or newer.
Are you fine with JavaScript-ish casts !! or should I replace them with proper (bool)foobar?","Now to be fair, the old toolchains tomato firmware use are only necessary for the kernel because of proprietary kernel modules.  They could use a much more recent toolchain for the majority of the userspace, or they could integrate a static binary built from a newer toolchain. So don't let me singlehandedly veto things if the majority think this is a move in the right direction.  tinc in tomato is my baby, so just trying to watch over it.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,353,2022-03-14T17:22:58Z,2022-03-15T07:45:15Z,2022-03-15T07:45:15Z,MERGED,True,37,30,3,https://github.com/hg,Silence remaining 'bugprone-narrowing-conversions',2,[],https://github.com/gsliepen/tinc/pull/353,https://github.com/gsliepen,6,https://github.com/gsliepen/tinc/pull/353#issuecomment-1067312145,"It's not the most important thing in the world, but it's probably best to fix these warnings instead of turning off the check completely.
Note that it only shows up with clang-tidy 12 or newer.
Are you fine with JavaScript-ish casts !! or should I replace them with proper (bool)foobar?","@lancethepants I just checked, even GCC 4.1 supports unnamed structs inside unions. That's one worry less!
@hg Nice. I would probably not bother to write an autoconf check, recent versions of autoconf seem to already automatically emit checks for C11 support.",True,{'THUMBS_UP': ['https://github.com/lancethepants']}
gsliepen/tinc,https://github.com/gsliepen/tinc,353,2022-03-14T17:22:58Z,2022-03-15T07:45:15Z,2022-03-15T07:45:15Z,MERGED,True,37,30,3,https://github.com/hg,Silence remaining 'bugprone-narrowing-conversions',2,[],https://github.com/gsliepen/tinc/pull/353,https://github.com/hg,7,https://github.com/gsliepen/tinc/pull/353#issuecomment-1067558462,"It's not the most important thing in the world, but it's probably best to fix these warnings instead of turning off the check completely.
Note that it only shows up with clang-tidy 12 or newer.
Are you fine with JavaScript-ish casts !! or should I replace them with proper (bool)foobar?","Thanks for the review.
Here's a test under gcc 4.1.2 just to be sure (which is 15 years old at this point).
It compiles even with -std=gnu89 (or without specifying any standard).",True,{'THUMBS_UP': ['https://github.com/lancethepants']}
gsliepen/tinc,https://github.com/gsliepen/tinc,354,2022-03-16T16:39:44Z,2022-03-20T18:23:33Z,2022-03-20T18:23:34Z,MERGED,True,406,97,12,https://github.com/hg,Add support for OpenSSL 3.0+,3,[],https://github.com/gsliepen/tinc/pull/354,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/354,"This is an attempt to close #347.
Since this touches cryptography you might prefer to do the work yourself. I'm okay with that; this PR could be used as a starting point.
I tested it on one of the nodes in my 20-something node network. Seems to work fine.
Here's the official migration guide. It's not of much help, the information on how to use the new APIs has to be picked piecemeal in OpenSSL sources, manpages, and examples.","This is an attempt to close #347.
Since this touches cryptography you might prefer to do the work yourself. I'm okay with that; this PR could be used as a starting point.
I tested it on one of the nodes in my 20-something node network. Seems to work fine.
Here's the official migration guide. It's not of much help, the information on how to use the new APIs has to be picked piecemeal in OpenSSL sources, manpages, and examples.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,354,2022-03-16T16:39:44Z,2022-03-20T18:23:33Z,2022-03-20T18:23:34Z,MERGED,True,406,97,12,https://github.com/hg,Add support for OpenSSL 3.0+,3,[],https://github.com/gsliepen/tinc/pull/354,https://github.com/hg,2,https://github.com/gsliepen/tinc/pull/354#issuecomment-1069336445,"This is an attempt to close #347.
Since this touches cryptography you might prefer to do the work yourself. I'm okay with that; this PR could be used as a starting point.
I tested it on one of the nodes in my 20-something node network. Seems to work fine.
Here's the official migration guide. It's not of much help, the information on how to use the new APIs has to be picked piecemeal in OpenSSL sources, manpages, and examples.",The CI run is here. It seems GitHub is not starting another one if the original is successful.,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,354,2022-03-16T16:39:44Z,2022-03-20T18:23:33Z,2022-03-20T18:23:34Z,MERGED,True,406,97,12,https://github.com/hg,Add support for OpenSSL 3.0+,3,[],https://github.com/gsliepen/tinc/pull/354,https://github.com/hg,3,https://github.com/gsliepen/tinc/pull/354#issuecomment-1070821135,"This is an attempt to close #347.
Since this touches cryptography you might prefer to do the work yourself. I'm okay with that; this PR could be used as a starting point.
I tested it on one of the nodes in my 20-something node network. Seems to work fine.
Here's the official migration guide. It's not of much help, the information on how to use the new APIs has to be picked piecemeal in OpenSSL sources, manpages, and examples.","Context reuse doesn't seem to be supported by the new API. Looks like an accidental omission.
I tried to do it without much success. The tests pass, but the binary fails to connect to other nodes running the original version of tinc:
Failed to decrypt and verify record from xxx (xx.yy.zz.qq port 655)
Failed to decrypt and verify record from yyy (xx.yy.zz.qq port 655)
…

So here's another solution. The context is initialized once and then duplicated each time it needs to be used. Seems to work fine.
I don't have a fast enough network to check everything properly, so here's a couple of dumb benchmarks running on a single machine:
reinit every time
[ ID] Interval           Transfer     Bitrate         Retr  Cwnd
[  5]   0.00-1.00   sec  35.0 MBytes   294 Mbits/sec   27    392 KBytes
[  5]   1.00-2.00   sec  32.5 MBytes   272 Mbits/sec    0    451 KBytes
[  5]   2.00-3.00   sec  33.8 MBytes   283 Mbits/sec    0    506 KBytes
[  5]   3.00-4.00   sec  33.8 MBytes   283 Mbits/sec    0    556 KBytes
[  5]   4.00-5.00   sec  35.0 MBytes   294 Mbits/sec    0    601 KBytes
[  5]   5.00-6.00   sec  45.0 MBytes   377 Mbits/sec    0    656 KBytes
[  5]   6.00-7.00   sec  45.0 MBytes   378 Mbits/sec    2    508 KBytes
[  5]   7.00-8.00   sec  45.0 MBytes   377 Mbits/sec    0    577 KBytes
[  5]   8.00-9.00   sec  43.8 MBytes   367 Mbits/sec    0    626 KBytes
[  5]   9.00-10.00  sec  45.0 MBytes   377 Mbits/sec    0    675 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-10.00  sec   394 MBytes   330 Mbits/sec   29             sender
[  5]   0.00-10.01  sec   392 MBytes   328 Mbits/sec                  receiver

duplicate
[ ID] Interval           Transfer     Bitrate         Retr  Cwnd
[  5]   0.00-1.00   sec  42.5 MBytes   356 Mbits/sec   96    687 KBytes
[  5]   1.00-2.00   sec  40.0 MBytes   336 Mbits/sec    6    537 KBytes
[  5]   2.00-3.00   sec  40.0 MBytes   336 Mbits/sec    0    591 KBytes
[  5]   3.00-4.00   sec  40.0 MBytes   336 Mbits/sec    0    643 KBytes
[  5]   4.00-5.00   sec  41.2 MBytes   346 Mbits/sec    6    474 KBytes
[  5]   5.00-6.00   sec  51.2 MBytes   430 Mbits/sec  139    556 KBytes
[  5]   6.00-7.00   sec  50.0 MBytes   419 Mbits/sec    9    440 KBytes
[  5]   7.00-8.00   sec  50.0 MBytes   419 Mbits/sec    0    522 KBytes
[  5]   8.00-9.00   sec  51.2 MBytes   430 Mbits/sec    0    591 KBytes
[  5]   9.00-10.00  sec  50.0 MBytes   419 Mbits/sec    0    653 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-10.00  sec   456 MBytes   383 Mbits/sec  256             sender
[  5]   0.00-10.01  sec   453 MBytes   380 Mbits/sec                  receiver

OpenSSL 1.1
[ ID] Interval           Transfer     Bitrate         Retr  Cwnd
[  5]   0.00-1.00   sec  40.6 MBytes   341 Mbits/sec   19    561 KBytes
[  5]   1.00-2.00   sec  38.8 MBytes   325 Mbits/sec    0    628 KBytes
[  5]   2.00-3.00   sec  38.8 MBytes   325 Mbits/sec    0    673 KBytes
[  5]   3.00-4.00   sec  37.5 MBytes   315 Mbits/sec    1    508 KBytes
[  5]   4.00-5.00   sec  40.0 MBytes   336 Mbits/sec    0    563 KBytes
[  5]   5.00-6.00   sec  50.0 MBytes   419 Mbits/sec    0    628 KBytes
[  5]   6.00-7.00   sec  48.8 MBytes   409 Mbits/sec    0    686 KBytes
[  5]   7.00-8.00   sec  50.0 MBytes   419 Mbits/sec    3    550 KBytes
[  5]   8.00-9.00   sec  50.0 MBytes   419 Mbits/sec    0    611 KBytes
[  5]   9.00-10.00  sec  50.0 MBytes   419 Mbits/sec    0    670 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-10.00  sec   444 MBytes   373 Mbits/sec   23             sender
[  5]   0.00-10.01  sec   442 MBytes   370 Mbits/sec                  receiver",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,354,2022-03-16T16:39:44Z,2022-03-20T18:23:33Z,2022-03-20T18:23:34Z,MERGED,True,406,97,12,https://github.com/hg,Add support for OpenSSL 3.0+,3,[],https://github.com/gsliepen/tinc/pull/354,https://github.com/hg,4,https://github.com/gsliepen/tinc/pull/354#issuecomment-1071040512,"This is an attempt to close #347.
Since this touches cryptography you might prefer to do the work yourself. I'm okay with that; this PR could be used as a starting point.
I tested it on one of the nodes in my 20-something node network. Seems to work fine.
Here's the official migration guide. It's not of much help, the information on how to use the new APIs has to be picked piecemeal in OpenSSL sources, manpages, and examples.","Cleaned up some of the copypasta. Not sure about rsa_public_encrypt() / rsa_private_decrypt(). They're exactly the same, except for the names of two functions they call. Should I extract common logic to this:
static bool rsa_encrypt_decrypt(rsa_t *rsa, const void *in, size_t len, void *out,
                                int (init)(EVP_PKEY_CTX *ctx),
                                int (process)(EVP_PKEY_CTX *ctx,
                                                unsigned char *out, size_t *outlen,
                                                const unsigned char *in, size_t inlen)
                               ) {
	EVP_PKEY_CTX *ctx = EVP_PKEY_CTX_new(rsa, NULL);

	if(ctx) {
		size_t outlen = len;

		bool ok = init(ctx) > 0
		          && EVP_PKEY_CTX_set_rsa_padding(ctx, RSA_NO_PADDING) > 0
		          && process(ctx, out, &outlen, in, len) > 0
		          && outlen == len;

		EVP_PKEY_CTX_free(ctx);

		if(ok) {
			return true;
		}
	}
}

// …
return rsa_encrypt_decrypt(rsa, in, len, out, EVP_PKEY_decrypt_init, EVP_PKEY_decrypt);

// …
return rsa_encrypt_decrypt(rsa, in, len, out, EVP_PKEY_encrypt_init, EVP_PKEY_encrypt);
or is it too much for your taste?
Same thing with cipher_encrypt() / cipher_decrypt().
I'm more used to working in higher-level languages where you wouldn't think twice about extracting common pieces and using such redirection.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,354,2022-03-16T16:39:44Z,2022-03-20T18:23:33Z,2022-03-20T18:23:34Z,MERGED,True,406,97,12,https://github.com/hg,Add support for OpenSSL 3.0+,3,[],https://github.com/gsliepen/tinc/pull/354,https://github.com/gsliepen,5,https://github.com/gsliepen/tinc/pull/354#issuecomment-1071289897,"This is an attempt to close #347.
Since this touches cryptography you might prefer to do the work yourself. I'm okay with that; this PR could be used as a starting point.
I tested it on one of the nodes in my 20-something node network. Seems to work fine.
Here's the official migration guide. It's not of much help, the information on how to use the new APIs has to be picked piecemeal in OpenSSL sources, manpages, and examples.","So here's another solution. The context is initialized once and then duplicated each time it needs to be used. Seems to work fine.

Well, it seems it has comparable performance to the old solution, so it's fine with me. Nice benchmarks!

Cleaned up some of the copypasta. Not sure about rsa_public_encrypt() / rsa_private_decrypt(). They're exactly the same, except for the names of two functions they call. Should I extract common logic to this: [...] or is it too much for your taste?

I'm fine with that, as long as code outside the openssl/ directory does not have to see any OpenSSL details. So if you make rsa_public_encrypt() and rsa_public_decrypt() wrapper functions that call rsa_encrypt_decrypt(), that's fine.

I'm more used to working in higher-level languages where you wouldn't think twice about extracting common pieces and using such redirection.

Yes, if I had a lot more time I would not hesitate spending it on rewriting tinc in C++ or Rust.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,354,2022-03-16T16:39:44Z,2022-03-20T18:23:33Z,2022-03-20T18:23:34Z,MERGED,True,406,97,12,https://github.com/hg,Add support for OpenSSL 3.0+,3,[],https://github.com/gsliepen/tinc/pull/354,https://github.com/hg,6,https://github.com/gsliepen/tinc/pull/354#issuecomment-1072484386,"This is an attempt to close #347.
Since this touches cryptography you might prefer to do the work yourself. I'm okay with that; this PR could be used as a starting point.
I tested it on one of the nodes in my 20-something node network. Seems to work fine.
Here's the official migration guide. It's not of much help, the information on how to use the new APIs has to be picked piecemeal in OpenSSL sources, manpages, and examples.","Thanks so much for putting your time in these reviews.
I cleaned up the remaining copypasta in src/openssl. There's not much difference in SLOC, but at least less logic is duplicated.

rewriting tinc in C++ or Rust

I thought about that, but didn't even dare to bring it up because it sounds like a sure way to lose at least some long-time users. If devices still rely on GCC 4.2, the Rust cross-compilation story there is probably nonexistent.
Looking at the official docs, the majority of targets that are important to tinc have these clauses:

not guaranteed to produce a working build
tier 2 targets often work to quite a good degree

It might just be Rust devs being very cautious with their wording, but it doesn't inspire much confidence.
C++ may actually be workable. GCC has (almost) full C++11 support since 4.8.1 (which is 9 years old), and the language lends itself to porting things slowly instead of doing full rewrites.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,355,2022-03-18T19:22:26Z,2022-03-23T06:32:44Z,2022-03-23T06:32:45Z,MERGED,True,1461,5488,107,https://github.com/hg,Change the build system to meson?,7,[],https://github.com/gsliepen/tinc/pull/355,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/355,"The PR is here mostly to have a better place for discussing the possible move (and so I don't lose the work again).
See history in #286 (which isn't really about meson).
CI is barely working, I'd prefer to finish it last if the change is agreed upon as it's a pain to maintain otherwise.

Running meson setup on freshly cloned source tree is pretty fast:
Fri, 18 Mar 2022 18:47:02 GMT # Running test flavor default
Fri, 18 Mar 2022 18:47:02 GMT ################################################################################
…
Fri, 18 Mar 2022 18:47:05 GMT ninja: entering directory 'build'
Fri, 18 Mar 2022 18:47:05 GMT [1/113] Compiling C object test/splice.p/splice.c.o

vs autotools:
Fri, 18 Mar 2022 14:49:08 GMT # Running test flavor default
Fri, 18 Mar 2022 14:49:08 GMT ################################################################################
…
Fri, 18 Mar 2022 14:49:19 GMT make[1]: Entering directory '/__w/tinc/tinc'

All in all it seems to save 20-50 seconds on each test run (autotools, meson).

Cross-compilation from Debian amd64 to mipsel and armhf requires these cross files:
[binaries]
c = 'arm-linux-gnueabihf-gcc'
pkgconfig = 'arm-linux-gnueabihf-pkg-config'
[binaries]
c = 'mipsel-linux-gnu-gcc'
pkgconfig = 'mipsel-linux-gnu-pkg-config'
or setting two environment variables (CC and PKG_CONFIG). Everything else is detected automatically.
So basically we have
$ CC=arm-linux-gnueabihf-gcc PKG_CONFIG=arm-linux-gnueabihf-pkg-config meson setup build --cross-file /dev/null

or
$ meson setup build --cross-file .ci/cross/armhf

vs current
$ ./configure --whatever --host=arm-linux-gnueabihf-pkg-config


I am not sure how to go about trying to cross-compile for Windows. mingw ships only a couple of prebuilt libraries. @gsliepen do you build everything from source?
I believe it requires a larger file, although it too can be written once and stored in the repository:
[binaries]
c = 'x86_64-w64-mingw32-gcc'
pkgconfig = 'x86_64-w64-mingw32-pkg-config'

[host_machine]
system = 'windows'
endian = 'little'
cpu = 'x86_64'
cpu_family = 'x86'
If your compiler is named differently, you can use the same file and override just the compiler with CC=xxx.","The PR is here mostly to have a better place for discussing the possible move (and so I don't lose the work again).
See history in #286 (which isn't really about meson).
CI is barely working, I'd prefer to finish it last if the change is agreed upon as it's a pain to maintain otherwise.

Running meson setup on freshly cloned source tree is pretty fast:
Fri, 18 Mar 2022 18:47:02 GMT # Running test flavor default
Fri, 18 Mar 2022 18:47:02 GMT ################################################################################
…
Fri, 18 Mar 2022 18:47:05 GMT ninja: entering directory 'build'
Fri, 18 Mar 2022 18:47:05 GMT [1/113] Compiling C object test/splice.p/splice.c.o

vs autotools:
Fri, 18 Mar 2022 14:49:08 GMT # Running test flavor default
Fri, 18 Mar 2022 14:49:08 GMT ################################################################################
…
Fri, 18 Mar 2022 14:49:19 GMT make[1]: Entering directory '/__w/tinc/tinc'

All in all it seems to save 20-50 seconds on each test run (autotools, meson).

Cross-compilation from Debian amd64 to mipsel and armhf requires these cross files:
[binaries]
c = 'arm-linux-gnueabihf-gcc'
pkgconfig = 'arm-linux-gnueabihf-pkg-config'
[binaries]
c = 'mipsel-linux-gnu-gcc'
pkgconfig = 'mipsel-linux-gnu-pkg-config'
or setting two environment variables (CC and PKG_CONFIG). Everything else is detected automatically.
So basically we have
$ CC=arm-linux-gnueabihf-gcc PKG_CONFIG=arm-linux-gnueabihf-pkg-config meson setup build --cross-file /dev/null

or
$ meson setup build --cross-file .ci/cross/armhf

vs current
$ ./configure --whatever --host=arm-linux-gnueabihf-pkg-config


I am not sure how to go about trying to cross-compile for Windows. mingw ships only a couple of prebuilt libraries. @gsliepen do you build everything from source?
I believe it requires a larger file, although it too can be written once and stored in the repository:
[binaries]
c = 'x86_64-w64-mingw32-gcc'
pkgconfig = 'x86_64-w64-mingw32-pkg-config'

[host_machine]
system = 'windows'
endian = 'little'
cpu = 'x86_64'
cpu_family = 'x86'
If your compiler is named differently, you can use the same file and override just the compiler with CC=xxx.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,355,2022-03-18T19:22:26Z,2022-03-23T06:32:44Z,2022-03-23T06:32:45Z,MERGED,True,1461,5488,107,https://github.com/hg,Change the build system to meson?,7,[],https://github.com/gsliepen/tinc/pull/355,https://github.com/gsliepen,2,https://github.com/gsliepen/tinc/pull/355#issuecomment-1072866165,"The PR is here mostly to have a better place for discussing the possible move (and so I don't lose the work again).
See history in #286 (which isn't really about meson).
CI is barely working, I'd prefer to finish it last if the change is agreed upon as it's a pain to maintain otherwise.

Running meson setup on freshly cloned source tree is pretty fast:
Fri, 18 Mar 2022 18:47:02 GMT # Running test flavor default
Fri, 18 Mar 2022 18:47:02 GMT ################################################################################
…
Fri, 18 Mar 2022 18:47:05 GMT ninja: entering directory 'build'
Fri, 18 Mar 2022 18:47:05 GMT [1/113] Compiling C object test/splice.p/splice.c.o

vs autotools:
Fri, 18 Mar 2022 14:49:08 GMT # Running test flavor default
Fri, 18 Mar 2022 14:49:08 GMT ################################################################################
…
Fri, 18 Mar 2022 14:49:19 GMT make[1]: Entering directory '/__w/tinc/tinc'

All in all it seems to save 20-50 seconds on each test run (autotools, meson).

Cross-compilation from Debian amd64 to mipsel and armhf requires these cross files:
[binaries]
c = 'arm-linux-gnueabihf-gcc'
pkgconfig = 'arm-linux-gnueabihf-pkg-config'
[binaries]
c = 'mipsel-linux-gnu-gcc'
pkgconfig = 'mipsel-linux-gnu-pkg-config'
or setting two environment variables (CC and PKG_CONFIG). Everything else is detected automatically.
So basically we have
$ CC=arm-linux-gnueabihf-gcc PKG_CONFIG=arm-linux-gnueabihf-pkg-config meson setup build --cross-file /dev/null

or
$ meson setup build --cross-file .ci/cross/armhf

vs current
$ ./configure --whatever --host=arm-linux-gnueabihf-pkg-config


I am not sure how to go about trying to cross-compile for Windows. mingw ships only a couple of prebuilt libraries. @gsliepen do you build everything from source?
I believe it requires a larger file, although it too can be written once and stored in the repository:
[binaries]
c = 'x86_64-w64-mingw32-gcc'
pkgconfig = 'x86_64-w64-mingw32-pkg-config'

[host_machine]
system = 'windows'
endian = 'little'
cpu = 'x86_64'
cpu_family = 'x86'
If your compiler is named differently, you can use the same file and override just the compiler with CC=xxx.","I am not sure how to go about trying to cross-compile for Windows. mingw ships only a couple of prebuilt libraries. @gsliepen do you build everything from source?

I managed with a cross file similar to the one you made for MinGW. I do build the dependencies from source, it's just making sure autotools/meson can find them.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,355,2022-03-18T19:22:26Z,2022-03-23T06:32:44Z,2022-03-23T06:32:45Z,MERGED,True,1461,5488,107,https://github.com/hg,Change the build system to meson?,7,[],https://github.com/gsliepen/tinc/pull/355,https://github.com/hg,3,https://github.com/gsliepen/tinc/pull/355#issuecomment-1073064065,"The PR is here mostly to have a better place for discussing the possible move (and so I don't lose the work again).
See history in #286 (which isn't really about meson).
CI is barely working, I'd prefer to finish it last if the change is agreed upon as it's a pain to maintain otherwise.

Running meson setup on freshly cloned source tree is pretty fast:
Fri, 18 Mar 2022 18:47:02 GMT # Running test flavor default
Fri, 18 Mar 2022 18:47:02 GMT ################################################################################
…
Fri, 18 Mar 2022 18:47:05 GMT ninja: entering directory 'build'
Fri, 18 Mar 2022 18:47:05 GMT [1/113] Compiling C object test/splice.p/splice.c.o

vs autotools:
Fri, 18 Mar 2022 14:49:08 GMT # Running test flavor default
Fri, 18 Mar 2022 14:49:08 GMT ################################################################################
…
Fri, 18 Mar 2022 14:49:19 GMT make[1]: Entering directory '/__w/tinc/tinc'

All in all it seems to save 20-50 seconds on each test run (autotools, meson).

Cross-compilation from Debian amd64 to mipsel and armhf requires these cross files:
[binaries]
c = 'arm-linux-gnueabihf-gcc'
pkgconfig = 'arm-linux-gnueabihf-pkg-config'
[binaries]
c = 'mipsel-linux-gnu-gcc'
pkgconfig = 'mipsel-linux-gnu-pkg-config'
or setting two environment variables (CC and PKG_CONFIG). Everything else is detected automatically.
So basically we have
$ CC=arm-linux-gnueabihf-gcc PKG_CONFIG=arm-linux-gnueabihf-pkg-config meson setup build --cross-file /dev/null

or
$ meson setup build --cross-file .ci/cross/armhf

vs current
$ ./configure --whatever --host=arm-linux-gnueabihf-pkg-config


I am not sure how to go about trying to cross-compile for Windows. mingw ships only a couple of prebuilt libraries. @gsliepen do you build everything from source?
I believe it requires a larger file, although it too can be written once and stored in the repository:
[binaries]
c = 'x86_64-w64-mingw32-gcc'
pkgconfig = 'x86_64-w64-mingw32-pkg-config'

[host_machine]
system = 'windows'
endian = 'little'
cpu = 'x86_64'
cpu_family = 'x86'
If your compiler is named differently, you can use the same file and override just the compiler with CC=xxx.","Windows is a pain, as usual. I look into fixing it next.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,355,2022-03-18T19:22:26Z,2022-03-23T06:32:44Z,2022-03-23T06:32:45Z,MERGED,True,1461,5488,107,https://github.com/hg,Change the build system to meson?,7,[],https://github.com/gsliepen/tinc/pull/355,https://github.com/hg,4,https://github.com/gsliepen/tinc/pull/355#issuecomment-1073920276,"The PR is here mostly to have a better place for discussing the possible move (and so I don't lose the work again).
See history in #286 (which isn't really about meson).
CI is barely working, I'd prefer to finish it last if the change is agreed upon as it's a pain to maintain otherwise.

Running meson setup on freshly cloned source tree is pretty fast:
Fri, 18 Mar 2022 18:47:02 GMT # Running test flavor default
Fri, 18 Mar 2022 18:47:02 GMT ################################################################################
…
Fri, 18 Mar 2022 18:47:05 GMT ninja: entering directory 'build'
Fri, 18 Mar 2022 18:47:05 GMT [1/113] Compiling C object test/splice.p/splice.c.o

vs autotools:
Fri, 18 Mar 2022 14:49:08 GMT # Running test flavor default
Fri, 18 Mar 2022 14:49:08 GMT ################################################################################
…
Fri, 18 Mar 2022 14:49:19 GMT make[1]: Entering directory '/__w/tinc/tinc'

All in all it seems to save 20-50 seconds on each test run (autotools, meson).

Cross-compilation from Debian amd64 to mipsel and armhf requires these cross files:
[binaries]
c = 'arm-linux-gnueabihf-gcc'
pkgconfig = 'arm-linux-gnueabihf-pkg-config'
[binaries]
c = 'mipsel-linux-gnu-gcc'
pkgconfig = 'mipsel-linux-gnu-pkg-config'
or setting two environment variables (CC and PKG_CONFIG). Everything else is detected automatically.
So basically we have
$ CC=arm-linux-gnueabihf-gcc PKG_CONFIG=arm-linux-gnueabihf-pkg-config meson setup build --cross-file /dev/null

or
$ meson setup build --cross-file .ci/cross/armhf

vs current
$ ./configure --whatever --host=arm-linux-gnueabihf-pkg-config


I am not sure how to go about trying to cross-compile for Windows. mingw ships only a couple of prebuilt libraries. @gsliepen do you build everything from source?
I believe it requires a larger file, although it too can be written once and stored in the repository:
[binaries]
c = 'x86_64-w64-mingw32-gcc'
pkgconfig = 'x86_64-w64-mingw32-pkg-config'

[host_machine]
system = 'windows'
endian = 'little'
cpu = 'x86_64'
cpu_family = 'x86'
If your compiler is named differently, you can use the same file and override just the compiler with CC=xxx.","I extracted some shared sources into separate static libraries, since it saves about a third of CPU time:
$ time ninja -C build
real	0m6.716s
user	0m21.727s
sys	0m2.651s

and after:
$ time ninja -C build
real	0m4.459s
user	0m14.399s
sys	0m1.838s

although the dependency tree is now less obvious.
If you'd rather keep it simple, I'll revert the change.

I'd like to restore Android build instructions in a separate PR a few days from now, as I currently don't have the means to download Android SDK (which is pretty large).

Edit: sorry for spamming with temporary commits, OpenBSD is being a bit of a PITA. If it doesn't start working soon I'll set it up locally and proceed there.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,355,2022-03-18T19:22:26Z,2022-03-23T06:32:44Z,2022-03-23T06:32:45Z,MERGED,True,1461,5488,107,https://github.com/hg,Change the build system to meson?,7,[],https://github.com/gsliepen/tinc/pull/355,https://github.com/hg,5,https://github.com/gsliepen/tinc/pull/355#issuecomment-1075052147,"The PR is here mostly to have a better place for discussing the possible move (and so I don't lose the work again).
See history in #286 (which isn't really about meson).
CI is barely working, I'd prefer to finish it last if the change is agreed upon as it's a pain to maintain otherwise.

Running meson setup on freshly cloned source tree is pretty fast:
Fri, 18 Mar 2022 18:47:02 GMT # Running test flavor default
Fri, 18 Mar 2022 18:47:02 GMT ################################################################################
…
Fri, 18 Mar 2022 18:47:05 GMT ninja: entering directory 'build'
Fri, 18 Mar 2022 18:47:05 GMT [1/113] Compiling C object test/splice.p/splice.c.o

vs autotools:
Fri, 18 Mar 2022 14:49:08 GMT # Running test flavor default
Fri, 18 Mar 2022 14:49:08 GMT ################################################################################
…
Fri, 18 Mar 2022 14:49:19 GMT make[1]: Entering directory '/__w/tinc/tinc'

All in all it seems to save 20-50 seconds on each test run (autotools, meson).

Cross-compilation from Debian amd64 to mipsel and armhf requires these cross files:
[binaries]
c = 'arm-linux-gnueabihf-gcc'
pkgconfig = 'arm-linux-gnueabihf-pkg-config'
[binaries]
c = 'mipsel-linux-gnu-gcc'
pkgconfig = 'mipsel-linux-gnu-pkg-config'
or setting two environment variables (CC and PKG_CONFIG). Everything else is detected automatically.
So basically we have
$ CC=arm-linux-gnueabihf-gcc PKG_CONFIG=arm-linux-gnueabihf-pkg-config meson setup build --cross-file /dev/null

or
$ meson setup build --cross-file .ci/cross/armhf

vs current
$ ./configure --whatever --host=arm-linux-gnueabihf-pkg-config


I am not sure how to go about trying to cross-compile for Windows. mingw ships only a couple of prebuilt libraries. @gsliepen do you build everything from source?
I believe it requires a larger file, although it too can be written once and stored in the repository:
[binaries]
c = 'x86_64-w64-mingw32-gcc'
pkgconfig = 'x86_64-w64-mingw32-pkg-config'

[host_machine]
system = 'windows'
endian = 'little'
cpu = 'x86_64'
cpu_family = 'x86'
If your compiler is named differently, you can use the same file and override just the compiler with CC=xxx.","I tried to test the Solaris build on current OmniOS (don't know how compatible they are really).
meson configures everything just fine, but code doesn't compile. Same with the 1.1 autotools branch. Some breakage seems to have accumulated since at least 7a54fe5.
I have zero experience with Solaris/Illumos. Maybe create an issue to restore support in case anyone knowledgeable is interested?

GitHub is having issues… again. A couple of CI jobs have failed because of that.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,355,2022-03-18T19:22:26Z,2022-03-23T06:32:44Z,2022-03-23T06:32:45Z,MERGED,True,1461,5488,107,https://github.com/hg,Change the build system to meson?,7,[],https://github.com/gsliepen/tinc/pull/355,https://github.com/gsliepen,6,https://github.com/gsliepen/tinc/pull/355#issuecomment-1075502085,"The PR is here mostly to have a better place for discussing the possible move (and so I don't lose the work again).
See history in #286 (which isn't really about meson).
CI is barely working, I'd prefer to finish it last if the change is agreed upon as it's a pain to maintain otherwise.

Running meson setup on freshly cloned source tree is pretty fast:
Fri, 18 Mar 2022 18:47:02 GMT # Running test flavor default
Fri, 18 Mar 2022 18:47:02 GMT ################################################################################
…
Fri, 18 Mar 2022 18:47:05 GMT ninja: entering directory 'build'
Fri, 18 Mar 2022 18:47:05 GMT [1/113] Compiling C object test/splice.p/splice.c.o

vs autotools:
Fri, 18 Mar 2022 14:49:08 GMT # Running test flavor default
Fri, 18 Mar 2022 14:49:08 GMT ################################################################################
…
Fri, 18 Mar 2022 14:49:19 GMT make[1]: Entering directory '/__w/tinc/tinc'

All in all it seems to save 20-50 seconds on each test run (autotools, meson).

Cross-compilation from Debian amd64 to mipsel and armhf requires these cross files:
[binaries]
c = 'arm-linux-gnueabihf-gcc'
pkgconfig = 'arm-linux-gnueabihf-pkg-config'
[binaries]
c = 'mipsel-linux-gnu-gcc'
pkgconfig = 'mipsel-linux-gnu-pkg-config'
or setting two environment variables (CC and PKG_CONFIG). Everything else is detected automatically.
So basically we have
$ CC=arm-linux-gnueabihf-gcc PKG_CONFIG=arm-linux-gnueabihf-pkg-config meson setup build --cross-file /dev/null

or
$ meson setup build --cross-file .ci/cross/armhf

vs current
$ ./configure --whatever --host=arm-linux-gnueabihf-pkg-config


I am not sure how to go about trying to cross-compile for Windows. mingw ships only a couple of prebuilt libraries. @gsliepen do you build everything from source?
I believe it requires a larger file, although it too can be written once and stored in the repository:
[binaries]
c = 'x86_64-w64-mingw32-gcc'
pkgconfig = 'x86_64-w64-mingw32-pkg-config'

[host_machine]
system = 'windows'
endian = 'little'
cpu = 'x86_64'
cpu_family = 'x86'
If your compiler is named differently, you can use the same file and override just the compiler with CC=xxx.","I tried to test the Solaris build on current OmniOS (don't know how compatible they are really).
meson configures everything just fine, but code doesn't compile. Same with the 1.1 autotools branch. Some breakage seems to have accumulated since at least 7a54fe5.
I have zero experience with Solaris/Illumos. Maybe create an issue to restore support in case anyone knowledgeable is interested?

I just tried it with OpenIndiana, and it is so frustrating that it makes me want to throw my computer out of the window, even though it's just running in a VM. I think I will just remove Solaris support unless someone steps up to maintain it. So unless you really want to, don't spend any more effort on this.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,355,2022-03-18T19:22:26Z,2022-03-23T06:32:44Z,2022-03-23T06:32:45Z,MERGED,True,1461,5488,107,https://github.com/hg,Change the build system to meson?,7,[],https://github.com/gsliepen/tinc/pull/355,https://github.com/hg,7,https://github.com/gsliepen/tinc/pull/355#issuecomment-1075524490,"The PR is here mostly to have a better place for discussing the possible move (and so I don't lose the work again).
See history in #286 (which isn't really about meson).
CI is barely working, I'd prefer to finish it last if the change is agreed upon as it's a pain to maintain otherwise.

Running meson setup on freshly cloned source tree is pretty fast:
Fri, 18 Mar 2022 18:47:02 GMT # Running test flavor default
Fri, 18 Mar 2022 18:47:02 GMT ################################################################################
…
Fri, 18 Mar 2022 18:47:05 GMT ninja: entering directory 'build'
Fri, 18 Mar 2022 18:47:05 GMT [1/113] Compiling C object test/splice.p/splice.c.o

vs autotools:
Fri, 18 Mar 2022 14:49:08 GMT # Running test flavor default
Fri, 18 Mar 2022 14:49:08 GMT ################################################################################
…
Fri, 18 Mar 2022 14:49:19 GMT make[1]: Entering directory '/__w/tinc/tinc'

All in all it seems to save 20-50 seconds on each test run (autotools, meson).

Cross-compilation from Debian amd64 to mipsel and armhf requires these cross files:
[binaries]
c = 'arm-linux-gnueabihf-gcc'
pkgconfig = 'arm-linux-gnueabihf-pkg-config'
[binaries]
c = 'mipsel-linux-gnu-gcc'
pkgconfig = 'mipsel-linux-gnu-pkg-config'
or setting two environment variables (CC and PKG_CONFIG). Everything else is detected automatically.
So basically we have
$ CC=arm-linux-gnueabihf-gcc PKG_CONFIG=arm-linux-gnueabihf-pkg-config meson setup build --cross-file /dev/null

or
$ meson setup build --cross-file .ci/cross/armhf

vs current
$ ./configure --whatever --host=arm-linux-gnueabihf-pkg-config


I am not sure how to go about trying to cross-compile for Windows. mingw ships only a couple of prebuilt libraries. @gsliepen do you build everything from source?
I believe it requires a larger file, although it too can be written once and stored in the repository:
[binaries]
c = 'x86_64-w64-mingw32-gcc'
pkgconfig = 'x86_64-w64-mingw32-pkg-config'

[host_machine]
system = 'windows'
endian = 'little'
cpu = 'x86_64'
cpu_family = 'x86'
If your compiler is named differently, you can use the same file and override just the compiler with CC=xxx.","I could have a look at Solaris after this PR and unit tests are in. At first glance OmniOS didn't seem much different from your average BSD, and it has some nice ideas: IIUC, it takes ZFS snapshots when you install software.
If code is unfixable, it won't take much time to remove it.
Although it'll probably bitrot again. There doesn't seem to be any public CI service that gives access to anything based on OpenSolaris, unless someone is willing to maintain their own OS images.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,355,2022-03-18T19:22:26Z,2022-03-23T06:32:44Z,2022-03-23T06:32:45Z,MERGED,True,1461,5488,107,https://github.com/hg,Change the build system to meson?,7,[],https://github.com/gsliepen/tinc/pull/355,https://github.com/hg,8,https://github.com/gsliepen/tinc/pull/355#issuecomment-1075957770,"The PR is here mostly to have a better place for discussing the possible move (and so I don't lose the work again).
See history in #286 (which isn't really about meson).
CI is barely working, I'd prefer to finish it last if the change is agreed upon as it's a pain to maintain otherwise.

Running meson setup on freshly cloned source tree is pretty fast:
Fri, 18 Mar 2022 18:47:02 GMT # Running test flavor default
Fri, 18 Mar 2022 18:47:02 GMT ################################################################################
…
Fri, 18 Mar 2022 18:47:05 GMT ninja: entering directory 'build'
Fri, 18 Mar 2022 18:47:05 GMT [1/113] Compiling C object test/splice.p/splice.c.o

vs autotools:
Fri, 18 Mar 2022 14:49:08 GMT # Running test flavor default
Fri, 18 Mar 2022 14:49:08 GMT ################################################################################
…
Fri, 18 Mar 2022 14:49:19 GMT make[1]: Entering directory '/__w/tinc/tinc'

All in all it seems to save 20-50 seconds on each test run (autotools, meson).

Cross-compilation from Debian amd64 to mipsel and armhf requires these cross files:
[binaries]
c = 'arm-linux-gnueabihf-gcc'
pkgconfig = 'arm-linux-gnueabihf-pkg-config'
[binaries]
c = 'mipsel-linux-gnu-gcc'
pkgconfig = 'mipsel-linux-gnu-pkg-config'
or setting two environment variables (CC and PKG_CONFIG). Everything else is detected automatically.
So basically we have
$ CC=arm-linux-gnueabihf-gcc PKG_CONFIG=arm-linux-gnueabihf-pkg-config meson setup build --cross-file /dev/null

or
$ meson setup build --cross-file .ci/cross/armhf

vs current
$ ./configure --whatever --host=arm-linux-gnueabihf-pkg-config


I am not sure how to go about trying to cross-compile for Windows. mingw ships only a couple of prebuilt libraries. @gsliepen do you build everything from source?
I believe it requires a larger file, although it too can be written once and stored in the repository:
[binaries]
c = 'x86_64-w64-mingw32-gcc'
pkgconfig = 'x86_64-w64-mingw32-pkg-config'

[host_machine]
system = 'windows'
endian = 'little'
cpu = 'x86_64'
cpu_family = 'x86'
If your compiler is named differently, you can use the same file and override just the compiler with CC=xxx.",Full diff.,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,356,2022-03-23T15:45:21Z,2022-03-27T18:44:22Z,2022-03-27T18:44:22Z,MERGED,True,44,15,6,https://github.com/hg,Restore Solaris support,1,[],https://github.com/gsliepen/tinc/pull/356,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/356,"scripts.test is disabled on Solaris because it reliably produces somewhat different line ordering:
$ diff scripts.test.1/scripts.out scripts.test.1/scripts.out.expected
12d11
< bar-started-1
13a13
> bar-started-1
16d15
< bar-stopped
18a18
> bar-stopped
21d20
< bar-started-2
23a23
> bar-started-2

It's probably not worth it to spend any time on this. It was fun enough making it work on NetBSD — you adjust a couple of things, tests start passing there and failing everywhere else.
I also don't think it's possible to make tests work on native shell tools. For example, grep misses support for an important flag (-m) and doesn't provide any alternatives.
Thankfully the system I'm using has GNU coreutils preinstalled.
$ uname -a
SunOS omnios 5.11 omnios-r151040-d75907718a i86pc i386 i86pc


Did a bit of debugging. Looks like tail sometimes loses its position within a file when you append to it, and starts from the beginning. This makes wait_script completely useless. I haven't seen this behavior anywhere else.","scripts.test is disabled on Solaris because it reliably produces somewhat different line ordering:
$ diff scripts.test.1/scripts.out scripts.test.1/scripts.out.expected
12d11
< bar-started-1
13a13
> bar-started-1
16d15
< bar-stopped
18a18
> bar-stopped
21d20
< bar-started-2
23a23
> bar-started-2

It's probably not worth it to spend any time on this. It was fun enough making it work on NetBSD — you adjust a couple of things, tests start passing there and failing everywhere else.
I also don't think it's possible to make tests work on native shell tools. For example, grep misses support for an important flag (-m) and doesn't provide any alternatives.
Thankfully the system I'm using has GNU coreutils preinstalled.
$ uname -a
SunOS omnios 5.11 omnios-r151040-d75907718a i86pc i386 i86pc


Did a bit of debugging. Looks like tail sometimes loses its position within a file when you append to it, and starts from the beginning. This makes wait_script completely useless. I haven't seen this behavior anywhere else.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,357,2022-03-25T17:41:21Z,2022-03-28T21:18:55Z,2022-04-07T04:17:48Z,MERGED,True,1662,323,75,https://github.com/hg,Add support for building with MSVC,9,[],https://github.com/gsliepen/tinc/pull/357,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/357,"Integration tests are disabled because of their dependence on Unix-like environment.
Project version will either have to be updated manually from now on, or you could start using tags without the release- prefix (then let me know and I'll update meson.build). We need'release-1.18'.replace('release-', '') to work, which only became available in 0.58, and you can't check what OS you're building for before project() is finished, so there's no way to ship an alternative script for Windows.
All compiler attributes are ignored for now, except for packed. I just realized we're checking for attribute support, but not doing anything with that information (same thing was happening with autotools). I think it's best to fix this in a separate PR.

mac had a random failure. NetBSD looks suspicious. I'll test it more locally.","Integration tests are disabled because of their dependence on Unix-like environment.
Project version will either have to be updated manually from now on, or you could start using tags without the release- prefix (then let me know and I'll update meson.build). We need'release-1.18'.replace('release-', '') to work, which only became available in 0.58, and you can't check what OS you're building for before project() is finished, so there's no way to ship an alternative script for Windows.
All compiler attributes are ignored for now, except for packed. I just realized we're checking for attribute support, but not doing anything with that information (same thing was happening with autotools). I think it's best to fix this in a separate PR.

mac had a random failure. NetBSD looks suspicious. I'll test it more locally.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,357,2022-03-25T17:41:21Z,2022-03-28T21:18:55Z,2022-04-07T04:17:48Z,MERGED,True,1662,323,75,https://github.com/hg,Add support for building with MSVC,9,[],https://github.com/gsliepen/tinc/pull/357,https://github.com/eli-schwartz,2,https://github.com/gsliepen/tinc/pull/357#issuecomment-1079293305,"Integration tests are disabled because of their dependence on Unix-like environment.
Project version will either have to be updated manually from now on, or you could start using tags without the release- prefix (then let me know and I'll update meson.build). We need'release-1.18'.replace('release-', '') to work, which only became available in 0.58, and you can't check what OS you're building for before project() is finished, so there's no way to ship an alternative script for Windows.
All compiler attributes are ignored for now, except for packed. I just realized we're checking for attribute support, but not doing anything with that information (same thing was happening with autotools). I think it's best to fix this in a separate PR.

mac had a random failure. NetBSD looks suspicious. I'll test it more locally.","and you can't check what OS you're building for before project() is finished, so there's no way to ship an alternative script for Windows.

You don't need a batch file on Windows and a shell script on unix.
You could use a python script on both, relying on the fact that Meson itself is written in python and can use that as a fallback to run the script.",True,"{'THUMBS_UP': ['https://github.com/hg', 'https://github.com/gsliepen']}"
gsliepen/tinc,https://github.com/gsliepen/tinc,357,2022-03-25T17:41:21Z,2022-03-28T21:18:55Z,2022-04-07T04:17:48Z,MERGED,True,1662,323,75,https://github.com/hg,Add support for building with MSVC,9,[],https://github.com/gsliepen/tinc/pull/357,https://github.com/hg,3,https://github.com/gsliepen/tinc/pull/357#issuecomment-1079304767,"Integration tests are disabled because of their dependence on Unix-like environment.
Project version will either have to be updated manually from now on, or you could start using tags without the release- prefix (then let me know and I'll update meson.build). We need'release-1.18'.replace('release-', '') to work, which only became available in 0.58, and you can't check what OS you're building for before project() is finished, so there's no way to ship an alternative script for Windows.
All compiler attributes are ignored for now, except for packed. I just realized we're checking for attribute support, but not doing anything with that information (same thing was happening with autotools). I think it's best to fix this in a separate PR.

mac had a random failure. NetBSD looks suspicious. I'll test it more locally.","Turns out you can just call the script and meson will wire everything up, even if there's no python in your %PATH%. I was expecting the opposite for some reason. Thank you, @eli-schwartz.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,357,2022-03-25T17:41:21Z,2022-03-28T21:18:55Z,2022-04-07T04:17:48Z,MERGED,True,1662,323,75,https://github.com/hg,Add support for building with MSVC,9,[],https://github.com/gsliepen/tinc/pull/357,https://github.com/hg,4,https://github.com/gsliepen/tinc/pull/357#issuecomment-1080009085,"Integration tests are disabled because of their dependence on Unix-like environment.
Project version will either have to be updated manually from now on, or you could start using tags without the release- prefix (then let me know and I'll update meson.build). We need'release-1.18'.replace('release-', '') to work, which only became available in 0.58, and you can't check what OS you're building for before project() is finished, so there's no way to ship an alternative script for Windows.
All compiler attributes are ignored for now, except for packed. I just realized we're checking for attribute support, but not doing anything with that information (same thing was happening with autotools). I think it's best to fix this in a separate PR.

mac had a random failure. NetBSD looks suspicious. I'll test it more locally.","After further testing on mac, this seems to be a random failure. They happen much more frequently on mac than on other operating systems. Since tests are being rewritten anyway, we'll see if it continues (maybe it's a bug in tinc then).",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,357,2022-03-25T17:41:21Z,2022-03-28T21:18:55Z,2022-04-07T04:17:48Z,MERGED,True,1662,323,75,https://github.com/hg,Add support for building with MSVC,9,[],https://github.com/gsliepen/tinc/pull/357,https://github.com/gsliepen,5,https://github.com/gsliepen/tinc/pull/357#issuecomment-1080017539,"Integration tests are disabled because of their dependence on Unix-like environment.
Project version will either have to be updated manually from now on, or you could start using tags without the release- prefix (then let me know and I'll update meson.build). We need'release-1.18'.replace('release-', '') to work, which only became available in 0.58, and you can't check what OS you're building for before project() is finished, so there's no way to ship an alternative script for Windows.
All compiler attributes are ignored for now, except for packed. I just realized we're checking for attribute support, but not doing anything with that information (same thing was happening with autotools). I think it's best to fix this in a separate PR.

mac had a random failure. NetBSD looks suspicious. I'll test it more locally.",I want to see if I can rewrite security.test and legacy-protocol.test anyway; they take much longer to run than the other tests. Currently they rely a lot on timing.,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,357,2022-03-25T17:41:21Z,2022-03-28T21:18:55Z,2022-04-07T04:17:48Z,MERGED,True,1662,323,75,https://github.com/hg,Add support for building with MSVC,9,[],https://github.com/gsliepen/tinc/pull/357,https://github.com/hg,6,https://github.com/gsliepen/tinc/pull/357#issuecomment-1080266808,"Integration tests are disabled because of their dependence on Unix-like environment.
Project version will either have to be updated manually from now on, or you could start using tags without the release- prefix (then let me know and I'll update meson.build). We need'release-1.18'.replace('release-', '') to work, which only became available in 0.58, and you can't check what OS you're building for before project() is finished, so there's no way to ship an alternative script for Windows.
All compiler attributes are ignored for now, except for packed. I just realized we're checking for attribute support, but not doing anything with that information (same thing was happening with autotools). I think it's best to fix this in a separate PR.

mac had a random failure. NetBSD looks suspicious. I'll test it more locally.","We probably can't get rid of packed because of Windows, unless I'm doing something wrong again: msvc, gcc.
The change in question.
I'll look into it more a bit later.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,359,2022-03-30T13:53:10Z,2022-03-31T05:43:27Z,2022-03-31T05:43:27Z,MERGED,True,14,3,2,https://github.com/hg,version.py: fall back to a version file if git directory is missing,1,[],https://github.com/gsliepen/tinc/pull/359,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/359,"We first try to get the git tag if .git directory is present. git is forced to look in the source tree and not go above it in case tinc's source is located inside another git repository.
If this fails, we read the VERSION file.
If that fails, we fall back to unknown.
The file will have to be updated manually. I can adjust the script to update the file automatically if it's called by the user (and not by meson), this is easy to do by looking at environment variables.
This should fix #358.","We first try to get the git tag if .git directory is present. git is forced to look in the source tree and not go above it in case tinc's source is located inside another git repository.
If this fails, we read the VERSION file.
If that fails, we fall back to unknown.
The file will have to be updated manually. I can adjust the script to update the file automatically if it's called by the user (and not by meson), this is easy to do by looking at environment variables.
This should fix #358.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,359,2022-03-30T13:53:10Z,2022-03-31T05:43:27Z,2022-03-31T05:43:27Z,MERGED,True,14,3,2,https://github.com/hg,version.py: fall back to a version file if git directory is missing,1,[],https://github.com/gsliepen/tinc/pull/359,https://github.com/gsliepen,2,https://github.com/gsliepen/tinc/pull/359#issuecomment-1083617312,"We first try to get the git tag if .git directory is present. git is forced to look in the source tree and not go above it in case tinc's source is located inside another git repository.
If this fails, we read the VERSION file.
If that fails, we fall back to unknown.
The file will have to be updated manually. I can adjust the script to update the file automatically if it's called by the user (and not by meson), this is easy to do by looking at environment variables.
This should fix #358.","It's not correct. If I try to build tinc without a .git/ directory, I get this error:
/tmp/tinc-1.1> meson build
[...]
/tmp/tinc-1.1> ninja -C build
ninja: Entering directory `build'
[29/95] Generating src/include/version_git.h with a custom command
fatal: not a git repository: '/tmp/tinc-1.1/src/include/.git'
could not read version from file [Errno 2] No such file or directory: '/tmp/tinc-1.1/src/include/VERSION'
[95/95] Linking target src/tinc",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,359,2022-03-30T13:53:10Z,2022-03-31T05:43:27Z,2022-03-31T05:43:27Z,MERGED,True,14,3,2,https://github.com/hg,version.py: fall back to a version file if git directory is missing,1,[],https://github.com/gsliepen/tinc/pull/359,https://github.com/hg,3,https://github.com/gsliepen/tinc/pull/359#issuecomment-1084094927,"We first try to get the git tag if .git directory is present. git is forced to look in the source tree and not go above it in case tinc's source is located inside another git repository.
If this fails, we read the VERSION file.
If that fails, we fall back to unknown.
The file will have to be updated manually. I can adjust the script to update the file automatically if it's called by the user (and not by meson), this is easy to do by looking at environment variables.
This should fix #358.","Oops, sorry. I forgot the source was located inside another repository. Should be fine now.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,360,2022-03-31T21:04:43Z,,2022-05-29T16:06:12Z,OPEN,False,1247,564,23,https://github.com/gsliepen,Add AES-256-GCM support to the new protocol,10,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/360,https://github.com/gsliepen,1,https://github.com/gsliepen/tinc/pull/360,,,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,362,2022-04-06T19:33:49Z,2022-04-10T09:56:56Z,2022-04-10T09:56:56Z,MERGED,True,3363,2171,78,https://github.com/hg,Rewrite tests in Python for better OS compatibility,5,[],https://github.com/gsliepen/tinc/pull/362,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/362,"These depend only on the standard library of Python 3.6 or later (used by RHEL 7; other distributions have newer versions). If system Python is missing, it falls back to the one used by meson.
Tests are using a somewhat different approach compared to the current suite. There are no hardcoded ports and Port 0 is used everywhere, but now we have to do the dance of starting nodes in a particular order and parsing their pidfiles to know the real port they listen on.
You have to pay more attention when writing tests, but it's the only reliable solution I could find from extensively testing a dozen ideas that allows us to keep full parallel test execution.

  Some other things that were tried

hardcoding port numbers, like in the current test suite — forces you to run all tests serially, or drop support for --repeat (which I don't think is possible to disable, so it's just something you have to know about); and there can still be conflicts with other software.
generating random ports using random.randint() with shared port range for all tests (1024 to 65535) — tolerable when running 4 tests in parallel, unusable with 16 or more.
same, but splitting it into smaller unique ranges, one for each test (slightly better than the previous one, not worth it).
same, but using hacks to try to exclude ports typically used for connect() (hopefully less conflicts with ""client"" ports, not much difference in practice).
binding a throwaway socket to port 0 and letting the OS choose a port, then binding tincd to that port (significantly more conflicts than trying ports randomly, Linux seems to use a very short port range, and further halves it to leave the other half for ""client"" ports, and this really shows in practice).
using random ports and binding tincd to randomly generated addresses in 127.0.0.0/8 — good stability and clear test code, but requires configuring the system on everything that's not Linux or Windows.
using a separate server which can be asked by test scripts to pick a port using one of the previous methods (so port allocation happens in a single place instead of spreading it throughout tests — it can make sure it doesn't give the same port twice) — not bad in practice, but is so convoluted I didn't push it past a simple prototype.
locking each test on a separate lock file to prevent it from running multiple copies in parallel.
and a few other hacks.


If you'd rather keep tests simpler, I don't see any other solution than to disable parallel test execution completely on everything other than Linux and Windows (where we can use the full subnet 127.0.0.0/8 and randomly generate both addresses for ListenAddress and ports for Port), or write an alternative test harness that doesn't run the same test multiple times in parallel (you can't disable this with meson).
Basic architecture
I intentionally kept things simple so there are fewer layers to unwrap if it gets in the way in more complicated tests.

meson starts the test script
test imports the required pieces of the testing library
it starts a notification server which receives event notifications from tincd scripts (the same idea we had in the old test suite, but here it's using UNIX sockets/Windows pipes instead of tail + grep)
you create a test context (a class named Test), and use it to get instances of a class named Tinc (the context remembers Tincs it has issued and uses them as described below)
you initialize the nodes using that Tinc (it's a thin wrapper around subprocess), and start issuing commands to them using one of these methods:

tinc() — start tinc with the specified arguments and return Popen
tincd() — same, but for tincd
cmd() — a convenience wrapper around tinc() which can pass text snippets into stdin, checks the return code for you, and returns (stdout, stderr)
and a few more, it's all commented.


when a test context exits (leaves the with statement), it stops every tinc and tincd started from it, and kills everything that refuses to stop.

If you initialize instances of the Tinc class directly, they won't be stopped automatically.
Tinc can also register tincd scripts and returns objects that let you wait on notifications from those scripts. Only one event is needed now (and thus only one is supported), but it's easy to add more.
There are some assertions (which should be used instead of the built-in assert because it doesn't print values on failure), a global logger, and a few helper functions for more complicated commands like exchange so the logic isn't repeated in several places.
Known issues
scripts.py
Port checks were dumbed down to checking that a non-empty value was passed. tincd on Windows behaves really strange with dynamically allocated ports on both sides of the connection, and I couldn't make it work after wasting half a day on it.
We have three choices here:

disable this test on Windows
use randomly generated port instead of Port 0 (and get intermittent test failures because of port conflicts)
keep the current basic check.

I don't think any other test functionality was lost. invite-offline.test and invite-online.test are rolled into invite.py.
Crashes on Alpine
Example.
SIGSEGV in a Python process that's running the test. Since there's no unsafe code in tests, I suspect this is because of musl.
These are pretty rare, just wanted you to be aware of them.
Failures on macOS
Same issue we have with the current test suite:
Cannot read greeting from control socket: No such file or directory

although tinc should definitely be able to connect to tincd because it is only started after we get a go-ahead from tinc-up.

https://github.com/hg/tinc/runs/5807386977?check_suite_focus=true#step:6:51533
https://github.com/hg/tinc/runs/5806692838?check_suite_focus=true#step:6:48233

So it's likely a tinc bug. I don't have access to macOS, and it's not easy to trigger to debug on CI machines. Can't help much here.

c1c5263 is a quick and dirty fix for #361. Don't pay much attention to it. I'll look into it while you're reviewing tests.","These depend only on the standard library of Python 3.6 or later (used by RHEL 7; other distributions have newer versions). If system Python is missing, it falls back to the one used by meson.
Tests are using a somewhat different approach compared to the current suite. There are no hardcoded ports and Port 0 is used everywhere, but now we have to do the dance of starting nodes in a particular order and parsing their pidfiles to know the real port they listen on.
You have to pay more attention when writing tests, but it's the only reliable solution I could find from extensively testing a dozen ideas that allows us to keep full parallel test execution.

  Some other things that were tried

hardcoding port numbers, like in the current test suite — forces you to run all tests serially, or drop support for --repeat (which I don't think is possible to disable, so it's just something you have to know about); and there can still be conflicts with other software.
generating random ports using random.randint() with shared port range for all tests (1024 to 65535) — tolerable when running 4 tests in parallel, unusable with 16 or more.
same, but splitting it into smaller unique ranges, one for each test (slightly better than the previous one, not worth it).
same, but using hacks to try to exclude ports typically used for connect() (hopefully less conflicts with ""client"" ports, not much difference in practice).
binding a throwaway socket to port 0 and letting the OS choose a port, then binding tincd to that port (significantly more conflicts than trying ports randomly, Linux seems to use a very short port range, and further halves it to leave the other half for ""client"" ports, and this really shows in practice).
using random ports and binding tincd to randomly generated addresses in 127.0.0.0/8 — good stability and clear test code, but requires configuring the system on everything that's not Linux or Windows.
using a separate server which can be asked by test scripts to pick a port using one of the previous methods (so port allocation happens in a single place instead of spreading it throughout tests — it can make sure it doesn't give the same port twice) — not bad in practice, but is so convoluted I didn't push it past a simple prototype.
locking each test on a separate lock file to prevent it from running multiple copies in parallel.
and a few other hacks.


If you'd rather keep tests simpler, I don't see any other solution than to disable parallel test execution completely on everything other than Linux and Windows (where we can use the full subnet 127.0.0.0/8 and randomly generate both addresses for ListenAddress and ports for Port), or write an alternative test harness that doesn't run the same test multiple times in parallel (you can't disable this with meson).
Basic architecture
I intentionally kept things simple so there are fewer layers to unwrap if it gets in the way in more complicated tests.

meson starts the test script
test imports the required pieces of the testing library
it starts a notification server which receives event notifications from tincd scripts (the same idea we had in the old test suite, but here it's using UNIX sockets/Windows pipes instead of tail + grep)
you create a test context (a class named Test), and use it to get instances of a class named Tinc (the context remembers Tincs it has issued and uses them as described below)
you initialize the nodes using that Tinc (it's a thin wrapper around subprocess), and start issuing commands to them using one of these methods:

tinc() — start tinc with the specified arguments and return Popen
tincd() — same, but for tincd
cmd() — a convenience wrapper around tinc() which can pass text snippets into stdin, checks the return code for you, and returns (stdout, stderr)
and a few more, it's all commented.


when a test context exits (leaves the with statement), it stops every tinc and tincd started from it, and kills everything that refuses to stop.

If you initialize instances of the Tinc class directly, they won't be stopped automatically.
Tinc can also register tincd scripts and returns objects that let you wait on notifications from those scripts. Only one event is needed now (and thus only one is supported), but it's easy to add more.
There are some assertions (which should be used instead of the built-in assert because it doesn't print values on failure), a global logger, and a few helper functions for more complicated commands like exchange so the logic isn't repeated in several places.
Known issues
scripts.py
Port checks were dumbed down to checking that a non-empty value was passed. tincd on Windows behaves really strange with dynamically allocated ports on both sides of the connection, and I couldn't make it work after wasting half a day on it.
We have three choices here:

disable this test on Windows
use randomly generated port instead of Port 0 (and get intermittent test failures because of port conflicts)
keep the current basic check.

I don't think any other test functionality was lost. invite-offline.test and invite-online.test are rolled into invite.py.
Crashes on Alpine
Example.
SIGSEGV in a Python process that's running the test. Since there's no unsafe code in tests, I suspect this is because of musl.
These are pretty rare, just wanted you to be aware of them.
Failures on macOS
Same issue we have with the current test suite:
Cannot read greeting from control socket: No such file or directory

although tinc should definitely be able to connect to tincd because it is only started after we get a go-ahead from tinc-up.

https://github.com/hg/tinc/runs/5807386977?check_suite_focus=true#step:6:51533
https://github.com/hg/tinc/runs/5806692838?check_suite_focus=true#step:6:48233

So it's likely a tinc bug. I don't have access to macOS, and it's not easy to trigger to debug on CI machines. Can't help much here.

c1c5263 is a quick and dirty fix for #361. Don't pay much attention to it. I'll look into it while you're reviewing tests.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,362,2022-04-06T19:33:49Z,2022-04-10T09:56:56Z,2022-04-10T09:56:56Z,MERGED,True,3363,2171,78,https://github.com/hg,Rewrite tests in Python for better OS compatibility,5,[],https://github.com/gsliepen/tinc/pull/362,https://github.com/hg,2,https://github.com/gsliepen/tinc/pull/362#issuecomment-1091183019,"These depend only on the standard library of Python 3.6 or later (used by RHEL 7; other distributions have newer versions). If system Python is missing, it falls back to the one used by meson.
Tests are using a somewhat different approach compared to the current suite. There are no hardcoded ports and Port 0 is used everywhere, but now we have to do the dance of starting nodes in a particular order and parsing their pidfiles to know the real port they listen on.
You have to pay more attention when writing tests, but it's the only reliable solution I could find from extensively testing a dozen ideas that allows us to keep full parallel test execution.

  Some other things that were tried

hardcoding port numbers, like in the current test suite — forces you to run all tests serially, or drop support for --repeat (which I don't think is possible to disable, so it's just something you have to know about); and there can still be conflicts with other software.
generating random ports using random.randint() with shared port range for all tests (1024 to 65535) — tolerable when running 4 tests in parallel, unusable with 16 or more.
same, but splitting it into smaller unique ranges, one for each test (slightly better than the previous one, not worth it).
same, but using hacks to try to exclude ports typically used for connect() (hopefully less conflicts with ""client"" ports, not much difference in practice).
binding a throwaway socket to port 0 and letting the OS choose a port, then binding tincd to that port (significantly more conflicts than trying ports randomly, Linux seems to use a very short port range, and further halves it to leave the other half for ""client"" ports, and this really shows in practice).
using random ports and binding tincd to randomly generated addresses in 127.0.0.0/8 — good stability and clear test code, but requires configuring the system on everything that's not Linux or Windows.
using a separate server which can be asked by test scripts to pick a port using one of the previous methods (so port allocation happens in a single place instead of spreading it throughout tests — it can make sure it doesn't give the same port twice) — not bad in practice, but is so convoluted I didn't push it past a simple prototype.
locking each test on a separate lock file to prevent it from running multiple copies in parallel.
and a few other hacks.


If you'd rather keep tests simpler, I don't see any other solution than to disable parallel test execution completely on everything other than Linux and Windows (where we can use the full subnet 127.0.0.0/8 and randomly generate both addresses for ListenAddress and ports for Port), or write an alternative test harness that doesn't run the same test multiple times in parallel (you can't disable this with meson).
Basic architecture
I intentionally kept things simple so there are fewer layers to unwrap if it gets in the way in more complicated tests.

meson starts the test script
test imports the required pieces of the testing library
it starts a notification server which receives event notifications from tincd scripts (the same idea we had in the old test suite, but here it's using UNIX sockets/Windows pipes instead of tail + grep)
you create a test context (a class named Test), and use it to get instances of a class named Tinc (the context remembers Tincs it has issued and uses them as described below)
you initialize the nodes using that Tinc (it's a thin wrapper around subprocess), and start issuing commands to them using one of these methods:

tinc() — start tinc with the specified arguments and return Popen
tincd() — same, but for tincd
cmd() — a convenience wrapper around tinc() which can pass text snippets into stdin, checks the return code for you, and returns (stdout, stderr)
and a few more, it's all commented.


when a test context exits (leaves the with statement), it stops every tinc and tincd started from it, and kills everything that refuses to stop.

If you initialize instances of the Tinc class directly, they won't be stopped automatically.
Tinc can also register tincd scripts and returns objects that let you wait on notifications from those scripts. Only one event is needed now (and thus only one is supported), but it's easy to add more.
There are some assertions (which should be used instead of the built-in assert because it doesn't print values on failure), a global logger, and a few helper functions for more complicated commands like exchange so the logic isn't repeated in several places.
Known issues
scripts.py
Port checks were dumbed down to checking that a non-empty value was passed. tincd on Windows behaves really strange with dynamically allocated ports on both sides of the connection, and I couldn't make it work after wasting half a day on it.
We have three choices here:

disable this test on Windows
use randomly generated port instead of Port 0 (and get intermittent test failures because of port conflicts)
keep the current basic check.

I don't think any other test functionality was lost. invite-offline.test and invite-online.test are rolled into invite.py.
Crashes on Alpine
Example.
SIGSEGV in a Python process that's running the test. Since there's no unsafe code in tests, I suspect this is because of musl.
These are pretty rare, just wanted you to be aware of them.
Failures on macOS
Same issue we have with the current test suite:
Cannot read greeting from control socket: No such file or directory

although tinc should definitely be able to connect to tincd because it is only started after we get a go-ahead from tinc-up.

https://github.com/hg/tinc/runs/5807386977?check_suite_focus=true#step:6:51533
https://github.com/hg/tinc/runs/5806692838?check_suite_focus=true#step:6:48233

So it's likely a tinc bug. I don't have access to macOS, and it's not easy to trigger to debug on CI machines. Can't help much here.

c1c5263 is a quick and dirty fix for #361. Don't pay much attention to it. I'll look into it while you're reviewing tests.","I'd disable the test on Windows then, and add an issue to sort this out later.

OK, it's a bit worse than that. I think we're forced to generate a port on our own and then pass it to bar.
There's a small window of time before bar is started where the port can be taken by something else, so this test will be flaky and there will be false positive failures.
If Port 0 is used, REMOTEPORT on foo's side contains not the bar server port you'd connect to, but the client port which bar used to connect to foo, which is different from the one we expect. This is what I was fighting yesterday and it's not just Windows.
It feels like an accidental omission to cover the case of Port 0. Why would you need a client port of the remote node? What would you do with that information? Or is it just me being stupid again?",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,362,2022-04-06T19:33:49Z,2022-04-10T09:56:56Z,2022-04-10T09:56:56Z,MERGED,True,3363,2171,78,https://github.com/hg,Rewrite tests in Python for better OS compatibility,5,[],https://github.com/gsliepen/tinc/pull/362,https://github.com/gsliepen,3,https://github.com/gsliepen/tinc/pull/362#issuecomment-1092020512,"These depend only on the standard library of Python 3.6 or later (used by RHEL 7; other distributions have newer versions). If system Python is missing, it falls back to the one used by meson.
Tests are using a somewhat different approach compared to the current suite. There are no hardcoded ports and Port 0 is used everywhere, but now we have to do the dance of starting nodes in a particular order and parsing their pidfiles to know the real port they listen on.
You have to pay more attention when writing tests, but it's the only reliable solution I could find from extensively testing a dozen ideas that allows us to keep full parallel test execution.

  Some other things that were tried

hardcoding port numbers, like in the current test suite — forces you to run all tests serially, or drop support for --repeat (which I don't think is possible to disable, so it's just something you have to know about); and there can still be conflicts with other software.
generating random ports using random.randint() with shared port range for all tests (1024 to 65535) — tolerable when running 4 tests in parallel, unusable with 16 or more.
same, but splitting it into smaller unique ranges, one for each test (slightly better than the previous one, not worth it).
same, but using hacks to try to exclude ports typically used for connect() (hopefully less conflicts with ""client"" ports, not much difference in practice).
binding a throwaway socket to port 0 and letting the OS choose a port, then binding tincd to that port (significantly more conflicts than trying ports randomly, Linux seems to use a very short port range, and further halves it to leave the other half for ""client"" ports, and this really shows in practice).
using random ports and binding tincd to randomly generated addresses in 127.0.0.0/8 — good stability and clear test code, but requires configuring the system on everything that's not Linux or Windows.
using a separate server which can be asked by test scripts to pick a port using one of the previous methods (so port allocation happens in a single place instead of spreading it throughout tests — it can make sure it doesn't give the same port twice) — not bad in practice, but is so convoluted I didn't push it past a simple prototype.
locking each test on a separate lock file to prevent it from running multiple copies in parallel.
and a few other hacks.


If you'd rather keep tests simpler, I don't see any other solution than to disable parallel test execution completely on everything other than Linux and Windows (where we can use the full subnet 127.0.0.0/8 and randomly generate both addresses for ListenAddress and ports for Port), or write an alternative test harness that doesn't run the same test multiple times in parallel (you can't disable this with meson).
Basic architecture
I intentionally kept things simple so there are fewer layers to unwrap if it gets in the way in more complicated tests.

meson starts the test script
test imports the required pieces of the testing library
it starts a notification server which receives event notifications from tincd scripts (the same idea we had in the old test suite, but here it's using UNIX sockets/Windows pipes instead of tail + grep)
you create a test context (a class named Test), and use it to get instances of a class named Tinc (the context remembers Tincs it has issued and uses them as described below)
you initialize the nodes using that Tinc (it's a thin wrapper around subprocess), and start issuing commands to them using one of these methods:

tinc() — start tinc with the specified arguments and return Popen
tincd() — same, but for tincd
cmd() — a convenience wrapper around tinc() which can pass text snippets into stdin, checks the return code for you, and returns (stdout, stderr)
and a few more, it's all commented.


when a test context exits (leaves the with statement), it stops every tinc and tincd started from it, and kills everything that refuses to stop.

If you initialize instances of the Tinc class directly, they won't be stopped automatically.
Tinc can also register tincd scripts and returns objects that let you wait on notifications from those scripts. Only one event is needed now (and thus only one is supported), but it's easy to add more.
There are some assertions (which should be used instead of the built-in assert because it doesn't print values on failure), a global logger, and a few helper functions for more complicated commands like exchange so the logic isn't repeated in several places.
Known issues
scripts.py
Port checks were dumbed down to checking that a non-empty value was passed. tincd on Windows behaves really strange with dynamically allocated ports on both sides of the connection, and I couldn't make it work after wasting half a day on it.
We have three choices here:

disable this test on Windows
use randomly generated port instead of Port 0 (and get intermittent test failures because of port conflicts)
keep the current basic check.

I don't think any other test functionality was lost. invite-offline.test and invite-online.test are rolled into invite.py.
Crashes on Alpine
Example.
SIGSEGV in a Python process that's running the test. Since there's no unsafe code in tests, I suspect this is because of musl.
These are pretty rare, just wanted you to be aware of them.
Failures on macOS
Same issue we have with the current test suite:
Cannot read greeting from control socket: No such file or directory

although tinc should definitely be able to connect to tincd because it is only started after we get a go-ahead from tinc-up.

https://github.com/hg/tinc/runs/5807386977?check_suite_focus=true#step:6:51533
https://github.com/hg/tinc/runs/5806692838?check_suite_focus=true#step:6:48233

So it's likely a tinc bug. I don't have access to macOS, and it's not easy to trigger to debug on CI machines. Can't help much here.

c1c5263 is a quick and dirty fix for #361. Don't pay much attention to it. I'll look into it while you're reviewing tests.","I'd disable the test on Windows then, and add an issue to sort this out later.

OK, it's a bit worse than that. I think we're forced to generate a port on our own and then pass it to bar.
There's a small window of time before bar is started where the port can be taken by something else, so this test will be flaky and there will be false positive failures.

True. I guess the chance of this might be high when running lots of tests in parallel. And you're also right that manually assigning ports is not ideal either, although it did work relatively well, especially inside containers where you are sure no ports are used anyway.

If Port 0 is used, REMOTEPORT on foo's side contains not the bar server port you'd connect to, but the client port which bar used to connect to foo, which is different from the one we expect. This is what I was fighting yesterday and it's not just Windows.
It feels like an accidental omission to cover the case of Port 0. Why would you need a client port of the remote node? What would you do with that information? Or is it just me being stupid again?

It is not what you want, but the information in $REMOTEPORT and $REMOTEADDRESS is useful for dynamically creating firewall rules for example. So I wouldn't change their behaviour.
You can actually find the port that a tincd that has Port 0 is listening on in its PID file (it's the last item on the line). What's missing is a way for tincctl to report that information. It should not be that hard to add it, since it's already parsing the PID file and getting the port, but currently it's just discarding it after creating the control socket.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,362,2022-04-06T19:33:49Z,2022-04-10T09:56:56Z,2022-04-10T09:56:56Z,MERGED,True,3363,2171,78,https://github.com/hg,Rewrite tests in Python for better OS compatibility,5,[],https://github.com/gsliepen/tinc/pull/362,https://github.com/gsliepen,4,https://github.com/gsliepen/tinc/pull/362#issuecomment-1092023636,"These depend only on the standard library of Python 3.6 or later (used by RHEL 7; other distributions have newer versions). If system Python is missing, it falls back to the one used by meson.
Tests are using a somewhat different approach compared to the current suite. There are no hardcoded ports and Port 0 is used everywhere, but now we have to do the dance of starting nodes in a particular order and parsing their pidfiles to know the real port they listen on.
You have to pay more attention when writing tests, but it's the only reliable solution I could find from extensively testing a dozen ideas that allows us to keep full parallel test execution.

  Some other things that were tried

hardcoding port numbers, like in the current test suite — forces you to run all tests serially, or drop support for --repeat (which I don't think is possible to disable, so it's just something you have to know about); and there can still be conflicts with other software.
generating random ports using random.randint() with shared port range for all tests (1024 to 65535) — tolerable when running 4 tests in parallel, unusable with 16 or more.
same, but splitting it into smaller unique ranges, one for each test (slightly better than the previous one, not worth it).
same, but using hacks to try to exclude ports typically used for connect() (hopefully less conflicts with ""client"" ports, not much difference in practice).
binding a throwaway socket to port 0 and letting the OS choose a port, then binding tincd to that port (significantly more conflicts than trying ports randomly, Linux seems to use a very short port range, and further halves it to leave the other half for ""client"" ports, and this really shows in practice).
using random ports and binding tincd to randomly generated addresses in 127.0.0.0/8 — good stability and clear test code, but requires configuring the system on everything that's not Linux or Windows.
using a separate server which can be asked by test scripts to pick a port using one of the previous methods (so port allocation happens in a single place instead of spreading it throughout tests — it can make sure it doesn't give the same port twice) — not bad in practice, but is so convoluted I didn't push it past a simple prototype.
locking each test on a separate lock file to prevent it from running multiple copies in parallel.
and a few other hacks.


If you'd rather keep tests simpler, I don't see any other solution than to disable parallel test execution completely on everything other than Linux and Windows (where we can use the full subnet 127.0.0.0/8 and randomly generate both addresses for ListenAddress and ports for Port), or write an alternative test harness that doesn't run the same test multiple times in parallel (you can't disable this with meson).
Basic architecture
I intentionally kept things simple so there are fewer layers to unwrap if it gets in the way in more complicated tests.

meson starts the test script
test imports the required pieces of the testing library
it starts a notification server which receives event notifications from tincd scripts (the same idea we had in the old test suite, but here it's using UNIX sockets/Windows pipes instead of tail + grep)
you create a test context (a class named Test), and use it to get instances of a class named Tinc (the context remembers Tincs it has issued and uses them as described below)
you initialize the nodes using that Tinc (it's a thin wrapper around subprocess), and start issuing commands to them using one of these methods:

tinc() — start tinc with the specified arguments and return Popen
tincd() — same, but for tincd
cmd() — a convenience wrapper around tinc() which can pass text snippets into stdin, checks the return code for you, and returns (stdout, stderr)
and a few more, it's all commented.


when a test context exits (leaves the with statement), it stops every tinc and tincd started from it, and kills everything that refuses to stop.

If you initialize instances of the Tinc class directly, they won't be stopped automatically.
Tinc can also register tincd scripts and returns objects that let you wait on notifications from those scripts. Only one event is needed now (and thus only one is supported), but it's easy to add more.
There are some assertions (which should be used instead of the built-in assert because it doesn't print values on failure), a global logger, and a few helper functions for more complicated commands like exchange so the logic isn't repeated in several places.
Known issues
scripts.py
Port checks were dumbed down to checking that a non-empty value was passed. tincd on Windows behaves really strange with dynamically allocated ports on both sides of the connection, and I couldn't make it work after wasting half a day on it.
We have three choices here:

disable this test on Windows
use randomly generated port instead of Port 0 (and get intermittent test failures because of port conflicts)
keep the current basic check.

I don't think any other test functionality was lost. invite-offline.test and invite-online.test are rolled into invite.py.
Crashes on Alpine
Example.
SIGSEGV in a Python process that's running the test. Since there's no unsafe code in tests, I suspect this is because of musl.
These are pretty rare, just wanted you to be aware of them.
Failures on macOS
Same issue we have with the current test suite:
Cannot read greeting from control socket: No such file or directory

although tinc should definitely be able to connect to tincd because it is only started after we get a go-ahead from tinc-up.

https://github.com/hg/tinc/runs/5807386977?check_suite_focus=true#step:6:51533
https://github.com/hg/tinc/runs/5806692838?check_suite_focus=true#step:6:48233

So it's likely a tinc bug. I don't have access to macOS, and it's not easy to trigger to debug on CI machines. Can't help much here.

c1c5263 is a quick and dirty fix for #361. Don't pay much attention to it. I'll look into it while you're reviewing tests.",I think scripts.py is missing an important thing that scripts.test did: the latter also checked that all the scripts ran in a specific order.,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,362,2022-04-06T19:33:49Z,2022-04-10T09:56:56Z,2022-04-10T09:56:56Z,MERGED,True,3363,2171,78,https://github.com/hg,Rewrite tests in Python for better OS compatibility,5,[],https://github.com/gsliepen/tinc/pull/362,https://github.com/hg,5,https://github.com/gsliepen/tinc/pull/362#issuecomment-1092966430,"These depend only on the standard library of Python 3.6 or later (used by RHEL 7; other distributions have newer versions). If system Python is missing, it falls back to the one used by meson.
Tests are using a somewhat different approach compared to the current suite. There are no hardcoded ports and Port 0 is used everywhere, but now we have to do the dance of starting nodes in a particular order and parsing their pidfiles to know the real port they listen on.
You have to pay more attention when writing tests, but it's the only reliable solution I could find from extensively testing a dozen ideas that allows us to keep full parallel test execution.

  Some other things that were tried

hardcoding port numbers, like in the current test suite — forces you to run all tests serially, or drop support for --repeat (which I don't think is possible to disable, so it's just something you have to know about); and there can still be conflicts with other software.
generating random ports using random.randint() with shared port range for all tests (1024 to 65535) — tolerable when running 4 tests in parallel, unusable with 16 or more.
same, but splitting it into smaller unique ranges, one for each test (slightly better than the previous one, not worth it).
same, but using hacks to try to exclude ports typically used for connect() (hopefully less conflicts with ""client"" ports, not much difference in practice).
binding a throwaway socket to port 0 and letting the OS choose a port, then binding tincd to that port (significantly more conflicts than trying ports randomly, Linux seems to use a very short port range, and further halves it to leave the other half for ""client"" ports, and this really shows in practice).
using random ports and binding tincd to randomly generated addresses in 127.0.0.0/8 — good stability and clear test code, but requires configuring the system on everything that's not Linux or Windows.
using a separate server which can be asked by test scripts to pick a port using one of the previous methods (so port allocation happens in a single place instead of spreading it throughout tests — it can make sure it doesn't give the same port twice) — not bad in practice, but is so convoluted I didn't push it past a simple prototype.
locking each test on a separate lock file to prevent it from running multiple copies in parallel.
and a few other hacks.


If you'd rather keep tests simpler, I don't see any other solution than to disable parallel test execution completely on everything other than Linux and Windows (where we can use the full subnet 127.0.0.0/8 and randomly generate both addresses for ListenAddress and ports for Port), or write an alternative test harness that doesn't run the same test multiple times in parallel (you can't disable this with meson).
Basic architecture
I intentionally kept things simple so there are fewer layers to unwrap if it gets in the way in more complicated tests.

meson starts the test script
test imports the required pieces of the testing library
it starts a notification server which receives event notifications from tincd scripts (the same idea we had in the old test suite, but here it's using UNIX sockets/Windows pipes instead of tail + grep)
you create a test context (a class named Test), and use it to get instances of a class named Tinc (the context remembers Tincs it has issued and uses them as described below)
you initialize the nodes using that Tinc (it's a thin wrapper around subprocess), and start issuing commands to them using one of these methods:

tinc() — start tinc with the specified arguments and return Popen
tincd() — same, but for tincd
cmd() — a convenience wrapper around tinc() which can pass text snippets into stdin, checks the return code for you, and returns (stdout, stderr)
and a few more, it's all commented.


when a test context exits (leaves the with statement), it stops every tinc and tincd started from it, and kills everything that refuses to stop.

If you initialize instances of the Tinc class directly, they won't be stopped automatically.
Tinc can also register tincd scripts and returns objects that let you wait on notifications from those scripts. Only one event is needed now (and thus only one is supported), but it's easy to add more.
There are some assertions (which should be used instead of the built-in assert because it doesn't print values on failure), a global logger, and a few helper functions for more complicated commands like exchange so the logic isn't repeated in several places.
Known issues
scripts.py
Port checks were dumbed down to checking that a non-empty value was passed. tincd on Windows behaves really strange with dynamically allocated ports on both sides of the connection, and I couldn't make it work after wasting half a day on it.
We have three choices here:

disable this test on Windows
use randomly generated port instead of Port 0 (and get intermittent test failures because of port conflicts)
keep the current basic check.

I don't think any other test functionality was lost. invite-offline.test and invite-online.test are rolled into invite.py.
Crashes on Alpine
Example.
SIGSEGV in a Python process that's running the test. Since there's no unsafe code in tests, I suspect this is because of musl.
These are pretty rare, just wanted you to be aware of them.
Failures on macOS
Same issue we have with the current test suite:
Cannot read greeting from control socket: No such file or directory

although tinc should definitely be able to connect to tincd because it is only started after we get a go-ahead from tinc-up.

https://github.com/hg/tinc/runs/5807386977?check_suite_focus=true#step:6:51533
https://github.com/hg/tinc/runs/5806692838?check_suite_focus=true#step:6:48233

So it's likely a tinc bug. I don't have access to macOS, and it's not easy to trigger to debug on CI machines. Can't help much here.

c1c5263 is a quick and dirty fix for #361. Don't pay much attention to it. I'll look into it while you're reviewing tests.","Changelog:

scripts.py: check that scripts get called in the correct order.
enable scripts.py on Windows.
add pylint (linter) and mypy (typechecker) to CI.
fix all pylint/mypy warnings.
wrap all linters with a helper script lint.py. Since it's doing almost exactly the same what reformat.py was doing, reformat has been merged into lint. Use lint.py --fix or the old ninja command (ninja -C build reformat).
use long options in .astylerc for better readability.
when creating tincd scripts, use template files instead of huge inline snippets.
and some stylistic changes.

While everything should be finished now, I'll have access to an unused 32-core server for the next couple of days and would like to loop the test suite there as an additional precaution before marking this PR as ready.
I'll look at #361 now, since c1c5263 is unlikely to work correctly.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,362,2022-04-06T19:33:49Z,2022-04-10T09:56:56Z,2022-04-10T09:56:56Z,MERGED,True,3363,2171,78,https://github.com/hg,Rewrite tests in Python for better OS compatibility,5,[],https://github.com/gsliepen/tinc/pull/362,https://github.com/hg,6,https://github.com/gsliepen/tinc/pull/362#issuecomment-1094119226,"These depend only on the standard library of Python 3.6 or later (used by RHEL 7; other distributions have newer versions). If system Python is missing, it falls back to the one used by meson.
Tests are using a somewhat different approach compared to the current suite. There are no hardcoded ports and Port 0 is used everywhere, but now we have to do the dance of starting nodes in a particular order and parsing their pidfiles to know the real port they listen on.
You have to pay more attention when writing tests, but it's the only reliable solution I could find from extensively testing a dozen ideas that allows us to keep full parallel test execution.

  Some other things that were tried

hardcoding port numbers, like in the current test suite — forces you to run all tests serially, or drop support for --repeat (which I don't think is possible to disable, so it's just something you have to know about); and there can still be conflicts with other software.
generating random ports using random.randint() with shared port range for all tests (1024 to 65535) — tolerable when running 4 tests in parallel, unusable with 16 or more.
same, but splitting it into smaller unique ranges, one for each test (slightly better than the previous one, not worth it).
same, but using hacks to try to exclude ports typically used for connect() (hopefully less conflicts with ""client"" ports, not much difference in practice).
binding a throwaway socket to port 0 and letting the OS choose a port, then binding tincd to that port (significantly more conflicts than trying ports randomly, Linux seems to use a very short port range, and further halves it to leave the other half for ""client"" ports, and this really shows in practice).
using random ports and binding tincd to randomly generated addresses in 127.0.0.0/8 — good stability and clear test code, but requires configuring the system on everything that's not Linux or Windows.
using a separate server which can be asked by test scripts to pick a port using one of the previous methods (so port allocation happens in a single place instead of spreading it throughout tests — it can make sure it doesn't give the same port twice) — not bad in practice, but is so convoluted I didn't push it past a simple prototype.
locking each test on a separate lock file to prevent it from running multiple copies in parallel.
and a few other hacks.


If you'd rather keep tests simpler, I don't see any other solution than to disable parallel test execution completely on everything other than Linux and Windows (where we can use the full subnet 127.0.0.0/8 and randomly generate both addresses for ListenAddress and ports for Port), or write an alternative test harness that doesn't run the same test multiple times in parallel (you can't disable this with meson).
Basic architecture
I intentionally kept things simple so there are fewer layers to unwrap if it gets in the way in more complicated tests.

meson starts the test script
test imports the required pieces of the testing library
it starts a notification server which receives event notifications from tincd scripts (the same idea we had in the old test suite, but here it's using UNIX sockets/Windows pipes instead of tail + grep)
you create a test context (a class named Test), and use it to get instances of a class named Tinc (the context remembers Tincs it has issued and uses them as described below)
you initialize the nodes using that Tinc (it's a thin wrapper around subprocess), and start issuing commands to them using one of these methods:

tinc() — start tinc with the specified arguments and return Popen
tincd() — same, but for tincd
cmd() — a convenience wrapper around tinc() which can pass text snippets into stdin, checks the return code for you, and returns (stdout, stderr)
and a few more, it's all commented.


when a test context exits (leaves the with statement), it stops every tinc and tincd started from it, and kills everything that refuses to stop.

If you initialize instances of the Tinc class directly, they won't be stopped automatically.
Tinc can also register tincd scripts and returns objects that let you wait on notifications from those scripts. Only one event is needed now (and thus only one is supported), but it's easy to add more.
There are some assertions (which should be used instead of the built-in assert because it doesn't print values on failure), a global logger, and a few helper functions for more complicated commands like exchange so the logic isn't repeated in several places.
Known issues
scripts.py
Port checks were dumbed down to checking that a non-empty value was passed. tincd on Windows behaves really strange with dynamically allocated ports on both sides of the connection, and I couldn't make it work after wasting half a day on it.
We have three choices here:

disable this test on Windows
use randomly generated port instead of Port 0 (and get intermittent test failures because of port conflicts)
keep the current basic check.

I don't think any other test functionality was lost. invite-offline.test and invite-online.test are rolled into invite.py.
Crashes on Alpine
Example.
SIGSEGV in a Python process that's running the test. Since there's no unsafe code in tests, I suspect this is because of musl.
These are pretty rare, just wanted you to be aware of them.
Failures on macOS
Same issue we have with the current test suite:
Cannot read greeting from control socket: No such file or directory

although tinc should definitely be able to connect to tincd because it is only started after we get a go-ahead from tinc-up.

https://github.com/hg/tinc/runs/5807386977?check_suite_focus=true#step:6:51533
https://github.com/hg/tinc/runs/5806692838?check_suite_focus=true#step:6:48233

So it's likely a tinc bug. I don't have access to macOS, and it's not easy to trigger to debug on CI machines. Can't help much here.

c1c5263 is a quick and dirty fix for #361. Don't pay much attention to it. I'll look into it while you're reviewing tests.","With latest changes, I think it's about as stable as it's going to get.

  Tests were run on …

32-core Intel-something, --num-processes on default 32
EL8
kernel: 4.18.0-348.12.2.el8_5.x86_64
gcc: 8.5.0
lz4-devel: 1.8.3
lzo-devel: 2.08
meson: 0.55.3
ncurses-devel: 6.1
pkgconf: 1.4.2
readline-devel: 7.0
zlib-devel: 1.2.11


Hours of meson test --repeat 11000 produced this:
Ok:                 175945
Expected Fail:      0
Fail:               55
Unexpected Pass:    0
Skipped:            0
Timeout:            0

54 of them in security.py, one in invite.py.

  Some details
All security.py failures look the same:
ERROR:security.py:Uncaught exception
Traceback (most recent call last):
  File ""/home/user/tinc/test/integration/security.py"", line 128, in <module>
    loop.run_until_complete(run_tests(context))
  File ""/usr/lib64/python3.6/asyncio/base_events.py"", line 484, in run_until_complete
    return future.result()
  File ""/home/user/tinc/test/integration/security.py"", line 115, in run_tests
    await test_id_timeout(foo)
  File ""/home/user/tinc/test/integration/security.py"", line 45, in test_id_timeout
    data = await send(foo.port, ""0 bar 17.7"", delay=TIMEOUT * 1.5)
  File ""/home/user/tinc/test/integration/security.py"", line 39, in send
    raise RuntimeError(""test should not have reached this line"")
RuntimeError: test should not have reached this line

and for the other one (I've seen this two or three times during 16-17k test runs in total, so it's pretty difficult to catch):
INFO:invite.py:join second node with localhost:33583/SvRsLgU7son8FIsLTEdwVj1BgtO9j0m0BsoZlFTPWCiSQy3q
DEBUG:invite.py:starting tinc rnmig0il6q: ""/home/user/tinc/build/src/tinc --net rnmig0il6q --config /home/user/tinc/build/test/integration/wd/invite.py/data/rnmig0il6q
--pidfile /home/user/tinc/build/test/integration/wd/invite.py/data/rnmig0il6q/pid join localhost:33583/SvRsLgU7son8FIsLTEdwVj1BgtO9j0m0BsoZlFTPWCiSQy3q""
DEBUG:invite.py:tinc rnmig0il6q: PID 1460029, in ""None"", want code 0DEBUG:invite.py:tinc rnmig0il6q: code 1, out """", err ""Both netname and configuration directory given, using the latter...
Connected to localhost port 33583...
Peer has an invalid key!
dehGocM/aONofz70p4IGYNqw6jCLF6j0fQEgNZ28pRJ
""

…

ERROR:invite.py:Uncaught exception
Traceback (most recent call last):
  File ""/home/user/tinc/test/integration/invite.py"", line 89, in <module>
    run_invite_test(context, start_before_invite=False)
  File ""/home/user/tinc/test/integration/invite.py"", line 40, in run_invite_test
    bar.cmd(""join"", foo_invite)
  File ""/home/user/tinc/test/integration/testlib/proc.py"", line 225, in cmd
    check.equals(code, res)
  File ""/home/user/tinc/test/integration/testlib/check.py"", line 26, in equals
    raise ValueError(f'expected ""{expected}"", got ""{actual}""')
ValueError: expected ""0"", got ""1""


So security.py has ~0.5% failure rate. Since it relies on timeouts, I don't see how to substantially improve that (increasing them doesn't help).
Very rarely, invite.py runs into what I believe to be a tinc bug where the author of an invitation doesn't respond to join, even if you do it manually after the test fails. Both sides just hang with zero output. It's difficult to reproduce, so I'm not reporting anything concrete yet.
Word to the wise: avoid using large values for --repeat. meson wasn't expecting such folly from its user and gobbled up 12 GBs of RAM closer to the finish line. It may have been fixed in later versions, though.

re #361: close() (aliased to CloseHandle()) was replaced with closesocket() where appropriate, since:

Do not use the CloseHandle function to close a socket. Instead, use the closesocket function, which releases all resources associated with the socket including the handle to the socket object.

Other uses look fine.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,362,2022-04-06T19:33:49Z,2022-04-10T09:56:56Z,2022-04-10T09:56:56Z,MERGED,True,3363,2171,78,https://github.com/hg,Rewrite tests in Python for better OS compatibility,5,[],https://github.com/gsliepen/tinc/pull/362,https://github.com/hg,7,https://github.com/gsliepen/tinc/pull/362#issuecomment-1094211029,"These depend only on the standard library of Python 3.6 or later (used by RHEL 7; other distributions have newer versions). If system Python is missing, it falls back to the one used by meson.
Tests are using a somewhat different approach compared to the current suite. There are no hardcoded ports and Port 0 is used everywhere, but now we have to do the dance of starting nodes in a particular order and parsing their pidfiles to know the real port they listen on.
You have to pay more attention when writing tests, but it's the only reliable solution I could find from extensively testing a dozen ideas that allows us to keep full parallel test execution.

  Some other things that were tried

hardcoding port numbers, like in the current test suite — forces you to run all tests serially, or drop support for --repeat (which I don't think is possible to disable, so it's just something you have to know about); and there can still be conflicts with other software.
generating random ports using random.randint() with shared port range for all tests (1024 to 65535) — tolerable when running 4 tests in parallel, unusable with 16 or more.
same, but splitting it into smaller unique ranges, one for each test (slightly better than the previous one, not worth it).
same, but using hacks to try to exclude ports typically used for connect() (hopefully less conflicts with ""client"" ports, not much difference in practice).
binding a throwaway socket to port 0 and letting the OS choose a port, then binding tincd to that port (significantly more conflicts than trying ports randomly, Linux seems to use a very short port range, and further halves it to leave the other half for ""client"" ports, and this really shows in practice).
using random ports and binding tincd to randomly generated addresses in 127.0.0.0/8 — good stability and clear test code, but requires configuring the system on everything that's not Linux or Windows.
using a separate server which can be asked by test scripts to pick a port using one of the previous methods (so port allocation happens in a single place instead of spreading it throughout tests — it can make sure it doesn't give the same port twice) — not bad in practice, but is so convoluted I didn't push it past a simple prototype.
locking each test on a separate lock file to prevent it from running multiple copies in parallel.
and a few other hacks.


If you'd rather keep tests simpler, I don't see any other solution than to disable parallel test execution completely on everything other than Linux and Windows (where we can use the full subnet 127.0.0.0/8 and randomly generate both addresses for ListenAddress and ports for Port), or write an alternative test harness that doesn't run the same test multiple times in parallel (you can't disable this with meson).
Basic architecture
I intentionally kept things simple so there are fewer layers to unwrap if it gets in the way in more complicated tests.

meson starts the test script
test imports the required pieces of the testing library
it starts a notification server which receives event notifications from tincd scripts (the same idea we had in the old test suite, but here it's using UNIX sockets/Windows pipes instead of tail + grep)
you create a test context (a class named Test), and use it to get instances of a class named Tinc (the context remembers Tincs it has issued and uses them as described below)
you initialize the nodes using that Tinc (it's a thin wrapper around subprocess), and start issuing commands to them using one of these methods:

tinc() — start tinc with the specified arguments and return Popen
tincd() — same, but for tincd
cmd() — a convenience wrapper around tinc() which can pass text snippets into stdin, checks the return code for you, and returns (stdout, stderr)
and a few more, it's all commented.


when a test context exits (leaves the with statement), it stops every tinc and tincd started from it, and kills everything that refuses to stop.

If you initialize instances of the Tinc class directly, they won't be stopped automatically.
Tinc can also register tincd scripts and returns objects that let you wait on notifications from those scripts. Only one event is needed now (and thus only one is supported), but it's easy to add more.
There are some assertions (which should be used instead of the built-in assert because it doesn't print values on failure), a global logger, and a few helper functions for more complicated commands like exchange so the logic isn't repeated in several places.
Known issues
scripts.py
Port checks were dumbed down to checking that a non-empty value was passed. tincd on Windows behaves really strange with dynamically allocated ports on both sides of the connection, and I couldn't make it work after wasting half a day on it.
We have three choices here:

disable this test on Windows
use randomly generated port instead of Port 0 (and get intermittent test failures because of port conflicts)
keep the current basic check.

I don't think any other test functionality was lost. invite-offline.test and invite-online.test are rolled into invite.py.
Crashes on Alpine
Example.
SIGSEGV in a Python process that's running the test. Since there's no unsafe code in tests, I suspect this is because of musl.
These are pretty rare, just wanted you to be aware of them.
Failures on macOS
Same issue we have with the current test suite:
Cannot read greeting from control socket: No such file or directory

although tinc should definitely be able to connect to tincd because it is only started after we get a go-ahead from tinc-up.

https://github.com/hg/tinc/runs/5807386977?check_suite_focus=true#step:6:51533
https://github.com/hg/tinc/runs/5806692838?check_suite_focus=true#step:6:48233

So it's likely a tinc bug. I don't have access to macOS, and it's not easy to trigger to debug on CI machines. Can't help much here.

c1c5263 is a quick and dirty fix for #361. Don't pay much attention to it. I'll look into it while you're reviewing tests.","Drive-by question: I remember there was some interest in moving away from C. Do you consider slowly moving the project to C++ to be worth it (like GCC has been doing since 2010)? The way they did it IIRC is first making all headers includeable into C++ files, then renaming and fixing C files one by one, and then improving from there.
Although, if we want to keep support for ancient routers, there will be no C++11 for the foreseeable future, since GCC 4.2 is needed for those, and relatively complete C++11 support became available in GCC 4.8.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,362,2022-04-06T19:33:49Z,2022-04-10T09:56:56Z,2022-04-10T09:56:56Z,MERGED,True,3363,2171,78,https://github.com/hg,Rewrite tests in Python for better OS compatibility,5,[],https://github.com/gsliepen/tinc/pull/362,https://github.com/gsliepen,8,https://github.com/gsliepen/tinc/pull/362#issuecomment-1094217911,"These depend only on the standard library of Python 3.6 or later (used by RHEL 7; other distributions have newer versions). If system Python is missing, it falls back to the one used by meson.
Tests are using a somewhat different approach compared to the current suite. There are no hardcoded ports and Port 0 is used everywhere, but now we have to do the dance of starting nodes in a particular order and parsing their pidfiles to know the real port they listen on.
You have to pay more attention when writing tests, but it's the only reliable solution I could find from extensively testing a dozen ideas that allows us to keep full parallel test execution.

  Some other things that were tried

hardcoding port numbers, like in the current test suite — forces you to run all tests serially, or drop support for --repeat (which I don't think is possible to disable, so it's just something you have to know about); and there can still be conflicts with other software.
generating random ports using random.randint() with shared port range for all tests (1024 to 65535) — tolerable when running 4 tests in parallel, unusable with 16 or more.
same, but splitting it into smaller unique ranges, one for each test (slightly better than the previous one, not worth it).
same, but using hacks to try to exclude ports typically used for connect() (hopefully less conflicts with ""client"" ports, not much difference in practice).
binding a throwaway socket to port 0 and letting the OS choose a port, then binding tincd to that port (significantly more conflicts than trying ports randomly, Linux seems to use a very short port range, and further halves it to leave the other half for ""client"" ports, and this really shows in practice).
using random ports and binding tincd to randomly generated addresses in 127.0.0.0/8 — good stability and clear test code, but requires configuring the system on everything that's not Linux or Windows.
using a separate server which can be asked by test scripts to pick a port using one of the previous methods (so port allocation happens in a single place instead of spreading it throughout tests — it can make sure it doesn't give the same port twice) — not bad in practice, but is so convoluted I didn't push it past a simple prototype.
locking each test on a separate lock file to prevent it from running multiple copies in parallel.
and a few other hacks.


If you'd rather keep tests simpler, I don't see any other solution than to disable parallel test execution completely on everything other than Linux and Windows (where we can use the full subnet 127.0.0.0/8 and randomly generate both addresses for ListenAddress and ports for Port), or write an alternative test harness that doesn't run the same test multiple times in parallel (you can't disable this with meson).
Basic architecture
I intentionally kept things simple so there are fewer layers to unwrap if it gets in the way in more complicated tests.

meson starts the test script
test imports the required pieces of the testing library
it starts a notification server which receives event notifications from tincd scripts (the same idea we had in the old test suite, but here it's using UNIX sockets/Windows pipes instead of tail + grep)
you create a test context (a class named Test), and use it to get instances of a class named Tinc (the context remembers Tincs it has issued and uses them as described below)
you initialize the nodes using that Tinc (it's a thin wrapper around subprocess), and start issuing commands to them using one of these methods:

tinc() — start tinc with the specified arguments and return Popen
tincd() — same, but for tincd
cmd() — a convenience wrapper around tinc() which can pass text snippets into stdin, checks the return code for you, and returns (stdout, stderr)
and a few more, it's all commented.


when a test context exits (leaves the with statement), it stops every tinc and tincd started from it, and kills everything that refuses to stop.

If you initialize instances of the Tinc class directly, they won't be stopped automatically.
Tinc can also register tincd scripts and returns objects that let you wait on notifications from those scripts. Only one event is needed now (and thus only one is supported), but it's easy to add more.
There are some assertions (which should be used instead of the built-in assert because it doesn't print values on failure), a global logger, and a few helper functions for more complicated commands like exchange so the logic isn't repeated in several places.
Known issues
scripts.py
Port checks were dumbed down to checking that a non-empty value was passed. tincd on Windows behaves really strange with dynamically allocated ports on both sides of the connection, and I couldn't make it work after wasting half a day on it.
We have three choices here:

disable this test on Windows
use randomly generated port instead of Port 0 (and get intermittent test failures because of port conflicts)
keep the current basic check.

I don't think any other test functionality was lost. invite-offline.test and invite-online.test are rolled into invite.py.
Crashes on Alpine
Example.
SIGSEGV in a Python process that's running the test. Since there's no unsafe code in tests, I suspect this is because of musl.
These are pretty rare, just wanted you to be aware of them.
Failures on macOS
Same issue we have with the current test suite:
Cannot read greeting from control socket: No such file or directory

although tinc should definitely be able to connect to tincd because it is only started after we get a go-ahead from tinc-up.

https://github.com/hg/tinc/runs/5807386977?check_suite_focus=true#step:6:51533
https://github.com/hg/tinc/runs/5806692838?check_suite_focus=true#step:6:48233

So it's likely a tinc bug. I don't have access to macOS, and it's not easy to trigger to debug on CI machines. Can't help much here.

c1c5263 is a quick and dirty fix for #361. Don't pay much attention to it. I'll look into it while you're reviewing tests.","Drive-by question: I remember there was some interest in moving away from C. Do you consider slowly moving the project to C++ to be worth it (like GCC has been doing since 2010)? The way they did it IIRC is first making all headers includeable into C++ files, then renaming and fixing C files one by one, and then improving from there.
Although, if we want to keep support for ancient routers, there will be no C++11 for the foreseeable future, since GCC 4.2 is needed for those, and relatively complete C++11 support became available in GCC 4.8.

I created #364 so we can discuss things there. I don't think anything before C++11 is desirable.",True,{'THUMBS_UP': ['https://github.com/hg']}
gsliepen/tinc,https://github.com/gsliepen/tinc,362,2022-04-06T19:33:49Z,2022-04-10T09:56:56Z,2022-04-10T09:56:56Z,MERGED,True,3363,2171,78,https://github.com/hg,Rewrite tests in Python for better OS compatibility,5,[],https://github.com/gsliepen/tinc/pull/362,https://github.com/hg,9,https://github.com/gsliepen/tinc/pull/362#issuecomment-1094226885,"These depend only on the standard library of Python 3.6 or later (used by RHEL 7; other distributions have newer versions). If system Python is missing, it falls back to the one used by meson.
Tests are using a somewhat different approach compared to the current suite. There are no hardcoded ports and Port 0 is used everywhere, but now we have to do the dance of starting nodes in a particular order and parsing their pidfiles to know the real port they listen on.
You have to pay more attention when writing tests, but it's the only reliable solution I could find from extensively testing a dozen ideas that allows us to keep full parallel test execution.

  Some other things that were tried

hardcoding port numbers, like in the current test suite — forces you to run all tests serially, or drop support for --repeat (which I don't think is possible to disable, so it's just something you have to know about); and there can still be conflicts with other software.
generating random ports using random.randint() with shared port range for all tests (1024 to 65535) — tolerable when running 4 tests in parallel, unusable with 16 or more.
same, but splitting it into smaller unique ranges, one for each test (slightly better than the previous one, not worth it).
same, but using hacks to try to exclude ports typically used for connect() (hopefully less conflicts with ""client"" ports, not much difference in practice).
binding a throwaway socket to port 0 and letting the OS choose a port, then binding tincd to that port (significantly more conflicts than trying ports randomly, Linux seems to use a very short port range, and further halves it to leave the other half for ""client"" ports, and this really shows in practice).
using random ports and binding tincd to randomly generated addresses in 127.0.0.0/8 — good stability and clear test code, but requires configuring the system on everything that's not Linux or Windows.
using a separate server which can be asked by test scripts to pick a port using one of the previous methods (so port allocation happens in a single place instead of spreading it throughout tests — it can make sure it doesn't give the same port twice) — not bad in practice, but is so convoluted I didn't push it past a simple prototype.
locking each test on a separate lock file to prevent it from running multiple copies in parallel.
and a few other hacks.


If you'd rather keep tests simpler, I don't see any other solution than to disable parallel test execution completely on everything other than Linux and Windows (where we can use the full subnet 127.0.0.0/8 and randomly generate both addresses for ListenAddress and ports for Port), or write an alternative test harness that doesn't run the same test multiple times in parallel (you can't disable this with meson).
Basic architecture
I intentionally kept things simple so there are fewer layers to unwrap if it gets in the way in more complicated tests.

meson starts the test script
test imports the required pieces of the testing library
it starts a notification server which receives event notifications from tincd scripts (the same idea we had in the old test suite, but here it's using UNIX sockets/Windows pipes instead of tail + grep)
you create a test context (a class named Test), and use it to get instances of a class named Tinc (the context remembers Tincs it has issued and uses them as described below)
you initialize the nodes using that Tinc (it's a thin wrapper around subprocess), and start issuing commands to them using one of these methods:

tinc() — start tinc with the specified arguments and return Popen
tincd() — same, but for tincd
cmd() — a convenience wrapper around tinc() which can pass text snippets into stdin, checks the return code for you, and returns (stdout, stderr)
and a few more, it's all commented.


when a test context exits (leaves the with statement), it stops every tinc and tincd started from it, and kills everything that refuses to stop.

If you initialize instances of the Tinc class directly, they won't be stopped automatically.
Tinc can also register tincd scripts and returns objects that let you wait on notifications from those scripts. Only one event is needed now (and thus only one is supported), but it's easy to add more.
There are some assertions (which should be used instead of the built-in assert because it doesn't print values on failure), a global logger, and a few helper functions for more complicated commands like exchange so the logic isn't repeated in several places.
Known issues
scripts.py
Port checks were dumbed down to checking that a non-empty value was passed. tincd on Windows behaves really strange with dynamically allocated ports on both sides of the connection, and I couldn't make it work after wasting half a day on it.
We have three choices here:

disable this test on Windows
use randomly generated port instead of Port 0 (and get intermittent test failures because of port conflicts)
keep the current basic check.

I don't think any other test functionality was lost. invite-offline.test and invite-online.test are rolled into invite.py.
Crashes on Alpine
Example.
SIGSEGV in a Python process that's running the test. Since there's no unsafe code in tests, I suspect this is because of musl.
These are pretty rare, just wanted you to be aware of them.
Failures on macOS
Same issue we have with the current test suite:
Cannot read greeting from control socket: No such file or directory

although tinc should definitely be able to connect to tincd because it is only started after we get a go-ahead from tinc-up.

https://github.com/hg/tinc/runs/5807386977?check_suite_focus=true#step:6:51533
https://github.com/hg/tinc/runs/5806692838?check_suite_focus=true#step:6:48233

So it's likely a tinc bug. I don't have access to macOS, and it's not easy to trigger to debug on CI machines. Can't help much here.

c1c5263 is a quick and dirty fix for #361. Don't pay much attention to it. I'll look into it while you're reviewing tests.","Probably not. security.py could see some improvement, but I have no idea how to go about it yet.
I ran some additional tests on local VMs, and it's been fine (not as extensive, though: only 4 CPUs, 1000 iterations on Windows, and 500 on each of the three BSDs and Solaris).",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,362,2022-04-06T19:33:49Z,2022-04-10T09:56:56Z,2022-04-10T09:56:56Z,MERGED,True,3363,2171,78,https://github.com/hg,Rewrite tests in Python for better OS compatibility,5,[],https://github.com/gsliepen/tinc/pull/362,https://github.com/gsliepen,10,https://github.com/gsliepen/tinc/pull/362#issuecomment-1094234483,"These depend only on the standard library of Python 3.6 or later (used by RHEL 7; other distributions have newer versions). If system Python is missing, it falls back to the one used by meson.
Tests are using a somewhat different approach compared to the current suite. There are no hardcoded ports and Port 0 is used everywhere, but now we have to do the dance of starting nodes in a particular order and parsing their pidfiles to know the real port they listen on.
You have to pay more attention when writing tests, but it's the only reliable solution I could find from extensively testing a dozen ideas that allows us to keep full parallel test execution.

  Some other things that were tried

hardcoding port numbers, like in the current test suite — forces you to run all tests serially, or drop support for --repeat (which I don't think is possible to disable, so it's just something you have to know about); and there can still be conflicts with other software.
generating random ports using random.randint() with shared port range for all tests (1024 to 65535) — tolerable when running 4 tests in parallel, unusable with 16 or more.
same, but splitting it into smaller unique ranges, one for each test (slightly better than the previous one, not worth it).
same, but using hacks to try to exclude ports typically used for connect() (hopefully less conflicts with ""client"" ports, not much difference in practice).
binding a throwaway socket to port 0 and letting the OS choose a port, then binding tincd to that port (significantly more conflicts than trying ports randomly, Linux seems to use a very short port range, and further halves it to leave the other half for ""client"" ports, and this really shows in practice).
using random ports and binding tincd to randomly generated addresses in 127.0.0.0/8 — good stability and clear test code, but requires configuring the system on everything that's not Linux or Windows.
using a separate server which can be asked by test scripts to pick a port using one of the previous methods (so port allocation happens in a single place instead of spreading it throughout tests — it can make sure it doesn't give the same port twice) — not bad in practice, but is so convoluted I didn't push it past a simple prototype.
locking each test on a separate lock file to prevent it from running multiple copies in parallel.
and a few other hacks.


If you'd rather keep tests simpler, I don't see any other solution than to disable parallel test execution completely on everything other than Linux and Windows (where we can use the full subnet 127.0.0.0/8 and randomly generate both addresses for ListenAddress and ports for Port), or write an alternative test harness that doesn't run the same test multiple times in parallel (you can't disable this with meson).
Basic architecture
I intentionally kept things simple so there are fewer layers to unwrap if it gets in the way in more complicated tests.

meson starts the test script
test imports the required pieces of the testing library
it starts a notification server which receives event notifications from tincd scripts (the same idea we had in the old test suite, but here it's using UNIX sockets/Windows pipes instead of tail + grep)
you create a test context (a class named Test), and use it to get instances of a class named Tinc (the context remembers Tincs it has issued and uses them as described below)
you initialize the nodes using that Tinc (it's a thin wrapper around subprocess), and start issuing commands to them using one of these methods:

tinc() — start tinc with the specified arguments and return Popen
tincd() — same, but for tincd
cmd() — a convenience wrapper around tinc() which can pass text snippets into stdin, checks the return code for you, and returns (stdout, stderr)
and a few more, it's all commented.


when a test context exits (leaves the with statement), it stops every tinc and tincd started from it, and kills everything that refuses to stop.

If you initialize instances of the Tinc class directly, they won't be stopped automatically.
Tinc can also register tincd scripts and returns objects that let you wait on notifications from those scripts. Only one event is needed now (and thus only one is supported), but it's easy to add more.
There are some assertions (which should be used instead of the built-in assert because it doesn't print values on failure), a global logger, and a few helper functions for more complicated commands like exchange so the logic isn't repeated in several places.
Known issues
scripts.py
Port checks were dumbed down to checking that a non-empty value was passed. tincd on Windows behaves really strange with dynamically allocated ports on both sides of the connection, and I couldn't make it work after wasting half a day on it.
We have three choices here:

disable this test on Windows
use randomly generated port instead of Port 0 (and get intermittent test failures because of port conflicts)
keep the current basic check.

I don't think any other test functionality was lost. invite-offline.test and invite-online.test are rolled into invite.py.
Crashes on Alpine
Example.
SIGSEGV in a Python process that's running the test. Since there's no unsafe code in tests, I suspect this is because of musl.
These are pretty rare, just wanted you to be aware of them.
Failures on macOS
Same issue we have with the current test suite:
Cannot read greeting from control socket: No such file or directory

although tinc should definitely be able to connect to tincd because it is only started after we get a go-ahead from tinc-up.

https://github.com/hg/tinc/runs/5807386977?check_suite_focus=true#step:6:51533
https://github.com/hg/tinc/runs/5806692838?check_suite_focus=true#step:6:48233

So it's likely a tinc bug. I don't have access to macOS, and it's not easy to trigger to debug on CI machines. Can't help much here.

c1c5263 is a quick and dirty fix for #361. Don't pay much attention to it. I'll look into it while you're reviewing tests.","Ok, I've been running 6 test suites in parallel for the last hour (about 2000 invocations in total), and no errors. This definitely was not possible with the old suite. So I'll merge it now and we can do improvements afterwards.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,365,2022-04-10T10:28:00Z,2022-04-10T12:16:53Z,2022-04-10T12:16:53Z,MERGED,True,2,2,1,https://github.com/hg,CI: fix paths in Windows installer script for the dev release,1,[],https://github.com/gsliepen/tinc/pull/365,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/365,"My bad. I forgot about the installer, since it only runs on pushes to the main branch.
I'll start always doing that with my ""fork"" to avoid this situation in the future.
https://github.com/hg/tinc/releases/tag/latest
The failure in static analysis job was entirely GitHub's fault; it happens relatively frequently.","My bad. I forgot about the installer, since it only runs on pushes to the main branch.
I'll start always doing that with my ""fork"" to avoid this situation in the future.
https://github.com/hg/tinc/releases/tag/latest
The failure in static analysis job was entirely GitHub's fault; it happens relatively frequently.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,366,2022-04-11T19:08:04Z,2022-04-11T20:02:42Z,2022-04-11T20:02:42Z,MERGED,True,110,53,4,https://github.com/hg,Reduce duplication in request handler tables,1,[],https://github.com/gsliepen/tinc/pull/366,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/366,"A couple of small refactors. Nothing serious, just some things I noticed while getting acquainted with the codebase.
They're now closer together so there's less chance for messing up the order, and we always do bounds checks now (the table is hidden inside a function so you can't use it directly).","A couple of small refactors. Nothing serious, just some things I noticed while getting acquainted with the codebase.
They're now closer together so there's less chance for messing up the order, and we always do bounds checks now (the table is hidden inside a function so you can't use it directly).",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,367,2022-04-11T19:08:09Z,2022-04-21T18:37:28Z,2022-04-21T18:37:28Z,CLOSED,False,297,157,30,https://github.com/hg,Use struct for legacy proto fields in connection_t,4,[],https://github.com/gsliepen/tinc/pull/367,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/367,I remember reading quite a while ago that legacy protocol stuff in connection_t should be separated into another struct. Was this what you meant?,I remember reading quite a while ago that legacy protocol stuff in connection_t should be separated into another struct. Was this what you meant?,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,367,2022-04-11T19:08:09Z,2022-04-21T18:37:28Z,2022-04-21T18:37:28Z,CLOSED,False,297,157,30,https://github.com/hg,Use struct for legacy proto fields in connection_t,4,[],https://github.com/gsliepen/tinc/pull/367,https://github.com/gsliepen,2,https://github.com/gsliepen/tinc/pull/367#issuecomment-1105621279,I remember reading quite a while ago that legacy protocol stuff in connection_t should be separated into another struct. Was this what you meant?,Rebased as 3919851,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,368,2022-04-11T19:08:13Z,2022-04-12T17:43:57Z,2022-04-12T17:43:58Z,CLOSED,False,341,259,30,https://github.com/hg,Changes to cryptographic RNG,1,[],https://github.com/gsliepen/tinc/pull/368,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/368,"extract copypasted code into a separate file
use it for libgcrypt (since we're already using it for OpenSSL, even though it provides its own generator)
add support for getrandom() on Linux

getrandom doesn't add very much, but it's also practically free to support; takes one open file descriptor away, adds the ability to work in badly configured chroots/containers where /dev/(u)random is missing.","extract copypasted code into a separate file
use it for libgcrypt (since we're already using it for OpenSSL, even though it provides its own generator)
add support for getrandom() on Linux

getrandom doesn't add very much, but it's also practically free to support; takes one open file descriptor away, adds the ability to work in badly configured chroots/containers where /dev/(u)random is missing.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,368,2022-04-11T19:08:13Z,2022-04-12T17:43:57Z,2022-04-12T17:43:58Z,CLOSED,False,341,259,30,https://github.com/hg,Changes to cryptographic RNG,1,[],https://github.com/gsliepen/tinc/pull/368,https://github.com/gsliepen,2,https://github.com/gsliepen/tinc/pull/368#issuecomment-1097012683,"extract copypasted code into a separate file
use it for libgcrypt (since we're already using it for OpenSSL, even though it provides its own generator)
add support for getrandom() on Linux

getrandom doesn't add very much, but it's also practically free to support; takes one open file descriptor away, adds the ability to work in badly configured chroots/containers where /dev/(u)random is missing.",Great! I don't think there's anything wrong with the expectedfailure test. Cherry-picked as 0fe6990.,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,369,2022-04-13T17:27:12Z,2022-04-28T18:35:12Z,2022-04-28T18:35:13Z,MERGED,True,211,4,7,https://github.com/hg,Convert tincd path args to absolute paths,1,[],https://github.com/gsliepen/tinc/pull/369,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/369,"Ran into this many times when testing tinc manually:
$ mkdir x
$ tinc -c x init foo
$ tinc -c x set DeviceType dummy
$ tincd -c x -D
Cannot open config file x/tinc.conf: No such file or directory
Failed to read `x/tinc.conf': No such file or directory

while absolute paths work fine:
$ tincd -c $PWD/x -D

It happens because tincd stores paths as they were passed, then does chdir to its configuration directory, and then tries to fopen.
I went for the simplest solution — resolve all paths to absolute before doing chdir.
Sadly, realpath fails if path does not exist (which is a problem for pidfile and logfile), so if that happens we fall back to concatenating getcwd and whatever was passed by the user.
It's what others are using, with the exception that we're skipping normalization (fopen works either way, and I don't think it makes sense to drag so much complexity to make logs a bit prettier).
Not sure about logfile and pidfile. If you pass relative paths, they currently work as relative to configuration directory, although it isn't obvious and is not mentioned in the documentation. With this PR it's a bit more consistent, but may cause regressions (although 1.1 is officially a development release).
What are your thoughts? We could use the old behavior for these two, and get rid of absolute_path (realpath will do since configuration directory must exist before starting tincd).","Ran into this many times when testing tinc manually:
$ mkdir x
$ tinc -c x init foo
$ tinc -c x set DeviceType dummy
$ tincd -c x -D
Cannot open config file x/tinc.conf: No such file or directory
Failed to read `x/tinc.conf': No such file or directory

while absolute paths work fine:
$ tincd -c $PWD/x -D

It happens because tincd stores paths as they were passed, then does chdir to its configuration directory, and then tries to fopen.
I went for the simplest solution — resolve all paths to absolute before doing chdir.
Sadly, realpath fails if path does not exist (which is a problem for pidfile and logfile), so if that happens we fall back to concatenating getcwd and whatever was passed by the user.
It's what others are using, with the exception that we're skipping normalization (fopen works either way, and I don't think it makes sense to drag so much complexity to make logs a bit prettier).
Not sure about logfile and pidfile. If you pass relative paths, they currently work as relative to configuration directory, although it isn't obvious and is not mentioned in the documentation. With this PR it's a bit more consistent, but may cause regressions (although 1.1 is officially a development release).
What are your thoughts? We could use the old behavior for these two, and get rid of absolute_path (realpath will do since configuration directory must exist before starting tincd).",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,369,2022-04-13T17:27:12Z,2022-04-28T18:35:12Z,2022-04-28T18:35:13Z,MERGED,True,211,4,7,https://github.com/hg,Convert tincd path args to absolute paths,1,[],https://github.com/gsliepen/tinc/pull/369,https://github.com/gsliepen,2,https://github.com/gsliepen/tinc/pull/369#issuecomment-1098371921,"Ran into this many times when testing tinc manually:
$ mkdir x
$ tinc -c x init foo
$ tinc -c x set DeviceType dummy
$ tincd -c x -D
Cannot open config file x/tinc.conf: No such file or directory
Failed to read `x/tinc.conf': No such file or directory

while absolute paths work fine:
$ tincd -c $PWD/x -D

It happens because tincd stores paths as they were passed, then does chdir to its configuration directory, and then tries to fopen.
I went for the simplest solution — resolve all paths to absolute before doing chdir.
Sadly, realpath fails if path does not exist (which is a problem for pidfile and logfile), so if that happens we fall back to concatenating getcwd and whatever was passed by the user.
It's what others are using, with the exception that we're skipping normalization (fopen works either way, and I don't think it makes sense to drag so much complexity to make logs a bit prettier).
Not sure about logfile and pidfile. If you pass relative paths, they currently work as relative to configuration directory, although it isn't obvious and is not mentioned in the documentation. With this PR it's a bit more consistent, but may cause regressions (although 1.1 is officially a development release).
What are your thoughts? We could use the old behavior for these two, and get rid of absolute_path (realpath will do since configuration directory must exist before starting tincd).","Your solution fails if you also use the --chroot option (not that it worked well before).
There are two reasons why we chdir():

Ensure we don't keep an arbitrary mount point busy
Ensure scripts are started with a predictable working directory

I think the best way would be to open the pidfile, logfile and control socket before calling chdir(), then after chdir() open tinc.conf and other config files without prepending confbase to it, because we know we already chdir()'ed into the configuration directory. The only question is how this will interact with daemon(), or worse, Windows's way of starting a service.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,369,2022-04-13T17:27:12Z,2022-04-28T18:35:12Z,2022-04-28T18:35:13Z,MERGED,True,211,4,7,https://github.com/hg,Convert tincd path args to absolute paths,1,[],https://github.com/gsliepen/tinc/pull/369,https://github.com/gsliepen,3,https://github.com/gsliepen/tinc/pull/369#issuecomment-1110246825,"Ran into this many times when testing tinc manually:
$ mkdir x
$ tinc -c x init foo
$ tinc -c x set DeviceType dummy
$ tincd -c x -D
Cannot open config file x/tinc.conf: No such file or directory
Failed to read `x/tinc.conf': No such file or directory

while absolute paths work fine:
$ tincd -c $PWD/x -D

It happens because tincd stores paths as they were passed, then does chdir to its configuration directory, and then tries to fopen.
I went for the simplest solution — resolve all paths to absolute before doing chdir.
Sadly, realpath fails if path does not exist (which is a problem for pidfile and logfile), so if that happens we fall back to concatenating getcwd and whatever was passed by the user.
It's what others are using, with the exception that we're skipping normalization (fopen works either way, and I don't think it makes sense to drag so much complexity to make logs a bit prettier).
Not sure about logfile and pidfile. If you pass relative paths, they currently work as relative to configuration directory, although it isn't obvious and is not mentioned in the documentation. With this PR it's a bit more consistent, but may cause regressions (although 1.1 is officially a development release).
What are your thoughts? We could use the old behavior for these two, and get rid of absolute_path (realpath will do since configuration directory must exist before starting tincd).","Hm, this is more difficult than I thought. Opening files before chdir()/chroot() is not enough; we want to be able to clean up PID files if we quit, and reopen log files if there's a HUP signal (to allow log rotation). We also have the daemon doing chdir() but the CLI not, and some code that builds path names is shared between them. So making absolute paths looks like the best solution after all.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,370,2022-04-16T08:20:33Z,2022-04-22T20:22:18Z,2022-04-22T20:22:18Z,MERGED,True,434,231,37,https://github.com/hg,Wipe (some) secrets from memory after use,2,[],https://github.com/gsliepen/tinc/pull/370,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/370,"While not a panacea, this is considered to be a good practice which doesn't cost us much.
The cryptographic libraries we're using are already doing that for some of their own data structures. This should additionally cover EC keys, a few strings potentially containing passwords, and various temporary key buffers.

I finally remembered to add libgcrypt to CI. This is not related to the main PR, but is bundled here to avoid creating even more conflicts.","While not a panacea, this is considered to be a good practice which doesn't cost us much.
The cryptographic libraries we're using are already doing that for some of their own data structures. This should additionally cover EC keys, a few strings potentially containing passwords, and various temporary key buffers.

I finally remembered to add libgcrypt to CI. This is not related to the main PR, but is bundled here to avoid creating even more conflicts.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,370,2022-04-16T08:20:33Z,2022-04-22T20:22:18Z,2022-04-22T20:22:18Z,MERGED,True,434,231,37,https://github.com/hg,Wipe (some) secrets from memory after use,2,[],https://github.com/gsliepen/tinc/pull/370,https://github.com/hg,2,https://github.com/gsliepen/tinc/pull/370#issuecomment-1106494657,"While not a panacea, this is considered to be a good practice which doesn't cost us much.
The cryptographic libraries we're using are already doing that for some of their own data structures. This should additionally cover EC keys, a few strings potentially containing passwords, and various temporary key buffers.

I finally remembered to add libgcrypt to CI. This is not related to the main PR, but is bundled here to avoid creating even more conflicts.","Good idea, thanks. I also added explicit_memset() since NetBSD decided to be a special snowflake in that regard. Now the fallback shouldn't be used by anything.

Another drive-by question: I've been updating man pages recently, and not having had the chance to write roff in the past, it's been… a bit of a rough ride. Macro names are really non-obvious, whitespace rules are somewhat arcane, and there are basically no modern tutorials for those who don't like to read (colorful, glossy, and and ridden with emoji, like you'd expect in the 21st century).
Now, I don't care about that much (most of the pain has been overcome by now), but if we hope to attract more contributors in the coming years, maybe it makes sense to look for more modern alternatives?
Like scdoc, which provides markdown-ish syntax, compiles into roff, is written in C (and is tiny), and available everywhere.
I mean, compare this to this or this (or even this, since it resembles markdown enough that GitHub markdown renderer mistakes it for one).
Now, markdown can be converted into man pages, but that requires something like pandoc, which is pretty heavy, while scdoc binary package on my system is around 30 KBs.
The downside is obvious — it adds another build dependency (although we can write scdoc, convert it to roff, and add that roff to the source tree).
Yes/no?",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,370,2022-04-16T08:20:33Z,2022-04-22T20:22:18Z,2022-04-22T20:22:18Z,MERGED,True,434,231,37,https://github.com/hg,Wipe (some) secrets from memory after use,2,[],https://github.com/gsliepen/tinc/pull/370,https://github.com/gsliepen,3,https://github.com/gsliepen/tinc/pull/370#issuecomment-1106828227,"While not a panacea, this is considered to be a good practice which doesn't cost us much.
The cryptographic libraries we're using are already doing that for some of their own data structures. This should additionally cover EC keys, a few strings potentially containing passwords, and various temporary key buffers.

I finally remembered to add libgcrypt to CI. This is not related to the main PR, but is bundled here to avoid creating even more conflicts.","Looks good!

Tinc uses the mdoc macros, which is already a higher level than pure roff, and intends to convey semantics instead of just how you want to style things (think LaTeX vs. TeX). In the past I was not too happy with the existing manpage generators, but perhaps they are better today.
As for scdoc, it looks cute, but whether it is tiny or not doesn't make much of a difference to someone who needs to install it as yet another dependency. I personally also find it very irritating that it's almost Markdown but didn't just go all the way. OTOH, I see scdoc is available in many package managers, which is great. If we go this route then maybe we can consider writing the manual in Markdown or something similar as well. Even more ideal would be to avoid the duplication of the documentation of command line and config file options.",True,{'THUMBS_UP': ['https://github.com/hg']}
gsliepen/tinc,https://github.com/gsliepen/tinc,371,2022-04-17T07:53:28Z,2022-04-21T18:28:36Z,2022-04-21T18:31:59Z,MERGED,True,524,138,19,https://github.com/hg,Handle `Port 0`: use actual port in tincd logs / tinc get Port / invitation URLs and files,2,[],https://github.com/gsliepen/tinc/pull/371,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/371,"This should cover #363.
Because TCP and UDP ports can differ if Port 0 is used, myport was converted to a struct.
Since communication with tincd involves parsing the pidfile, we read the port from there instead of asking tincd. This is simpler, and does not requre adding more control request types, breaking compatibility with older daemons.
I had to write a small piece of yet another configuration parser. I'll look into extracting them into a separate 'library' so we don't reimplement the wheel over and over again.","This should cover #363.
Because TCP and UDP ports can differ if Port 0 is used, myport was converted to a struct.
Since communication with tincd involves parsing the pidfile, we read the port from there instead of asking tincd. This is simpler, and does not requre adding more control request types, breaking compatibility with older daemons.
I had to write a small piece of yet another configuration parser. I'll look into extracting them into a separate 'library' so we don't reimplement the wheel over and over again.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,371,2022-04-17T07:53:28Z,2022-04-21T18:28:36Z,2022-04-21T18:31:59Z,MERGED,True,524,138,19,https://github.com/hg,Handle `Port 0`: use actual port in tincd logs / tinc get Port / invitation URLs and files,2,[],https://github.com/gsliepen/tinc/pull/371,https://github.com/gsliepen,2,https://github.com/gsliepen/tinc/pull/371#issuecomment-1104263512,"This should cover #363.
Because TCP and UDP ports can differ if Port 0 is used, myport was converted to a struct.
Since communication with tincd involves parsing the pidfile, we read the port from there instead of asking tincd. This is simpler, and does not requre adding more control request types, breaking compatibility with older daemons.
I had to write a small piece of yet another configuration parser. I'll look into extracting them into a separate 'library' so we don't reimplement the wheel over and over again.","This is already an improvement. However, if I start tinc with Port 0 it currently is listening on 4 different ports, because of having both TCP and UDP sockets on both IPv4 and IPv6. Part of the protocol assumes that there is just one port tinc is listening in for everything. With two daemons listening on Port 0, with your patch it would be possible to have one invite the other via IPv4. However, if they were both dual-stacked but there was no viable IPv4 connection between them, only IPv6, they would not be able to join. Also, UDP would fail to work.
A possible solution is to check after binding the first TCP listening port what the actual port is (this can be done using getsockname()). Then it can use that port for all other sockets. If a subsequent listening socket fails to bind, you could still fall back to port 0 for that socket.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,371,2022-04-17T07:53:28Z,2022-04-21T18:28:36Z,2022-04-21T18:31:59Z,MERGED,True,524,138,19,https://github.com/hg,Handle `Port 0`: use actual port in tincd logs / tinc get Port / invitation URLs and files,2,[],https://github.com/gsliepen/tinc/pull/371,https://github.com/hg,3,https://github.com/gsliepen/tinc/pull/371#issuecomment-1105177590,"This should cover #363.
Because TCP and UDP ports can differ if Port 0 is used, myport was converted to a struct.
Since communication with tincd involves parsing the pidfile, we read the port from there instead of asking tincd. This is simpler, and does not requre adding more control request types, breaking compatibility with older daemons.
I had to write a small piece of yet another configuration parser. I'll look into extracting them into a separate 'library' so we don't reimplement the wheel over and over again.","Good idea. This should cover it.
udp   UNCONN 0      0      0.0.0.0:35887      0.0.0.0:*
udp   UNCONN 0      0         [::]:35887         [::]:*
tcp   LISTEN 0      3      0.0.0.0:35887      0.0.0.0:*
tcp   LISTEN 0      3         [::]:35887         [::]:*

re CI failure: ugh. I wish there was an active macOS user among the developers. Apple really doesn't want you to support their OS.
GitHub CI has a 6-hour time limit, and you can SSH in there through third-party hacks like this one. I'll see if that'd be enough to debug the issues we've been having.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,371,2022-04-17T07:53:28Z,2022-04-21T18:28:36Z,2022-04-21T18:31:59Z,MERGED,True,524,138,19,https://github.com/hg,Handle `Port 0`: use actual port in tincd logs / tinc get Port / invitation URLs and files,2,[],https://github.com/gsliepen/tinc/pull/371,https://github.com/gsliepen,4,https://github.com/gsliepen/tinc/pull/371#issuecomment-1105615945,"This should cover #363.
Because TCP and UDP ports can differ if Port 0 is used, myport was converted to a struct.
Since communication with tincd involves parsing the pidfile, we read the port from there instead of asking tincd. This is simpler, and does not requre adding more control request types, breaking compatibility with older daemons.
I had to write a small piece of yet another configuration parser. I'll look into extracting them into a separate 'library' so we don't reimplement the wheel over and over again.",I have a Mac Mini I tested it on.,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,372,2022-04-18T10:33:46Z,2022-04-28T21:30:46Z,2022-04-28T21:30:46Z,MERGED,True,227,161,56,https://github.com/hg,Changes to compiler flags & function attributes,2,[],https://github.com/gsliepen/tinc/pull/372,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/372,"Bits and pieces that are somewhat related:

change some compiler flags:

enable CFI checks (no effect on older CPUs, does this on modern x86; the article is about the kernel, but the tech is similar). Ubuntu has been doing that for years.
add more stack smashing checks (and make stack non-executable)
enable more warnings on top of -Wall -Wextra (particularly warn about VLAs which we cannot use anymore because of MSVC, and about missing enum cases, which helps when adding new values to enums)


fix warnings triggered by new flags
since doing that involves adding a bunch of __attribute__((format)), use the opportunity to add __attribute__((malloc(dealloc)) so newer GCC warn us about using wrong deallocators
fix a couple of leaks found by -fanalyzer (gives lots of false positives, so it's a bit early to enable it permanently)
use current year in copyright messages

Currently tinc --version says the copyright expired 3 years ago, tincd --version has its own opinion on this.
Let's just get the year from the OS and never touch the message again.

I would have posted this separately, but only cbadb52 can be split off without causing more conflicts (of which are are enough already from previous PRs), and it's only three lines.","Bits and pieces that are somewhat related:

change some compiler flags:

enable CFI checks (no effect on older CPUs, does this on modern x86; the article is about the kernel, but the tech is similar). Ubuntu has been doing that for years.
add more stack smashing checks (and make stack non-executable)
enable more warnings on top of -Wall -Wextra (particularly warn about VLAs which we cannot use anymore because of MSVC, and about missing enum cases, which helps when adding new values to enums)


fix warnings triggered by new flags
since doing that involves adding a bunch of __attribute__((format)), use the opportunity to add __attribute__((malloc(dealloc)) so newer GCC warn us about using wrong deallocators
fix a couple of leaks found by -fanalyzer (gives lots of false positives, so it's a bit early to enable it permanently)
use current year in copyright messages

Currently tinc --version says the copyright expired 3 years ago, tincd --version has its own opinion on this.
Let's just get the year from the OS and never touch the message again.

I would have posted this separately, but only cbadb52 can be split off without causing more conflicts (of which are are enough already from previous PRs), and it's only three lines.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,375,2022-04-22T06:22:36Z,2022-04-22T19:44:57Z,2022-04-22T19:44:58Z,MERGED,True,16,0,2,https://github.com/hg,CI: fix building Ubuntu packages (and ignore further failures),3,[],https://github.com/gsliepen/tinc/pull/375,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/375,"The issue is described here. It's pretty wild to have breaking changes in a stable distribution, even though it's a security fix.
Package jobs turned out to be a pain. Since it's a just a minor additional feature of having CI and not its main task, let's not mark jobs as failed if it couldn't build or upload packages.
I'll still be looking at full results and fixing issues as they crop up.","The issue is described here. It's pretty wild to have breaking changes in a stable distribution, even though it's a security fix.
Package jobs turned out to be a pain. Since it's a just a minor additional feature of having CI and not its main task, let's not mark jobs as failed if it couldn't build or upload packages.
I'll still be looking at full results and fixing issues as they crop up.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,376,2022-04-22T14:03:09Z,2022-04-22T20:20:41Z,2022-04-22T20:20:41Z,MERGED,True,39,17,2,https://github.com/hg,Add building quickstart to the top of README.md,1,[],https://github.com/gsliepen/tinc/pull/376,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/376,"Written to be as short as possible. We have INSTALL.md, but its existence is not very obvious, and it's pretty detailed and long-winded.","Written to be as short as possible. We have INSTALL.md, but its existence is not very obvious, and it's pretty detailed and long-winded.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,377,2022-04-23T07:09:05Z,2022-04-26T17:37:16Z,2022-04-26T17:37:17Z,MERGED,True,165,22,10,https://github.com/hg,Timestamps and a bit of color in tincd `stderr` logs,1,[],https://github.com/gsliepen/tinc/pull/377,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/377,"I've been using this recently to make important messages easier to see during debugging. Don't know what your opinion is on toys like this, so just throwing it out there.
Should work on Windows since ~2015 (on older versions SetConsoleMode() will fail and we keep colors off).
The test on other operating systems is similar to what GCC does.
Only the 16-color palette is used, with the exception of gray (it's from the 8-bit one). Should be available everywhere by now.","I've been using this recently to make important messages easier to see during debugging. Don't know what your opinion is on toys like this, so just throwing it out there.
Should work on Windows since ~2015 (on older versions SetConsoleMode() will fail and we keep colors off).
The test on other operating systems is similar to what GCC does.
Only the 16-color palette is used, with the exception of gray (it's from the 8-bit one). Should be available everywhere by now.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,377,2022-04-23T07:09:05Z,2022-04-26T17:37:16Z,2022-04-26T17:37:17Z,MERGED,True,165,22,10,https://github.com/hg,Timestamps and a bit of color in tincd `stderr` logs,1,[],https://github.com/gsliepen/tinc/pull/377,https://github.com/hg,2,https://github.com/gsliepen/tinc/pull/377#issuecomment-1107409284,"I've been using this recently to make important messages easier to see during debugging. Don't know what your opinion is on toys like this, so just throwing it out there.
Should work on Windows since ~2015 (on older versions SetConsoleMode() will fail and we keep colors off).
The test on other operating systems is similar to what GCC does.
Only the 16-color palette is used, with the exception of gray (it's from the 8-bit one). Should be available everywhere by now.","Well, this is weird. The check that's failing UBSAN is disabled:
https://github.com/gsliepen/tinc/blob/1.1/.ci/sanitizers/run.sh#L11
and it was working fine yesterday, but now it stopped caring for some reason.
I think I'll just move sanitizer jobs to containers, similar to how other tests are run. GitHub virtual environments are painful to deal with directly.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,377,2022-04-23T07:09:05Z,2022-04-26T17:37:16Z,2022-04-26T17:37:17Z,MERGED,True,165,22,10,https://github.com/hg,Timestamps and a bit of color in tincd `stderr` logs,1,[],https://github.com/gsliepen/tinc/pull/377,https://github.com/gsliepen,3,https://github.com/gsliepen/tinc/pull/377#issuecomment-1107467630,"I've been using this recently to make important messages easier to see during debugging. Don't know what your opinion is on toys like this, so just throwing it out there.
Should work on Windows since ~2015 (on older versions SetConsoleMode() will fail and we keep colors off).
The test on other operating systems is similar to what GCC does.
Only the 16-color palette is used, with the exception of gray (it's from the 8-bit one). Should be available everywhere by now.",Sure. The only drawback is that you are only coloring the stderr output when running tinc in the foreground. It would be nice if the output of tinc log and the log messages sent via the umbilical fd when tinc start spawns tincd would also have the same format and coloring.,True,{'THUMBS_UP': ['https://github.com/hg']}
gsliepen/tinc,https://github.com/gsliepen/tinc,377,2022-04-23T07:09:05Z,2022-04-26T17:37:16Z,2022-04-26T17:37:17Z,MERGED,True,165,22,10,https://github.com/hg,Timestamps and a bit of color in tincd `stderr` logs,1,[],https://github.com/gsliepen/tinc/pull/377,https://github.com/hg,4,https://github.com/gsliepen/tinc/pull/377#issuecomment-1108907834,"I've been using this recently to make important messages easier to see during debugging. Don't know what your opinion is on toys like this, so just throwing it out there.
Should work on Windows since ~2015 (on older versions SetConsoleMode() will fail and we keep colors off).
The test on other operating systems is similar to what GCC does.
Only the 16-color palette is used, with the exception of gray (it's from the 8-bit one). Should be available everywhere by now.","Good idea, thanks for the suggestion.
It's a bit contrived since we need to support multiple concurrent tinc logs, some of which may not be able to show colors.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,378,2022-04-23T19:13:10Z,2022-04-24T20:21:53Z,2022-04-24T20:21:53Z,MERGED,True,1348,112,15,https://github.com/hg,Fix a few bugs in proxy support; add tests,1,[],https://github.com/gsliepen/tinc/pull/378,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/378,"I started writing this to check that exec proxy was not broken by sandboxing, but it's now large enough to post separately.
socks5 authentication didn't actually work since if you request it, socks5 servers send an additional two-byte message with authentication results, which wasn't checked correctly.
This not only shows with the hand-rolled Python proxy, but also with sockd (which I use heavily with many programs that support authenticated socks5).
Compare proxy responses for anonymous and authenticated socks5:
anon (ok)   50 50
anon (err)  50 52
auth (ok)   52 10 50

Error conditions are not covered by tests yet because tincd bails out too early and doesn't log the messages we need. It treats invalid responses as it should, so it's mostly a cosmetic issue. I'll fix that separately after more important things are done.","I started writing this to check that exec proxy was not broken by sandboxing, but it's now large enough to post separately.
socks5 authentication didn't actually work since if you request it, socks5 servers send an additional two-byte message with authentication results, which wasn't checked correctly.
This not only shows with the hand-rolled Python proxy, but also with sockd (which I use heavily with many programs that support authenticated socks5).
Compare proxy responses for anonymous and authenticated socks5:
anon (ok)   50 50
anon (err)  50 52
auth (ok)   52 10 50

Error conditions are not covered by tests yet because tincd bails out too early and doesn't log the messages we need. It treats invalid responses as it should, so it's mostly a cosmetic issue. I'll fix that separately after more important things are done.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,378,2022-04-23T19:13:10Z,2022-04-24T20:21:53Z,2022-04-24T20:21:53Z,MERGED,True,1348,112,15,https://github.com/hg,Fix a few bugs in proxy support; add tests,1,[],https://github.com/gsliepen/tinc/pull/378,https://github.com/hg,2,https://github.com/gsliepen/tinc/pull/378#issuecomment-1107885908,"I started writing this to check that exec proxy was not broken by sandboxing, but it's now large enough to post separately.
socks5 authentication didn't actually work since if you request it, socks5 servers send an additional two-byte message with authentication results, which wasn't checked correctly.
This not only shows with the hand-rolled Python proxy, but also with sockd (which I use heavily with many programs that support authenticated socks5).
Compare proxy responses for anonymous and authenticated socks5:
anon (ok)   50 50
anon (err)  50 52
auth (ok)   52 10 50

Error conditions are not covered by tests yet because tincd bails out too early and doesn't log the messages we need. It treats invalid responses as it should, so it's mostly a cosmetic issue. I'll fix that separately after more important things are done.","The patch is on the heavy side, but most of it are tests. Those are easy to get rid of.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,379,2022-04-25T13:47:31Z,2022-05-02T19:15:02Z,2022-05-02T19:15:03Z,MERGED,True,768,39,45,https://github.com/hg,Add basic sandboxing for OpenBSD,3,[],https://github.com/gsliepen/tinc/pull/379,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/379,"Uses pledge()/unveil() to limit what tincd/tinc can do after initialization finishes.
Paths are only restricted for tincd. It's not difficult to write a similar list for tincctl, but since it's a oneshot program which isn't running for months accepting random connections from around the internet, I don't think it makes much sense to do so, taking support costs into consideration.
sandbox is a meson option (and not a boolean) since it may come in handy when adding support for other operating systems (for example, only if libseccomp is present).
Can't call myself an experienced OpenBSD user, so if anyone knowledgeable is willing to test this — be my guest. I've been running this code for a few days without any issues, but it surely has the potential to cause breakage.

This PR also makes scripts optional by adding a new configuration variable DisableScripts.
Personally, I have no use for them. Network interfaces can be configured through other means.
This is what disabling scripts allows us to do:

drop access to fork() and execve() (but only if proxytype is not PROXY_EXEC — we notify the user in that case)

since we cannot put any restrictions on child processes (because they're expected to be able to do anything the user can do), this leaves a giant escape hatch in case of attack.
privileges are limited once everything is initialized, so daemon() is not a problem.


even if that somehow happens, limit our children's privileges to exit() and nothing else.
remove access to scriptinterpreter, /bin, /sbin, /usr/bin, /usr/local/bin, etc.
make stuff in tinc configuration directory non-executable (without changing file flags).

Here are promises with DisableScripts = yes:
openbsd$ ps -O pledge | grep [t]incd
20571 stdio,rpath,wpath,cpath,inet,unix,dns    p2  S+pU     0:00.01 ./build/src/tincd -c /tmp/foo -D

and without:
openbsd$ ps -O pledge | grep [t]incd
65412 stdio,rpath,wpath,cpath,inet,unix,dns,proc,exec    p2  S+pU     0:00.01 ./build/src/tincd -c /tmp/foo -D

and here's the full list.
I don't think we can do much better without splitting tincd into multiple restricted processes like OpenBSD does with its daemons.","Uses pledge()/unveil() to limit what tincd/tinc can do after initialization finishes.
Paths are only restricted for tincd. It's not difficult to write a similar list for tincctl, but since it's a oneshot program which isn't running for months accepting random connections from around the internet, I don't think it makes much sense to do so, taking support costs into consideration.
sandbox is a meson option (and not a boolean) since it may come in handy when adding support for other operating systems (for example, only if libseccomp is present).
Can't call myself an experienced OpenBSD user, so if anyone knowledgeable is willing to test this — be my guest. I've been running this code for a few days without any issues, but it surely has the potential to cause breakage.

This PR also makes scripts optional by adding a new configuration variable DisableScripts.
Personally, I have no use for them. Network interfaces can be configured through other means.
This is what disabling scripts allows us to do:

drop access to fork() and execve() (but only if proxytype is not PROXY_EXEC — we notify the user in that case)

since we cannot put any restrictions on child processes (because they're expected to be able to do anything the user can do), this leaves a giant escape hatch in case of attack.
privileges are limited once everything is initialized, so daemon() is not a problem.


even if that somehow happens, limit our children's privileges to exit() and nothing else.
remove access to scriptinterpreter, /bin, /sbin, /usr/bin, /usr/local/bin, etc.
make stuff in tinc configuration directory non-executable (without changing file flags).

Here are promises with DisableScripts = yes:
openbsd$ ps -O pledge | grep [t]incd
20571 stdio,rpath,wpath,cpath,inet,unix,dns    p2  S+pU     0:00.01 ./build/src/tincd -c /tmp/foo -D

and without:
openbsd$ ps -O pledge | grep [t]incd
65412 stdio,rpath,wpath,cpath,inet,unix,dns,proc,exec    p2  S+pU     0:00.01 ./build/src/tincd -c /tmp/foo -D

and here's the full list.
I don't think we can do much better without splitting tincd into multiple restricted processes like OpenBSD does with its daemons.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,379,2022-04-25T13:47:31Z,2022-05-02T19:15:02Z,2022-05-02T19:15:03Z,MERGED,True,768,39,45,https://github.com/hg,Add basic sandboxing for OpenBSD,3,[],https://github.com/gsliepen/tinc/pull/379,https://github.com/hg,2,https://github.com/gsliepen/tinc/pull/379#issuecomment-1108607223,"Uses pledge()/unveil() to limit what tincd/tinc can do after initialization finishes.
Paths are only restricted for tincd. It's not difficult to write a similar list for tincctl, but since it's a oneshot program which isn't running for months accepting random connections from around the internet, I don't think it makes much sense to do so, taking support costs into consideration.
sandbox is a meson option (and not a boolean) since it may come in handy when adding support for other operating systems (for example, only if libseccomp is present).
Can't call myself an experienced OpenBSD user, so if anyone knowledgeable is willing to test this — be my guest. I've been running this code for a few days without any issues, but it surely has the potential to cause breakage.

This PR also makes scripts optional by adding a new configuration variable DisableScripts.
Personally, I have no use for them. Network interfaces can be configured through other means.
This is what disabling scripts allows us to do:

drop access to fork() and execve() (but only if proxytype is not PROXY_EXEC — we notify the user in that case)

since we cannot put any restrictions on child processes (because they're expected to be able to do anything the user can do), this leaves a giant escape hatch in case of attack.
privileges are limited once everything is initialized, so daemon() is not a problem.


even if that somehow happens, limit our children's privileges to exit() and nothing else.
remove access to scriptinterpreter, /bin, /sbin, /usr/bin, /usr/local/bin, etc.
make stuff in tinc configuration directory non-executable (without changing file flags).

Here are promises with DisableScripts = yes:
openbsd$ ps -O pledge | grep [t]incd
20571 stdio,rpath,wpath,cpath,inet,unix,dns    p2  S+pU     0:00.01 ./build/src/tincd -c /tmp/foo -D

and without:
openbsd$ ps -O pledge | grep [t]incd
65412 stdio,rpath,wpath,cpath,inet,unix,dns,proc,exec    p2  S+pU     0:00.01 ./build/src/tincd -c /tmp/foo -D

and here's the full list.
I don't think we can do much better without splitting tincd into multiple restricted processes like OpenBSD does with its daemons.","Now, about doing the same for Linux: it's probably going to use seccomp-bpf (maybe through libseccomp, but likely without it since rules are likely to be static, and it's not difficult to write a BPF program for a static rule list).
The question is what approach to use: either allow or deny by default.
Obviously, it would be much better to only allow syscalls we actually use, but I worry about third-party libraries. For example, tinc didn't use getrandom() until recently, but OpenSSL did, and any library could start using any newfangled syscall when some user builds tinc with a newer version we haven't tested yet.
So I lean towards blocking:

more dangerous syscalls (like fork/clone/execve if scripts are disabled)
pivot_root since chroot is done before dropping privileges
and stuff like create_module

Another way would be implement both and replace --no-sandbox with a more flexible option (like --sandbox=none, or --sandbox=lax, or --sandbox=strong, with the default being lax), and let the user opt-in into stricter filtering if they wish to.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,379,2022-04-25T13:47:31Z,2022-05-02T19:15:02Z,2022-05-02T19:15:03Z,MERGED,True,768,39,45,https://github.com/hg,Add basic sandboxing for OpenBSD,3,[],https://github.com/gsliepen/tinc/pull/379,https://github.com/hg,3,https://github.com/gsliepen/tinc/pull/379#issuecomment-1114185992,"Uses pledge()/unveil() to limit what tincd/tinc can do after initialization finishes.
Paths are only restricted for tincd. It's not difficult to write a similar list for tincctl, but since it's a oneshot program which isn't running for months accepting random connections from around the internet, I don't think it makes much sense to do so, taking support costs into consideration.
sandbox is a meson option (and not a boolean) since it may come in handy when adding support for other operating systems (for example, only if libseccomp is present).
Can't call myself an experienced OpenBSD user, so if anyone knowledgeable is willing to test this — be my guest. I've been running this code for a few days without any issues, but it surely has the potential to cause breakage.

This PR also makes scripts optional by adding a new configuration variable DisableScripts.
Personally, I have no use for them. Network interfaces can be configured through other means.
This is what disabling scripts allows us to do:

drop access to fork() and execve() (but only if proxytype is not PROXY_EXEC — we notify the user in that case)

since we cannot put any restrictions on child processes (because they're expected to be able to do anything the user can do), this leaves a giant escape hatch in case of attack.
privileges are limited once everything is initialized, so daemon() is not a problem.


even if that somehow happens, limit our children's privileges to exit() and nothing else.
remove access to scriptinterpreter, /bin, /sbin, /usr/bin, /usr/local/bin, etc.
make stuff in tinc configuration directory non-executable (without changing file flags).

Here are promises with DisableScripts = yes:
openbsd$ ps -O pledge | grep [t]incd
20571 stdio,rpath,wpath,cpath,inet,unix,dns    p2  S+pU     0:00.01 ./build/src/tincd -c /tmp/foo -D

and without:
openbsd$ ps -O pledge | grep [t]incd
65412 stdio,rpath,wpath,cpath,inet,unix,dns,proc,exec    p2  S+pU     0:00.01 ./build/src/tincd -c /tmp/foo -D

and here's the full list.
I don't think we can do much better without splitting tincd into multiple restricted processes like OpenBSD does with its daemons.","I think this is about as restrictive as I can make it.
Non-standard executable paths are not available even on normal level since doing that pretty much requires rx access to everything (including home directories and other interesting places).
We could add another level (low) which permits that, but it's probably better to encourage users to put binaries into /usr/local/bin and be done with it.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,379,2022-04-25T13:47:31Z,2022-05-02T19:15:02Z,2022-05-02T19:15:03Z,MERGED,True,768,39,45,https://github.com/hg,Add basic sandboxing for OpenBSD,3,[],https://github.com/gsliepen/tinc/pull/379,https://github.com/hg,4,https://github.com/gsliepen/tinc/pull/379#issuecomment-1114663142,"Uses pledge()/unveil() to limit what tincd/tinc can do after initialization finishes.
Paths are only restricted for tincd. It's not difficult to write a similar list for tincctl, but since it's a oneshot program which isn't running for months accepting random connections from around the internet, I don't think it makes much sense to do so, taking support costs into consideration.
sandbox is a meson option (and not a boolean) since it may come in handy when adding support for other operating systems (for example, only if libseccomp is present).
Can't call myself an experienced OpenBSD user, so if anyone knowledgeable is willing to test this — be my guest. I've been running this code for a few days without any issues, but it surely has the potential to cause breakage.

This PR also makes scripts optional by adding a new configuration variable DisableScripts.
Personally, I have no use for them. Network interfaces can be configured through other means.
This is what disabling scripts allows us to do:

drop access to fork() and execve() (but only if proxytype is not PROXY_EXEC — we notify the user in that case)

since we cannot put any restrictions on child processes (because they're expected to be able to do anything the user can do), this leaves a giant escape hatch in case of attack.
privileges are limited once everything is initialized, so daemon() is not a problem.


even if that somehow happens, limit our children's privileges to exit() and nothing else.
remove access to scriptinterpreter, /bin, /sbin, /usr/bin, /usr/local/bin, etc.
make stuff in tinc configuration directory non-executable (without changing file flags).

Here are promises with DisableScripts = yes:
openbsd$ ps -O pledge | grep [t]incd
20571 stdio,rpath,wpath,cpath,inet,unix,dns    p2  S+pU     0:00.01 ./build/src/tincd -c /tmp/foo -D

and without:
openbsd$ ps -O pledge | grep [t]incd
65412 stdio,rpath,wpath,cpath,inet,unix,dns,proc,exec    p2  S+pU     0:00.01 ./build/src/tincd -c /tmp/foo -D

and here's the full list.
I don't think we can do much better without splitting tincd into multiple restricted processes like OpenBSD does with its daemons.","Thanks for the review. I think it would be best to merge #382 first. libgcrypt support was broken and I nearly missed that because it's painful to continuously retest all configurations manually.
It's caused by 'secure memory', which is initialized using mlock() on first allocation (unless you do it separately), which fails since we've dropped privileges by that point.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,379,2022-04-25T13:47:31Z,2022-05-02T19:15:02Z,2022-05-02T19:15:03Z,MERGED,True,768,39,45,https://github.com/hg,Add basic sandboxing for OpenBSD,3,[],https://github.com/gsliepen/tinc/pull/379,https://github.com/gsliepen,5,https://github.com/gsliepen/tinc/pull/379#issuecomment-1115258329,"Uses pledge()/unveil() to limit what tincd/tinc can do after initialization finishes.
Paths are only restricted for tincd. It's not difficult to write a similar list for tincctl, but since it's a oneshot program which isn't running for months accepting random connections from around the internet, I don't think it makes much sense to do so, taking support costs into consideration.
sandbox is a meson option (and not a boolean) since it may come in handy when adding support for other operating systems (for example, only if libseccomp is present).
Can't call myself an experienced OpenBSD user, so if anyone knowledgeable is willing to test this — be my guest. I've been running this code for a few days without any issues, but it surely has the potential to cause breakage.

This PR also makes scripts optional by adding a new configuration variable DisableScripts.
Personally, I have no use for them. Network interfaces can be configured through other means.
This is what disabling scripts allows us to do:

drop access to fork() and execve() (but only if proxytype is not PROXY_EXEC — we notify the user in that case)

since we cannot put any restrictions on child processes (because they're expected to be able to do anything the user can do), this leaves a giant escape hatch in case of attack.
privileges are limited once everything is initialized, so daemon() is not a problem.


even if that somehow happens, limit our children's privileges to exit() and nothing else.
remove access to scriptinterpreter, /bin, /sbin, /usr/bin, /usr/local/bin, etc.
make stuff in tinc configuration directory non-executable (without changing file flags).

Here are promises with DisableScripts = yes:
openbsd$ ps -O pledge | grep [t]incd
20571 stdio,rpath,wpath,cpath,inet,unix,dns    p2  S+pU     0:00.01 ./build/src/tincd -c /tmp/foo -D

and without:
openbsd$ ps -O pledge | grep [t]incd
65412 stdio,rpath,wpath,cpath,inet,unix,dns,proc,exec    p2  S+pU     0:00.01 ./build/src/tincd -c /tmp/foo -D

and here's the full list.
I don't think we can do much better without splitting tincd into multiple restricted processes like OpenBSD does with its daemons.","It's caused by 'secure memory', which is initialized using mlock() on first allocation (unless you do it separately), which fails since we've dropped privileges by that point.

Good catch!",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,380,2022-04-26T14:06:52Z,2022-04-26T17:38:01Z,2022-04-26T17:38:01Z,MERGED,True,161,93,4,https://github.com/hg,Use enums for command-line options,1,[],https://github.com/gsliepen/tinc/pull/380,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/380,"This is a pretty minor thing. Split off from #379 since it's not needed there anymore.
Also fix a small bug in sptps_test where --tun was mentioned in documentation but not actually parsed.","This is a pretty minor thing. Split off from #379 since it's not needed there anymore.
Also fix a small bug in sptps_test where --tun was mentioned in documentation but not actually parsed.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,381,2022-04-27T15:03:26Z,2022-04-27T17:55:45Z,2022-04-27T17:55:46Z,MERGED,True,20,20,5,https://github.com/hg,Fix reading broken keys using libgcrypt,2,[],https://github.com/gsliepen/tinc/pull/381,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/381,"The unsigned overflow check actually turned out to be useful. It uncovered an old bug in the asn.1 parser where it read sequence length without checking if it's preceeded by a SEQUENCE tag.
This is the reason UBSAN job was failing.
I posted the first commit as part of #372, but I want to do more testing on that one, so it's added here.","The unsigned overflow check actually turned out to be useful. It uncovered an old bug in the asn.1 parser where it read sequence length without checking if it's preceeded by a SEQUENCE tag.
This is the reason UBSAN job was failing.
I posted the first commit as part of #372, but I want to do more testing on that one, so it's added here.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,382,2022-05-01T12:40:23Z,2022-05-02T18:46:02Z,2022-05-02T18:46:03Z,MERGED,True,60,66,8,https://github.com/hg,CI: run all test flavors on BSDs,3,[],https://github.com/gsliepen/tinc/pull/382,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/382,"Let's try running all test flavors on BSDs too.
We're not using the same scripts here since sourcehut does not support saving build artifacts on failure, and scripts are too different anyway.
Also use system versions of OpenSSL/curses/readline.","Let's try running all test flavors on BSDs too.
We're not using the same scripts here since sourcehut does not support saving build artifacts on failure, and scripts are too different anyway.
Also use system versions of OpenSSL/curses/readline.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,382,2022-05-01T12:40:23Z,2022-05-02T18:46:02Z,2022-05-02T18:46:03Z,MERGED,True,60,66,8,https://github.com/hg,CI: run all test flavors on BSDs,3,[],https://github.com/gsliepen/tinc/pull/382,https://github.com/hg,2,https://github.com/gsliepen/tinc/pull/382#issuecomment-1114230924,"Let's try running all test flavors on BSDs too.
We're not using the same scripts here since sourcehut does not support saving build artifacts on failure, and scripts are too different anyway.
Also use system versions of OpenSSL/curses/readline.",The failure in mingw is caused by a recent change to the ncurses package and is fixed by #379.,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,382,2022-05-01T12:40:23Z,2022-05-02T18:46:02Z,2022-05-02T18:46:03Z,MERGED,True,60,66,8,https://github.com/hg,CI: run all test flavors on BSDs,3,[],https://github.com/gsliepen/tinc/pull/382,https://github.com/hg,3,https://github.com/gsliepen/tinc/pull/382#issuecomment-1114286417,"Let's try running all test flavors on BSDs too.
We're not using the same scripts here since sourcehut does not support saving build artifacts on failure, and scripts are too different anyway.
Also use system versions of OpenSSL/curses/readline.","I additionally replaced getrandom() with getentropy(), which is present on most of the supported operating systems:

Linux
macOS
OpenBSD
FreeBSD
Illumos
DragonflyBSD

It should have been used from the start if I were more of a BSD guy.
Since Windows has its own CryptGenRandom(), /dev/urandom is now only used by NetBSD.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,384,2022-05-07T11:32:23Z,2022-05-17T14:45:11Z,2022-05-17T14:45:11Z,MERGED,True,0,1,1,https://github.com/hg,Remove -Qunused-arguments,1,[],https://github.com/gsliepen/tinc/pull/384,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/384,"I believe it's not actually needed anymore, let's check what BSD clangs think about that.
Should silence #383 if this is correct.","I believe it's not actually needed anymore, let's check what BSD clangs think about that.
Should silence #383 if this is correct.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,386,2022-05-15T16:38:45Z,,2022-05-29T14:56:23Z,OPEN,False,1211,153,27,https://github.com/hg,Add Linux sandbox (seccomp-bpf + Landlock LSM),2,"['enhancement', '1.1', 'linux']",https://github.com/gsliepen/tinc/pull/386,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/386,"Landlock is similar to unveil() and is available on Linux 5.13+.

https://lwn.net/Articles/859908
https://docs.kernel.org/security/landlock.html

Since both are inherited by child processes, and there's no way to disable this, we use a trick similar to what browsers are doing — fork a process early, drop privileges on the main one, and use the privileged process for running scripts.
This also lets us remove access to fork()/execve() on OpenBSD for both sandbox levels.
Hardware
Only amd64 and aarch64 are supported because I don't have access to anything else, and it's pretty dangerous to ""support"" other architectures without actually testing them. For example, some architectures use socketcall instead of separate accept/bind/connect/etc, some implement gettimeofday through VDSO instead of an actual syscall, and so on.
If a user wishes to go ahead anyway, they can force-enable the sandbox with:
$ meson setup build -D sandbox=enabled

Security
There is at least one way to circumvent the sandbox, but I believe it will only work with a non-empty ScriptsInterpreter. Since tincd has full access to the hosts subdirectory, the attacker can create a hosts/xxx-up or hosts/xxx-down script and ask the script worker to execute it.
It shouldn't be possible with an empty interpreter since you need to make the script executable, and both umask() and all chmod-related syscalls are blocked by seccomp.
Additionally, we remove write access to existing scripts inside hosts/ to prevent broken tincd from rewriting them and gaining shell access.
Reassigning ScriptsInterpreter to another value at runtime shouldn't be possible since script worker uses its own copies of all configuration variables, and access to other processes' memory is prevented by seccomp.
tincd also doesn't have write access to its own configuration, so it cannot rewrite the config and restart itself.
Performance
The PR doesn't seem to affect simple iperf3 between two nodes in any way. The results may be different with hundreds of nodes, but I don't have the hardware to test this.
With seccomp-bpf and Landlock
[ ID] Interval           Transfer     Bitrate         Retr  Cwnd
[  5]   0.00-1.00   sec  99.4 MBytes   834 Mbits/sec    0   3.15 MBytes
[  5]   1.00-2.00   sec  93.8 MBytes   786 Mbits/sec    0   3.15 MBytes
[  5]   2.00-3.00   sec  95.0 MBytes   797 Mbits/sec  4112   1.19 MBytes
[  5]   3.00-4.00   sec  98.8 MBytes   828 Mbits/sec    0   1.30 MBytes
[  5]   4.00-5.00   sec  98.8 MBytes   828 Mbits/sec   10   1.38 MBytes
[  5]   5.00-6.00   sec   115 MBytes   965 Mbits/sec  653    631 KBytes
[  5]   6.00-7.00   sec   114 MBytes   954 Mbits/sec    1    567 KBytes
[  5]   7.00-8.00   sec   114 MBytes   954 Mbits/sec    1    501 KBytes
[  5]   8.00-9.00   sec   115 MBytes   965 Mbits/sec    0    652 KBytes
[  5]   9.00-10.00  sec   114 MBytes   954 Mbits/sec    5    591 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-10.00  sec  1.03 GBytes   887 Mbits/sec  4782             sender
[  5]   0.00-10.01  sec  1.03 GBytes   884 Mbits/sec                  receiver

Without sandbox
[  5] local 192.168.1.1 port 57292 connected to 192.168.1.2 port 5201
[ ID] Interval           Transfer     Bitrate         Retr  Cwnd
[  5]   0.00-1.00   sec   107 MBytes   899 Mbits/sec  222    420 KBytes
[  5]   1.00-2.00   sec  98.8 MBytes   828 Mbits/sec    0    574 KBytes
[  5]   2.00-3.00   sec   104 MBytes   870 Mbits/sec    0    701 KBytes
[  5]   3.00-4.00   sec   106 MBytes   891 Mbits/sec    7    634 KBytes
[  5]   4.00-5.00   sec   100 MBytes   839 Mbits/sec    3    551 KBytes
[  5]   5.00-6.00   sec   106 MBytes   891 Mbits/sec    0    686 KBytes
[  5]   6.00-7.00   sec   108 MBytes   902 Mbits/sec    4    619 KBytes
[  5]   7.00-8.00   sec   108 MBytes   902 Mbits/sec    1    547 KBytes
[  5]   8.00-9.00   sec   109 MBytes   912 Mbits/sec    0    684 KBytes
[  5]   9.00-10.00  sec   108 MBytes   902 Mbits/sec    4    621 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-10.00  sec  1.03 GBytes   884 Mbits/sec  241             sender
[  5]   0.00-10.01  sec  1.03 GBytes   881 Mbits/sec                  receiver","Landlock is similar to unveil() and is available on Linux 5.13+.

https://lwn.net/Articles/859908
https://docs.kernel.org/security/landlock.html

Since both are inherited by child processes, and there's no way to disable this, we use a trick similar to what browsers are doing — fork a process early, drop privileges on the main one, and use the privileged process for running scripts.
This also lets us remove access to fork()/execve() on OpenBSD for both sandbox levels.
Hardware
Only amd64 and aarch64 are supported because I don't have access to anything else, and it's pretty dangerous to ""support"" other architectures without actually testing them. For example, some architectures use socketcall instead of separate accept/bind/connect/etc, some implement gettimeofday through VDSO instead of an actual syscall, and so on.
If a user wishes to go ahead anyway, they can force-enable the sandbox with:
$ meson setup build -D sandbox=enabled

Security
There is at least one way to circumvent the sandbox, but I believe it will only work with a non-empty ScriptsInterpreter. Since tincd has full access to the hosts subdirectory, the attacker can create a hosts/xxx-up or hosts/xxx-down script and ask the script worker to execute it.
It shouldn't be possible with an empty interpreter since you need to make the script executable, and both umask() and all chmod-related syscalls are blocked by seccomp.
Additionally, we remove write access to existing scripts inside hosts/ to prevent broken tincd from rewriting them and gaining shell access.
Reassigning ScriptsInterpreter to another value at runtime shouldn't be possible since script worker uses its own copies of all configuration variables, and access to other processes' memory is prevented by seccomp.
tincd also doesn't have write access to its own configuration, so it cannot rewrite the config and restart itself.
Performance
The PR doesn't seem to affect simple iperf3 between two nodes in any way. The results may be different with hundreds of nodes, but I don't have the hardware to test this.
With seccomp-bpf and Landlock
[ ID] Interval           Transfer     Bitrate         Retr  Cwnd
[  5]   0.00-1.00   sec  99.4 MBytes   834 Mbits/sec    0   3.15 MBytes
[  5]   1.00-2.00   sec  93.8 MBytes   786 Mbits/sec    0   3.15 MBytes
[  5]   2.00-3.00   sec  95.0 MBytes   797 Mbits/sec  4112   1.19 MBytes
[  5]   3.00-4.00   sec  98.8 MBytes   828 Mbits/sec    0   1.30 MBytes
[  5]   4.00-5.00   sec  98.8 MBytes   828 Mbits/sec   10   1.38 MBytes
[  5]   5.00-6.00   sec   115 MBytes   965 Mbits/sec  653    631 KBytes
[  5]   6.00-7.00   sec   114 MBytes   954 Mbits/sec    1    567 KBytes
[  5]   7.00-8.00   sec   114 MBytes   954 Mbits/sec    1    501 KBytes
[  5]   8.00-9.00   sec   115 MBytes   965 Mbits/sec    0    652 KBytes
[  5]   9.00-10.00  sec   114 MBytes   954 Mbits/sec    5    591 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-10.00  sec  1.03 GBytes   887 Mbits/sec  4782             sender
[  5]   0.00-10.01  sec  1.03 GBytes   884 Mbits/sec                  receiver

Without sandbox
[  5] local 192.168.1.1 port 57292 connected to 192.168.1.2 port 5201
[ ID] Interval           Transfer     Bitrate         Retr  Cwnd
[  5]   0.00-1.00   sec   107 MBytes   899 Mbits/sec  222    420 KBytes
[  5]   1.00-2.00   sec  98.8 MBytes   828 Mbits/sec    0    574 KBytes
[  5]   2.00-3.00   sec   104 MBytes   870 Mbits/sec    0    701 KBytes
[  5]   3.00-4.00   sec   106 MBytes   891 Mbits/sec    7    634 KBytes
[  5]   4.00-5.00   sec   100 MBytes   839 Mbits/sec    3    551 KBytes
[  5]   5.00-6.00   sec   106 MBytes   891 Mbits/sec    0    686 KBytes
[  5]   6.00-7.00   sec   108 MBytes   902 Mbits/sec    4    619 KBytes
[  5]   7.00-8.00   sec   108 MBytes   902 Mbits/sec    1    547 KBytes
[  5]   8.00-9.00   sec   109 MBytes   912 Mbits/sec    0    684 KBytes
[  5]   9.00-10.00  sec   108 MBytes   902 Mbits/sec    4    621 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-10.00  sec  1.03 GBytes   884 Mbits/sec  241             sender
[  5]   0.00-10.01  sec  1.03 GBytes   881 Mbits/sec                  receiver",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,386,2022-05-15T16:38:45Z,,2022-05-29T14:56:23Z,OPEN,False,1211,153,27,https://github.com/hg,Add Linux sandbox (seccomp-bpf + Landlock LSM),2,"['enhancement', '1.1', 'linux']",https://github.com/gsliepen/tinc/pull/386,https://github.com/hg,2,https://github.com/gsliepen/tinc/pull/386#issuecomment-1129180520,"Landlock is similar to unveil() and is available on Linux 5.13+.

https://lwn.net/Articles/859908
https://docs.kernel.org/security/landlock.html

Since both are inherited by child processes, and there's no way to disable this, we use a trick similar to what browsers are doing — fork a process early, drop privileges on the main one, and use the privileged process for running scripts.
This also lets us remove access to fork()/execve() on OpenBSD for both sandbox levels.
Hardware
Only amd64 and aarch64 are supported because I don't have access to anything else, and it's pretty dangerous to ""support"" other architectures without actually testing them. For example, some architectures use socketcall instead of separate accept/bind/connect/etc, some implement gettimeofday through VDSO instead of an actual syscall, and so on.
If a user wishes to go ahead anyway, they can force-enable the sandbox with:
$ meson setup build -D sandbox=enabled

Security
There is at least one way to circumvent the sandbox, but I believe it will only work with a non-empty ScriptsInterpreter. Since tincd has full access to the hosts subdirectory, the attacker can create a hosts/xxx-up or hosts/xxx-down script and ask the script worker to execute it.
It shouldn't be possible with an empty interpreter since you need to make the script executable, and both umask() and all chmod-related syscalls are blocked by seccomp.
Additionally, we remove write access to existing scripts inside hosts/ to prevent broken tincd from rewriting them and gaining shell access.
Reassigning ScriptsInterpreter to another value at runtime shouldn't be possible since script worker uses its own copies of all configuration variables, and access to other processes' memory is prevented by seccomp.
tincd also doesn't have write access to its own configuration, so it cannot rewrite the config and restart itself.
Performance
The PR doesn't seem to affect simple iperf3 between two nodes in any way. The results may be different with hundreds of nodes, but I don't have the hardware to test this.
With seccomp-bpf and Landlock
[ ID] Interval           Transfer     Bitrate         Retr  Cwnd
[  5]   0.00-1.00   sec  99.4 MBytes   834 Mbits/sec    0   3.15 MBytes
[  5]   1.00-2.00   sec  93.8 MBytes   786 Mbits/sec    0   3.15 MBytes
[  5]   2.00-3.00   sec  95.0 MBytes   797 Mbits/sec  4112   1.19 MBytes
[  5]   3.00-4.00   sec  98.8 MBytes   828 Mbits/sec    0   1.30 MBytes
[  5]   4.00-5.00   sec  98.8 MBytes   828 Mbits/sec   10   1.38 MBytes
[  5]   5.00-6.00   sec   115 MBytes   965 Mbits/sec  653    631 KBytes
[  5]   6.00-7.00   sec   114 MBytes   954 Mbits/sec    1    567 KBytes
[  5]   7.00-8.00   sec   114 MBytes   954 Mbits/sec    1    501 KBytes
[  5]   8.00-9.00   sec   115 MBytes   965 Mbits/sec    0    652 KBytes
[  5]   9.00-10.00  sec   114 MBytes   954 Mbits/sec    5    591 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-10.00  sec  1.03 GBytes   887 Mbits/sec  4782             sender
[  5]   0.00-10.01  sec  1.03 GBytes   884 Mbits/sec                  receiver

Without sandbox
[  5] local 192.168.1.1 port 57292 connected to 192.168.1.2 port 5201
[ ID] Interval           Transfer     Bitrate         Retr  Cwnd
[  5]   0.00-1.00   sec   107 MBytes   899 Mbits/sec  222    420 KBytes
[  5]   1.00-2.00   sec  98.8 MBytes   828 Mbits/sec    0    574 KBytes
[  5]   2.00-3.00   sec   104 MBytes   870 Mbits/sec    0    701 KBytes
[  5]   3.00-4.00   sec   106 MBytes   891 Mbits/sec    7    634 KBytes
[  5]   4.00-5.00   sec   100 MBytes   839 Mbits/sec    3    551 KBytes
[  5]   5.00-6.00   sec   106 MBytes   891 Mbits/sec    0    686 KBytes
[  5]   6.00-7.00   sec   108 MBytes   902 Mbits/sec    4    619 KBytes
[  5]   7.00-8.00   sec   108 MBytes   902 Mbits/sec    1    547 KBytes
[  5]   8.00-9.00   sec   109 MBytes   912 Mbits/sec    0    684 KBytes
[  5]   9.00-10.00  sec   108 MBytes   902 Mbits/sec    4    621 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-10.00  sec  1.03 GBytes   884 Mbits/sec  241             sender
[  5]   0.00-10.01  sec  1.03 GBytes   881 Mbits/sec                  receiver","Thanks for the review, fixed. No need to rush this, the change is quite intrusive and risky.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,386,2022-05-15T16:38:45Z,,2022-05-29T14:56:23Z,OPEN,False,1211,153,27,https://github.com/hg,Add Linux sandbox (seccomp-bpf + Landlock LSM),2,"['enhancement', '1.1', 'linux']",https://github.com/gsliepen/tinc/pull/386,https://github.com/hg,3,https://github.com/gsliepen/tinc/pull/386#issuecomment-1138864360,"Landlock is similar to unveil() and is available on Linux 5.13+.

https://lwn.net/Articles/859908
https://docs.kernel.org/security/landlock.html

Since both are inherited by child processes, and there's no way to disable this, we use a trick similar to what browsers are doing — fork a process early, drop privileges on the main one, and use the privileged process for running scripts.
This also lets us remove access to fork()/execve() on OpenBSD for both sandbox levels.
Hardware
Only amd64 and aarch64 are supported because I don't have access to anything else, and it's pretty dangerous to ""support"" other architectures without actually testing them. For example, some architectures use socketcall instead of separate accept/bind/connect/etc, some implement gettimeofday through VDSO instead of an actual syscall, and so on.
If a user wishes to go ahead anyway, they can force-enable the sandbox with:
$ meson setup build -D sandbox=enabled

Security
There is at least one way to circumvent the sandbox, but I believe it will only work with a non-empty ScriptsInterpreter. Since tincd has full access to the hosts subdirectory, the attacker can create a hosts/xxx-up or hosts/xxx-down script and ask the script worker to execute it.
It shouldn't be possible with an empty interpreter since you need to make the script executable, and both umask() and all chmod-related syscalls are blocked by seccomp.
Additionally, we remove write access to existing scripts inside hosts/ to prevent broken tincd from rewriting them and gaining shell access.
Reassigning ScriptsInterpreter to another value at runtime shouldn't be possible since script worker uses its own copies of all configuration variables, and access to other processes' memory is prevented by seccomp.
tincd also doesn't have write access to its own configuration, so it cannot rewrite the config and restart itself.
Performance
The PR doesn't seem to affect simple iperf3 between two nodes in any way. The results may be different with hundreds of nodes, but I don't have the hardware to test this.
With seccomp-bpf and Landlock
[ ID] Interval           Transfer     Bitrate         Retr  Cwnd
[  5]   0.00-1.00   sec  99.4 MBytes   834 Mbits/sec    0   3.15 MBytes
[  5]   1.00-2.00   sec  93.8 MBytes   786 Mbits/sec    0   3.15 MBytes
[  5]   2.00-3.00   sec  95.0 MBytes   797 Mbits/sec  4112   1.19 MBytes
[  5]   3.00-4.00   sec  98.8 MBytes   828 Mbits/sec    0   1.30 MBytes
[  5]   4.00-5.00   sec  98.8 MBytes   828 Mbits/sec   10   1.38 MBytes
[  5]   5.00-6.00   sec   115 MBytes   965 Mbits/sec  653    631 KBytes
[  5]   6.00-7.00   sec   114 MBytes   954 Mbits/sec    1    567 KBytes
[  5]   7.00-8.00   sec   114 MBytes   954 Mbits/sec    1    501 KBytes
[  5]   8.00-9.00   sec   115 MBytes   965 Mbits/sec    0    652 KBytes
[  5]   9.00-10.00  sec   114 MBytes   954 Mbits/sec    5    591 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-10.00  sec  1.03 GBytes   887 Mbits/sec  4782             sender
[  5]   0.00-10.01  sec  1.03 GBytes   884 Mbits/sec                  receiver

Without sandbox
[  5] local 192.168.1.1 port 57292 connected to 192.168.1.2 port 5201
[ ID] Interval           Transfer     Bitrate         Retr  Cwnd
[  5]   0.00-1.00   sec   107 MBytes   899 Mbits/sec  222    420 KBytes
[  5]   1.00-2.00   sec  98.8 MBytes   828 Mbits/sec    0    574 KBytes
[  5]   2.00-3.00   sec   104 MBytes   870 Mbits/sec    0    701 KBytes
[  5]   3.00-4.00   sec   106 MBytes   891 Mbits/sec    7    634 KBytes
[  5]   4.00-5.00   sec   100 MBytes   839 Mbits/sec    3    551 KBytes
[  5]   5.00-6.00   sec   106 MBytes   891 Mbits/sec    0    686 KBytes
[  5]   6.00-7.00   sec   108 MBytes   902 Mbits/sec    4    619 KBytes
[  5]   7.00-8.00   sec   108 MBytes   902 Mbits/sec    1    547 KBytes
[  5]   8.00-9.00   sec   109 MBytes   912 Mbits/sec    0    684 KBytes
[  5]   9.00-10.00  sec   108 MBytes   902 Mbits/sec    4    621 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-10.00  sec  1.03 GBytes   884 Mbits/sec  241             sender
[  5]   0.00-10.01  sec  1.03 GBytes   881 Mbits/sec                  receiver","I'll mark this as WIP for now, best to merge this after everything else is in.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,386,2022-05-15T16:38:45Z,,2022-05-29T14:56:23Z,OPEN,False,1211,153,27,https://github.com/hg,Add Linux sandbox (seccomp-bpf + Landlock LSM),2,"['enhancement', '1.1', 'linux']",https://github.com/gsliepen/tinc/pull/386,https://github.com/hg,4,https://github.com/gsliepen/tinc/pull/386#issuecomment-1140466043,"Landlock is similar to unveil() and is available on Linux 5.13+.

https://lwn.net/Articles/859908
https://docs.kernel.org/security/landlock.html

Since both are inherited by child processes, and there's no way to disable this, we use a trick similar to what browsers are doing — fork a process early, drop privileges on the main one, and use the privileged process for running scripts.
This also lets us remove access to fork()/execve() on OpenBSD for both sandbox levels.
Hardware
Only amd64 and aarch64 are supported because I don't have access to anything else, and it's pretty dangerous to ""support"" other architectures without actually testing them. For example, some architectures use socketcall instead of separate accept/bind/connect/etc, some implement gettimeofday through VDSO instead of an actual syscall, and so on.
If a user wishes to go ahead anyway, they can force-enable the sandbox with:
$ meson setup build -D sandbox=enabled

Security
There is at least one way to circumvent the sandbox, but I believe it will only work with a non-empty ScriptsInterpreter. Since tincd has full access to the hosts subdirectory, the attacker can create a hosts/xxx-up or hosts/xxx-down script and ask the script worker to execute it.
It shouldn't be possible with an empty interpreter since you need to make the script executable, and both umask() and all chmod-related syscalls are blocked by seccomp.
Additionally, we remove write access to existing scripts inside hosts/ to prevent broken tincd from rewriting them and gaining shell access.
Reassigning ScriptsInterpreter to another value at runtime shouldn't be possible since script worker uses its own copies of all configuration variables, and access to other processes' memory is prevented by seccomp.
tincd also doesn't have write access to its own configuration, so it cannot rewrite the config and restart itself.
Performance
The PR doesn't seem to affect simple iperf3 between two nodes in any way. The results may be different with hundreds of nodes, but I don't have the hardware to test this.
With seccomp-bpf and Landlock
[ ID] Interval           Transfer     Bitrate         Retr  Cwnd
[  5]   0.00-1.00   sec  99.4 MBytes   834 Mbits/sec    0   3.15 MBytes
[  5]   1.00-2.00   sec  93.8 MBytes   786 Mbits/sec    0   3.15 MBytes
[  5]   2.00-3.00   sec  95.0 MBytes   797 Mbits/sec  4112   1.19 MBytes
[  5]   3.00-4.00   sec  98.8 MBytes   828 Mbits/sec    0   1.30 MBytes
[  5]   4.00-5.00   sec  98.8 MBytes   828 Mbits/sec   10   1.38 MBytes
[  5]   5.00-6.00   sec   115 MBytes   965 Mbits/sec  653    631 KBytes
[  5]   6.00-7.00   sec   114 MBytes   954 Mbits/sec    1    567 KBytes
[  5]   7.00-8.00   sec   114 MBytes   954 Mbits/sec    1    501 KBytes
[  5]   8.00-9.00   sec   115 MBytes   965 Mbits/sec    0    652 KBytes
[  5]   9.00-10.00  sec   114 MBytes   954 Mbits/sec    5    591 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-10.00  sec  1.03 GBytes   887 Mbits/sec  4782             sender
[  5]   0.00-10.01  sec  1.03 GBytes   884 Mbits/sec                  receiver

Without sandbox
[  5] local 192.168.1.1 port 57292 connected to 192.168.1.2 port 5201
[ ID] Interval           Transfer     Bitrate         Retr  Cwnd
[  5]   0.00-1.00   sec   107 MBytes   899 Mbits/sec  222    420 KBytes
[  5]   1.00-2.00   sec  98.8 MBytes   828 Mbits/sec    0    574 KBytes
[  5]   2.00-3.00   sec   104 MBytes   870 Mbits/sec    0    701 KBytes
[  5]   3.00-4.00   sec   106 MBytes   891 Mbits/sec    7    634 KBytes
[  5]   4.00-5.00   sec   100 MBytes   839 Mbits/sec    3    551 KBytes
[  5]   5.00-6.00   sec   106 MBytes   891 Mbits/sec    0    686 KBytes
[  5]   6.00-7.00   sec   108 MBytes   902 Mbits/sec    4    619 KBytes
[  5]   7.00-8.00   sec   108 MBytes   902 Mbits/sec    1    547 KBytes
[  5]   8.00-9.00   sec   109 MBytes   912 Mbits/sec    0    684 KBytes
[  5]   9.00-10.00  sec   108 MBytes   902 Mbits/sec    4    621 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-10.00  sec  1.03 GBytes   884 Mbits/sec  241             sender
[  5]   0.00-10.01  sec  1.03 GBytes   881 Mbits/sec                  receiver","After some recent changes to debian:testing, it fails to even resolve localhost without access to NSS dynamic libraries (blocking access to nsswitch.conf doesn't help), so I had to open a lot more paths (luckily it doesn't need write access anywhere).
I'll work on test coverage a bit more before marking this as finished.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,387,2022-05-17T14:33:59Z,2022-05-26T17:54:10Z,2022-05-26T17:54:10Z,MERGED,True,827,475,14,https://github.com/hg,BSD: add kqueue support,2,[],https://github.com/gsliepen/tinc/pull/387,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/387,"Similar to #266, but for FreeBSD/OpenBSD/NetBSD/macOS.
event.c is in need of splitting into multiple files. I'd rather do that in a separate PR.
Performance
It would be great to test this on physical machines with a fast network between them, if only I had the hardware. So here are results for a FreeBSD VM (13.1) on a Linux desktop (5.17.5).
Profiles
Start tincd, run 30 seconds of iperf3, stop tincd.
select
%   cumulative   self              self     total
 time   seconds   seconds    calls  ms/call  ms/call  name
 27.6       5.27     5.27       10   527.41   527.41  __sys_write [3]
 17.9       8.69     3.42        0  100.00%           __sys_select [13]
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
 15.0      11.56     2.87        0  100.00%           _mcount [16]
 14.9      14.40     2.84        0  100.00%           __sys_sendto [17]
  9.8      16.28     1.87        0  100.00%           _recvfrom [20]
  2.0      16.67     0.39 12124817     0.00     0.00  logger [11]
  1.8      17.01     0.34        0  100.00%           .mcount (501)
  1.5      17.30     0.29        1   291.34  6852.63  event_loop [2]
  1.5      17.58     0.28       20    14.22    14.22  __sys_read [39]
  0.7      17.72     0.14  2017455     0.00     0.00  __svfscanf [36]
  0.6      17.85     0.12  3026242     0.00     0.00  __vdso_gettc [48]
  0.6      17.96     0.11  1012231     0.00     0.00  __vfprintf [44]
  0.6      18.07     0.11  5054394     0.00     0.00  memcpy [50]
  0.5      18.16     0.09  3029506     0.00     0.00  route [14]
  0.4      18.24     0.08  2017424     0.00     0.00  receive_meta [6]

kqueue
%   cumulative   self              self     total
 time   seconds   seconds    calls  ms/call  ms/call  name
 27.4       4.92     4.92       10   492.41   492.41  __sys_write [5]
 17.1       8.00     3.07        0  100.00%           __sys_sendto [17]
 16.5      10.96     2.97        0  100.00%           _mcount [18]
 12.3      13.18     2.21        0  100.00%           _recvfrom [21]
 12.2      15.36     2.19  3879960     0.00     0.00  __sys_kevent [23]
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  2.0      15.72     0.36 11660378     0.00     0.00  logger [12]
  2.0      16.07     0.35        0  100.00%           .mcount (498)
  1.5      16.34     0.27       20    13.46    13.46  _read [40]
  1.0      16.52     0.17  1940474     0.00     0.00  __svfscanf [38]
  0.8      16.66     0.14   973307     0.00     0.00  __vfprintf [45]
  0.6      16.77     0.11        1   114.30  8491.48  event_loop [2]
  0.6      16.87     0.11  4860650     0.00     0.00  memcpy [48]
  0.5      16.97     0.10  1940434     0.00     0.00  receive_meta [4]
  0.5      17.06     0.09  2913615     0.00     0.00  route [7]
  0.4      17.13     0.08  1941372     0.00     0.00  __vdso_gettc [58]

Baseline
Direct connection, no tincd.
[ ID] Interval           Transfer     Bitrate         Retr  Cwnd
[  5]   0.00-1.00   sec  4.46 GBytes  38.3 Gbits/sec    0   1.67 MBytes
[  5]   1.00-2.00   sec  4.72 GBytes  40.6 Gbits/sec    0   1.67 MBytes
[  5]   2.00-3.00   sec  4.74 GBytes  40.7 Gbits/sec    0   1.67 MBytes
[  5]   3.00-4.00   sec  4.78 GBytes  41.1 Gbits/sec    0   1.67 MBytes
[  5]   4.00-5.00   sec  4.73 GBytes  40.6 Gbits/sec    0   1.67 MBytes
[  5]   5.00-6.00   sec  4.77 GBytes  41.0 Gbits/sec    0   1.67 MBytes
[  5]   6.00-7.00   sec  4.76 GBytes  40.9 Gbits/sec    0   1.67 MBytes
[  5]   7.00-8.00   sec  4.72 GBytes  40.6 Gbits/sec    0   1.67 MBytes
[  5]   8.00-9.00   sec  4.74 GBytes  40.7 Gbits/sec    0   1.67 MBytes
[  5]   9.00-10.00  sec  4.69 GBytes  40.3 Gbits/sec    0   1.67 MBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-10.00  sec  47.1 GBytes  40.5 Gbits/sec    0             sender
[  5]   0.00-10.00  sec  47.1 GBytes  40.5 Gbits/sec                  receiver

$ wrk -c400 -d5s http://192.168.122.4
Running 5s test @ http://192.168.122.4
  2 threads and 400 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     6.92ms  557.62us  20.31ms   97.69%
    Req/Sec    29.05k   848.97    30.30k    80.00%
  289106 requests in 5.02s, 234.36MB read
Requests/sec:  57641.66
Transfer/sec:     46.73MB

epoll + select
$ wrk -c400 -d30s http://10.0.0.2
Running 30s test @ http://10.0.0.2
  2 threads and 400 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency    37.70ms   82.95ms 845.70ms   87.98%
    Req/Sec    31.46k     5.44k   52.88k    72.67%
  1878491 requests in 30.03s, 1.49GB read
Requests/sec:  62554.59
Transfer/sec:     50.71MB

[ ID] Interval           Transfer     Bitrate         Retr  Cwnd
[  5]   0.00-1.00   sec   109 MBytes   917 Mbits/sec    0   1.69 MBytes
[  5]   1.00-2.00   sec  98.8 MBytes   828 Mbits/sec    0   1.69 MBytes
[  5]   2.00-3.00   sec   108 MBytes   902 Mbits/sec  485   1.30 MBytes
[  5]   3.00-4.00   sec   112 MBytes   944 Mbits/sec    0   1.41 MBytes
[  5]   4.00-5.00   sec   110 MBytes   923 Mbits/sec    0   1.51 MBytes
[  5]   5.00-6.00   sec   101 MBytes   849 Mbits/sec    0   1.57 MBytes
[  5]   6.00-7.00   sec   105 MBytes   881 Mbits/sec    0   1.61 MBytes
[  5]   7.00-8.00   sec  97.5 MBytes   818 Mbits/sec    0   1.61 MBytes
[  5]   8.00-9.00   sec  96.2 MBytes   807 Mbits/sec    0   1.61 MBytes
[  5]   9.00-10.00  sec   109 MBytes   912 Mbits/sec    0   1.65 MBytes
[  5]  10.00-11.00  sec   108 MBytes   902 Mbits/sec  729    597 KBytes
[  5]  11.00-12.00  sec   110 MBytes   923 Mbits/sec    0    724 KBytes
[  5]  12.00-13.00  sec   118 MBytes   986 Mbits/sec   34    646 KBytes
[  5]  13.00-14.00  sec   116 MBytes   975 Mbits/sec    0    773 KBytes
[  5]  14.00-15.00  sec   114 MBytes   954 Mbits/sec    0    881 KBytes
[  5]  15.00-16.00  sec   119 MBytes   996 Mbits/sec    2    718 KBytes
[  5]  16.00-17.00  sec   116 MBytes   975 Mbits/sec   20    646 KBytes
[  5]  17.00-18.00  sec   118 MBytes   986 Mbits/sec    0    775 KBytes
[  5]  18.00-19.00  sec   122 MBytes  1.03 Gbits/sec   10    655 KBytes
[  5]  19.00-20.00  sec   120 MBytes  1.01 Gbits/sec    0    786 KBytes
[  5]  20.00-21.00  sec   119 MBytes   996 Mbits/sec   21    673 KBytes
[  5]  21.00-22.00  sec   114 MBytes   954 Mbits/sec   19    576 KBytes
[  5]  22.00-23.00  sec   118 MBytes   986 Mbits/sec    0    717 KBytes
[  5]  23.00-24.00  sec   116 MBytes   975 Mbits/sec    3    649 KBytes
[  5]  24.00-25.00  sec   116 MBytes   975 Mbits/sec    9    576 KBytes
[  5]  25.00-26.00  sec   115 MBytes   965 Mbits/sec    0    716 KBytes
[  5]  26.00-27.00  sec   114 MBytes   954 Mbits/sec    0    827 KBytes
[  5]  27.00-28.00  sec   119 MBytes   996 Mbits/sec    2    665 KBytes
[  5]  28.00-29.00  sec   116 MBytes   975 Mbits/sec    0    789 KBytes
[  5]  29.00-30.00  sec   119 MBytes   996 Mbits/sec    0    898 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-30.00  sec  3.29 GBytes   943 Mbits/sec  1334             sender
[  5]   0.00-30.01  sec  3.29 GBytes   942 Mbits/sec                  receiver

epoll + kqueue
$ wrk -c400 -d30s http://10.0.0.2
Running 30s test @ http://10.0.0.2
  2 threads and 400 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency    34.13ms   79.44ms 986.57ms   88.72%
    Req/Sec    30.34k     5.57k   52.94k    70.00%
  1811878 requests in 30.03s, 1.43GB read
Requests/sec:  60327.43
Transfer/sec:     48.90MB

[ ID] Interval           Transfer     Bitrate         Retr  Cwnd
[  5]   0.00-1.00   sec   119 MBytes   998 Mbits/sec  706    634 KBytes
[  5]   1.00-2.00   sec   118 MBytes   986 Mbits/sec   38    536 KBytes
[  5]   2.00-3.00   sec   120 MBytes  1.01 Gbits/sec    0    689 KBytes
[  5]   3.00-4.00   sec   119 MBytes   996 Mbits/sec    2    631 KBytes
[  5]   4.00-5.00   sec   115 MBytes   965 Mbits/sec    0    755 KBytes
[  5]   5.00-6.00   sec   118 MBytes   986 Mbits/sec    0    868 KBytes
[  5]   6.00-7.00   sec   120 MBytes  1.01 Gbits/sec  150    505 KBytes
[  5]   7.00-8.00   sec   121 MBytes  1.02 Gbits/sec    0    663 KBytes
[  5]   8.00-9.00   sec   122 MBytes  1.03 Gbits/sec    0    796 KBytes
[  5]   9.00-10.00  sec   120 MBytes  1.01 Gbits/sec   98    659 KBytes
[  5]  10.00-11.00  sec   121 MBytes  1.02 Gbits/sec    0    792 KBytes
[  5]  11.00-12.00  sec   125 MBytes  1.05 Gbits/sec    0    902 KBytes
[  5]  12.00-13.00  sec   116 MBytes   975 Mbits/sec   23    576 KBytes
[  5]  13.00-14.00  sec   119 MBytes   996 Mbits/sec    0    716 KBytes
[  5]  14.00-15.00  sec   118 MBytes   986 Mbits/sec   27    609 KBytes
[  5]  15.00-16.00  sec   120 MBytes  1.01 Gbits/sec    0    748 KBytes
[  5]  16.00-17.00  sec   118 MBytes   986 Mbits/sec   59    650 KBytes
[  5]  17.00-18.00  sec   120 MBytes  1.01 Gbits/sec   21    577 KBytes
[  5]  18.00-19.00  sec   122 MBytes  1.03 Gbits/sec   11    502 KBytes
[  5]  19.00-20.00  sec   121 MBytes  1.02 Gbits/sec    0    663 KBytes
[  5]  20.00-21.00  sec   118 MBytes   986 Mbits/sec    0    790 KBytes
[  5]  21.00-22.00  sec   118 MBytes   986 Mbits/sec   40    560 KBytes
[  5]  22.00-23.00  sec   119 MBytes   996 Mbits/sec    0    706 KBytes
[  5]  23.00-24.00  sec   124 MBytes  1.04 Gbits/sec    0    829 KBytes
[  5]  24.00-25.00  sec   124 MBytes  1.04 Gbits/sec   76    703 KBytes
[  5]  25.00-26.00  sec   124 MBytes  1.04 Gbits/sec   35    585 KBytes
[  5]  26.00-27.00  sec   125 MBytes  1.05 Gbits/sec    0    732 KBytes
[  5]  27.00-28.00  sec   122 MBytes  1.03 Gbits/sec   20    665 KBytes
[  5]  28.00-29.00  sec   119 MBytes   996 Mbits/sec    0    789 KBytes
[  5]  29.00-30.00  sec   120 MBytes  1.01 Gbits/sec   49    478 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-30.00  sec  3.52 GBytes  1.01 Gbits/sec  1355             sender
[  5]   0.00-30.01  sec  3.52 GBytes  1.01 Gbits/sec                  receiver

wrk results are very unstable and could easily be swapped the other way. The only real difference I'm seeing are somewhat lower latencies with kqueue.","Similar to #266, but for FreeBSD/OpenBSD/NetBSD/macOS.
event.c is in need of splitting into multiple files. I'd rather do that in a separate PR.
Performance
It would be great to test this on physical machines with a fast network between them, if only I had the hardware. So here are results for a FreeBSD VM (13.1) on a Linux desktop (5.17.5).
Profiles
Start tincd, run 30 seconds of iperf3, stop tincd.
select
%   cumulative   self              self     total
 time   seconds   seconds    calls  ms/call  ms/call  name
 27.6       5.27     5.27       10   527.41   527.41  __sys_write [3]
 17.9       8.69     3.42        0  100.00%           __sys_select [13]
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
 15.0      11.56     2.87        0  100.00%           _mcount [16]
 14.9      14.40     2.84        0  100.00%           __sys_sendto [17]
  9.8      16.28     1.87        0  100.00%           _recvfrom [20]
  2.0      16.67     0.39 12124817     0.00     0.00  logger [11]
  1.8      17.01     0.34        0  100.00%           .mcount (501)
  1.5      17.30     0.29        1   291.34  6852.63  event_loop [2]
  1.5      17.58     0.28       20    14.22    14.22  __sys_read [39]
  0.7      17.72     0.14  2017455     0.00     0.00  __svfscanf [36]
  0.6      17.85     0.12  3026242     0.00     0.00  __vdso_gettc [48]
  0.6      17.96     0.11  1012231     0.00     0.00  __vfprintf [44]
  0.6      18.07     0.11  5054394     0.00     0.00  memcpy [50]
  0.5      18.16     0.09  3029506     0.00     0.00  route [14]
  0.4      18.24     0.08  2017424     0.00     0.00  receive_meta [6]

kqueue
%   cumulative   self              self     total
 time   seconds   seconds    calls  ms/call  ms/call  name
 27.4       4.92     4.92       10   492.41   492.41  __sys_write [5]
 17.1       8.00     3.07        0  100.00%           __sys_sendto [17]
 16.5      10.96     2.97        0  100.00%           _mcount [18]
 12.3      13.18     2.21        0  100.00%           _recvfrom [21]
 12.2      15.36     2.19  3879960     0.00     0.00  __sys_kevent [23]
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  2.0      15.72     0.36 11660378     0.00     0.00  logger [12]
  2.0      16.07     0.35        0  100.00%           .mcount (498)
  1.5      16.34     0.27       20    13.46    13.46  _read [40]
  1.0      16.52     0.17  1940474     0.00     0.00  __svfscanf [38]
  0.8      16.66     0.14   973307     0.00     0.00  __vfprintf [45]
  0.6      16.77     0.11        1   114.30  8491.48  event_loop [2]
  0.6      16.87     0.11  4860650     0.00     0.00  memcpy [48]
  0.5      16.97     0.10  1940434     0.00     0.00  receive_meta [4]
  0.5      17.06     0.09  2913615     0.00     0.00  route [7]
  0.4      17.13     0.08  1941372     0.00     0.00  __vdso_gettc [58]

Baseline
Direct connection, no tincd.
[ ID] Interval           Transfer     Bitrate         Retr  Cwnd
[  5]   0.00-1.00   sec  4.46 GBytes  38.3 Gbits/sec    0   1.67 MBytes
[  5]   1.00-2.00   sec  4.72 GBytes  40.6 Gbits/sec    0   1.67 MBytes
[  5]   2.00-3.00   sec  4.74 GBytes  40.7 Gbits/sec    0   1.67 MBytes
[  5]   3.00-4.00   sec  4.78 GBytes  41.1 Gbits/sec    0   1.67 MBytes
[  5]   4.00-5.00   sec  4.73 GBytes  40.6 Gbits/sec    0   1.67 MBytes
[  5]   5.00-6.00   sec  4.77 GBytes  41.0 Gbits/sec    0   1.67 MBytes
[  5]   6.00-7.00   sec  4.76 GBytes  40.9 Gbits/sec    0   1.67 MBytes
[  5]   7.00-8.00   sec  4.72 GBytes  40.6 Gbits/sec    0   1.67 MBytes
[  5]   8.00-9.00   sec  4.74 GBytes  40.7 Gbits/sec    0   1.67 MBytes
[  5]   9.00-10.00  sec  4.69 GBytes  40.3 Gbits/sec    0   1.67 MBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-10.00  sec  47.1 GBytes  40.5 Gbits/sec    0             sender
[  5]   0.00-10.00  sec  47.1 GBytes  40.5 Gbits/sec                  receiver

$ wrk -c400 -d5s http://192.168.122.4
Running 5s test @ http://192.168.122.4
  2 threads and 400 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     6.92ms  557.62us  20.31ms   97.69%
    Req/Sec    29.05k   848.97    30.30k    80.00%
  289106 requests in 5.02s, 234.36MB read
Requests/sec:  57641.66
Transfer/sec:     46.73MB

epoll + select
$ wrk -c400 -d30s http://10.0.0.2
Running 30s test @ http://10.0.0.2
  2 threads and 400 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency    37.70ms   82.95ms 845.70ms   87.98%
    Req/Sec    31.46k     5.44k   52.88k    72.67%
  1878491 requests in 30.03s, 1.49GB read
Requests/sec:  62554.59
Transfer/sec:     50.71MB

[ ID] Interval           Transfer     Bitrate         Retr  Cwnd
[  5]   0.00-1.00   sec   109 MBytes   917 Mbits/sec    0   1.69 MBytes
[  5]   1.00-2.00   sec  98.8 MBytes   828 Mbits/sec    0   1.69 MBytes
[  5]   2.00-3.00   sec   108 MBytes   902 Mbits/sec  485   1.30 MBytes
[  5]   3.00-4.00   sec   112 MBytes   944 Mbits/sec    0   1.41 MBytes
[  5]   4.00-5.00   sec   110 MBytes   923 Mbits/sec    0   1.51 MBytes
[  5]   5.00-6.00   sec   101 MBytes   849 Mbits/sec    0   1.57 MBytes
[  5]   6.00-7.00   sec   105 MBytes   881 Mbits/sec    0   1.61 MBytes
[  5]   7.00-8.00   sec  97.5 MBytes   818 Mbits/sec    0   1.61 MBytes
[  5]   8.00-9.00   sec  96.2 MBytes   807 Mbits/sec    0   1.61 MBytes
[  5]   9.00-10.00  sec   109 MBytes   912 Mbits/sec    0   1.65 MBytes
[  5]  10.00-11.00  sec   108 MBytes   902 Mbits/sec  729    597 KBytes
[  5]  11.00-12.00  sec   110 MBytes   923 Mbits/sec    0    724 KBytes
[  5]  12.00-13.00  sec   118 MBytes   986 Mbits/sec   34    646 KBytes
[  5]  13.00-14.00  sec   116 MBytes   975 Mbits/sec    0    773 KBytes
[  5]  14.00-15.00  sec   114 MBytes   954 Mbits/sec    0    881 KBytes
[  5]  15.00-16.00  sec   119 MBytes   996 Mbits/sec    2    718 KBytes
[  5]  16.00-17.00  sec   116 MBytes   975 Mbits/sec   20    646 KBytes
[  5]  17.00-18.00  sec   118 MBytes   986 Mbits/sec    0    775 KBytes
[  5]  18.00-19.00  sec   122 MBytes  1.03 Gbits/sec   10    655 KBytes
[  5]  19.00-20.00  sec   120 MBytes  1.01 Gbits/sec    0    786 KBytes
[  5]  20.00-21.00  sec   119 MBytes   996 Mbits/sec   21    673 KBytes
[  5]  21.00-22.00  sec   114 MBytes   954 Mbits/sec   19    576 KBytes
[  5]  22.00-23.00  sec   118 MBytes   986 Mbits/sec    0    717 KBytes
[  5]  23.00-24.00  sec   116 MBytes   975 Mbits/sec    3    649 KBytes
[  5]  24.00-25.00  sec   116 MBytes   975 Mbits/sec    9    576 KBytes
[  5]  25.00-26.00  sec   115 MBytes   965 Mbits/sec    0    716 KBytes
[  5]  26.00-27.00  sec   114 MBytes   954 Mbits/sec    0    827 KBytes
[  5]  27.00-28.00  sec   119 MBytes   996 Mbits/sec    2    665 KBytes
[  5]  28.00-29.00  sec   116 MBytes   975 Mbits/sec    0    789 KBytes
[  5]  29.00-30.00  sec   119 MBytes   996 Mbits/sec    0    898 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-30.00  sec  3.29 GBytes   943 Mbits/sec  1334             sender
[  5]   0.00-30.01  sec  3.29 GBytes   942 Mbits/sec                  receiver

epoll + kqueue
$ wrk -c400 -d30s http://10.0.0.2
Running 30s test @ http://10.0.0.2
  2 threads and 400 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency    34.13ms   79.44ms 986.57ms   88.72%
    Req/Sec    30.34k     5.57k   52.94k    70.00%
  1811878 requests in 30.03s, 1.43GB read
Requests/sec:  60327.43
Transfer/sec:     48.90MB

[ ID] Interval           Transfer     Bitrate         Retr  Cwnd
[  5]   0.00-1.00   sec   119 MBytes   998 Mbits/sec  706    634 KBytes
[  5]   1.00-2.00   sec   118 MBytes   986 Mbits/sec   38    536 KBytes
[  5]   2.00-3.00   sec   120 MBytes  1.01 Gbits/sec    0    689 KBytes
[  5]   3.00-4.00   sec   119 MBytes   996 Mbits/sec    2    631 KBytes
[  5]   4.00-5.00   sec   115 MBytes   965 Mbits/sec    0    755 KBytes
[  5]   5.00-6.00   sec   118 MBytes   986 Mbits/sec    0    868 KBytes
[  5]   6.00-7.00   sec   120 MBytes  1.01 Gbits/sec  150    505 KBytes
[  5]   7.00-8.00   sec   121 MBytes  1.02 Gbits/sec    0    663 KBytes
[  5]   8.00-9.00   sec   122 MBytes  1.03 Gbits/sec    0    796 KBytes
[  5]   9.00-10.00  sec   120 MBytes  1.01 Gbits/sec   98    659 KBytes
[  5]  10.00-11.00  sec   121 MBytes  1.02 Gbits/sec    0    792 KBytes
[  5]  11.00-12.00  sec   125 MBytes  1.05 Gbits/sec    0    902 KBytes
[  5]  12.00-13.00  sec   116 MBytes   975 Mbits/sec   23    576 KBytes
[  5]  13.00-14.00  sec   119 MBytes   996 Mbits/sec    0    716 KBytes
[  5]  14.00-15.00  sec   118 MBytes   986 Mbits/sec   27    609 KBytes
[  5]  15.00-16.00  sec   120 MBytes  1.01 Gbits/sec    0    748 KBytes
[  5]  16.00-17.00  sec   118 MBytes   986 Mbits/sec   59    650 KBytes
[  5]  17.00-18.00  sec   120 MBytes  1.01 Gbits/sec   21    577 KBytes
[  5]  18.00-19.00  sec   122 MBytes  1.03 Gbits/sec   11    502 KBytes
[  5]  19.00-20.00  sec   121 MBytes  1.02 Gbits/sec    0    663 KBytes
[  5]  20.00-21.00  sec   118 MBytes   986 Mbits/sec    0    790 KBytes
[  5]  21.00-22.00  sec   118 MBytes   986 Mbits/sec   40    560 KBytes
[  5]  22.00-23.00  sec   119 MBytes   996 Mbits/sec    0    706 KBytes
[  5]  23.00-24.00  sec   124 MBytes  1.04 Gbits/sec    0    829 KBytes
[  5]  24.00-25.00  sec   124 MBytes  1.04 Gbits/sec   76    703 KBytes
[  5]  25.00-26.00  sec   124 MBytes  1.04 Gbits/sec   35    585 KBytes
[  5]  26.00-27.00  sec   125 MBytes  1.05 Gbits/sec    0    732 KBytes
[  5]  27.00-28.00  sec   122 MBytes  1.03 Gbits/sec   20    665 KBytes
[  5]  28.00-29.00  sec   119 MBytes   996 Mbits/sec    0    789 KBytes
[  5]  29.00-30.00  sec   120 MBytes  1.01 Gbits/sec   49    478 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-30.00  sec  3.52 GBytes  1.01 Gbits/sec  1355             sender
[  5]   0.00-30.01  sec  3.52 GBytes  1.01 Gbits/sec                  receiver

wrk results are very unstable and could easily be swapped the other way. The only real difference I'm seeing are somewhat lower latencies with kqueue.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,387,2022-05-17T14:33:59Z,2022-05-26T17:54:10Z,2022-05-26T17:54:10Z,MERGED,True,827,475,14,https://github.com/hg,BSD: add kqueue support,2,[],https://github.com/gsliepen/tinc/pull/387,https://github.com/hg,2,https://github.com/gsliepen/tinc/pull/387#issuecomment-1128953093,"Similar to #266, but for FreeBSD/OpenBSD/NetBSD/macOS.
event.c is in need of splitting into multiple files. I'd rather do that in a separate PR.
Performance
It would be great to test this on physical machines with a fast network between them, if only I had the hardware. So here are results for a FreeBSD VM (13.1) on a Linux desktop (5.17.5).
Profiles
Start tincd, run 30 seconds of iperf3, stop tincd.
select
%   cumulative   self              self     total
 time   seconds   seconds    calls  ms/call  ms/call  name
 27.6       5.27     5.27       10   527.41   527.41  __sys_write [3]
 17.9       8.69     3.42        0  100.00%           __sys_select [13]
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
 15.0      11.56     2.87        0  100.00%           _mcount [16]
 14.9      14.40     2.84        0  100.00%           __sys_sendto [17]
  9.8      16.28     1.87        0  100.00%           _recvfrom [20]
  2.0      16.67     0.39 12124817     0.00     0.00  logger [11]
  1.8      17.01     0.34        0  100.00%           .mcount (501)
  1.5      17.30     0.29        1   291.34  6852.63  event_loop [2]
  1.5      17.58     0.28       20    14.22    14.22  __sys_read [39]
  0.7      17.72     0.14  2017455     0.00     0.00  __svfscanf [36]
  0.6      17.85     0.12  3026242     0.00     0.00  __vdso_gettc [48]
  0.6      17.96     0.11  1012231     0.00     0.00  __vfprintf [44]
  0.6      18.07     0.11  5054394     0.00     0.00  memcpy [50]
  0.5      18.16     0.09  3029506     0.00     0.00  route [14]
  0.4      18.24     0.08  2017424     0.00     0.00  receive_meta [6]

kqueue
%   cumulative   self              self     total
 time   seconds   seconds    calls  ms/call  ms/call  name
 27.4       4.92     4.92       10   492.41   492.41  __sys_write [5]
 17.1       8.00     3.07        0  100.00%           __sys_sendto [17]
 16.5      10.96     2.97        0  100.00%           _mcount [18]
 12.3      13.18     2.21        0  100.00%           _recvfrom [21]
 12.2      15.36     2.19  3879960     0.00     0.00  __sys_kevent [23]
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  2.0      15.72     0.36 11660378     0.00     0.00  logger [12]
  2.0      16.07     0.35        0  100.00%           .mcount (498)
  1.5      16.34     0.27       20    13.46    13.46  _read [40]
  1.0      16.52     0.17  1940474     0.00     0.00  __svfscanf [38]
  0.8      16.66     0.14   973307     0.00     0.00  __vfprintf [45]
  0.6      16.77     0.11        1   114.30  8491.48  event_loop [2]
  0.6      16.87     0.11  4860650     0.00     0.00  memcpy [48]
  0.5      16.97     0.10  1940434     0.00     0.00  receive_meta [4]
  0.5      17.06     0.09  2913615     0.00     0.00  route [7]
  0.4      17.13     0.08  1941372     0.00     0.00  __vdso_gettc [58]

Baseline
Direct connection, no tincd.
[ ID] Interval           Transfer     Bitrate         Retr  Cwnd
[  5]   0.00-1.00   sec  4.46 GBytes  38.3 Gbits/sec    0   1.67 MBytes
[  5]   1.00-2.00   sec  4.72 GBytes  40.6 Gbits/sec    0   1.67 MBytes
[  5]   2.00-3.00   sec  4.74 GBytes  40.7 Gbits/sec    0   1.67 MBytes
[  5]   3.00-4.00   sec  4.78 GBytes  41.1 Gbits/sec    0   1.67 MBytes
[  5]   4.00-5.00   sec  4.73 GBytes  40.6 Gbits/sec    0   1.67 MBytes
[  5]   5.00-6.00   sec  4.77 GBytes  41.0 Gbits/sec    0   1.67 MBytes
[  5]   6.00-7.00   sec  4.76 GBytes  40.9 Gbits/sec    0   1.67 MBytes
[  5]   7.00-8.00   sec  4.72 GBytes  40.6 Gbits/sec    0   1.67 MBytes
[  5]   8.00-9.00   sec  4.74 GBytes  40.7 Gbits/sec    0   1.67 MBytes
[  5]   9.00-10.00  sec  4.69 GBytes  40.3 Gbits/sec    0   1.67 MBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-10.00  sec  47.1 GBytes  40.5 Gbits/sec    0             sender
[  5]   0.00-10.00  sec  47.1 GBytes  40.5 Gbits/sec                  receiver

$ wrk -c400 -d5s http://192.168.122.4
Running 5s test @ http://192.168.122.4
  2 threads and 400 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     6.92ms  557.62us  20.31ms   97.69%
    Req/Sec    29.05k   848.97    30.30k    80.00%
  289106 requests in 5.02s, 234.36MB read
Requests/sec:  57641.66
Transfer/sec:     46.73MB

epoll + select
$ wrk -c400 -d30s http://10.0.0.2
Running 30s test @ http://10.0.0.2
  2 threads and 400 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency    37.70ms   82.95ms 845.70ms   87.98%
    Req/Sec    31.46k     5.44k   52.88k    72.67%
  1878491 requests in 30.03s, 1.49GB read
Requests/sec:  62554.59
Transfer/sec:     50.71MB

[ ID] Interval           Transfer     Bitrate         Retr  Cwnd
[  5]   0.00-1.00   sec   109 MBytes   917 Mbits/sec    0   1.69 MBytes
[  5]   1.00-2.00   sec  98.8 MBytes   828 Mbits/sec    0   1.69 MBytes
[  5]   2.00-3.00   sec   108 MBytes   902 Mbits/sec  485   1.30 MBytes
[  5]   3.00-4.00   sec   112 MBytes   944 Mbits/sec    0   1.41 MBytes
[  5]   4.00-5.00   sec   110 MBytes   923 Mbits/sec    0   1.51 MBytes
[  5]   5.00-6.00   sec   101 MBytes   849 Mbits/sec    0   1.57 MBytes
[  5]   6.00-7.00   sec   105 MBytes   881 Mbits/sec    0   1.61 MBytes
[  5]   7.00-8.00   sec  97.5 MBytes   818 Mbits/sec    0   1.61 MBytes
[  5]   8.00-9.00   sec  96.2 MBytes   807 Mbits/sec    0   1.61 MBytes
[  5]   9.00-10.00  sec   109 MBytes   912 Mbits/sec    0   1.65 MBytes
[  5]  10.00-11.00  sec   108 MBytes   902 Mbits/sec  729    597 KBytes
[  5]  11.00-12.00  sec   110 MBytes   923 Mbits/sec    0    724 KBytes
[  5]  12.00-13.00  sec   118 MBytes   986 Mbits/sec   34    646 KBytes
[  5]  13.00-14.00  sec   116 MBytes   975 Mbits/sec    0    773 KBytes
[  5]  14.00-15.00  sec   114 MBytes   954 Mbits/sec    0    881 KBytes
[  5]  15.00-16.00  sec   119 MBytes   996 Mbits/sec    2    718 KBytes
[  5]  16.00-17.00  sec   116 MBytes   975 Mbits/sec   20    646 KBytes
[  5]  17.00-18.00  sec   118 MBytes   986 Mbits/sec    0    775 KBytes
[  5]  18.00-19.00  sec   122 MBytes  1.03 Gbits/sec   10    655 KBytes
[  5]  19.00-20.00  sec   120 MBytes  1.01 Gbits/sec    0    786 KBytes
[  5]  20.00-21.00  sec   119 MBytes   996 Mbits/sec   21    673 KBytes
[  5]  21.00-22.00  sec   114 MBytes   954 Mbits/sec   19    576 KBytes
[  5]  22.00-23.00  sec   118 MBytes   986 Mbits/sec    0    717 KBytes
[  5]  23.00-24.00  sec   116 MBytes   975 Mbits/sec    3    649 KBytes
[  5]  24.00-25.00  sec   116 MBytes   975 Mbits/sec    9    576 KBytes
[  5]  25.00-26.00  sec   115 MBytes   965 Mbits/sec    0    716 KBytes
[  5]  26.00-27.00  sec   114 MBytes   954 Mbits/sec    0    827 KBytes
[  5]  27.00-28.00  sec   119 MBytes   996 Mbits/sec    2    665 KBytes
[  5]  28.00-29.00  sec   116 MBytes   975 Mbits/sec    0    789 KBytes
[  5]  29.00-30.00  sec   119 MBytes   996 Mbits/sec    0    898 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-30.00  sec  3.29 GBytes   943 Mbits/sec  1334             sender
[  5]   0.00-30.01  sec  3.29 GBytes   942 Mbits/sec                  receiver

epoll + kqueue
$ wrk -c400 -d30s http://10.0.0.2
Running 30s test @ http://10.0.0.2
  2 threads and 400 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency    34.13ms   79.44ms 986.57ms   88.72%
    Req/Sec    30.34k     5.57k   52.94k    70.00%
  1811878 requests in 30.03s, 1.43GB read
Requests/sec:  60327.43
Transfer/sec:     48.90MB

[ ID] Interval           Transfer     Bitrate         Retr  Cwnd
[  5]   0.00-1.00   sec   119 MBytes   998 Mbits/sec  706    634 KBytes
[  5]   1.00-2.00   sec   118 MBytes   986 Mbits/sec   38    536 KBytes
[  5]   2.00-3.00   sec   120 MBytes  1.01 Gbits/sec    0    689 KBytes
[  5]   3.00-4.00   sec   119 MBytes   996 Mbits/sec    2    631 KBytes
[  5]   4.00-5.00   sec   115 MBytes   965 Mbits/sec    0    755 KBytes
[  5]   5.00-6.00   sec   118 MBytes   986 Mbits/sec    0    868 KBytes
[  5]   6.00-7.00   sec   120 MBytes  1.01 Gbits/sec  150    505 KBytes
[  5]   7.00-8.00   sec   121 MBytes  1.02 Gbits/sec    0    663 KBytes
[  5]   8.00-9.00   sec   122 MBytes  1.03 Gbits/sec    0    796 KBytes
[  5]   9.00-10.00  sec   120 MBytes  1.01 Gbits/sec   98    659 KBytes
[  5]  10.00-11.00  sec   121 MBytes  1.02 Gbits/sec    0    792 KBytes
[  5]  11.00-12.00  sec   125 MBytes  1.05 Gbits/sec    0    902 KBytes
[  5]  12.00-13.00  sec   116 MBytes   975 Mbits/sec   23    576 KBytes
[  5]  13.00-14.00  sec   119 MBytes   996 Mbits/sec    0    716 KBytes
[  5]  14.00-15.00  sec   118 MBytes   986 Mbits/sec   27    609 KBytes
[  5]  15.00-16.00  sec   120 MBytes  1.01 Gbits/sec    0    748 KBytes
[  5]  16.00-17.00  sec   118 MBytes   986 Mbits/sec   59    650 KBytes
[  5]  17.00-18.00  sec   120 MBytes  1.01 Gbits/sec   21    577 KBytes
[  5]  18.00-19.00  sec   122 MBytes  1.03 Gbits/sec   11    502 KBytes
[  5]  19.00-20.00  sec   121 MBytes  1.02 Gbits/sec    0    663 KBytes
[  5]  20.00-21.00  sec   118 MBytes   986 Mbits/sec    0    790 KBytes
[  5]  21.00-22.00  sec   118 MBytes   986 Mbits/sec   40    560 KBytes
[  5]  22.00-23.00  sec   119 MBytes   996 Mbits/sec    0    706 KBytes
[  5]  23.00-24.00  sec   124 MBytes  1.04 Gbits/sec    0    829 KBytes
[  5]  24.00-25.00  sec   124 MBytes  1.04 Gbits/sec   76    703 KBytes
[  5]  25.00-26.00  sec   124 MBytes  1.04 Gbits/sec   35    585 KBytes
[  5]  26.00-27.00  sec   125 MBytes  1.05 Gbits/sec    0    732 KBytes
[  5]  27.00-28.00  sec   122 MBytes  1.03 Gbits/sec   20    665 KBytes
[  5]  28.00-29.00  sec   119 MBytes   996 Mbits/sec    0    789 KBytes
[  5]  29.00-30.00  sec   120 MBytes  1.01 Gbits/sec   49    478 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-30.00  sec  3.52 GBytes  1.01 Gbits/sec  1355             sender
[  5]   0.00-30.01  sec  3.52 GBytes  1.01 Gbits/sec                  receiver

wrk results are very unstable and could easily be swapped the other way. The only real difference I'm seeing are somewhat lower latencies with kqueue.","Fedora job will fail because F36 is using OpenSSL 3.0. Fixed in #386.

There's also this patch which removes unnecessary calls to kevent(), improving iperf3 throughput by 4%.
Not sure how safe it is, though, since it depends on flags always being in agreement with internal kqueue state, unlike how both select and epoll support are implemented.
Edit: not needed anymore, see below.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,387,2022-05-17T14:33:59Z,2022-05-26T17:54:10Z,2022-05-26T17:54:10Z,MERGED,True,827,475,14,https://github.com/hg,BSD: add kqueue support,2,[],https://github.com/gsliepen/tinc/pull/387,https://github.com/gsliepen,3,https://github.com/gsliepen/tinc/pull/387#issuecomment-1129001922,"Similar to #266, but for FreeBSD/OpenBSD/NetBSD/macOS.
event.c is in need of splitting into multiple files. I'd rather do that in a separate PR.
Performance
It would be great to test this on physical machines with a fast network between them, if only I had the hardware. So here are results for a FreeBSD VM (13.1) on a Linux desktop (5.17.5).
Profiles
Start tincd, run 30 seconds of iperf3, stop tincd.
select
%   cumulative   self              self     total
 time   seconds   seconds    calls  ms/call  ms/call  name
 27.6       5.27     5.27       10   527.41   527.41  __sys_write [3]
 17.9       8.69     3.42        0  100.00%           __sys_select [13]
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
 15.0      11.56     2.87        0  100.00%           _mcount [16]
 14.9      14.40     2.84        0  100.00%           __sys_sendto [17]
  9.8      16.28     1.87        0  100.00%           _recvfrom [20]
  2.0      16.67     0.39 12124817     0.00     0.00  logger [11]
  1.8      17.01     0.34        0  100.00%           .mcount (501)
  1.5      17.30     0.29        1   291.34  6852.63  event_loop [2]
  1.5      17.58     0.28       20    14.22    14.22  __sys_read [39]
  0.7      17.72     0.14  2017455     0.00     0.00  __svfscanf [36]
  0.6      17.85     0.12  3026242     0.00     0.00  __vdso_gettc [48]
  0.6      17.96     0.11  1012231     0.00     0.00  __vfprintf [44]
  0.6      18.07     0.11  5054394     0.00     0.00  memcpy [50]
  0.5      18.16     0.09  3029506     0.00     0.00  route [14]
  0.4      18.24     0.08  2017424     0.00     0.00  receive_meta [6]

kqueue
%   cumulative   self              self     total
 time   seconds   seconds    calls  ms/call  ms/call  name
 27.4       4.92     4.92       10   492.41   492.41  __sys_write [5]
 17.1       8.00     3.07        0  100.00%           __sys_sendto [17]
 16.5      10.96     2.97        0  100.00%           _mcount [18]
 12.3      13.18     2.21        0  100.00%           _recvfrom [21]
 12.2      15.36     2.19  3879960     0.00     0.00  __sys_kevent [23]
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  2.0      15.72     0.36 11660378     0.00     0.00  logger [12]
  2.0      16.07     0.35        0  100.00%           .mcount (498)
  1.5      16.34     0.27       20    13.46    13.46  _read [40]
  1.0      16.52     0.17  1940474     0.00     0.00  __svfscanf [38]
  0.8      16.66     0.14   973307     0.00     0.00  __vfprintf [45]
  0.6      16.77     0.11        1   114.30  8491.48  event_loop [2]
  0.6      16.87     0.11  4860650     0.00     0.00  memcpy [48]
  0.5      16.97     0.10  1940434     0.00     0.00  receive_meta [4]
  0.5      17.06     0.09  2913615     0.00     0.00  route [7]
  0.4      17.13     0.08  1941372     0.00     0.00  __vdso_gettc [58]

Baseline
Direct connection, no tincd.
[ ID] Interval           Transfer     Bitrate         Retr  Cwnd
[  5]   0.00-1.00   sec  4.46 GBytes  38.3 Gbits/sec    0   1.67 MBytes
[  5]   1.00-2.00   sec  4.72 GBytes  40.6 Gbits/sec    0   1.67 MBytes
[  5]   2.00-3.00   sec  4.74 GBytes  40.7 Gbits/sec    0   1.67 MBytes
[  5]   3.00-4.00   sec  4.78 GBytes  41.1 Gbits/sec    0   1.67 MBytes
[  5]   4.00-5.00   sec  4.73 GBytes  40.6 Gbits/sec    0   1.67 MBytes
[  5]   5.00-6.00   sec  4.77 GBytes  41.0 Gbits/sec    0   1.67 MBytes
[  5]   6.00-7.00   sec  4.76 GBytes  40.9 Gbits/sec    0   1.67 MBytes
[  5]   7.00-8.00   sec  4.72 GBytes  40.6 Gbits/sec    0   1.67 MBytes
[  5]   8.00-9.00   sec  4.74 GBytes  40.7 Gbits/sec    0   1.67 MBytes
[  5]   9.00-10.00  sec  4.69 GBytes  40.3 Gbits/sec    0   1.67 MBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-10.00  sec  47.1 GBytes  40.5 Gbits/sec    0             sender
[  5]   0.00-10.00  sec  47.1 GBytes  40.5 Gbits/sec                  receiver

$ wrk -c400 -d5s http://192.168.122.4
Running 5s test @ http://192.168.122.4
  2 threads and 400 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     6.92ms  557.62us  20.31ms   97.69%
    Req/Sec    29.05k   848.97    30.30k    80.00%
  289106 requests in 5.02s, 234.36MB read
Requests/sec:  57641.66
Transfer/sec:     46.73MB

epoll + select
$ wrk -c400 -d30s http://10.0.0.2
Running 30s test @ http://10.0.0.2
  2 threads and 400 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency    37.70ms   82.95ms 845.70ms   87.98%
    Req/Sec    31.46k     5.44k   52.88k    72.67%
  1878491 requests in 30.03s, 1.49GB read
Requests/sec:  62554.59
Transfer/sec:     50.71MB

[ ID] Interval           Transfer     Bitrate         Retr  Cwnd
[  5]   0.00-1.00   sec   109 MBytes   917 Mbits/sec    0   1.69 MBytes
[  5]   1.00-2.00   sec  98.8 MBytes   828 Mbits/sec    0   1.69 MBytes
[  5]   2.00-3.00   sec   108 MBytes   902 Mbits/sec  485   1.30 MBytes
[  5]   3.00-4.00   sec   112 MBytes   944 Mbits/sec    0   1.41 MBytes
[  5]   4.00-5.00   sec   110 MBytes   923 Mbits/sec    0   1.51 MBytes
[  5]   5.00-6.00   sec   101 MBytes   849 Mbits/sec    0   1.57 MBytes
[  5]   6.00-7.00   sec   105 MBytes   881 Mbits/sec    0   1.61 MBytes
[  5]   7.00-8.00   sec  97.5 MBytes   818 Mbits/sec    0   1.61 MBytes
[  5]   8.00-9.00   sec  96.2 MBytes   807 Mbits/sec    0   1.61 MBytes
[  5]   9.00-10.00  sec   109 MBytes   912 Mbits/sec    0   1.65 MBytes
[  5]  10.00-11.00  sec   108 MBytes   902 Mbits/sec  729    597 KBytes
[  5]  11.00-12.00  sec   110 MBytes   923 Mbits/sec    0    724 KBytes
[  5]  12.00-13.00  sec   118 MBytes   986 Mbits/sec   34    646 KBytes
[  5]  13.00-14.00  sec   116 MBytes   975 Mbits/sec    0    773 KBytes
[  5]  14.00-15.00  sec   114 MBytes   954 Mbits/sec    0    881 KBytes
[  5]  15.00-16.00  sec   119 MBytes   996 Mbits/sec    2    718 KBytes
[  5]  16.00-17.00  sec   116 MBytes   975 Mbits/sec   20    646 KBytes
[  5]  17.00-18.00  sec   118 MBytes   986 Mbits/sec    0    775 KBytes
[  5]  18.00-19.00  sec   122 MBytes  1.03 Gbits/sec   10    655 KBytes
[  5]  19.00-20.00  sec   120 MBytes  1.01 Gbits/sec    0    786 KBytes
[  5]  20.00-21.00  sec   119 MBytes   996 Mbits/sec   21    673 KBytes
[  5]  21.00-22.00  sec   114 MBytes   954 Mbits/sec   19    576 KBytes
[  5]  22.00-23.00  sec   118 MBytes   986 Mbits/sec    0    717 KBytes
[  5]  23.00-24.00  sec   116 MBytes   975 Mbits/sec    3    649 KBytes
[  5]  24.00-25.00  sec   116 MBytes   975 Mbits/sec    9    576 KBytes
[  5]  25.00-26.00  sec   115 MBytes   965 Mbits/sec    0    716 KBytes
[  5]  26.00-27.00  sec   114 MBytes   954 Mbits/sec    0    827 KBytes
[  5]  27.00-28.00  sec   119 MBytes   996 Mbits/sec    2    665 KBytes
[  5]  28.00-29.00  sec   116 MBytes   975 Mbits/sec    0    789 KBytes
[  5]  29.00-30.00  sec   119 MBytes   996 Mbits/sec    0    898 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-30.00  sec  3.29 GBytes   943 Mbits/sec  1334             sender
[  5]   0.00-30.01  sec  3.29 GBytes   942 Mbits/sec                  receiver

epoll + kqueue
$ wrk -c400 -d30s http://10.0.0.2
Running 30s test @ http://10.0.0.2
  2 threads and 400 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency    34.13ms   79.44ms 986.57ms   88.72%
    Req/Sec    30.34k     5.57k   52.94k    70.00%
  1811878 requests in 30.03s, 1.43GB read
Requests/sec:  60327.43
Transfer/sec:     48.90MB

[ ID] Interval           Transfer     Bitrate         Retr  Cwnd
[  5]   0.00-1.00   sec   119 MBytes   998 Mbits/sec  706    634 KBytes
[  5]   1.00-2.00   sec   118 MBytes   986 Mbits/sec   38    536 KBytes
[  5]   2.00-3.00   sec   120 MBytes  1.01 Gbits/sec    0    689 KBytes
[  5]   3.00-4.00   sec   119 MBytes   996 Mbits/sec    2    631 KBytes
[  5]   4.00-5.00   sec   115 MBytes   965 Mbits/sec    0    755 KBytes
[  5]   5.00-6.00   sec   118 MBytes   986 Mbits/sec    0    868 KBytes
[  5]   6.00-7.00   sec   120 MBytes  1.01 Gbits/sec  150    505 KBytes
[  5]   7.00-8.00   sec   121 MBytes  1.02 Gbits/sec    0    663 KBytes
[  5]   8.00-9.00   sec   122 MBytes  1.03 Gbits/sec    0    796 KBytes
[  5]   9.00-10.00  sec   120 MBytes  1.01 Gbits/sec   98    659 KBytes
[  5]  10.00-11.00  sec   121 MBytes  1.02 Gbits/sec    0    792 KBytes
[  5]  11.00-12.00  sec   125 MBytes  1.05 Gbits/sec    0    902 KBytes
[  5]  12.00-13.00  sec   116 MBytes   975 Mbits/sec   23    576 KBytes
[  5]  13.00-14.00  sec   119 MBytes   996 Mbits/sec    0    716 KBytes
[  5]  14.00-15.00  sec   118 MBytes   986 Mbits/sec   27    609 KBytes
[  5]  15.00-16.00  sec   120 MBytes  1.01 Gbits/sec    0    748 KBytes
[  5]  16.00-17.00  sec   118 MBytes   986 Mbits/sec   59    650 KBytes
[  5]  17.00-18.00  sec   120 MBytes  1.01 Gbits/sec   21    577 KBytes
[  5]  18.00-19.00  sec   122 MBytes  1.03 Gbits/sec   11    502 KBytes
[  5]  19.00-20.00  sec   121 MBytes  1.02 Gbits/sec    0    663 KBytes
[  5]  20.00-21.00  sec   118 MBytes   986 Mbits/sec    0    790 KBytes
[  5]  21.00-22.00  sec   118 MBytes   986 Mbits/sec   40    560 KBytes
[  5]  22.00-23.00  sec   119 MBytes   996 Mbits/sec    0    706 KBytes
[  5]  23.00-24.00  sec   124 MBytes  1.04 Gbits/sec    0    829 KBytes
[  5]  24.00-25.00  sec   124 MBytes  1.04 Gbits/sec   76    703 KBytes
[  5]  25.00-26.00  sec   124 MBytes  1.04 Gbits/sec   35    585 KBytes
[  5]  26.00-27.00  sec   125 MBytes  1.05 Gbits/sec    0    732 KBytes
[  5]  27.00-28.00  sec   122 MBytes  1.03 Gbits/sec   20    665 KBytes
[  5]  28.00-29.00  sec   119 MBytes   996 Mbits/sec    0    789 KBytes
[  5]  29.00-30.00  sec   120 MBytes  1.01 Gbits/sec   49    478 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-30.00  sec  3.52 GBytes  1.01 Gbits/sec  1355             sender
[  5]   0.00-30.01  sec  3.52 GBytes  1.01 Gbits/sec                  receiver

wrk results are very unstable and could easily be swapped the other way. The only real difference I'm seeing are somewhat lower latencies with kqueue.",I have some older machines with dual Ethernet ports I could convince to run FreeBSD. Results from a VM should indeed be taken with a very large grain of salt.,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,387,2022-05-17T14:33:59Z,2022-05-26T17:54:10Z,2022-05-26T17:54:10Z,MERGED,True,827,475,14,https://github.com/hg,BSD: add kqueue support,2,[],https://github.com/gsliepen/tinc/pull/387,https://github.com/hg,4,https://github.com/gsliepen/tinc/pull/387#issuecomment-1129624829,"Similar to #266, but for FreeBSD/OpenBSD/NetBSD/macOS.
event.c is in need of splitting into multiple files. I'd rather do that in a separate PR.
Performance
It would be great to test this on physical machines with a fast network between them, if only I had the hardware. So here are results for a FreeBSD VM (13.1) on a Linux desktop (5.17.5).
Profiles
Start tincd, run 30 seconds of iperf3, stop tincd.
select
%   cumulative   self              self     total
 time   seconds   seconds    calls  ms/call  ms/call  name
 27.6       5.27     5.27       10   527.41   527.41  __sys_write [3]
 17.9       8.69     3.42        0  100.00%           __sys_select [13]
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
 15.0      11.56     2.87        0  100.00%           _mcount [16]
 14.9      14.40     2.84        0  100.00%           __sys_sendto [17]
  9.8      16.28     1.87        0  100.00%           _recvfrom [20]
  2.0      16.67     0.39 12124817     0.00     0.00  logger [11]
  1.8      17.01     0.34        0  100.00%           .mcount (501)
  1.5      17.30     0.29        1   291.34  6852.63  event_loop [2]
  1.5      17.58     0.28       20    14.22    14.22  __sys_read [39]
  0.7      17.72     0.14  2017455     0.00     0.00  __svfscanf [36]
  0.6      17.85     0.12  3026242     0.00     0.00  __vdso_gettc [48]
  0.6      17.96     0.11  1012231     0.00     0.00  __vfprintf [44]
  0.6      18.07     0.11  5054394     0.00     0.00  memcpy [50]
  0.5      18.16     0.09  3029506     0.00     0.00  route [14]
  0.4      18.24     0.08  2017424     0.00     0.00  receive_meta [6]

kqueue
%   cumulative   self              self     total
 time   seconds   seconds    calls  ms/call  ms/call  name
 27.4       4.92     4.92       10   492.41   492.41  __sys_write [5]
 17.1       8.00     3.07        0  100.00%           __sys_sendto [17]
 16.5      10.96     2.97        0  100.00%           _mcount [18]
 12.3      13.18     2.21        0  100.00%           _recvfrom [21]
 12.2      15.36     2.19  3879960     0.00     0.00  __sys_kevent [23]
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  2.0      15.72     0.36 11660378     0.00     0.00  logger [12]
  2.0      16.07     0.35        0  100.00%           .mcount (498)
  1.5      16.34     0.27       20    13.46    13.46  _read [40]
  1.0      16.52     0.17  1940474     0.00     0.00  __svfscanf [38]
  0.8      16.66     0.14   973307     0.00     0.00  __vfprintf [45]
  0.6      16.77     0.11        1   114.30  8491.48  event_loop [2]
  0.6      16.87     0.11  4860650     0.00     0.00  memcpy [48]
  0.5      16.97     0.10  1940434     0.00     0.00  receive_meta [4]
  0.5      17.06     0.09  2913615     0.00     0.00  route [7]
  0.4      17.13     0.08  1941372     0.00     0.00  __vdso_gettc [58]

Baseline
Direct connection, no tincd.
[ ID] Interval           Transfer     Bitrate         Retr  Cwnd
[  5]   0.00-1.00   sec  4.46 GBytes  38.3 Gbits/sec    0   1.67 MBytes
[  5]   1.00-2.00   sec  4.72 GBytes  40.6 Gbits/sec    0   1.67 MBytes
[  5]   2.00-3.00   sec  4.74 GBytes  40.7 Gbits/sec    0   1.67 MBytes
[  5]   3.00-4.00   sec  4.78 GBytes  41.1 Gbits/sec    0   1.67 MBytes
[  5]   4.00-5.00   sec  4.73 GBytes  40.6 Gbits/sec    0   1.67 MBytes
[  5]   5.00-6.00   sec  4.77 GBytes  41.0 Gbits/sec    0   1.67 MBytes
[  5]   6.00-7.00   sec  4.76 GBytes  40.9 Gbits/sec    0   1.67 MBytes
[  5]   7.00-8.00   sec  4.72 GBytes  40.6 Gbits/sec    0   1.67 MBytes
[  5]   8.00-9.00   sec  4.74 GBytes  40.7 Gbits/sec    0   1.67 MBytes
[  5]   9.00-10.00  sec  4.69 GBytes  40.3 Gbits/sec    0   1.67 MBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-10.00  sec  47.1 GBytes  40.5 Gbits/sec    0             sender
[  5]   0.00-10.00  sec  47.1 GBytes  40.5 Gbits/sec                  receiver

$ wrk -c400 -d5s http://192.168.122.4
Running 5s test @ http://192.168.122.4
  2 threads and 400 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     6.92ms  557.62us  20.31ms   97.69%
    Req/Sec    29.05k   848.97    30.30k    80.00%
  289106 requests in 5.02s, 234.36MB read
Requests/sec:  57641.66
Transfer/sec:     46.73MB

epoll + select
$ wrk -c400 -d30s http://10.0.0.2
Running 30s test @ http://10.0.0.2
  2 threads and 400 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency    37.70ms   82.95ms 845.70ms   87.98%
    Req/Sec    31.46k     5.44k   52.88k    72.67%
  1878491 requests in 30.03s, 1.49GB read
Requests/sec:  62554.59
Transfer/sec:     50.71MB

[ ID] Interval           Transfer     Bitrate         Retr  Cwnd
[  5]   0.00-1.00   sec   109 MBytes   917 Mbits/sec    0   1.69 MBytes
[  5]   1.00-2.00   sec  98.8 MBytes   828 Mbits/sec    0   1.69 MBytes
[  5]   2.00-3.00   sec   108 MBytes   902 Mbits/sec  485   1.30 MBytes
[  5]   3.00-4.00   sec   112 MBytes   944 Mbits/sec    0   1.41 MBytes
[  5]   4.00-5.00   sec   110 MBytes   923 Mbits/sec    0   1.51 MBytes
[  5]   5.00-6.00   sec   101 MBytes   849 Mbits/sec    0   1.57 MBytes
[  5]   6.00-7.00   sec   105 MBytes   881 Mbits/sec    0   1.61 MBytes
[  5]   7.00-8.00   sec  97.5 MBytes   818 Mbits/sec    0   1.61 MBytes
[  5]   8.00-9.00   sec  96.2 MBytes   807 Mbits/sec    0   1.61 MBytes
[  5]   9.00-10.00  sec   109 MBytes   912 Mbits/sec    0   1.65 MBytes
[  5]  10.00-11.00  sec   108 MBytes   902 Mbits/sec  729    597 KBytes
[  5]  11.00-12.00  sec   110 MBytes   923 Mbits/sec    0    724 KBytes
[  5]  12.00-13.00  sec   118 MBytes   986 Mbits/sec   34    646 KBytes
[  5]  13.00-14.00  sec   116 MBytes   975 Mbits/sec    0    773 KBytes
[  5]  14.00-15.00  sec   114 MBytes   954 Mbits/sec    0    881 KBytes
[  5]  15.00-16.00  sec   119 MBytes   996 Mbits/sec    2    718 KBytes
[  5]  16.00-17.00  sec   116 MBytes   975 Mbits/sec   20    646 KBytes
[  5]  17.00-18.00  sec   118 MBytes   986 Mbits/sec    0    775 KBytes
[  5]  18.00-19.00  sec   122 MBytes  1.03 Gbits/sec   10    655 KBytes
[  5]  19.00-20.00  sec   120 MBytes  1.01 Gbits/sec    0    786 KBytes
[  5]  20.00-21.00  sec   119 MBytes   996 Mbits/sec   21    673 KBytes
[  5]  21.00-22.00  sec   114 MBytes   954 Mbits/sec   19    576 KBytes
[  5]  22.00-23.00  sec   118 MBytes   986 Mbits/sec    0    717 KBytes
[  5]  23.00-24.00  sec   116 MBytes   975 Mbits/sec    3    649 KBytes
[  5]  24.00-25.00  sec   116 MBytes   975 Mbits/sec    9    576 KBytes
[  5]  25.00-26.00  sec   115 MBytes   965 Mbits/sec    0    716 KBytes
[  5]  26.00-27.00  sec   114 MBytes   954 Mbits/sec    0    827 KBytes
[  5]  27.00-28.00  sec   119 MBytes   996 Mbits/sec    2    665 KBytes
[  5]  28.00-29.00  sec   116 MBytes   975 Mbits/sec    0    789 KBytes
[  5]  29.00-30.00  sec   119 MBytes   996 Mbits/sec    0    898 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-30.00  sec  3.29 GBytes   943 Mbits/sec  1334             sender
[  5]   0.00-30.01  sec  3.29 GBytes   942 Mbits/sec                  receiver

epoll + kqueue
$ wrk -c400 -d30s http://10.0.0.2
Running 30s test @ http://10.0.0.2
  2 threads and 400 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency    34.13ms   79.44ms 986.57ms   88.72%
    Req/Sec    30.34k     5.57k   52.94k    70.00%
  1811878 requests in 30.03s, 1.43GB read
Requests/sec:  60327.43
Transfer/sec:     48.90MB

[ ID] Interval           Transfer     Bitrate         Retr  Cwnd
[  5]   0.00-1.00   sec   119 MBytes   998 Mbits/sec  706    634 KBytes
[  5]   1.00-2.00   sec   118 MBytes   986 Mbits/sec   38    536 KBytes
[  5]   2.00-3.00   sec   120 MBytes  1.01 Gbits/sec    0    689 KBytes
[  5]   3.00-4.00   sec   119 MBytes   996 Mbits/sec    2    631 KBytes
[  5]   4.00-5.00   sec   115 MBytes   965 Mbits/sec    0    755 KBytes
[  5]   5.00-6.00   sec   118 MBytes   986 Mbits/sec    0    868 KBytes
[  5]   6.00-7.00   sec   120 MBytes  1.01 Gbits/sec  150    505 KBytes
[  5]   7.00-8.00   sec   121 MBytes  1.02 Gbits/sec    0    663 KBytes
[  5]   8.00-9.00   sec   122 MBytes  1.03 Gbits/sec    0    796 KBytes
[  5]   9.00-10.00  sec   120 MBytes  1.01 Gbits/sec   98    659 KBytes
[  5]  10.00-11.00  sec   121 MBytes  1.02 Gbits/sec    0    792 KBytes
[  5]  11.00-12.00  sec   125 MBytes  1.05 Gbits/sec    0    902 KBytes
[  5]  12.00-13.00  sec   116 MBytes   975 Mbits/sec   23    576 KBytes
[  5]  13.00-14.00  sec   119 MBytes   996 Mbits/sec    0    716 KBytes
[  5]  14.00-15.00  sec   118 MBytes   986 Mbits/sec   27    609 KBytes
[  5]  15.00-16.00  sec   120 MBytes  1.01 Gbits/sec    0    748 KBytes
[  5]  16.00-17.00  sec   118 MBytes   986 Mbits/sec   59    650 KBytes
[  5]  17.00-18.00  sec   120 MBytes  1.01 Gbits/sec   21    577 KBytes
[  5]  18.00-19.00  sec   122 MBytes  1.03 Gbits/sec   11    502 KBytes
[  5]  19.00-20.00  sec   121 MBytes  1.02 Gbits/sec    0    663 KBytes
[  5]  20.00-21.00  sec   118 MBytes   986 Mbits/sec    0    790 KBytes
[  5]  21.00-22.00  sec   118 MBytes   986 Mbits/sec   40    560 KBytes
[  5]  22.00-23.00  sec   119 MBytes   996 Mbits/sec    0    706 KBytes
[  5]  23.00-24.00  sec   124 MBytes  1.04 Gbits/sec    0    829 KBytes
[  5]  24.00-25.00  sec   124 MBytes  1.04 Gbits/sec   76    703 KBytes
[  5]  25.00-26.00  sec   124 MBytes  1.04 Gbits/sec   35    585 KBytes
[  5]  26.00-27.00  sec   125 MBytes  1.05 Gbits/sec    0    732 KBytes
[  5]  27.00-28.00  sec   122 MBytes  1.03 Gbits/sec   20    665 KBytes
[  5]  28.00-29.00  sec   119 MBytes   996 Mbits/sec    0    789 KBytes
[  5]  29.00-30.00  sec   120 MBytes  1.01 Gbits/sec   49    478 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-30.00  sec  3.52 GBytes  1.01 Gbits/sec  1355             sender
[  5]   0.00-30.01  sec  3.52 GBytes  1.01 Gbits/sec                  receiver

wrk results are very unstable and could easily be swapped the other way. The only real difference I'm seeing are somewhat lower latencies with kqueue.","kqueue setup is now reduced to a single syscall thanks to EV_RECEIPT which I originally missed in the man page.

iperf3 benchmark
[ ID] Interval           Transfer     Bitrate         Retr  Cwnd
[  5]   0.00-1.00   sec   128 MBytes  1.07 Gbits/sec  289    628 KBytes
[  5]   1.00-2.00   sec   125 MBytes  1.05 Gbits/sec    0    768 KBytes
[  5]   2.00-3.00   sec   126 MBytes  1.06 Gbits/sec    8    667 KBytes
[  5]   3.00-4.00   sec   125 MBytes  1.05 Gbits/sec   25    594 KBytes
[  5]   4.00-5.00   sec   124 MBytes  1.04 Gbits/sec    0    737 KBytes
[  5]   5.00-6.00   sec   124 MBytes  1.04 Gbits/sec   22    669 KBytes
[  5]   6.00-7.00   sec   125 MBytes  1.05 Gbits/sec    0    802 KBytes
[  5]   7.00-8.00   sec   125 MBytes  1.05 Gbits/sec   65    488 KBytes
[  5]   8.00-9.00   sec   122 MBytes  1.03 Gbits/sec    0    653 KBytes
[  5]   9.00-10.00  sec   124 MBytes  1.04 Gbits/sec    0    786 KBytes
[  5]  10.00-11.00  sec   125 MBytes  1.05 Gbits/sec   45    675 KBytes
[  5]  11.00-12.00  sec   125 MBytes  1.05 Gbits/sec   39    581 KBytes
[  5]  12.00-13.00  sec   125 MBytes  1.05 Gbits/sec    0    732 KBytes
[  5]  13.00-14.00  sec   121 MBytes  1.02 Gbits/sec    1    649 KBytes
[  5]  14.00-15.00  sec   124 MBytes  1.04 Gbits/sec   37    554 KBytes
[  5]  15.00-16.00  sec   122 MBytes  1.03 Gbits/sec    0    706 KBytes
[  5]  16.00-17.00  sec   121 MBytes  1.02 Gbits/sec   10    643 KBytes
[  5]  17.00-18.00  sec   122 MBytes  1.03 Gbits/sec    4    584 KBytes
[  5]  18.00-19.00  sec   124 MBytes  1.04 Gbits/sec    0    730 KBytes
[  5]  19.00-20.00  sec   124 MBytes  1.04 Gbits/sec   35    658 KBytes
[  5]  20.00-21.00  sec   122 MBytes  1.03 Gbits/sec   37    573 KBytes
[  5]  21.00-22.00  sec   128 MBytes  1.07 Gbits/sec    0    724 KBytes
[  5]  22.00-23.00  sec   122 MBytes  1.03 Gbits/sec   45    622 KBytes
[  5]  23.00-24.00  sec   129 MBytes  1.08 Gbits/sec    0    769 KBytes
[  5]  24.00-25.00  sec   121 MBytes  1.02 Gbits/sec   77    662 KBytes
[  5]  25.00-26.00  sec   129 MBytes  1.08 Gbits/sec    0    798 KBytes
[  5]  26.00-27.00  sec   128 MBytes  1.07 Gbits/sec   65    665 KBytes
[  5]  27.00-28.00  sec   125 MBytes  1.05 Gbits/sec    0    796 KBytes
[  5]  28.00-29.00  sec   130 MBytes  1.09 Gbits/sec   25    680 KBytes
[  5]  29.00-30.00  sec   125 MBytes  1.05 Gbits/sec    0    813 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-30.00  sec  3.65 GBytes  1.05 Gbits/sec  829             sender
[  5]   0.00-30.01  sec  3.65 GBytes  1.05 Gbits/sec                  receiver",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,387,2022-05-17T14:33:59Z,2022-05-26T17:54:10Z,2022-05-26T17:54:10Z,MERGED,True,827,475,14,https://github.com/hg,BSD: add kqueue support,2,[],https://github.com/gsliepen/tinc/pull/387,https://github.com/hg,5,https://github.com/gsliepen/tinc/pull/387#issuecomment-1129748253,"Similar to #266, but for FreeBSD/OpenBSD/NetBSD/macOS.
event.c is in need of splitting into multiple files. I'd rather do that in a separate PR.
Performance
It would be great to test this on physical machines with a fast network between them, if only I had the hardware. So here are results for a FreeBSD VM (13.1) on a Linux desktop (5.17.5).
Profiles
Start tincd, run 30 seconds of iperf3, stop tincd.
select
%   cumulative   self              self     total
 time   seconds   seconds    calls  ms/call  ms/call  name
 27.6       5.27     5.27       10   527.41   527.41  __sys_write [3]
 17.9       8.69     3.42        0  100.00%           __sys_select [13]
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
 15.0      11.56     2.87        0  100.00%           _mcount [16]
 14.9      14.40     2.84        0  100.00%           __sys_sendto [17]
  9.8      16.28     1.87        0  100.00%           _recvfrom [20]
  2.0      16.67     0.39 12124817     0.00     0.00  logger [11]
  1.8      17.01     0.34        0  100.00%           .mcount (501)
  1.5      17.30     0.29        1   291.34  6852.63  event_loop [2]
  1.5      17.58     0.28       20    14.22    14.22  __sys_read [39]
  0.7      17.72     0.14  2017455     0.00     0.00  __svfscanf [36]
  0.6      17.85     0.12  3026242     0.00     0.00  __vdso_gettc [48]
  0.6      17.96     0.11  1012231     0.00     0.00  __vfprintf [44]
  0.6      18.07     0.11  5054394     0.00     0.00  memcpy [50]
  0.5      18.16     0.09  3029506     0.00     0.00  route [14]
  0.4      18.24     0.08  2017424     0.00     0.00  receive_meta [6]

kqueue
%   cumulative   self              self     total
 time   seconds   seconds    calls  ms/call  ms/call  name
 27.4       4.92     4.92       10   492.41   492.41  __sys_write [5]
 17.1       8.00     3.07        0  100.00%           __sys_sendto [17]
 16.5      10.96     2.97        0  100.00%           _mcount [18]
 12.3      13.18     2.21        0  100.00%           _recvfrom [21]
 12.2      15.36     2.19  3879960     0.00     0.00  __sys_kevent [23]
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  2.0      15.72     0.36 11660378     0.00     0.00  logger [12]
  2.0      16.07     0.35        0  100.00%           .mcount (498)
  1.5      16.34     0.27       20    13.46    13.46  _read [40]
  1.0      16.52     0.17  1940474     0.00     0.00  __svfscanf [38]
  0.8      16.66     0.14   973307     0.00     0.00  __vfprintf [45]
  0.6      16.77     0.11        1   114.30  8491.48  event_loop [2]
  0.6      16.87     0.11  4860650     0.00     0.00  memcpy [48]
  0.5      16.97     0.10  1940434     0.00     0.00  receive_meta [4]
  0.5      17.06     0.09  2913615     0.00     0.00  route [7]
  0.4      17.13     0.08  1941372     0.00     0.00  __vdso_gettc [58]

Baseline
Direct connection, no tincd.
[ ID] Interval           Transfer     Bitrate         Retr  Cwnd
[  5]   0.00-1.00   sec  4.46 GBytes  38.3 Gbits/sec    0   1.67 MBytes
[  5]   1.00-2.00   sec  4.72 GBytes  40.6 Gbits/sec    0   1.67 MBytes
[  5]   2.00-3.00   sec  4.74 GBytes  40.7 Gbits/sec    0   1.67 MBytes
[  5]   3.00-4.00   sec  4.78 GBytes  41.1 Gbits/sec    0   1.67 MBytes
[  5]   4.00-5.00   sec  4.73 GBytes  40.6 Gbits/sec    0   1.67 MBytes
[  5]   5.00-6.00   sec  4.77 GBytes  41.0 Gbits/sec    0   1.67 MBytes
[  5]   6.00-7.00   sec  4.76 GBytes  40.9 Gbits/sec    0   1.67 MBytes
[  5]   7.00-8.00   sec  4.72 GBytes  40.6 Gbits/sec    0   1.67 MBytes
[  5]   8.00-9.00   sec  4.74 GBytes  40.7 Gbits/sec    0   1.67 MBytes
[  5]   9.00-10.00  sec  4.69 GBytes  40.3 Gbits/sec    0   1.67 MBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-10.00  sec  47.1 GBytes  40.5 Gbits/sec    0             sender
[  5]   0.00-10.00  sec  47.1 GBytes  40.5 Gbits/sec                  receiver

$ wrk -c400 -d5s http://192.168.122.4
Running 5s test @ http://192.168.122.4
  2 threads and 400 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     6.92ms  557.62us  20.31ms   97.69%
    Req/Sec    29.05k   848.97    30.30k    80.00%
  289106 requests in 5.02s, 234.36MB read
Requests/sec:  57641.66
Transfer/sec:     46.73MB

epoll + select
$ wrk -c400 -d30s http://10.0.0.2
Running 30s test @ http://10.0.0.2
  2 threads and 400 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency    37.70ms   82.95ms 845.70ms   87.98%
    Req/Sec    31.46k     5.44k   52.88k    72.67%
  1878491 requests in 30.03s, 1.49GB read
Requests/sec:  62554.59
Transfer/sec:     50.71MB

[ ID] Interval           Transfer     Bitrate         Retr  Cwnd
[  5]   0.00-1.00   sec   109 MBytes   917 Mbits/sec    0   1.69 MBytes
[  5]   1.00-2.00   sec  98.8 MBytes   828 Mbits/sec    0   1.69 MBytes
[  5]   2.00-3.00   sec   108 MBytes   902 Mbits/sec  485   1.30 MBytes
[  5]   3.00-4.00   sec   112 MBytes   944 Mbits/sec    0   1.41 MBytes
[  5]   4.00-5.00   sec   110 MBytes   923 Mbits/sec    0   1.51 MBytes
[  5]   5.00-6.00   sec   101 MBytes   849 Mbits/sec    0   1.57 MBytes
[  5]   6.00-7.00   sec   105 MBytes   881 Mbits/sec    0   1.61 MBytes
[  5]   7.00-8.00   sec  97.5 MBytes   818 Mbits/sec    0   1.61 MBytes
[  5]   8.00-9.00   sec  96.2 MBytes   807 Mbits/sec    0   1.61 MBytes
[  5]   9.00-10.00  sec   109 MBytes   912 Mbits/sec    0   1.65 MBytes
[  5]  10.00-11.00  sec   108 MBytes   902 Mbits/sec  729    597 KBytes
[  5]  11.00-12.00  sec   110 MBytes   923 Mbits/sec    0    724 KBytes
[  5]  12.00-13.00  sec   118 MBytes   986 Mbits/sec   34    646 KBytes
[  5]  13.00-14.00  sec   116 MBytes   975 Mbits/sec    0    773 KBytes
[  5]  14.00-15.00  sec   114 MBytes   954 Mbits/sec    0    881 KBytes
[  5]  15.00-16.00  sec   119 MBytes   996 Mbits/sec    2    718 KBytes
[  5]  16.00-17.00  sec   116 MBytes   975 Mbits/sec   20    646 KBytes
[  5]  17.00-18.00  sec   118 MBytes   986 Mbits/sec    0    775 KBytes
[  5]  18.00-19.00  sec   122 MBytes  1.03 Gbits/sec   10    655 KBytes
[  5]  19.00-20.00  sec   120 MBytes  1.01 Gbits/sec    0    786 KBytes
[  5]  20.00-21.00  sec   119 MBytes   996 Mbits/sec   21    673 KBytes
[  5]  21.00-22.00  sec   114 MBytes   954 Mbits/sec   19    576 KBytes
[  5]  22.00-23.00  sec   118 MBytes   986 Mbits/sec    0    717 KBytes
[  5]  23.00-24.00  sec   116 MBytes   975 Mbits/sec    3    649 KBytes
[  5]  24.00-25.00  sec   116 MBytes   975 Mbits/sec    9    576 KBytes
[  5]  25.00-26.00  sec   115 MBytes   965 Mbits/sec    0    716 KBytes
[  5]  26.00-27.00  sec   114 MBytes   954 Mbits/sec    0    827 KBytes
[  5]  27.00-28.00  sec   119 MBytes   996 Mbits/sec    2    665 KBytes
[  5]  28.00-29.00  sec   116 MBytes   975 Mbits/sec    0    789 KBytes
[  5]  29.00-30.00  sec   119 MBytes   996 Mbits/sec    0    898 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-30.00  sec  3.29 GBytes   943 Mbits/sec  1334             sender
[  5]   0.00-30.01  sec  3.29 GBytes   942 Mbits/sec                  receiver

epoll + kqueue
$ wrk -c400 -d30s http://10.0.0.2
Running 30s test @ http://10.0.0.2
  2 threads and 400 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency    34.13ms   79.44ms 986.57ms   88.72%
    Req/Sec    30.34k     5.57k   52.94k    70.00%
  1811878 requests in 30.03s, 1.43GB read
Requests/sec:  60327.43
Transfer/sec:     48.90MB

[ ID] Interval           Transfer     Bitrate         Retr  Cwnd
[  5]   0.00-1.00   sec   119 MBytes   998 Mbits/sec  706    634 KBytes
[  5]   1.00-2.00   sec   118 MBytes   986 Mbits/sec   38    536 KBytes
[  5]   2.00-3.00   sec   120 MBytes  1.01 Gbits/sec    0    689 KBytes
[  5]   3.00-4.00   sec   119 MBytes   996 Mbits/sec    2    631 KBytes
[  5]   4.00-5.00   sec   115 MBytes   965 Mbits/sec    0    755 KBytes
[  5]   5.00-6.00   sec   118 MBytes   986 Mbits/sec    0    868 KBytes
[  5]   6.00-7.00   sec   120 MBytes  1.01 Gbits/sec  150    505 KBytes
[  5]   7.00-8.00   sec   121 MBytes  1.02 Gbits/sec    0    663 KBytes
[  5]   8.00-9.00   sec   122 MBytes  1.03 Gbits/sec    0    796 KBytes
[  5]   9.00-10.00  sec   120 MBytes  1.01 Gbits/sec   98    659 KBytes
[  5]  10.00-11.00  sec   121 MBytes  1.02 Gbits/sec    0    792 KBytes
[  5]  11.00-12.00  sec   125 MBytes  1.05 Gbits/sec    0    902 KBytes
[  5]  12.00-13.00  sec   116 MBytes   975 Mbits/sec   23    576 KBytes
[  5]  13.00-14.00  sec   119 MBytes   996 Mbits/sec    0    716 KBytes
[  5]  14.00-15.00  sec   118 MBytes   986 Mbits/sec   27    609 KBytes
[  5]  15.00-16.00  sec   120 MBytes  1.01 Gbits/sec    0    748 KBytes
[  5]  16.00-17.00  sec   118 MBytes   986 Mbits/sec   59    650 KBytes
[  5]  17.00-18.00  sec   120 MBytes  1.01 Gbits/sec   21    577 KBytes
[  5]  18.00-19.00  sec   122 MBytes  1.03 Gbits/sec   11    502 KBytes
[  5]  19.00-20.00  sec   121 MBytes  1.02 Gbits/sec    0    663 KBytes
[  5]  20.00-21.00  sec   118 MBytes   986 Mbits/sec    0    790 KBytes
[  5]  21.00-22.00  sec   118 MBytes   986 Mbits/sec   40    560 KBytes
[  5]  22.00-23.00  sec   119 MBytes   996 Mbits/sec    0    706 KBytes
[  5]  23.00-24.00  sec   124 MBytes  1.04 Gbits/sec    0    829 KBytes
[  5]  24.00-25.00  sec   124 MBytes  1.04 Gbits/sec   76    703 KBytes
[  5]  25.00-26.00  sec   124 MBytes  1.04 Gbits/sec   35    585 KBytes
[  5]  26.00-27.00  sec   125 MBytes  1.05 Gbits/sec    0    732 KBytes
[  5]  27.00-28.00  sec   122 MBytes  1.03 Gbits/sec   20    665 KBytes
[  5]  28.00-29.00  sec   119 MBytes   996 Mbits/sec    0    789 KBytes
[  5]  29.00-30.00  sec   120 MBytes  1.01 Gbits/sec   49    478 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-30.00  sec  3.52 GBytes  1.01 Gbits/sec  1355             sender
[  5]   0.00-30.01  sec  3.52 GBytes  1.01 Gbits/sec                  receiver

wrk results are very unstable and could easily be swapped the other way. The only real difference I'm seeing are somewhat lower latencies with kqueue.","The difference is more significant on OpenBSD (same limitations — it's a similarly configured virtual machine).
select
[ ID] Interval           Transfer     Bitrate         Retr  Cwnd
[  5]   0.00-1.00   sec  21.6 MBytes   181 Mbits/sec    0   52.3 KBytes
[  5]   1.00-2.00   sec  22.0 MBytes   185 Mbits/sec    0   86.3 KBytes
[  5]   2.00-3.00   sec  22.1 MBytes   185 Mbits/sec    0    127 KBytes
[  5]   3.00-4.00   sec  21.6 MBytes   182 Mbits/sec    8   93.3 KBytes
[  5]   4.00-5.00   sec  21.7 MBytes   182 Mbits/sec    5    119 KBytes
[  5]   5.00-6.00   sec  22.4 MBytes   188 Mbits/sec    9    123 KBytes
[  5]   6.00-7.00   sec  22.1 MBytes   185 Mbits/sec    6    107 KBytes
[  5]   7.00-8.00   sec  21.5 MBytes   180 Mbits/sec    5    127 KBytes
[  5]   8.00-9.00   sec  22.1 MBytes   185 Mbits/sec   14    110 KBytes
[  5]   9.00-10.00  sec  22.1 MBytes   185 Mbits/sec    8   94.7 KBytes
[  5]  10.00-11.00  sec  22.1 MBytes   186 Mbits/sec   12    119 KBytes
[  5]  11.00-12.00  sec  22.1 MBytes   186 Mbits/sec   10    100 KBytes
[  5]  12.00-13.00  sec  22.1 MBytes   185 Mbits/sec    4    129 KBytes
[  5]  13.00-14.00  sec  21.7 MBytes   182 Mbits/sec   16    110 KBytes
[  5]  14.00-15.00  sec  21.7 MBytes   182 Mbits/sec    5    112 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-15.00  sec   329 MBytes   184 Mbits/sec  102             sender
[  5]   0.00-15.00  sec   328 MBytes   184 Mbits/sec                  receiver

kqueue
[ ID] Interval           Transfer     Bitrate         Retr  Cwnd
[  5]   0.00-1.00   sec  33.7 MBytes   282 Mbits/sec    0   55.1 KBytes
[  5]   1.00-2.00   sec  35.8 MBytes   300 Mbits/sec    0   86.3 KBytes
[  5]   2.00-3.00   sec  37.6 MBytes   315 Mbits/sec    0    120 KBytes
[  5]   3.00-4.00   sec  37.7 MBytes   316 Mbits/sec    0    154 KBytes
[  5]   4.00-5.00   sec  36.2 MBytes   304 Mbits/sec    0    189 KBytes
[  5]   5.00-6.00   sec  36.4 MBytes   305 Mbits/sec    0    225 KBytes
[  5]   6.00-7.00   sec  35.8 MBytes   300 Mbits/sec    0    256 KBytes
[  5]   7.00-8.00   sec  36.1 MBytes   303 Mbits/sec    0    305 KBytes
[  5]   8.00-9.00   sec  36.2 MBytes   303 Mbits/sec    0    332 KBytes
[  5]   9.00-10.00  sec  36.8 MBytes   309 Mbits/sec    0    365 KBytes
[  5]  10.00-11.00  sec  36.5 MBytes   307 Mbits/sec    0    532 KBytes
[  5]  11.00-12.00  sec  37.0 MBytes   311 Mbits/sec    0    532 KBytes
[  5]  12.00-13.00  sec  36.0 MBytes   302 Mbits/sec    0    532 KBytes
[  5]  13.00-14.00  sec  36.0 MBytes   302 Mbits/sec    0    532 KBytes
[  5]  14.00-15.00  sec  37.0 MBytes   311 Mbits/sec    0    532 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-15.00  sec   545 MBytes   305 Mbits/sec    0             sender
[  5]   0.00-15.02  sec   543 MBytes   303 Mbits/sec                  receiver",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,387,2022-05-17T14:33:59Z,2022-05-26T17:54:10Z,2022-05-26T17:54:10Z,MERGED,True,827,475,14,https://github.com/hg,BSD: add kqueue support,2,[],https://github.com/gsliepen/tinc/pull/387,https://github.com/hg,6,https://github.com/gsliepen/tinc/pull/387#issuecomment-1133598489,"Similar to #266, but for FreeBSD/OpenBSD/NetBSD/macOS.
event.c is in need of splitting into multiple files. I'd rather do that in a separate PR.
Performance
It would be great to test this on physical machines with a fast network between them, if only I had the hardware. So here are results for a FreeBSD VM (13.1) on a Linux desktop (5.17.5).
Profiles
Start tincd, run 30 seconds of iperf3, stop tincd.
select
%   cumulative   self              self     total
 time   seconds   seconds    calls  ms/call  ms/call  name
 27.6       5.27     5.27       10   527.41   527.41  __sys_write [3]
 17.9       8.69     3.42        0  100.00%           __sys_select [13]
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
 15.0      11.56     2.87        0  100.00%           _mcount [16]
 14.9      14.40     2.84        0  100.00%           __sys_sendto [17]
  9.8      16.28     1.87        0  100.00%           _recvfrom [20]
  2.0      16.67     0.39 12124817     0.00     0.00  logger [11]
  1.8      17.01     0.34        0  100.00%           .mcount (501)
  1.5      17.30     0.29        1   291.34  6852.63  event_loop [2]
  1.5      17.58     0.28       20    14.22    14.22  __sys_read [39]
  0.7      17.72     0.14  2017455     0.00     0.00  __svfscanf [36]
  0.6      17.85     0.12  3026242     0.00     0.00  __vdso_gettc [48]
  0.6      17.96     0.11  1012231     0.00     0.00  __vfprintf [44]
  0.6      18.07     0.11  5054394     0.00     0.00  memcpy [50]
  0.5      18.16     0.09  3029506     0.00     0.00  route [14]
  0.4      18.24     0.08  2017424     0.00     0.00  receive_meta [6]

kqueue
%   cumulative   self              self     total
 time   seconds   seconds    calls  ms/call  ms/call  name
 27.4       4.92     4.92       10   492.41   492.41  __sys_write [5]
 17.1       8.00     3.07        0  100.00%           __sys_sendto [17]
 16.5      10.96     2.97        0  100.00%           _mcount [18]
 12.3      13.18     2.21        0  100.00%           _recvfrom [21]
 12.2      15.36     2.19  3879960     0.00     0.00  __sys_kevent [23]
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  2.0      15.72     0.36 11660378     0.00     0.00  logger [12]
  2.0      16.07     0.35        0  100.00%           .mcount (498)
  1.5      16.34     0.27       20    13.46    13.46  _read [40]
  1.0      16.52     0.17  1940474     0.00     0.00  __svfscanf [38]
  0.8      16.66     0.14   973307     0.00     0.00  __vfprintf [45]
  0.6      16.77     0.11        1   114.30  8491.48  event_loop [2]
  0.6      16.87     0.11  4860650     0.00     0.00  memcpy [48]
  0.5      16.97     0.10  1940434     0.00     0.00  receive_meta [4]
  0.5      17.06     0.09  2913615     0.00     0.00  route [7]
  0.4      17.13     0.08  1941372     0.00     0.00  __vdso_gettc [58]

Baseline
Direct connection, no tincd.
[ ID] Interval           Transfer     Bitrate         Retr  Cwnd
[  5]   0.00-1.00   sec  4.46 GBytes  38.3 Gbits/sec    0   1.67 MBytes
[  5]   1.00-2.00   sec  4.72 GBytes  40.6 Gbits/sec    0   1.67 MBytes
[  5]   2.00-3.00   sec  4.74 GBytes  40.7 Gbits/sec    0   1.67 MBytes
[  5]   3.00-4.00   sec  4.78 GBytes  41.1 Gbits/sec    0   1.67 MBytes
[  5]   4.00-5.00   sec  4.73 GBytes  40.6 Gbits/sec    0   1.67 MBytes
[  5]   5.00-6.00   sec  4.77 GBytes  41.0 Gbits/sec    0   1.67 MBytes
[  5]   6.00-7.00   sec  4.76 GBytes  40.9 Gbits/sec    0   1.67 MBytes
[  5]   7.00-8.00   sec  4.72 GBytes  40.6 Gbits/sec    0   1.67 MBytes
[  5]   8.00-9.00   sec  4.74 GBytes  40.7 Gbits/sec    0   1.67 MBytes
[  5]   9.00-10.00  sec  4.69 GBytes  40.3 Gbits/sec    0   1.67 MBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-10.00  sec  47.1 GBytes  40.5 Gbits/sec    0             sender
[  5]   0.00-10.00  sec  47.1 GBytes  40.5 Gbits/sec                  receiver

$ wrk -c400 -d5s http://192.168.122.4
Running 5s test @ http://192.168.122.4
  2 threads and 400 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     6.92ms  557.62us  20.31ms   97.69%
    Req/Sec    29.05k   848.97    30.30k    80.00%
  289106 requests in 5.02s, 234.36MB read
Requests/sec:  57641.66
Transfer/sec:     46.73MB

epoll + select
$ wrk -c400 -d30s http://10.0.0.2
Running 30s test @ http://10.0.0.2
  2 threads and 400 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency    37.70ms   82.95ms 845.70ms   87.98%
    Req/Sec    31.46k     5.44k   52.88k    72.67%
  1878491 requests in 30.03s, 1.49GB read
Requests/sec:  62554.59
Transfer/sec:     50.71MB

[ ID] Interval           Transfer     Bitrate         Retr  Cwnd
[  5]   0.00-1.00   sec   109 MBytes   917 Mbits/sec    0   1.69 MBytes
[  5]   1.00-2.00   sec  98.8 MBytes   828 Mbits/sec    0   1.69 MBytes
[  5]   2.00-3.00   sec   108 MBytes   902 Mbits/sec  485   1.30 MBytes
[  5]   3.00-4.00   sec   112 MBytes   944 Mbits/sec    0   1.41 MBytes
[  5]   4.00-5.00   sec   110 MBytes   923 Mbits/sec    0   1.51 MBytes
[  5]   5.00-6.00   sec   101 MBytes   849 Mbits/sec    0   1.57 MBytes
[  5]   6.00-7.00   sec   105 MBytes   881 Mbits/sec    0   1.61 MBytes
[  5]   7.00-8.00   sec  97.5 MBytes   818 Mbits/sec    0   1.61 MBytes
[  5]   8.00-9.00   sec  96.2 MBytes   807 Mbits/sec    0   1.61 MBytes
[  5]   9.00-10.00  sec   109 MBytes   912 Mbits/sec    0   1.65 MBytes
[  5]  10.00-11.00  sec   108 MBytes   902 Mbits/sec  729    597 KBytes
[  5]  11.00-12.00  sec   110 MBytes   923 Mbits/sec    0    724 KBytes
[  5]  12.00-13.00  sec   118 MBytes   986 Mbits/sec   34    646 KBytes
[  5]  13.00-14.00  sec   116 MBytes   975 Mbits/sec    0    773 KBytes
[  5]  14.00-15.00  sec   114 MBytes   954 Mbits/sec    0    881 KBytes
[  5]  15.00-16.00  sec   119 MBytes   996 Mbits/sec    2    718 KBytes
[  5]  16.00-17.00  sec   116 MBytes   975 Mbits/sec   20    646 KBytes
[  5]  17.00-18.00  sec   118 MBytes   986 Mbits/sec    0    775 KBytes
[  5]  18.00-19.00  sec   122 MBytes  1.03 Gbits/sec   10    655 KBytes
[  5]  19.00-20.00  sec   120 MBytes  1.01 Gbits/sec    0    786 KBytes
[  5]  20.00-21.00  sec   119 MBytes   996 Mbits/sec   21    673 KBytes
[  5]  21.00-22.00  sec   114 MBytes   954 Mbits/sec   19    576 KBytes
[  5]  22.00-23.00  sec   118 MBytes   986 Mbits/sec    0    717 KBytes
[  5]  23.00-24.00  sec   116 MBytes   975 Mbits/sec    3    649 KBytes
[  5]  24.00-25.00  sec   116 MBytes   975 Mbits/sec    9    576 KBytes
[  5]  25.00-26.00  sec   115 MBytes   965 Mbits/sec    0    716 KBytes
[  5]  26.00-27.00  sec   114 MBytes   954 Mbits/sec    0    827 KBytes
[  5]  27.00-28.00  sec   119 MBytes   996 Mbits/sec    2    665 KBytes
[  5]  28.00-29.00  sec   116 MBytes   975 Mbits/sec    0    789 KBytes
[  5]  29.00-30.00  sec   119 MBytes   996 Mbits/sec    0    898 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-30.00  sec  3.29 GBytes   943 Mbits/sec  1334             sender
[  5]   0.00-30.01  sec  3.29 GBytes   942 Mbits/sec                  receiver

epoll + kqueue
$ wrk -c400 -d30s http://10.0.0.2
Running 30s test @ http://10.0.0.2
  2 threads and 400 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency    34.13ms   79.44ms 986.57ms   88.72%
    Req/Sec    30.34k     5.57k   52.94k    70.00%
  1811878 requests in 30.03s, 1.43GB read
Requests/sec:  60327.43
Transfer/sec:     48.90MB

[ ID] Interval           Transfer     Bitrate         Retr  Cwnd
[  5]   0.00-1.00   sec   119 MBytes   998 Mbits/sec  706    634 KBytes
[  5]   1.00-2.00   sec   118 MBytes   986 Mbits/sec   38    536 KBytes
[  5]   2.00-3.00   sec   120 MBytes  1.01 Gbits/sec    0    689 KBytes
[  5]   3.00-4.00   sec   119 MBytes   996 Mbits/sec    2    631 KBytes
[  5]   4.00-5.00   sec   115 MBytes   965 Mbits/sec    0    755 KBytes
[  5]   5.00-6.00   sec   118 MBytes   986 Mbits/sec    0    868 KBytes
[  5]   6.00-7.00   sec   120 MBytes  1.01 Gbits/sec  150    505 KBytes
[  5]   7.00-8.00   sec   121 MBytes  1.02 Gbits/sec    0    663 KBytes
[  5]   8.00-9.00   sec   122 MBytes  1.03 Gbits/sec    0    796 KBytes
[  5]   9.00-10.00  sec   120 MBytes  1.01 Gbits/sec   98    659 KBytes
[  5]  10.00-11.00  sec   121 MBytes  1.02 Gbits/sec    0    792 KBytes
[  5]  11.00-12.00  sec   125 MBytes  1.05 Gbits/sec    0    902 KBytes
[  5]  12.00-13.00  sec   116 MBytes   975 Mbits/sec   23    576 KBytes
[  5]  13.00-14.00  sec   119 MBytes   996 Mbits/sec    0    716 KBytes
[  5]  14.00-15.00  sec   118 MBytes   986 Mbits/sec   27    609 KBytes
[  5]  15.00-16.00  sec   120 MBytes  1.01 Gbits/sec    0    748 KBytes
[  5]  16.00-17.00  sec   118 MBytes   986 Mbits/sec   59    650 KBytes
[  5]  17.00-18.00  sec   120 MBytes  1.01 Gbits/sec   21    577 KBytes
[  5]  18.00-19.00  sec   122 MBytes  1.03 Gbits/sec   11    502 KBytes
[  5]  19.00-20.00  sec   121 MBytes  1.02 Gbits/sec    0    663 KBytes
[  5]  20.00-21.00  sec   118 MBytes   986 Mbits/sec    0    790 KBytes
[  5]  21.00-22.00  sec   118 MBytes   986 Mbits/sec   40    560 KBytes
[  5]  22.00-23.00  sec   119 MBytes   996 Mbits/sec    0    706 KBytes
[  5]  23.00-24.00  sec   124 MBytes  1.04 Gbits/sec    0    829 KBytes
[  5]  24.00-25.00  sec   124 MBytes  1.04 Gbits/sec   76    703 KBytes
[  5]  25.00-26.00  sec   124 MBytes  1.04 Gbits/sec   35    585 KBytes
[  5]  26.00-27.00  sec   125 MBytes  1.05 Gbits/sec    0    732 KBytes
[  5]  27.00-28.00  sec   122 MBytes  1.03 Gbits/sec   20    665 KBytes
[  5]  28.00-29.00  sec   119 MBytes   996 Mbits/sec    0    789 KBytes
[  5]  29.00-30.00  sec   120 MBytes  1.01 Gbits/sec   49    478 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-30.00  sec  3.52 GBytes  1.01 Gbits/sec  1355             sender
[  5]   0.00-30.01  sec  3.52 GBytes  1.01 Gbits/sec                  receiver

wrk results are very unstable and could easily be swapped the other way. The only real difference I'm seeing are somewhat lower latencies with kqueue.","I split event.c as it's pretty difficult to work with already. Two I/O tree updates were missing in Windows code because it's hard to keep track of all the #ifdefs.
There's a small amount of copy-pasted code in functions like io_add/io_set.
Getting rid of it requires introducing more ""public"" functions and more calls between translation units. I didn't think it to be worth it, but if you'd rather not have duplicate logic, let me know.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,387,2022-05-17T14:33:59Z,2022-05-26T17:54:10Z,2022-05-26T17:54:10Z,MERGED,True,827,475,14,https://github.com/hg,BSD: add kqueue support,2,[],https://github.com/gsliepen/tinc/pull/387,https://github.com/gsliepen,7,https://github.com/gsliepen/tinc/pull/387#issuecomment-1138850652,"Similar to #266, but for FreeBSD/OpenBSD/NetBSD/macOS.
event.c is in need of splitting into multiple files. I'd rather do that in a separate PR.
Performance
It would be great to test this on physical machines with a fast network between them, if only I had the hardware. So here are results for a FreeBSD VM (13.1) on a Linux desktop (5.17.5).
Profiles
Start tincd, run 30 seconds of iperf3, stop tincd.
select
%   cumulative   self              self     total
 time   seconds   seconds    calls  ms/call  ms/call  name
 27.6       5.27     5.27       10   527.41   527.41  __sys_write [3]
 17.9       8.69     3.42        0  100.00%           __sys_select [13]
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
 15.0      11.56     2.87        0  100.00%           _mcount [16]
 14.9      14.40     2.84        0  100.00%           __sys_sendto [17]
  9.8      16.28     1.87        0  100.00%           _recvfrom [20]
  2.0      16.67     0.39 12124817     0.00     0.00  logger [11]
  1.8      17.01     0.34        0  100.00%           .mcount (501)
  1.5      17.30     0.29        1   291.34  6852.63  event_loop [2]
  1.5      17.58     0.28       20    14.22    14.22  __sys_read [39]
  0.7      17.72     0.14  2017455     0.00     0.00  __svfscanf [36]
  0.6      17.85     0.12  3026242     0.00     0.00  __vdso_gettc [48]
  0.6      17.96     0.11  1012231     0.00     0.00  __vfprintf [44]
  0.6      18.07     0.11  5054394     0.00     0.00  memcpy [50]
  0.5      18.16     0.09  3029506     0.00     0.00  route [14]
  0.4      18.24     0.08  2017424     0.00     0.00  receive_meta [6]

kqueue
%   cumulative   self              self     total
 time   seconds   seconds    calls  ms/call  ms/call  name
 27.4       4.92     4.92       10   492.41   492.41  __sys_write [5]
 17.1       8.00     3.07        0  100.00%           __sys_sendto [17]
 16.5      10.96     2.97        0  100.00%           _mcount [18]
 12.3      13.18     2.21        0  100.00%           _recvfrom [21]
 12.2      15.36     2.19  3879960     0.00     0.00  __sys_kevent [23]
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  2.0      15.72     0.36 11660378     0.00     0.00  logger [12]
  2.0      16.07     0.35        0  100.00%           .mcount (498)
  1.5      16.34     0.27       20    13.46    13.46  _read [40]
  1.0      16.52     0.17  1940474     0.00     0.00  __svfscanf [38]
  0.8      16.66     0.14   973307     0.00     0.00  __vfprintf [45]
  0.6      16.77     0.11        1   114.30  8491.48  event_loop [2]
  0.6      16.87     0.11  4860650     0.00     0.00  memcpy [48]
  0.5      16.97     0.10  1940434     0.00     0.00  receive_meta [4]
  0.5      17.06     0.09  2913615     0.00     0.00  route [7]
  0.4      17.13     0.08  1941372     0.00     0.00  __vdso_gettc [58]

Baseline
Direct connection, no tincd.
[ ID] Interval           Transfer     Bitrate         Retr  Cwnd
[  5]   0.00-1.00   sec  4.46 GBytes  38.3 Gbits/sec    0   1.67 MBytes
[  5]   1.00-2.00   sec  4.72 GBytes  40.6 Gbits/sec    0   1.67 MBytes
[  5]   2.00-3.00   sec  4.74 GBytes  40.7 Gbits/sec    0   1.67 MBytes
[  5]   3.00-4.00   sec  4.78 GBytes  41.1 Gbits/sec    0   1.67 MBytes
[  5]   4.00-5.00   sec  4.73 GBytes  40.6 Gbits/sec    0   1.67 MBytes
[  5]   5.00-6.00   sec  4.77 GBytes  41.0 Gbits/sec    0   1.67 MBytes
[  5]   6.00-7.00   sec  4.76 GBytes  40.9 Gbits/sec    0   1.67 MBytes
[  5]   7.00-8.00   sec  4.72 GBytes  40.6 Gbits/sec    0   1.67 MBytes
[  5]   8.00-9.00   sec  4.74 GBytes  40.7 Gbits/sec    0   1.67 MBytes
[  5]   9.00-10.00  sec  4.69 GBytes  40.3 Gbits/sec    0   1.67 MBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-10.00  sec  47.1 GBytes  40.5 Gbits/sec    0             sender
[  5]   0.00-10.00  sec  47.1 GBytes  40.5 Gbits/sec                  receiver

$ wrk -c400 -d5s http://192.168.122.4
Running 5s test @ http://192.168.122.4
  2 threads and 400 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     6.92ms  557.62us  20.31ms   97.69%
    Req/Sec    29.05k   848.97    30.30k    80.00%
  289106 requests in 5.02s, 234.36MB read
Requests/sec:  57641.66
Transfer/sec:     46.73MB

epoll + select
$ wrk -c400 -d30s http://10.0.0.2
Running 30s test @ http://10.0.0.2
  2 threads and 400 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency    37.70ms   82.95ms 845.70ms   87.98%
    Req/Sec    31.46k     5.44k   52.88k    72.67%
  1878491 requests in 30.03s, 1.49GB read
Requests/sec:  62554.59
Transfer/sec:     50.71MB

[ ID] Interval           Transfer     Bitrate         Retr  Cwnd
[  5]   0.00-1.00   sec   109 MBytes   917 Mbits/sec    0   1.69 MBytes
[  5]   1.00-2.00   sec  98.8 MBytes   828 Mbits/sec    0   1.69 MBytes
[  5]   2.00-3.00   sec   108 MBytes   902 Mbits/sec  485   1.30 MBytes
[  5]   3.00-4.00   sec   112 MBytes   944 Mbits/sec    0   1.41 MBytes
[  5]   4.00-5.00   sec   110 MBytes   923 Mbits/sec    0   1.51 MBytes
[  5]   5.00-6.00   sec   101 MBytes   849 Mbits/sec    0   1.57 MBytes
[  5]   6.00-7.00   sec   105 MBytes   881 Mbits/sec    0   1.61 MBytes
[  5]   7.00-8.00   sec  97.5 MBytes   818 Mbits/sec    0   1.61 MBytes
[  5]   8.00-9.00   sec  96.2 MBytes   807 Mbits/sec    0   1.61 MBytes
[  5]   9.00-10.00  sec   109 MBytes   912 Mbits/sec    0   1.65 MBytes
[  5]  10.00-11.00  sec   108 MBytes   902 Mbits/sec  729    597 KBytes
[  5]  11.00-12.00  sec   110 MBytes   923 Mbits/sec    0    724 KBytes
[  5]  12.00-13.00  sec   118 MBytes   986 Mbits/sec   34    646 KBytes
[  5]  13.00-14.00  sec   116 MBytes   975 Mbits/sec    0    773 KBytes
[  5]  14.00-15.00  sec   114 MBytes   954 Mbits/sec    0    881 KBytes
[  5]  15.00-16.00  sec   119 MBytes   996 Mbits/sec    2    718 KBytes
[  5]  16.00-17.00  sec   116 MBytes   975 Mbits/sec   20    646 KBytes
[  5]  17.00-18.00  sec   118 MBytes   986 Mbits/sec    0    775 KBytes
[  5]  18.00-19.00  sec   122 MBytes  1.03 Gbits/sec   10    655 KBytes
[  5]  19.00-20.00  sec   120 MBytes  1.01 Gbits/sec    0    786 KBytes
[  5]  20.00-21.00  sec   119 MBytes   996 Mbits/sec   21    673 KBytes
[  5]  21.00-22.00  sec   114 MBytes   954 Mbits/sec   19    576 KBytes
[  5]  22.00-23.00  sec   118 MBytes   986 Mbits/sec    0    717 KBytes
[  5]  23.00-24.00  sec   116 MBytes   975 Mbits/sec    3    649 KBytes
[  5]  24.00-25.00  sec   116 MBytes   975 Mbits/sec    9    576 KBytes
[  5]  25.00-26.00  sec   115 MBytes   965 Mbits/sec    0    716 KBytes
[  5]  26.00-27.00  sec   114 MBytes   954 Mbits/sec    0    827 KBytes
[  5]  27.00-28.00  sec   119 MBytes   996 Mbits/sec    2    665 KBytes
[  5]  28.00-29.00  sec   116 MBytes   975 Mbits/sec    0    789 KBytes
[  5]  29.00-30.00  sec   119 MBytes   996 Mbits/sec    0    898 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-30.00  sec  3.29 GBytes   943 Mbits/sec  1334             sender
[  5]   0.00-30.01  sec  3.29 GBytes   942 Mbits/sec                  receiver

epoll + kqueue
$ wrk -c400 -d30s http://10.0.0.2
Running 30s test @ http://10.0.0.2
  2 threads and 400 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency    34.13ms   79.44ms 986.57ms   88.72%
    Req/Sec    30.34k     5.57k   52.94k    70.00%
  1811878 requests in 30.03s, 1.43GB read
Requests/sec:  60327.43
Transfer/sec:     48.90MB

[ ID] Interval           Transfer     Bitrate         Retr  Cwnd
[  5]   0.00-1.00   sec   119 MBytes   998 Mbits/sec  706    634 KBytes
[  5]   1.00-2.00   sec   118 MBytes   986 Mbits/sec   38    536 KBytes
[  5]   2.00-3.00   sec   120 MBytes  1.01 Gbits/sec    0    689 KBytes
[  5]   3.00-4.00   sec   119 MBytes   996 Mbits/sec    2    631 KBytes
[  5]   4.00-5.00   sec   115 MBytes   965 Mbits/sec    0    755 KBytes
[  5]   5.00-6.00   sec   118 MBytes   986 Mbits/sec    0    868 KBytes
[  5]   6.00-7.00   sec   120 MBytes  1.01 Gbits/sec  150    505 KBytes
[  5]   7.00-8.00   sec   121 MBytes  1.02 Gbits/sec    0    663 KBytes
[  5]   8.00-9.00   sec   122 MBytes  1.03 Gbits/sec    0    796 KBytes
[  5]   9.00-10.00  sec   120 MBytes  1.01 Gbits/sec   98    659 KBytes
[  5]  10.00-11.00  sec   121 MBytes  1.02 Gbits/sec    0    792 KBytes
[  5]  11.00-12.00  sec   125 MBytes  1.05 Gbits/sec    0    902 KBytes
[  5]  12.00-13.00  sec   116 MBytes   975 Mbits/sec   23    576 KBytes
[  5]  13.00-14.00  sec   119 MBytes   996 Mbits/sec    0    716 KBytes
[  5]  14.00-15.00  sec   118 MBytes   986 Mbits/sec   27    609 KBytes
[  5]  15.00-16.00  sec   120 MBytes  1.01 Gbits/sec    0    748 KBytes
[  5]  16.00-17.00  sec   118 MBytes   986 Mbits/sec   59    650 KBytes
[  5]  17.00-18.00  sec   120 MBytes  1.01 Gbits/sec   21    577 KBytes
[  5]  18.00-19.00  sec   122 MBytes  1.03 Gbits/sec   11    502 KBytes
[  5]  19.00-20.00  sec   121 MBytes  1.02 Gbits/sec    0    663 KBytes
[  5]  20.00-21.00  sec   118 MBytes   986 Mbits/sec    0    790 KBytes
[  5]  21.00-22.00  sec   118 MBytes   986 Mbits/sec   40    560 KBytes
[  5]  22.00-23.00  sec   119 MBytes   996 Mbits/sec    0    706 KBytes
[  5]  23.00-24.00  sec   124 MBytes  1.04 Gbits/sec    0    829 KBytes
[  5]  24.00-25.00  sec   124 MBytes  1.04 Gbits/sec   76    703 KBytes
[  5]  25.00-26.00  sec   124 MBytes  1.04 Gbits/sec   35    585 KBytes
[  5]  26.00-27.00  sec   125 MBytes  1.05 Gbits/sec    0    732 KBytes
[  5]  27.00-28.00  sec   122 MBytes  1.03 Gbits/sec   20    665 KBytes
[  5]  28.00-29.00  sec   119 MBytes   996 Mbits/sec    0    789 KBytes
[  5]  29.00-30.00  sec   120 MBytes  1.01 Gbits/sec   49    478 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-30.00  sec  3.52 GBytes  1.01 Gbits/sec  1355             sender
[  5]   0.00-30.01  sec  3.52 GBytes  1.01 Gbits/sec                  receiver

wrk results are very unstable and could easily be swapped the other way. The only real difference I'm seeing are somewhat lower latencies with kqueue.","Ok, tried it on FreeBSD on two identical nodes with a gigabit Ethernet switch between them. I'm not trusting iperf results anymore since I got this:



Connection
Throughput




Direct
615 Mbit/s


1.1
646 Mbit/s


hg/kqueue
690 Mbit/s



I've rerun the tests, there's a standard deviation of a few Mbit/s. I don't know why the direct connection is slower. Anyway, no regression for your patch, even a ~7% boost in performance (although I would take that with a grain of salt).",True,{'THUMBS_UP': ['https://github.com/hg']}
gsliepen/tinc,https://github.com/gsliepen/tinc,388,2022-05-20T13:03:12Z,2022-05-29T10:48:10Z,2022-05-29T10:48:10Z,MERGED,True,635,249,33,https://github.com/hg,Improve recently seen address cache,4,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/388,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/388,"See #373.
Cache directory is recreated as necessary. While it may be annoying for some users, I don't think it has any real downsides (besides maybe adding a small amount of flash wear on old routers), and there are lots of existing configurations out there that could benefit from this cache. I don't expect many users to read release notes for all software they use.","See #373.
Cache directory is recreated as necessary. While it may be annoying for some users, I don't think it has any real downsides (besides maybe adding a small amount of flash wear on old routers), and there are lots of existing configurations out there that could benefit from this cache. I don't expect many users to read release notes for all software they use.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,388,2022-05-20T13:03:12Z,2022-05-29T10:48:10Z,2022-05-29T10:48:10Z,MERGED,True,635,249,33,https://github.com/hg,Improve recently seen address cache,4,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/388,https://github.com/hg,2,https://github.com/gsliepen/tinc/pull/388#issuecomment-1132880649,"See #373.
Cache directory is recreated as necessary. While it may be annoying for some users, I don't think it has any real downsides (besides maybe adding a small amount of flash wear on old routers), and there are lots of existing configurations out there that could benefit from this cache. I don't expect many users to read release notes for all software they use.","This also flushed out an old bug which I've often run into in the past:

setup node pub with a publicly available IP and port.
put node nat behind NAT or firewall.
join them somehow so they know each other's addresses.
pub starts connecting to nat and fails because of firewall/NAT.
meanwhile, nat successfully connects back to pub.
pub still thinks it has a pending outgoing connection to nat.
pub adds nat's public address to address cache (in pong handler, graph.c, or any other place), not realizing it's using a ""client"" port which won't be available anymore after the current connection is closed.

One might wonder why node nat is being given a public address when it cannot accept incoming connections, but it makes sense if there are multiple nodes behind the firewall. External nodes can be configured to ignore them, at the cost of much additional complexity in Ansible playbooks.
Here's how it looks in logs:
2022-05-20 18:12:13 NOTICE  Connection from x.y.z.q port 60310
2022-05-20 18:12:13 NOTICE  Trying to re-establish outgoing connection in 5 seconds
2022-05-20 18:12:13 NOTICE  Connection with foo (x.y.z.q port 60310) activated
2022-05-20 18:12:18 INFO    Already connected to foo
2022-05-20 18:12:18 DEBUG   Caching recent address for foo

After restarting tincd it uses wrongly cached ports (both nodes should use 655):
2022-05-20 18:14:56 DEBUG   Error while connecting to foo (x.q.z.y port 35870): Connection refused
2022-05-20 18:14:57 DEBUG   Error while connecting to bar (x.y.z.q port 60310): Connection refused

The last commit attempts to fix that. It may be completely wrong because I'm not sure why we're retrying outgoing connections if there already is a working connection.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,388,2022-05-20T13:03:12Z,2022-05-29T10:48:10Z,2022-05-29T10:48:10Z,MERGED,True,635,249,33,https://github.com/hg,Improve recently seen address cache,4,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/388,https://github.com/gsliepen,3,https://github.com/gsliepen/tinc/pull/388#issuecomment-1133777693,"See #373.
Cache directory is recreated as necessary. While it may be annoying for some users, I don't think it has any real downsides (besides maybe adding a small amount of flash wear on old routers), and there are lots of existing configurations out there that could benefit from this cache. I don't expect many users to read release notes for all software they use.","I'm getting a failure in the fs test:
not ok 10 - test_fopenmask_new
# 0x1e8 != 0x1c0
# ../test/unit/test_fs.c:210: error: Failure!

The reason is that I have my umask set to 077. The fs unit tests should probably call umask(0) before doing anything else.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,388,2022-05-20T13:03:12Z,2022-05-29T10:48:10Z,2022-05-29T10:48:10Z,MERGED,True,635,249,33,https://github.com/hg,Improve recently seen address cache,4,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/388,https://github.com/gsliepen,4,https://github.com/gsliepen/tinc/pull/388#issuecomment-1140422808,"See #373.
Cache directory is recreated as necessary. While it may be annoying for some users, I don't think it has any real downsides (besides maybe adding a small amount of flash wear on old routers), and there are lots of existing configurations out there that could benefit from this cache. I don't expect many users to read release notes for all software they use.","Thanks, nice work again! One thing I want to note though is that you often add unrelated commits to a pull request. For example, in this PR you fix an outgoing connection issue and add Markdown reformatting to lint.py. Those have nothing to do with the address cache. The refactoring of filesystem-related functions is somewhat related, as it cleans up some of the code dealing with making directories, but it could also have been in a separate PR. Splitting them makes reviewing easier and increases the likelihood that I can merge individual PRs earlier.",True,{'THUMBS_UP': ['https://github.com/hg']}
gsliepen/tinc,https://github.com/gsliepen/tinc,389,2022-05-21T10:59:14Z,2022-05-21T22:14:29Z,2022-05-21T22:14:29Z,MERGED,True,13,3,2,https://github.com/hg,CI: remove OpenSSL 3 from Fedora; add RHEL 9 & Alpine Edge,1,[],https://github.com/gsliepen/tinc/pull/389,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/389,"Extracted from #386, since merging it may take some time, and we've been getting red CI for weeks.
Fedora 36 uses OpenSSL 3, so we remove it from there. It will continue to crop up as distributions move to OpenSSL 3.
Alpine Edge is useful to test newest versions of musl (I added it in #386 because it used some syscalls not needed by previous versions of musl).
RHEL 9 is quite obvious. It's a beta release, but it works fine, and the final release should be out soon.","Extracted from #386, since merging it may take some time, and we've been getting red CI for weeks.
Fedora 36 uses OpenSSL 3, so we remove it from there. It will continue to crop up as distributions move to OpenSSL 3.
Alpine Edge is useful to test newest versions of musl (I added it in #386 because it used some syscalls not needed by previous versions of musl).
RHEL 9 is quite obvious. It's a beta release, but it works fine, and the final release should be out soon.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,392,2022-05-22T14:38:39Z,,2022-05-26T17:56:02Z,OPEN,False,1063,33,16,https://github.com/hg,ChaCha20: add optimized versions for amd64 (SSSE3 & AVX2),1,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/392,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/392,"With the 'new' protocol, ChaCha is taking a decent amount of CPU time, at least in debug build (optimization makes perf output unreadable):
Children      Self  Command  Shared Object         Symbol
-   99.72%     0.00%  tincd    libc.so.6             [.] __libc_init_first
     __libc_init_first
   - main
      - 99.71% main_loop
         - 90.08% event_loop
            - 69.62% handle_incoming_vpn_data
               - 69.20% handle_incoming_vpn_packet
                  - 68.06% receive_udppacket
                     - 67.88% sptps_receive_data
                        - 67.68% sptps_receive_data_datagram
                           - 49.15% chacha_poly1305_decrypt
                                39.06% chacha_encrypt_bytes
                                9.83% poly1305_auth
                           + 17.80% receive_sptps_record
                  + 0.67% lookup_node_udp
            + 13.34% handle_device_data
            + 4.69% recvmmsg
            + 1.37% handle_meta_io
         + 9.50% epoll_wait

tincd is using the lowest common denominator implementation of this function. Let's add a couple of optimized ones based on compiler intrinsics.
All the hard work has been done by Romain Dolbeau. I just copied it with some adjustments.
Compatibility
x86 / amd64
We'll be shipping three versions of the function (or two, with old compilers without avx2 support):

generic C implementation
another one based on SSSE3
another one based on AVX2

The right one is picked at runtime depending on current CPU capabilities.
Other architectures
Only the old C implementation is used. ARM Neon could be added later.
Benchmarks

i5-4460
Linux 5.17.5
gcc 12.1
iperf3 in two network namespaces
performance CPU governor, as few processes as possible, all the basic benchmarking stuff

TL;DR: 20-22% increase in throughput.

bench_chacha.c
Percentage is relative to generic C implementation.
C
      32:     2790793.08 op/s
     256:     1261587.31 op/s
     512:      728262.56 op/s
    1024:      390193.12 op/s
   16384:       26361.08 op/s
  131072:        3320.87 op/s
 1048576:         415.73 op/s

SSE
      32:     3112408.34 op/s (+11%)
     256:     2441758.81 op/s (+93%)
     512:     1627719.13 op/s (+123%)
    1024:      972969.81 op/s (+149%)
   16384:       74304.47 op/s (+181%)
  131072:        9427.75 op/s (+183%)
 1048576:        1182.82 op/s (+184%)

AVX2
      32:     3159181.11 op/s (+13%)
     256:     2449003.64 op/s (+94%)
     512:     2450859.66 op/s (+236%)
    1024:     1628639.74 op/s (+317%)
   16384:      145438.38 op/s (+451%)
  131072:       18729.81 op/s (+464%)
 1048576:        2330.21 op/s (+460%)

Always resolving the correct function (instead of doing it once and storing in a pointer) is a bit slower:
      32:     3126362.45 op/s
     256:     2395000.08 op/s
     512:     2399900.36 op/s
    1024:     1600087.45 op/s
   16384:      144505.38 op/s
  131072:       18464.47 op/s
 1048576:        2295.46 op/s


iperf3:

buildtype=release
C
[  5]  55.00-56.00  sec   115 MBytes   965 Mbits/sec    2    557 KBytes
[  5]  56.00-57.00  sec   115 MBytes   965 Mbits/sec    1    491 KBytes
[  5]  57.00-58.00  sec   116 MBytes   975 Mbits/sec    0    648 KBytes
[  5]  58.00-59.00  sec   115 MBytes   965 Mbits/sec    1    588 KBytes
[  5]  59.00-60.00  sec   115 MBytes   965 Mbits/sec    2    522 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-60.00  sec  6.73 GBytes   963 Mbits/sec  136             sender
[  5]   0.00-60.00  sec  6.73 GBytes   963 Mbits/sec                  receiver

SSSE3
[  5]  55.00-56.00  sec   130 MBytes  1.09 Gbits/sec   25    600 KBytes
[  5]  56.00-57.00  sec   131 MBytes  1.10 Gbits/sec    2    560 KBytes
[  5]  57.00-58.00  sec   130 MBytes  1.09 Gbits/sec    2    515 KBytes
[  5]  58.00-59.00  sec   132 MBytes  1.11 Gbits/sec    0    683 KBytes
[  5]  59.00-60.00  sec   131 MBytes  1.10 Gbits/sec    2    649 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-60.00  sec  7.64 GBytes  1.09 Gbits/sec  2659             sender
[  5]   0.00-60.00  sec  7.64 GBytes  1.09 Gbits/sec                  receiver

AVX2
[  5]  55.00-56.00  sec   142 MBytes  1.20 Gbits/sec    2    602 KBytes
[  5]  56.00-57.00  sec   141 MBytes  1.19 Gbits/sec    2    574 KBytes
[  5]  57.00-58.00  sec   142 MBytes  1.20 Gbits/sec    1    550 KBytes
[  5]  58.00-59.00  sec   142 MBytes  1.20 Gbits/sec    2    520 KBytes
[  5]  59.00-60.00  sec   142 MBytes  1.20 Gbits/sec    1    494 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-60.00  sec  8.29 GBytes  1.19 Gbits/sec  1126             sender
[  5]   0.00-60.00  sec  8.28 GBytes  1.19 Gbits/sec                  receiver


I thought that it might be possible that optimizing for a specific CPU or auto-vectorization that is performed at -O3 would remove the need of writing assembly:

buildtype=release + -march=native -mtune=native
C
[  5]  55.00-56.00  sec   110 MBytes   923 Mbits/sec    1    498 KBytes
[  5]  56.00-57.00  sec   110 MBytes   923 Mbits/sec    0    646 KBytes
[  5]  57.00-58.00  sec   110 MBytes   923 Mbits/sec    3    581 KBytes
[  5]  58.00-59.00  sec   110 MBytes   923 Mbits/sec    2    506 KBytes
[  5]  59.00-60.00  sec   110 MBytes   923 Mbits/sec    0    650 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-60.00  sec  6.40 GBytes   916 Mbits/sec  2579             sender
[  5]   0.00-60.01  sec  6.40 GBytes   916 Mbits/sec                  receiver

AVX2
[  5]  55.00-56.00  sec   141 MBytes  1.18 Gbits/sec    4    649 KBytes
[  5]  56.00-57.00  sec   142 MBytes  1.20 Gbits/sec    1    626 KBytes
[  5]  57.00-58.00  sec   142 MBytes  1.20 Gbits/sec    2    602 KBytes
[  5]  58.00-59.00  sec   142 MBytes  1.20 Gbits/sec    1    571 KBytes
[  5]  59.00-60.00  sec   141 MBytes  1.18 Gbits/sec    3    539 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-60.00  sec  8.30 GBytes  1.19 Gbits/sec  981             sender
[  5]   0.00-60.00  sec  8.30 GBytes  1.19 Gbits/sec                  receiver



-O3 + -march=native -mtune=native
C
[  5]  55.00-56.00  sec   111 MBytes   933 Mbits/sec    0    680 KBytes
[  5]  56.00-57.00  sec   111 MBytes   933 Mbits/sec    3    619 KBytes
[  5]  57.00-58.00  sec   112 MBytes   944 Mbits/sec    1    554 KBytes
[  5]  58.00-59.00  sec   111 MBytes   933 Mbits/sec    0    691 KBytes
[  5]  59.00-60.00  sec   111 MBytes   933 Mbits/sec    2    634 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-60.00  sec  6.48 GBytes   927 Mbits/sec  3267             sender
[  5]   0.00-60.00  sec  6.47 GBytes   926 Mbits/sec                  receiver

AVX2
[  5]  55.00-56.00  sec   139 MBytes  1.16 Gbits/sec    1    639 KBytes
[  5]  56.00-57.00  sec   139 MBytes  1.16 Gbits/sec    1    607 KBytes
[  5]  57.00-58.00  sec   138 MBytes  1.15 Gbits/sec    1    578 KBytes
[  5]  58.00-59.00  sec   139 MBytes  1.16 Gbits/sec    2    546 KBytes
[  5]  59.00-60.00  sec   138 MBytes  1.15 Gbits/sec    1    510 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-60.00  sec  8.01 GBytes  1.15 Gbits/sec  312             sender
[  5]   0.00-60.00  sec  8.00 GBytes  1.15 Gbits/sec                  receiver


Not really.","With the 'new' protocol, ChaCha is taking a decent amount of CPU time, at least in debug build (optimization makes perf output unreadable):
Children      Self  Command  Shared Object         Symbol
-   99.72%     0.00%  tincd    libc.so.6             [.] __libc_init_first
     __libc_init_first
   - main
      - 99.71% main_loop
         - 90.08% event_loop
            - 69.62% handle_incoming_vpn_data
               - 69.20% handle_incoming_vpn_packet
                  - 68.06% receive_udppacket
                     - 67.88% sptps_receive_data
                        - 67.68% sptps_receive_data_datagram
                           - 49.15% chacha_poly1305_decrypt
                                39.06% chacha_encrypt_bytes
                                9.83% poly1305_auth
                           + 17.80% receive_sptps_record
                  + 0.67% lookup_node_udp
            + 13.34% handle_device_data
            + 4.69% recvmmsg
            + 1.37% handle_meta_io
         + 9.50% epoll_wait

tincd is using the lowest common denominator implementation of this function. Let's add a couple of optimized ones based on compiler intrinsics.
All the hard work has been done by Romain Dolbeau. I just copied it with some adjustments.
Compatibility
x86 / amd64
We'll be shipping three versions of the function (or two, with old compilers without avx2 support):

generic C implementation
another one based on SSSE3
another one based on AVX2

The right one is picked at runtime depending on current CPU capabilities.
Other architectures
Only the old C implementation is used. ARM Neon could be added later.
Benchmarks

i5-4460
Linux 5.17.5
gcc 12.1
iperf3 in two network namespaces
performance CPU governor, as few processes as possible, all the basic benchmarking stuff

TL;DR: 20-22% increase in throughput.

bench_chacha.c
Percentage is relative to generic C implementation.
C
      32:     2790793.08 op/s
     256:     1261587.31 op/s
     512:      728262.56 op/s
    1024:      390193.12 op/s
   16384:       26361.08 op/s
  131072:        3320.87 op/s
 1048576:         415.73 op/s

SSE
      32:     3112408.34 op/s (+11%)
     256:     2441758.81 op/s (+93%)
     512:     1627719.13 op/s (+123%)
    1024:      972969.81 op/s (+149%)
   16384:       74304.47 op/s (+181%)
  131072:        9427.75 op/s (+183%)
 1048576:        1182.82 op/s (+184%)

AVX2
      32:     3159181.11 op/s (+13%)
     256:     2449003.64 op/s (+94%)
     512:     2450859.66 op/s (+236%)
    1024:     1628639.74 op/s (+317%)
   16384:      145438.38 op/s (+451%)
  131072:       18729.81 op/s (+464%)
 1048576:        2330.21 op/s (+460%)

Always resolving the correct function (instead of doing it once and storing in a pointer) is a bit slower:
      32:     3126362.45 op/s
     256:     2395000.08 op/s
     512:     2399900.36 op/s
    1024:     1600087.45 op/s
   16384:      144505.38 op/s
  131072:       18464.47 op/s
 1048576:        2295.46 op/s


iperf3:

buildtype=release
C
[  5]  55.00-56.00  sec   115 MBytes   965 Mbits/sec    2    557 KBytes
[  5]  56.00-57.00  sec   115 MBytes   965 Mbits/sec    1    491 KBytes
[  5]  57.00-58.00  sec   116 MBytes   975 Mbits/sec    0    648 KBytes
[  5]  58.00-59.00  sec   115 MBytes   965 Mbits/sec    1    588 KBytes
[  5]  59.00-60.00  sec   115 MBytes   965 Mbits/sec    2    522 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-60.00  sec  6.73 GBytes   963 Mbits/sec  136             sender
[  5]   0.00-60.00  sec  6.73 GBytes   963 Mbits/sec                  receiver

SSSE3
[  5]  55.00-56.00  sec   130 MBytes  1.09 Gbits/sec   25    600 KBytes
[  5]  56.00-57.00  sec   131 MBytes  1.10 Gbits/sec    2    560 KBytes
[  5]  57.00-58.00  sec   130 MBytes  1.09 Gbits/sec    2    515 KBytes
[  5]  58.00-59.00  sec   132 MBytes  1.11 Gbits/sec    0    683 KBytes
[  5]  59.00-60.00  sec   131 MBytes  1.10 Gbits/sec    2    649 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-60.00  sec  7.64 GBytes  1.09 Gbits/sec  2659             sender
[  5]   0.00-60.00  sec  7.64 GBytes  1.09 Gbits/sec                  receiver

AVX2
[  5]  55.00-56.00  sec   142 MBytes  1.20 Gbits/sec    2    602 KBytes
[  5]  56.00-57.00  sec   141 MBytes  1.19 Gbits/sec    2    574 KBytes
[  5]  57.00-58.00  sec   142 MBytes  1.20 Gbits/sec    1    550 KBytes
[  5]  58.00-59.00  sec   142 MBytes  1.20 Gbits/sec    2    520 KBytes
[  5]  59.00-60.00  sec   142 MBytes  1.20 Gbits/sec    1    494 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-60.00  sec  8.29 GBytes  1.19 Gbits/sec  1126             sender
[  5]   0.00-60.00  sec  8.28 GBytes  1.19 Gbits/sec                  receiver


I thought that it might be possible that optimizing for a specific CPU or auto-vectorization that is performed at -O3 would remove the need of writing assembly:

buildtype=release + -march=native -mtune=native
C
[  5]  55.00-56.00  sec   110 MBytes   923 Mbits/sec    1    498 KBytes
[  5]  56.00-57.00  sec   110 MBytes   923 Mbits/sec    0    646 KBytes
[  5]  57.00-58.00  sec   110 MBytes   923 Mbits/sec    3    581 KBytes
[  5]  58.00-59.00  sec   110 MBytes   923 Mbits/sec    2    506 KBytes
[  5]  59.00-60.00  sec   110 MBytes   923 Mbits/sec    0    650 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-60.00  sec  6.40 GBytes   916 Mbits/sec  2579             sender
[  5]   0.00-60.01  sec  6.40 GBytes   916 Mbits/sec                  receiver

AVX2
[  5]  55.00-56.00  sec   141 MBytes  1.18 Gbits/sec    4    649 KBytes
[  5]  56.00-57.00  sec   142 MBytes  1.20 Gbits/sec    1    626 KBytes
[  5]  57.00-58.00  sec   142 MBytes  1.20 Gbits/sec    2    602 KBytes
[  5]  58.00-59.00  sec   142 MBytes  1.20 Gbits/sec    1    571 KBytes
[  5]  59.00-60.00  sec   141 MBytes  1.18 Gbits/sec    3    539 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-60.00  sec  8.30 GBytes  1.19 Gbits/sec  981             sender
[  5]   0.00-60.00  sec  8.30 GBytes  1.19 Gbits/sec                  receiver



-O3 + -march=native -mtune=native
C
[  5]  55.00-56.00  sec   111 MBytes   933 Mbits/sec    0    680 KBytes
[  5]  56.00-57.00  sec   111 MBytes   933 Mbits/sec    3    619 KBytes
[  5]  57.00-58.00  sec   112 MBytes   944 Mbits/sec    1    554 KBytes
[  5]  58.00-59.00  sec   111 MBytes   933 Mbits/sec    0    691 KBytes
[  5]  59.00-60.00  sec   111 MBytes   933 Mbits/sec    2    634 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-60.00  sec  6.48 GBytes   927 Mbits/sec  3267             sender
[  5]   0.00-60.00  sec  6.47 GBytes   926 Mbits/sec                  receiver

AVX2
[  5]  55.00-56.00  sec   139 MBytes  1.16 Gbits/sec    1    639 KBytes
[  5]  56.00-57.00  sec   139 MBytes  1.16 Gbits/sec    1    607 KBytes
[  5]  57.00-58.00  sec   138 MBytes  1.15 Gbits/sec    1    578 KBytes
[  5]  58.00-59.00  sec   139 MBytes  1.16 Gbits/sec    2    546 KBytes
[  5]  59.00-60.00  sec   138 MBytes  1.15 Gbits/sec    1    510 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-60.00  sec  8.01 GBytes  1.15 Gbits/sec  312             sender
[  5]   0.00-60.00  sec  8.00 GBytes  1.15 Gbits/sec                  receiver


Not really.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,392,2022-05-22T14:38:39Z,,2022-05-26T17:56:02Z,OPEN,False,1063,33,16,https://github.com/hg,ChaCha20: add optimized versions for amd64 (SSSE3 & AVX2),1,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/392,https://github.com/hg,2,https://github.com/gsliepen/tinc/pull/392#issuecomment-1133932017,"With the 'new' protocol, ChaCha is taking a decent amount of CPU time, at least in debug build (optimization makes perf output unreadable):
Children      Self  Command  Shared Object         Symbol
-   99.72%     0.00%  tincd    libc.so.6             [.] __libc_init_first
     __libc_init_first
   - main
      - 99.71% main_loop
         - 90.08% event_loop
            - 69.62% handle_incoming_vpn_data
               - 69.20% handle_incoming_vpn_packet
                  - 68.06% receive_udppacket
                     - 67.88% sptps_receive_data
                        - 67.68% sptps_receive_data_datagram
                           - 49.15% chacha_poly1305_decrypt
                                39.06% chacha_encrypt_bytes
                                9.83% poly1305_auth
                           + 17.80% receive_sptps_record
                  + 0.67% lookup_node_udp
            + 13.34% handle_device_data
            + 4.69% recvmmsg
            + 1.37% handle_meta_io
         + 9.50% epoll_wait

tincd is using the lowest common denominator implementation of this function. Let's add a couple of optimized ones based on compiler intrinsics.
All the hard work has been done by Romain Dolbeau. I just copied it with some adjustments.
Compatibility
x86 / amd64
We'll be shipping three versions of the function (or two, with old compilers without avx2 support):

generic C implementation
another one based on SSSE3
another one based on AVX2

The right one is picked at runtime depending on current CPU capabilities.
Other architectures
Only the old C implementation is used. ARM Neon could be added later.
Benchmarks

i5-4460
Linux 5.17.5
gcc 12.1
iperf3 in two network namespaces
performance CPU governor, as few processes as possible, all the basic benchmarking stuff

TL;DR: 20-22% increase in throughput.

bench_chacha.c
Percentage is relative to generic C implementation.
C
      32:     2790793.08 op/s
     256:     1261587.31 op/s
     512:      728262.56 op/s
    1024:      390193.12 op/s
   16384:       26361.08 op/s
  131072:        3320.87 op/s
 1048576:         415.73 op/s

SSE
      32:     3112408.34 op/s (+11%)
     256:     2441758.81 op/s (+93%)
     512:     1627719.13 op/s (+123%)
    1024:      972969.81 op/s (+149%)
   16384:       74304.47 op/s (+181%)
  131072:        9427.75 op/s (+183%)
 1048576:        1182.82 op/s (+184%)

AVX2
      32:     3159181.11 op/s (+13%)
     256:     2449003.64 op/s (+94%)
     512:     2450859.66 op/s (+236%)
    1024:     1628639.74 op/s (+317%)
   16384:      145438.38 op/s (+451%)
  131072:       18729.81 op/s (+464%)
 1048576:        2330.21 op/s (+460%)

Always resolving the correct function (instead of doing it once and storing in a pointer) is a bit slower:
      32:     3126362.45 op/s
     256:     2395000.08 op/s
     512:     2399900.36 op/s
    1024:     1600087.45 op/s
   16384:      144505.38 op/s
  131072:       18464.47 op/s
 1048576:        2295.46 op/s


iperf3:

buildtype=release
C
[  5]  55.00-56.00  sec   115 MBytes   965 Mbits/sec    2    557 KBytes
[  5]  56.00-57.00  sec   115 MBytes   965 Mbits/sec    1    491 KBytes
[  5]  57.00-58.00  sec   116 MBytes   975 Mbits/sec    0    648 KBytes
[  5]  58.00-59.00  sec   115 MBytes   965 Mbits/sec    1    588 KBytes
[  5]  59.00-60.00  sec   115 MBytes   965 Mbits/sec    2    522 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-60.00  sec  6.73 GBytes   963 Mbits/sec  136             sender
[  5]   0.00-60.00  sec  6.73 GBytes   963 Mbits/sec                  receiver

SSSE3
[  5]  55.00-56.00  sec   130 MBytes  1.09 Gbits/sec   25    600 KBytes
[  5]  56.00-57.00  sec   131 MBytes  1.10 Gbits/sec    2    560 KBytes
[  5]  57.00-58.00  sec   130 MBytes  1.09 Gbits/sec    2    515 KBytes
[  5]  58.00-59.00  sec   132 MBytes  1.11 Gbits/sec    0    683 KBytes
[  5]  59.00-60.00  sec   131 MBytes  1.10 Gbits/sec    2    649 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-60.00  sec  7.64 GBytes  1.09 Gbits/sec  2659             sender
[  5]   0.00-60.00  sec  7.64 GBytes  1.09 Gbits/sec                  receiver

AVX2
[  5]  55.00-56.00  sec   142 MBytes  1.20 Gbits/sec    2    602 KBytes
[  5]  56.00-57.00  sec   141 MBytes  1.19 Gbits/sec    2    574 KBytes
[  5]  57.00-58.00  sec   142 MBytes  1.20 Gbits/sec    1    550 KBytes
[  5]  58.00-59.00  sec   142 MBytes  1.20 Gbits/sec    2    520 KBytes
[  5]  59.00-60.00  sec   142 MBytes  1.20 Gbits/sec    1    494 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-60.00  sec  8.29 GBytes  1.19 Gbits/sec  1126             sender
[  5]   0.00-60.00  sec  8.28 GBytes  1.19 Gbits/sec                  receiver


I thought that it might be possible that optimizing for a specific CPU or auto-vectorization that is performed at -O3 would remove the need of writing assembly:

buildtype=release + -march=native -mtune=native
C
[  5]  55.00-56.00  sec   110 MBytes   923 Mbits/sec    1    498 KBytes
[  5]  56.00-57.00  sec   110 MBytes   923 Mbits/sec    0    646 KBytes
[  5]  57.00-58.00  sec   110 MBytes   923 Mbits/sec    3    581 KBytes
[  5]  58.00-59.00  sec   110 MBytes   923 Mbits/sec    2    506 KBytes
[  5]  59.00-60.00  sec   110 MBytes   923 Mbits/sec    0    650 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-60.00  sec  6.40 GBytes   916 Mbits/sec  2579             sender
[  5]   0.00-60.01  sec  6.40 GBytes   916 Mbits/sec                  receiver

AVX2
[  5]  55.00-56.00  sec   141 MBytes  1.18 Gbits/sec    4    649 KBytes
[  5]  56.00-57.00  sec   142 MBytes  1.20 Gbits/sec    1    626 KBytes
[  5]  57.00-58.00  sec   142 MBytes  1.20 Gbits/sec    2    602 KBytes
[  5]  58.00-59.00  sec   142 MBytes  1.20 Gbits/sec    1    571 KBytes
[  5]  59.00-60.00  sec   141 MBytes  1.18 Gbits/sec    3    539 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-60.00  sec  8.30 GBytes  1.19 Gbits/sec  981             sender
[  5]   0.00-60.00  sec  8.30 GBytes  1.19 Gbits/sec                  receiver



-O3 + -march=native -mtune=native
C
[  5]  55.00-56.00  sec   111 MBytes   933 Mbits/sec    0    680 KBytes
[  5]  56.00-57.00  sec   111 MBytes   933 Mbits/sec    3    619 KBytes
[  5]  57.00-58.00  sec   112 MBytes   944 Mbits/sec    1    554 KBytes
[  5]  58.00-59.00  sec   111 MBytes   933 Mbits/sec    0    691 KBytes
[  5]  59.00-60.00  sec   111 MBytes   933 Mbits/sec    2    634 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-60.00  sec  6.48 GBytes   927 Mbits/sec  3267             sender
[  5]   0.00-60.00  sec  6.47 GBytes   926 Mbits/sec                  receiver

AVX2
[  5]  55.00-56.00  sec   139 MBytes  1.16 Gbits/sec    1    639 KBytes
[  5]  56.00-57.00  sec   139 MBytes  1.16 Gbits/sec    1    607 KBytes
[  5]  57.00-58.00  sec   138 MBytes  1.15 Gbits/sec    1    578 KBytes
[  5]  58.00-59.00  sec   139 MBytes  1.16 Gbits/sec    2    546 KBytes
[  5]  59.00-60.00  sec   138 MBytes  1.15 Gbits/sec    1    510 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-60.00  sec  8.01 GBytes  1.15 Gbits/sec  312             sender
[  5]   0.00-60.00  sec  8.00 GBytes  1.15 Gbits/sec                  receiver


Not really.","I tried the NEON implementation from the same author. It's doesn't have as much of an edge over the generic one, at least on Neoverse-N1. So iperf3 speeds are comparable.
If anyone has an old Raspberry Pi and wants to test this on a slower CPU — be my guest. The code is in pretty bad shape since it's work in progress, but it does work.
Otherwise, I see no reason to merge NEON support.
generic
      32:     2846064.09 op/s
     256:     1424432.86 op/s
     512:      850478.15 op/s
    1024:      473508.42 op/s
   16384:       33032.01 op/s
  131072:        4146.80 op/s
 1048576:         517.55 op/s

[  5]  55.00-56.00  sec   100 MBytes   839 Mbits/sec    0    658 KBytes
[  5]  56.00-57.00  sec   101 MBytes   849 Mbits/sec    8    571 KBytes
[  5]  57.00-58.00  sec   102 MBytes   860 Mbits/sec    2    484 KBytes
[  5]  58.00-59.00  sec   101 MBytes   849 Mbits/sec    0    622 KBytes
[  5]  59.00-60.00  sec   101 MBytes   849 Mbits/sec    1    532 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-60.00  sec  5.67 GBytes   812 Mbits/sec  2875             sender
[  5]   0.00-60.00  sec  5.67 GBytes   812 Mbits/sec                  receiver

NEON
       32:     2933899.98 op/s (+3%)
      256:     1943603.43 op/s (+36%)
      512:     1242317.12 op/s (+46%)
     1024:      724495.40 op/s (+53%)
    16384:       53621.92 op/s (+62%)
   131072:        6754.49 op/s (+62%)
  1048576:         844.45 op/s (+63%)

[  5]  55.00-56.00  sec   101 MBytes   849 Mbits/sec    1    536 KBytes
[  5]  56.00-57.00  sec   100 MBytes   839 Mbits/sec    0    666 KBytes
[  5]  57.00-58.00  sec   101 MBytes   849 Mbits/sec    3    584 KBytes
[  5]  58.00-59.00  sec   100 MBytes   839 Mbits/sec    0    704 KBytes
[  5]  59.00-60.00  sec   102 MBytes   860 Mbits/sec    2    626 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-60.00  sec  5.81 GBytes   832 Mbits/sec  1660             sender
[  5]   0.00-60.00  sec  5.81 GBytes   832 Mbits/sec                  receiver


Badly modified `ns_ping.py` for running iperf3
#!/usr/bin/env python3

""""""Create two network namespaces and run ping between them.""""""

import os
import signal
import subprocess as subp
import typing as T

from testlib import external as ext, util, template, cmd
from testlib.log import log
from testlib.proc import Tinc, Script
from testlib.test import Test

util.require_root()
util.require_command(""ip"", ""netns"", ""list"")
util.require_path(""/dev/net/tun"")

IP_FOO = ""192.168.1.1""
IP_BAR = ""192.168.1.2""
MASK = 24


def init(ctx: Test) -> T.Tuple[Tinc, Tinc]:
    """"""Initialize new test nodes.""""""
    foo, bar = ctx.node(), ctx.node()

    log.info(""create network namespaces"")
    assert ext.netns_add(foo.name)
    assert ext.netns_add(bar.name)

    log.info(""initialize two nodes"")

    stdin = f""""""
        init {foo}
        set Port 0
        set Subnet {IP_FOO}
        set Interface {foo}
        set Address localhost
        set AutoConnect no
    """"""
    foo.cmd(stdin=stdin)
    foo.add_script(Script.TINC_UP, template.make_netns_config(foo.name, IP_FOO, MASK))
    foo.start()

    stdin = f""""""
        init {bar}
        set Port 0
        set Subnet {IP_BAR}
        set Interface {bar}
        set Address localhost
        set AutoConnect no
    """"""
    bar.cmd(stdin=stdin)
    bar.add_script(Script.TINC_UP, template.make_netns_config(bar.name, IP_BAR, MASK))

    cmd.exchange(foo, bar)

    return foo, bar


def ping(namespace: str, ip_addr: str) -> int:
    """"""Send pings between two network namespaces.""""""
    log.info(""pinging node from netns %s at %s"", namespace, ip_addr)

    proc = subp.run(
        [""ip"", ""netns"", ""exec"", namespace, ""iperf3"", ""-t"", ""60"", ""-c"", ip_addr], check=False
    )

    log.info(""ping finished with code %d"", proc.returncode)
    return proc.returncode


with Test(""ns-ping"") as context:
    foo_node, bar_node = init(context)
    bar_node.cmd(""start"")

    log.info(""waiting for nodes to come up"")
    bar_node[Script.TINC_UP].wait()

    log.info(""add script foo/host-up"")
    bar_node.add_script(foo_node.script_up)

    log.info(""add ConnectTo clause"")
    bar_node.cmd(""add"", ""ConnectTo"", foo_node.name)

    log.info(""bar waits for foo"")
    bar_node[foo_node.script_up].wait()

    subp.Popen([""ip"", ""netns"", ""exec"", bar_node.name, ""iperf3"", ""-s""], stdout=subp.DEVNULL, stderr=subp.DEVNULL)

    log.info(""ping must work after connection is up"")
    assert not ping(foo_node.name, IP_BAR)",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,392,2022-05-22T14:38:39Z,,2022-05-26T17:56:02Z,OPEN,False,1063,33,16,https://github.com/hg,ChaCha20: add optimized versions for amd64 (SSSE3 & AVX2),1,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/392,https://github.com/gsliepen,3,https://github.com/gsliepen/tinc/pull/392#issuecomment-1133962762,"With the 'new' protocol, ChaCha is taking a decent amount of CPU time, at least in debug build (optimization makes perf output unreadable):
Children      Self  Command  Shared Object         Symbol
-   99.72%     0.00%  tincd    libc.so.6             [.] __libc_init_first
     __libc_init_first
   - main
      - 99.71% main_loop
         - 90.08% event_loop
            - 69.62% handle_incoming_vpn_data
               - 69.20% handle_incoming_vpn_packet
                  - 68.06% receive_udppacket
                     - 67.88% sptps_receive_data
                        - 67.68% sptps_receive_data_datagram
                           - 49.15% chacha_poly1305_decrypt
                                39.06% chacha_encrypt_bytes
                                9.83% poly1305_auth
                           + 17.80% receive_sptps_record
                  + 0.67% lookup_node_udp
            + 13.34% handle_device_data
            + 4.69% recvmmsg
            + 1.37% handle_meta_io
         + 9.50% epoll_wait

tincd is using the lowest common denominator implementation of this function. Let's add a couple of optimized ones based on compiler intrinsics.
All the hard work has been done by Romain Dolbeau. I just copied it with some adjustments.
Compatibility
x86 / amd64
We'll be shipping three versions of the function (or two, with old compilers without avx2 support):

generic C implementation
another one based on SSSE3
another one based on AVX2

The right one is picked at runtime depending on current CPU capabilities.
Other architectures
Only the old C implementation is used. ARM Neon could be added later.
Benchmarks

i5-4460
Linux 5.17.5
gcc 12.1
iperf3 in two network namespaces
performance CPU governor, as few processes as possible, all the basic benchmarking stuff

TL;DR: 20-22% increase in throughput.

bench_chacha.c
Percentage is relative to generic C implementation.
C
      32:     2790793.08 op/s
     256:     1261587.31 op/s
     512:      728262.56 op/s
    1024:      390193.12 op/s
   16384:       26361.08 op/s
  131072:        3320.87 op/s
 1048576:         415.73 op/s

SSE
      32:     3112408.34 op/s (+11%)
     256:     2441758.81 op/s (+93%)
     512:     1627719.13 op/s (+123%)
    1024:      972969.81 op/s (+149%)
   16384:       74304.47 op/s (+181%)
  131072:        9427.75 op/s (+183%)
 1048576:        1182.82 op/s (+184%)

AVX2
      32:     3159181.11 op/s (+13%)
     256:     2449003.64 op/s (+94%)
     512:     2450859.66 op/s (+236%)
    1024:     1628639.74 op/s (+317%)
   16384:      145438.38 op/s (+451%)
  131072:       18729.81 op/s (+464%)
 1048576:        2330.21 op/s (+460%)

Always resolving the correct function (instead of doing it once and storing in a pointer) is a bit slower:
      32:     3126362.45 op/s
     256:     2395000.08 op/s
     512:     2399900.36 op/s
    1024:     1600087.45 op/s
   16384:      144505.38 op/s
  131072:       18464.47 op/s
 1048576:        2295.46 op/s


iperf3:

buildtype=release
C
[  5]  55.00-56.00  sec   115 MBytes   965 Mbits/sec    2    557 KBytes
[  5]  56.00-57.00  sec   115 MBytes   965 Mbits/sec    1    491 KBytes
[  5]  57.00-58.00  sec   116 MBytes   975 Mbits/sec    0    648 KBytes
[  5]  58.00-59.00  sec   115 MBytes   965 Mbits/sec    1    588 KBytes
[  5]  59.00-60.00  sec   115 MBytes   965 Mbits/sec    2    522 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-60.00  sec  6.73 GBytes   963 Mbits/sec  136             sender
[  5]   0.00-60.00  sec  6.73 GBytes   963 Mbits/sec                  receiver

SSSE3
[  5]  55.00-56.00  sec   130 MBytes  1.09 Gbits/sec   25    600 KBytes
[  5]  56.00-57.00  sec   131 MBytes  1.10 Gbits/sec    2    560 KBytes
[  5]  57.00-58.00  sec   130 MBytes  1.09 Gbits/sec    2    515 KBytes
[  5]  58.00-59.00  sec   132 MBytes  1.11 Gbits/sec    0    683 KBytes
[  5]  59.00-60.00  sec   131 MBytes  1.10 Gbits/sec    2    649 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-60.00  sec  7.64 GBytes  1.09 Gbits/sec  2659             sender
[  5]   0.00-60.00  sec  7.64 GBytes  1.09 Gbits/sec                  receiver

AVX2
[  5]  55.00-56.00  sec   142 MBytes  1.20 Gbits/sec    2    602 KBytes
[  5]  56.00-57.00  sec   141 MBytes  1.19 Gbits/sec    2    574 KBytes
[  5]  57.00-58.00  sec   142 MBytes  1.20 Gbits/sec    1    550 KBytes
[  5]  58.00-59.00  sec   142 MBytes  1.20 Gbits/sec    2    520 KBytes
[  5]  59.00-60.00  sec   142 MBytes  1.20 Gbits/sec    1    494 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-60.00  sec  8.29 GBytes  1.19 Gbits/sec  1126             sender
[  5]   0.00-60.00  sec  8.28 GBytes  1.19 Gbits/sec                  receiver


I thought that it might be possible that optimizing for a specific CPU or auto-vectorization that is performed at -O3 would remove the need of writing assembly:

buildtype=release + -march=native -mtune=native
C
[  5]  55.00-56.00  sec   110 MBytes   923 Mbits/sec    1    498 KBytes
[  5]  56.00-57.00  sec   110 MBytes   923 Mbits/sec    0    646 KBytes
[  5]  57.00-58.00  sec   110 MBytes   923 Mbits/sec    3    581 KBytes
[  5]  58.00-59.00  sec   110 MBytes   923 Mbits/sec    2    506 KBytes
[  5]  59.00-60.00  sec   110 MBytes   923 Mbits/sec    0    650 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-60.00  sec  6.40 GBytes   916 Mbits/sec  2579             sender
[  5]   0.00-60.01  sec  6.40 GBytes   916 Mbits/sec                  receiver

AVX2
[  5]  55.00-56.00  sec   141 MBytes  1.18 Gbits/sec    4    649 KBytes
[  5]  56.00-57.00  sec   142 MBytes  1.20 Gbits/sec    1    626 KBytes
[  5]  57.00-58.00  sec   142 MBytes  1.20 Gbits/sec    2    602 KBytes
[  5]  58.00-59.00  sec   142 MBytes  1.20 Gbits/sec    1    571 KBytes
[  5]  59.00-60.00  sec   141 MBytes  1.18 Gbits/sec    3    539 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-60.00  sec  8.30 GBytes  1.19 Gbits/sec  981             sender
[  5]   0.00-60.00  sec  8.30 GBytes  1.19 Gbits/sec                  receiver



-O3 + -march=native -mtune=native
C
[  5]  55.00-56.00  sec   111 MBytes   933 Mbits/sec    0    680 KBytes
[  5]  56.00-57.00  sec   111 MBytes   933 Mbits/sec    3    619 KBytes
[  5]  57.00-58.00  sec   112 MBytes   944 Mbits/sec    1    554 KBytes
[  5]  58.00-59.00  sec   111 MBytes   933 Mbits/sec    0    691 KBytes
[  5]  59.00-60.00  sec   111 MBytes   933 Mbits/sec    2    634 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-60.00  sec  6.48 GBytes   927 Mbits/sec  3267             sender
[  5]   0.00-60.00  sec  6.47 GBytes   926 Mbits/sec                  receiver

AVX2
[  5]  55.00-56.00  sec   139 MBytes  1.16 Gbits/sec    1    639 KBytes
[  5]  56.00-57.00  sec   139 MBytes  1.16 Gbits/sec    1    607 KBytes
[  5]  57.00-58.00  sec   138 MBytes  1.15 Gbits/sec    1    578 KBytes
[  5]  58.00-59.00  sec   139 MBytes  1.16 Gbits/sec    2    546 KBytes
[  5]  59.00-60.00  sec   138 MBytes  1.15 Gbits/sec    1    510 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-60.00  sec  8.01 GBytes  1.15 Gbits/sec  312             sender
[  5]   0.00-60.00  sec  8.00 GBytes  1.15 Gbits/sec                  receiver


Not really.","The benchmark code you wrote is not really measuring the usage pattern tinc has. The sptps_speed program (which you might have to explicitly build using ninja -C build src/sptps_speed) tests the SPTPS protocol more thoroughly, using typical MTU-sized packets.
Performance measurements using debug builds are mostly useless. Have you tried configuring the build system with -Dbuildtype=debugoptimized?
I also have a branch (PR #360) that adds AES-256-GCM support to SPTPS, which depends on OpenSSL, but it will then also use OpenSSL for Chacha20-Poly1305. It might be interesting to compare the speed with this optimized version as well.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,392,2022-05-22T14:38:39Z,,2022-05-26T17:56:02Z,OPEN,False,1063,33,16,https://github.com/hg,ChaCha20: add optimized versions for amd64 (SSSE3 & AVX2),1,"['enhancement', '1.1']",https://github.com/gsliepen/tinc/pull/392,https://github.com/hg,4,https://github.com/gsliepen/tinc/pull/392#issuecomment-1134317734,"With the 'new' protocol, ChaCha is taking a decent amount of CPU time, at least in debug build (optimization makes perf output unreadable):
Children      Self  Command  Shared Object         Symbol
-   99.72%     0.00%  tincd    libc.so.6             [.] __libc_init_first
     __libc_init_first
   - main
      - 99.71% main_loop
         - 90.08% event_loop
            - 69.62% handle_incoming_vpn_data
               - 69.20% handle_incoming_vpn_packet
                  - 68.06% receive_udppacket
                     - 67.88% sptps_receive_data
                        - 67.68% sptps_receive_data_datagram
                           - 49.15% chacha_poly1305_decrypt
                                39.06% chacha_encrypt_bytes
                                9.83% poly1305_auth
                           + 17.80% receive_sptps_record
                  + 0.67% lookup_node_udp
            + 13.34% handle_device_data
            + 4.69% recvmmsg
            + 1.37% handle_meta_io
         + 9.50% epoll_wait

tincd is using the lowest common denominator implementation of this function. Let's add a couple of optimized ones based on compiler intrinsics.
All the hard work has been done by Romain Dolbeau. I just copied it with some adjustments.
Compatibility
x86 / amd64
We'll be shipping three versions of the function (or two, with old compilers without avx2 support):

generic C implementation
another one based on SSSE3
another one based on AVX2

The right one is picked at runtime depending on current CPU capabilities.
Other architectures
Only the old C implementation is used. ARM Neon could be added later.
Benchmarks

i5-4460
Linux 5.17.5
gcc 12.1
iperf3 in two network namespaces
performance CPU governor, as few processes as possible, all the basic benchmarking stuff

TL;DR: 20-22% increase in throughput.

bench_chacha.c
Percentage is relative to generic C implementation.
C
      32:     2790793.08 op/s
     256:     1261587.31 op/s
     512:      728262.56 op/s
    1024:      390193.12 op/s
   16384:       26361.08 op/s
  131072:        3320.87 op/s
 1048576:         415.73 op/s

SSE
      32:     3112408.34 op/s (+11%)
     256:     2441758.81 op/s (+93%)
     512:     1627719.13 op/s (+123%)
    1024:      972969.81 op/s (+149%)
   16384:       74304.47 op/s (+181%)
  131072:        9427.75 op/s (+183%)
 1048576:        1182.82 op/s (+184%)

AVX2
      32:     3159181.11 op/s (+13%)
     256:     2449003.64 op/s (+94%)
     512:     2450859.66 op/s (+236%)
    1024:     1628639.74 op/s (+317%)
   16384:      145438.38 op/s (+451%)
  131072:       18729.81 op/s (+464%)
 1048576:        2330.21 op/s (+460%)

Always resolving the correct function (instead of doing it once and storing in a pointer) is a bit slower:
      32:     3126362.45 op/s
     256:     2395000.08 op/s
     512:     2399900.36 op/s
    1024:     1600087.45 op/s
   16384:      144505.38 op/s
  131072:       18464.47 op/s
 1048576:        2295.46 op/s


iperf3:

buildtype=release
C
[  5]  55.00-56.00  sec   115 MBytes   965 Mbits/sec    2    557 KBytes
[  5]  56.00-57.00  sec   115 MBytes   965 Mbits/sec    1    491 KBytes
[  5]  57.00-58.00  sec   116 MBytes   975 Mbits/sec    0    648 KBytes
[  5]  58.00-59.00  sec   115 MBytes   965 Mbits/sec    1    588 KBytes
[  5]  59.00-60.00  sec   115 MBytes   965 Mbits/sec    2    522 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-60.00  sec  6.73 GBytes   963 Mbits/sec  136             sender
[  5]   0.00-60.00  sec  6.73 GBytes   963 Mbits/sec                  receiver

SSSE3
[  5]  55.00-56.00  sec   130 MBytes  1.09 Gbits/sec   25    600 KBytes
[  5]  56.00-57.00  sec   131 MBytes  1.10 Gbits/sec    2    560 KBytes
[  5]  57.00-58.00  sec   130 MBytes  1.09 Gbits/sec    2    515 KBytes
[  5]  58.00-59.00  sec   132 MBytes  1.11 Gbits/sec    0    683 KBytes
[  5]  59.00-60.00  sec   131 MBytes  1.10 Gbits/sec    2    649 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-60.00  sec  7.64 GBytes  1.09 Gbits/sec  2659             sender
[  5]   0.00-60.00  sec  7.64 GBytes  1.09 Gbits/sec                  receiver

AVX2
[  5]  55.00-56.00  sec   142 MBytes  1.20 Gbits/sec    2    602 KBytes
[  5]  56.00-57.00  sec   141 MBytes  1.19 Gbits/sec    2    574 KBytes
[  5]  57.00-58.00  sec   142 MBytes  1.20 Gbits/sec    1    550 KBytes
[  5]  58.00-59.00  sec   142 MBytes  1.20 Gbits/sec    2    520 KBytes
[  5]  59.00-60.00  sec   142 MBytes  1.20 Gbits/sec    1    494 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-60.00  sec  8.29 GBytes  1.19 Gbits/sec  1126             sender
[  5]   0.00-60.00  sec  8.28 GBytes  1.19 Gbits/sec                  receiver


I thought that it might be possible that optimizing for a specific CPU or auto-vectorization that is performed at -O3 would remove the need of writing assembly:

buildtype=release + -march=native -mtune=native
C
[  5]  55.00-56.00  sec   110 MBytes   923 Mbits/sec    1    498 KBytes
[  5]  56.00-57.00  sec   110 MBytes   923 Mbits/sec    0    646 KBytes
[  5]  57.00-58.00  sec   110 MBytes   923 Mbits/sec    3    581 KBytes
[  5]  58.00-59.00  sec   110 MBytes   923 Mbits/sec    2    506 KBytes
[  5]  59.00-60.00  sec   110 MBytes   923 Mbits/sec    0    650 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-60.00  sec  6.40 GBytes   916 Mbits/sec  2579             sender
[  5]   0.00-60.01  sec  6.40 GBytes   916 Mbits/sec                  receiver

AVX2
[  5]  55.00-56.00  sec   141 MBytes  1.18 Gbits/sec    4    649 KBytes
[  5]  56.00-57.00  sec   142 MBytes  1.20 Gbits/sec    1    626 KBytes
[  5]  57.00-58.00  sec   142 MBytes  1.20 Gbits/sec    2    602 KBytes
[  5]  58.00-59.00  sec   142 MBytes  1.20 Gbits/sec    1    571 KBytes
[  5]  59.00-60.00  sec   141 MBytes  1.18 Gbits/sec    3    539 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-60.00  sec  8.30 GBytes  1.19 Gbits/sec  981             sender
[  5]   0.00-60.00  sec  8.30 GBytes  1.19 Gbits/sec                  receiver



-O3 + -march=native -mtune=native
C
[  5]  55.00-56.00  sec   111 MBytes   933 Mbits/sec    0    680 KBytes
[  5]  56.00-57.00  sec   111 MBytes   933 Mbits/sec    3    619 KBytes
[  5]  57.00-58.00  sec   112 MBytes   944 Mbits/sec    1    554 KBytes
[  5]  58.00-59.00  sec   111 MBytes   933 Mbits/sec    0    691 KBytes
[  5]  59.00-60.00  sec   111 MBytes   933 Mbits/sec    2    634 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-60.00  sec  6.48 GBytes   927 Mbits/sec  3267             sender
[  5]   0.00-60.00  sec  6.47 GBytes   926 Mbits/sec                  receiver

AVX2
[  5]  55.00-56.00  sec   139 MBytes  1.16 Gbits/sec    1    639 KBytes
[  5]  56.00-57.00  sec   139 MBytes  1.16 Gbits/sec    1    607 KBytes
[  5]  57.00-58.00  sec   138 MBytes  1.15 Gbits/sec    1    578 KBytes
[  5]  58.00-59.00  sec   139 MBytes  1.16 Gbits/sec    2    546 KBytes
[  5]  59.00-60.00  sec   138 MBytes  1.15 Gbits/sec    1    510 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-60.00  sec  8.01 GBytes  1.15 Gbits/sec  312             sender
[  5]   0.00-60.00  sec  8.00 GBytes  1.15 Gbits/sec                  receiver


Not really.","Oh yes. If you're willing to reintroduce dependency on libssl, it would of course be best. We get highly optimized code for all possible architectures for free.
TL;DR:



flavor
throughput




generic
0.974 Gbit/s


avx2
1.19 Gbit/s


libssl1.1
1.28 Gbit/s


libssl3.1
1.23 Gbit/s*



*: probably a debug build

  detailed results
generic
Generating keys for 10 seconds:          27182.71 op/s
Ed25519 sign for 10 seconds:             25932.53 op/s
Ed25519 verify for 10 seconds:            8360.30 op/s
ECDH for 10 seconds:                      6783.36 op/s
SPTPS/TCP authenticate for 10 seconds:    3173.35 op/s
SPTPS/TCP transmit for 10 seconds:           2.47 Gbit/s
SPTPS/UDP authenticate for 10 seconds:    3167.00 op/s
SPTPS/UDP transmit for 10 seconds:           2.46 Gbit/s

[  5]  55.00-56.00  sec   116 MBytes   975 Mbits/sec    0    686 KBytes
[  5]  56.00-57.00  sec   119 MBytes   996 Mbits/sec    1    634 KBytes
[  5]  57.00-58.00  sec   118 MBytes   986 Mbits/sec    2    573 KBytes
[  5]  58.00-59.00  sec   118 MBytes   986 Mbits/sec    1    506 KBytes
[  5]  59.00-60.00  sec   118 MBytes   986 Mbits/sec    0    662 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-60.00  sec  6.80 GBytes   974 Mbits/sec  5725             sender
[  5]   0.00-60.01  sec  6.80 GBytes   973 Mbits/sec                  receiver

avx2
Generating keys for 10 seconds:          27313.96 op/s
Ed25519 sign for 10 seconds:             26049.17 op/s
Ed25519 verify for 10 seconds:            8411.54 op/s
ECDH for 10 seconds:                      6792.54 op/s
SPTPS/TCP authenticate for 10 seconds:    3156.87 op/s
SPTPS/TCP transmit for 10 seconds:           4.00 Gbit/s
SPTPS/UDP authenticate for 10 seconds:    3160.10 op/s
SPTPS/UDP transmit for 10 seconds:           4.13 Gbit/s

[  5]  25.00-26.00  sec   142 MBytes  1.20 Gbits/sec    1    509 KBytes
[  5]  26.00-27.00  sec   142 MBytes  1.20 Gbits/sec    0    691 KBytes
[  5]  27.00-28.00  sec   142 MBytes  1.20 Gbits/sec    1    672 KBytes
[  5]  28.00-29.00  sec   142 MBytes  1.20 Gbits/sec    1    649 KBytes
[  5]  29.00-30.00  sec   142 MBytes  1.20 Gbits/sec    2    619 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-30.00  sec  4.12 GBytes  1.19 Gbits/sec  273             sender
[  5]   0.00-30.00  sec  4.12 GBytes  1.19 Gbits/sec                  receiver

alt (OpenSSL 1.1.1.o)
Generating keys for 10 seconds:          27294.88 op/s
Ed25519 sign for 10 seconds:             26004.59 op/s
Ed25519 verify for 10 seconds:            8409.03 op/s
ECDH for 10 seconds:                      6786.60 op/s

Cipher suite 0 (Chacha20-Poly1305):
SPTPS/TCP authenticate for 10 seconds:    3182.28 op/s
SPTPS/TCP transmit for 10 seconds:           6.24 Gbit/s
SPTPS/UDP authenticate for 10 seconds:    3178.83 op/s
SPTPS/UDP transmit for 10 seconds:           6.16 Gbit/s

Cipher suite 1 (AES-256-GCM):
SPTPS/TCP authenticate for 10 seconds:    3177.70 op/s
SPTPS/TCP transmit for 10 seconds:           8.89 Gbit/s
SPTPS/UDP authenticate for 10 seconds:    3169.44 op/s
SPTPS/UDP transmit for 10 seconds:           8.73 Gbit/s

[  5]  25.00-26.00  sec   154 MBytes  1.29 Gbits/sec    1    628 KBytes
[  5]  26.00-27.00  sec   154 MBytes  1.29 Gbits/sec    4    619 KBytes
[  5]  27.00-28.00  sec   155 MBytes  1.30 Gbits/sec    2    611 KBytes
[  5]  28.00-29.00  sec   155 MBytes  1.30 Gbits/sec    2    595 KBytes
[  5]  29.00-30.00  sec   154 MBytes  1.29 Gbits/sec    1    585 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-30.00  sec  4.42 GBytes  1.28 Gbits/sec  3427             sender
[  5]   0.00-30.00  sec  4.41 GBytes  1.28 Gbits/sec                  receiver

alt (OpenSSL 3.1)
I don't remember what flags were used to build the library. It may be a debug build, so don't pay much attention to it.
Generating keys for 10 seconds:          27368.60 op/s
Ed25519 sign for 10 seconds:             26068.22 op/s
Ed25519 verify for 10 seconds:            8434.89 op/s
ECDH for 10 seconds:                      6839.51 op/s

Cipher suite 0 (Chacha20-Poly1305):
SPTPS/TCP authenticate for 10 seconds:    3152.25 op/s
SPTPS/TCP transmit for 10 seconds:           5.83 Gbit/s
SPTPS/UDP authenticate for 10 seconds:    3149.35 op/s
SPTPS/UDP transmit for 10 seconds:           5.77 Gbit/s

Cipher suite 1 (AES-256-GCM):
SPTPS/TCP authenticate for 10 seconds:    3151.33 op/s
SPTPS/TCP transmit for 10 seconds:           7.69 Gbit/s
SPTPS/UDP authenticate for 10 seconds:    3149.60 op/s
SPTPS/UDP transmit for 10 seconds:           7.88 Gbit/s

[  5]  25.00-26.00  sec   148 MBytes  1.24 Gbits/sec    4    670 KBytes
[  5]  26.00-27.00  sec   148 MBytes  1.24 Gbits/sec    2    649 KBytes
[  5]  27.00-28.00  sec   148 MBytes  1.24 Gbits/sec    1    632 KBytes
[  5]  28.00-29.00  sec   148 MBytes  1.24 Gbits/sec    2    609 KBytes
[  5]  29.00-30.00  sec   148 MBytes  1.24 Gbits/sec    1    591 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bitrate         Retr
[  5]   0.00-30.00  sec  4.24 GBytes  1.23 Gbits/sec  973             sender
[  5]   0.00-30.00  sec  4.24 GBytes  1.22 Gbits/sec                  receiver


I'll leave it here for now until after #360 is merged.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,394,2022-05-23T10:14:18Z,2022-05-23T18:31:00Z,2022-05-23T18:31:01Z,MERGED,True,106,3,3,https://github.com/hg,Fix weight comparison in edge BFS,1,[],https://github.com/gsliepen/tinc/pull/394,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/394,"re #393
I'm guessing BFS could be replaced with a more effective algorithm? I wanted to model a large-ish network with dozens of edges, but it quickly became obvious sssp_bfs() doesn't pick the most efficient route in complex cases. So this PR comes with a minimal test only to reproduce this issue.","re #393
I'm guessing BFS could be replaced with a more effective algorithm? I wanted to model a large-ish network with dozens of edges, but it quickly became obvious sssp_bfs() doesn't pick the most efficient route in complex cases. So this PR comes with a minimal test only to reproduce this issue.",True,{'ROCKET': ['https://github.com/crazyboycjr']}
gsliepen/tinc,https://github.com/gsliepen/tinc,395,2022-05-23T14:08:40Z,2022-05-23T19:40:33Z,2022-05-23T19:40:34Z,MERGED,True,55,73,10,https://github.com/hg,CI: use compilation database for clang-tidy job,2,[],https://github.com/gsliepen/tinc/pull/395,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/395,"I didn't realize LLVM already ships a runner for clang-tidy which picks files from the compilation database. This lets us avoid wrapping optional C files in giant #ifdefs.
By the way, we're still only running a single check. I'll start adding more one by one and fixing whatever is reported while working on other things.","I didn't realize LLVM already ships a runner for clang-tidy which picks files from the compilation database. This lets us avoid wrapping optional C files in giant #ifdefs.
By the way, we're still only running a single check. I'll start adding more one by one and fixing whatever is reported while working on other things.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,395,2022-05-23T14:08:40Z,2022-05-23T19:40:33Z,2022-05-23T19:40:34Z,MERGED,True,55,73,10,https://github.com/hg,CI: use compilation database for clang-tidy job,2,[],https://github.com/gsliepen/tinc/pull/395,https://github.com/hg,2,https://github.com/gsliepen/tinc/pull/395#issuecomment-1134968783,"I didn't realize LLVM already ships a runner for clang-tidy which picks files from the compilation database. This lets us avoid wrapping optional C files in giant #ifdefs.
By the way, we're still only running a single check. I'll start adding more one by one and fixing whatever is reported while working on other things.","Here are some checks for starters. A few suggested issues are actually interesting (printf in signal handler, zero alloca(), a couple of memory leaks).
Filling sockaddr_ll in raw socket device code with '0' (as opposed to 0) looks like a typo. Other examples I'm reading around the 'net use 0. Is this correct? Sorry, no idea how to quickly test this device.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,396,2022-05-23T14:08:52Z,2022-05-23T20:05:37Z,2022-05-23T20:05:37Z,MERGED,True,120,5,9,https://github.com/hg,Add optional systemd integration,1,[],https://github.com/gsliepen/tinc/pull/396,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/396,"startup & shutdown notifications
optional watchdog with auto-restart on hang (enabled if WatchdogSec is set in systemd unit)

re #338
Static analysis job will fail until this is rebased on top of #395.

The code is using libsystemd because the library is going to be present on any systemd-based distribution anyway. Otherwise, we're going have to handle things like:

If the $WATCHDOG_USEC environment variable is set, and the $WATCHDOG_PID variable is unset or set to the PID of the current process, the service manager expects notifications from this process.


If the usec parameter is non-NULL, sd_watchdog_enabled() will write the timeout in µs for the watchdog logic to it.

(which really means parsing data passed by systemd in environment variables)

If the first character of $NOTIFY_SOCKET is ""@"", the string is understood as Linux abstract namespace socket.

and so on.

There's also the RELOADING event, but I see no point in adding it since configuration reloading is nearly instantaneous.","startup & shutdown notifications
optional watchdog with auto-restart on hang (enabled if WatchdogSec is set in systemd unit)

re #338
Static analysis job will fail until this is rebased on top of #395.

The code is using libsystemd because the library is going to be present on any systemd-based distribution anyway. Otherwise, we're going have to handle things like:

If the $WATCHDOG_USEC environment variable is set, and the $WATCHDOG_PID variable is unset or set to the PID of the current process, the service manager expects notifications from this process.


If the usec parameter is non-NULL, sd_watchdog_enabled() will write the timeout in µs for the watchdog logic to it.

(which really means parsing data passed by systemd in environment variables)

If the first character of $NOTIFY_SOCKET is ""@"", the string is understood as Linux abstract namespace socket.

and so on.

There's also the RELOADING event, but I see no point in adding it since configuration reloading is nearly instantaneous.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,398,2022-05-26T16:23:14Z,2022-05-27T20:45:59Z,2022-05-27T20:45:59Z,MERGED,True,1200,13,17,https://github.com/hg,Add integration tests for most tincctl commands,10,"['1.1', 'test_suite']",https://github.com/gsliepen/tinc/pull/398,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/398,"The RHEL 9 clone we're using has just been released. I think these are the usual mirror syncing issues, it should start working soon.

Things to do later:

REQ_CONNECT doesn't seem to be implemented at all, tinc connect does nothing.
half of new tests are disabled on Windows because tincctl connections often hang inexplicably. Since tincctl uses UNIX sockets everywhere but Windows, and TCP on Windows, there's probably a bug there. I don't currently have access to that OS, maybe I'll look into that in a few weeks.","The RHEL 9 clone we're using has just been released. I think these are the usual mirror syncing issues, it should start working soon.

Things to do later:

REQ_CONNECT doesn't seem to be implemented at all, tinc connect does nothing.
half of new tests are disabled on Windows because tincctl connections often hang inexplicably. Since tincctl uses UNIX sockets everywhere but Windows, and TCP on Windows, there's probably a bug there. I don't currently have access to that OS, maybe I'll look into that in a few weeks.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,398,2022-05-26T16:23:14Z,2022-05-27T20:45:59Z,2022-05-27T20:45:59Z,MERGED,True,1200,13,17,https://github.com/hg,Add integration tests for most tincctl commands,10,"['1.1', 'test_suite']",https://github.com/gsliepen/tinc/pull/398,https://github.com/gsliepen,2,https://github.com/gsliepen/tinc/pull/398#issuecomment-1138868799,"The RHEL 9 clone we're using has just been released. I think these are the usual mirror syncing issues, it should start working soon.

Things to do later:

REQ_CONNECT doesn't seem to be implemented at all, tinc connect does nothing.
half of new tests are disabled on Windows because tincctl connections often hang inexplicably. Since tincctl uses UNIX sockets everywhere but Windows, and TCP on Windows, there's probably a bug there. I don't currently have access to that OS, maybe I'll look into that in a few weeks.","Tinc runs under Wine, I wonder if the issue is reproducable there? Use DeviceType = dummy of course.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,398,2022-05-26T16:23:14Z,2022-05-27T20:45:59Z,2022-05-27T20:45:59Z,MERGED,True,1200,13,17,https://github.com/hg,Add integration tests for most tincctl commands,10,"['1.1', 'test_suite']",https://github.com/gsliepen/tinc/pull/398,https://github.com/hg,3,https://github.com/gsliepen/tinc/pull/398#issuecomment-1138878668,"The RHEL 9 clone we're using has just been released. I think these are the usual mirror syncing issues, it should start working soon.

Things to do later:

REQ_CONNECT doesn't seem to be implemented at all, tinc connect does nothing.
half of new tests are disabled on Windows because tincctl connections often hang inexplicably. Since tincctl uses UNIX sockets everywhere but Windows, and TCP on Windows, there's probably a bug there. I don't currently have access to that OS, maybe I'll look into that in a few weeks.","I remember tests having terrible issues running under Wine (both the shell scripts, and the newer Python-based suites). That's why mingw cross-compilation job doesn't run any tests. Let's use this as an opportunity to try to fix both.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,398,2022-05-26T16:23:14Z,2022-05-27T20:45:59Z,2022-05-27T20:45:59Z,MERGED,True,1200,13,17,https://github.com/hg,Add integration tests for most tincctl commands,10,"['1.1', 'test_suite']",https://github.com/gsliepen/tinc/pull/398,https://github.com/hg,4,https://github.com/gsliepen/tinc/pull/398#issuecomment-1139580032,"The RHEL 9 clone we're using has just been released. I think these are the usual mirror syncing issues, it should start working soon.

Things to do later:

REQ_CONNECT doesn't seem to be implemented at all, tinc connect does nothing.
half of new tests are disabled on Windows because tincctl connections often hang inexplicably. Since tincctl uses UNIX sockets everywhere but Windows, and TCP on Windows, there's probably a bug there. I don't currently have access to that OS, maybe I'll look into that in a few weeks.","Windows tests shoud work after rebasing on top of #399.
https://github.com/hg/tinc/actions/runs/2396396271",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,399,2022-05-27T12:37:14Z,2022-05-27T17:51:55Z,2022-05-27T17:51:55Z,MERGED,True,99,23,4,https://github.com/hg,Don't tarpit localhost connections,1,[],https://github.com/gsliepen/tinc/pull/399,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/399,"The reason Windows tests were hanging was pretty obvious in retrospect — since control connections use TCP there, connection limits apply to them, so they were getting tarpitted.
We could disable tarpit for tests, but I'm pretty sure this is also useful on end-user machines since it's really easy to get blocked by calling tincctl a dozen times in a row fromt a script.","The reason Windows tests were hanging was pretty obvious in retrospect — since control connections use TCP there, connection limits apply to them, so they were getting tarpitted.
We could disable tarpit for tests, but I'm pretty sure this is also useful on end-user machines since it's really easy to get blocked by calling tincctl a dozen times in a row fromt a script.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,399,2022-05-27T12:37:14Z,2022-05-27T17:51:55Z,2022-05-27T17:51:55Z,MERGED,True,99,23,4,https://github.com/hg,Don't tarpit localhost connections,1,[],https://github.com/gsliepen/tinc/pull/399,https://github.com/gsliepen,2,https://github.com/gsliepen/tinc/pull/399#issuecomment-1139891490,"The reason Windows tests were hanging was pretty obvious in retrospect — since control connections use TCP there, connection limits apply to them, so they were getting tarpitted.
We could disable tarpit for tests, but I'm pretty sure this is also useful on end-user machines since it's really easy to get blocked by calling tincctl a dozen times in a row fromt a script.",D'oh!,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,400,2022-05-28T14:22:01Z,2022-05-28T20:41:58Z,2022-05-29T03:45:16Z,MERGED,True,444,73,10,https://github.com/hg,Add compatibility checks to CI (old tinc & muon),3,"['1.1', 'CI']",https://github.com/gsliepen/tinc/pull/400,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/400,"old tinc
re #397
Any idea what other useful checks can be added that do not require reimplementing a second test suite?
muon
Ensures we have some level of compatibility with muon to have tinc buildable on systems with only a C compiler.
Unit tests won't run since it doesn't consider SIGABRT to be a 'proper' way of terminating a must_fail test.
Integration tests don't work for obvious reasons.","old tinc
re #397
Any idea what other useful checks can be added that do not require reimplementing a second test suite?
muon
Ensures we have some level of compatibility with muon to have tinc buildable on systems with only a C compiler.
Unit tests won't run since it doesn't consider SIGABRT to be a 'proper' way of terminating a must_fail test.
Integration tests don't work for obvious reasons.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,400,2022-05-28T14:22:01Z,2022-05-28T20:41:58Z,2022-05-29T03:45:16Z,MERGED,True,444,73,10,https://github.com/hg,Add compatibility checks to CI (old tinc & muon),3,"['1.1', 'CI']",https://github.com/gsliepen/tinc/pull/400,https://github.com/gsliepen,2,https://github.com/gsliepen/tinc/pull/400#issuecomment-1140290252,"old tinc
re #397
Any idea what other useful checks can be added that do not require reimplementing a second test suite?
muon
Ensures we have some level of compatibility with muon to have tinc buildable on systems with only a C compiler.
Unit tests won't run since it doesn't consider SIGABRT to be a 'proper' way of terminating a must_fail test.
Integration tests don't work for obvious reasons.","For me it fails to build with muon

Ah, I did not have libpkgconf-dev installed when building muon. With that in place, it works fine.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,400,2022-05-28T14:22:01Z,2022-05-28T20:41:58Z,2022-05-29T03:45:16Z,MERGED,True,444,73,10,https://github.com/hg,Add compatibility checks to CI (old tinc & muon),3,"['1.1', 'CI']",https://github.com/gsliepen/tinc/pull/400,https://github.com/hg,3,https://github.com/gsliepen/tinc/pull/400#issuecomment-1140293601,"old tinc
re #397
Any idea what other useful checks can be added that do not require reimplementing a second test suite?
muon
Ensures we have some level of compatibility with muon to have tinc buildable on systems with only a C compiler.
Unit tests won't run since it doesn't consider SIGABRT to be a 'proper' way of terminating a must_fail test.
Integration tests don't work for obvious reasons.","Ah, I did not have libpkgconf-dev installed when building muon. With that in place, it works fine.

I guess wrapped lzo will not be available until type_name() is implemented in muon.
It was actually the reason for that clause about ""optional features"" not working.
IIRC cc.has_header() doesn't look up headers in subprojects, so a call to type_name cannot be removed if we want to have best experience for meson users.

samurai embedding seems buggy. The .so is not installed automatically, you have to copy it and then do some ld configuration, and even after that it failed on my machine with weird errors.
It also requires ninja or samurai to be available, which kind of defeats the point.
So we build samurai from source, too.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,402,2022-05-31T15:24:25Z,2022-05-31T20:24:49Z,2022-05-31T20:24:49Z,CLOSED,False,80,56,4,https://github.com/hg,Shorter paths to PID files in integration tests,2,[],https://github.com/gsliepen/tinc/pull/402,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/402,"Should hopefully close #401.
Test without these changes: https://github.com/hg/tinc/runs/6672588831?check_suite_focus=true#step:9:362","Should hopefully close #401.
Test without these changes: https://github.com/hg/tinc/runs/6672588831?check_suite_focus=true#step:9:362",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,402,2022-05-31T15:24:25Z,2022-05-31T20:24:49Z,2022-05-31T20:24:49Z,CLOSED,False,80,56,4,https://github.com/hg,Shorter paths to PID files in integration tests,2,[],https://github.com/gsliepen/tinc/pull/402,https://github.com/hg,2,https://github.com/gsliepen/tinc/pull/402#issuecomment-1142607105,"Should hopefully close #401.
Test without these changes: https://github.com/hg/tinc/runs/6672588831?check_suite_focus=true#step:9:362",Merged as 49265a9.,True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,403,2022-06-02T13:23:48Z,2022-06-02T19:36:52Z,2022-06-02T19:36:52Z,MERGED,True,9,3,2,https://github.com/hg,Fixes for a couple of small issues found by tests,2,[],https://github.com/gsliepen/tinc/pull/403,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/403,"The first commit prevents going over listen_socket on tincd deinitialization.
The easiest way to trigger this is to start tincd with LISTEN_FDS=9 (see additions to the test suite).
The second is a fix for what looks like another false-positive (although I guess it's possible in a multi-threaded program?). It happens with clang-tidy 14.

https://github.com/hg/tinc/runs/6708258540?check_suite_focus=true#step:7:971
https://github.com/hg/tinc/runs/6708568659?check_suite_focus=true#step:7:2641","The first commit prevents going over listen_socket on tincd deinitialization.
The easiest way to trigger this is to start tincd with LISTEN_FDS=9 (see additions to the test suite).
The second is a fix for what looks like another false-positive (although I guess it's possible in a multi-threaded program?). It happens with clang-tidy 14.

https://github.com/hg/tinc/runs/6708258540?check_suite_focus=true#step:7:971
https://github.com/hg/tinc/runs/6708568659?check_suite_focus=true#step:7:2641",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,404,2022-06-02T13:28:20Z,2022-06-04T10:05:12Z,2022-06-04T10:05:12Z,MERGED,True,1117,245,40,https://github.com/hg,Add more integration tests,3,[],https://github.com/gsliepen/tinc/pull/404,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/404,"A few more tests mostly related to device configuration. These will fail without #403.
https://github.com/hg/tinc/actions/runs/2428377765
I think all of the easy pickings are covered. The remaining variables are used deep in tincd internals and require lots of setup to test (often needing root and functioning network, and thus only working on Linux). I'll continue adding tests for them, but more slowly because of this.","A few more tests mostly related to device configuration. These will fail without #403.
https://github.com/hg/tinc/actions/runs/2428377765
I think all of the easy pickings are covered. The remaining variables are used deep in tincd internals and require lots of setup to test (often needing root and functioning network, and thus only working on Linux). I'll continue adding tests for them, but more slowly because of this.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,405,2022-06-04T12:23:29Z,2022-06-05T13:23:39Z,2022-06-05T13:23:39Z,MERGED,True,101,6,6,https://github.com/hg,Notify 'tinc join' about invitation errors,2,[],https://github.com/gsliepen/tinc/pull/405,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/405,"See #255
New server, new client
Connected to localhost port 13394...
Request rejected: invitation is invalid or missing.
Invitation cancelled.
(exit code 1)

New server, old client
Connected to localhost port 13394...
Invitation cancelled.
(exit code 1)

Old server, new client
Connected to localhost port 655...
(10-second pause)
Timed out waiting for server to reply.
Cannot read greeting from peer
(exit code 1)

I'll refactor sptps record codes (1/2/3) in a separate PR.","See #255
New server, new client
Connected to localhost port 13394...
Request rejected: invitation is invalid or missing.
Invitation cancelled.
(exit code 1)

New server, old client
Connected to localhost port 13394...
Invitation cancelled.
(exit code 1)

Old server, new client
Connected to localhost port 655...
(10-second pause)
Timed out waiting for server to reply.
Cannot read greeting from peer
(exit code 1)

I'll refactor sptps record codes (1/2/3) in a separate PR.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,405,2022-06-04T12:23:29Z,2022-06-05T13:23:39Z,2022-06-05T13:23:39Z,MERGED,True,101,6,6,https://github.com/hg,Notify 'tinc join' about invitation errors,2,[],https://github.com/gsliepen/tinc/pull/405,https://github.com/hg,2,https://github.com/gsliepen/tinc/pull/405#issuecomment-1146784687,"See #255
New server, new client
Connected to localhost port 13394...
Request rejected: invitation is invalid or missing.
Invitation cancelled.
(exit code 1)

New server, old client
Connected to localhost port 13394...
Invitation cancelled.
(exit code 1)

Old server, new client
Connected to localhost port 655...
(10-second pause)
Timed out waiting for server to reply.
Cannot read greeting from peer
(exit code 1)

I'll refactor sptps record codes (1/2/3) in a separate PR.","Not sure it's possible to resolve #255 properly if we want to both tarpit suspicious connections, and not leave the user hanging (since every failing connection is treated as suspicious).
I added timeouts to both places where client could hang and didn't touch the server,

aside
although TBH I don't see what prevents a malicious actor from doing the same. Something like Go makes writing these things really easy: start MaxConnectionBurst goroutines, split a dictionary between them, and try words in a loop with a 1-second timeout until one of them goes through (which both works around the tarpit, and prevents you from running into connection burst limits).
Or even something like this:
while read -rp word; do
  url=$(build_url ""$word"")
  timeout 1 tinc join nsa.gov/""$url"" && {
    echo ""success: $word""
    exit 0
  }
done
Start ten of them in parallel (using the appropriately named GNU parallel) until one finds something.
I guess this can be prevented by remembering IPs and adding per-IP limits, but with increasing use of CGNAT it may do more harm than good (a bad guy can buy hundreds of proxies for pennies, or just use tor).
Purely in theory, if connection is closed by the server, the client can guess the reason by accurate timing, but this can be worked around by closing it after a randomly generated delay.


tinc join output has been updated to encourage the user to seek assistance if repeated joins fail to work. All possible code paths seem to provide their own error messages already (including str2addrinfo(): it lets you know when it fails to look up a domain).

A few examples (covered by new tests)
There are basically three error modes:

obviously bad URL (we notify the user of that)
connection error (the problem can be on either side of the connection; we ask to double-check the URL, maybe they copied it wrong)
server error (probably; we ask the user to retry and contact the guy on the other side if it doesn't help)

bad domain
$ /tmp/build/src/tinc -c i join frobnicator:13394/C92j2YTpTzZoiS3bR_-F873nMr9bDxW5Ut4ONNrhyN8-_10g
Error looking up frobnicator port 13394: Name or service not known

bad url
$ /tmp/build/src/tinc -c i join frobnicator
Invalid invitation URL.

bad port
$ /tmp/build/src/tinc -c i join localhost:1337/QUAuoWrDjKB6QT1IJhpmydsSCC2N2B3-6NnCeXpEeNZauuif
Could not connect to 127.0.0.1 port 1337: Connection refused
Could not connect to inviter. Please make sure the URL you entered is valid.

URL from another server
$ /tmp/build/src/tinc -c i join 'localhost:13394/vaMdJSNRsKa834yYbPCP2JV2oFHTYsKgooYiRJrmV9GRvdf1'
Connected to localhost port 13394...
Peer has an invalid key. Please make sure you're using the correct URL.
9CErgCAUk1R4ugLUxCmODMHbP+682Smt+XxVTTr7joB

broken secret
$ /tmp/build/src/tinc -c i join frobnicator:13394/C92j2YTpTzZoiS3bR_-F873nMr9bDxW5Ut4ONNrhyN8-_10
Invalid invitation URL.

almost correct URL (one char replaced)
ERROR   Peer 127.0.0.1 port 42572 tried to use non-existing invitation yNC0rjfFMcs-oC1lpHMBCndl

$ /tmp/build/src/tinc -c i join localhost:13394/QUAuoWrDjKB6QT1IJhpmydsSCC2N2B3-6NnCeXpEeNZauuif
Connected to localhost port 13394...
(5-second pause)
Timed out waiting for the server to reply.
Invitation cancelled. Please try again and contact the inviter for assistance if this error persists.

invitations removed from the server
Error before sptps is established
ERROR   Got invitation from 127.0.0.1 port 53768 but we don't have an invitation key

$ /tmp/build/src/tinc -c i join 'localhost:13394/vaMdJSNRsKa834yYbPCP2JV2oFHTYsKgooYiRJrmV9GRvdf1'
Connected to localhost port 13394...
(5-second pause)
Timed out waiting for the server to reply.
Cannot read greeting from peer
Invitation cancelled. Please try again and contact the inviter for assistance if this error persists.

bad URL
Error after sptps is established
ERROR   Peer 127.0.0.1 port 38490 tried to use non-existing invitation DYihGIhImzevayj1U1WCBA_c

$ /tmp/build/src/tinc -c i join localhost:13394/C92j2YTpTzZoiS3bR_-F873nMr9bDxW5Ut4ONNrhyN8-_10g
Connected to localhost port 13394...
(5-second pause)
Timed out waiting for the server to reply.
Invitation cancelled. Please try again and contact the inviter for assistance if this error persists.",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,405,2022-06-04T12:23:29Z,2022-06-05T13:23:39Z,2022-06-05T13:23:39Z,MERGED,True,101,6,6,https://github.com/hg,Notify 'tinc join' about invitation errors,2,[],https://github.com/gsliepen/tinc/pull/405,https://github.com/gsliepen,3,https://github.com/gsliepen/tinc/pull/405#issuecomment-1146803466,"See #255
New server, new client
Connected to localhost port 13394...
Request rejected: invitation is invalid or missing.
Invitation cancelled.
(exit code 1)

New server, old client
Connected to localhost port 13394...
Invitation cancelled.
(exit code 1)

Old server, new client
Connected to localhost port 655...
(10-second pause)
Timed out waiting for server to reply.
Cannot read greeting from peer
(exit code 1)

I'll refactor sptps record codes (1/2/3) in a separate PR.","Tarpitting is not a perfect defense at all, but it does help against low volume attacks. Having timeouts in the client is a good thing to add, even if we didn't tarpit. The new error messages are a huge improvement!",True,{}
gsliepen/tinc,https://github.com/gsliepen/tinc,406,2022-06-04T12:37:14Z,2022-06-04T13:41:57Z,2022-06-04T13:41:57Z,MERGED,True,1,1,1,https://github.com/hg,`version.py`: fix support for Python < 3.9,1,[],https://github.com/gsliepen/tinc/pull/406,https://github.com/hg,1,https://github.com/gsliepen/tinc/pull/406,"Ugh. I put too much trust into pylint's compatibility checks (it notices these things… sometimes).
FreeBSD 13.1:
ninja: Entering directory `/usr/home/neko/tinc/build'
[1/21] Generating src/include/version_git.h with a custom command
Traceback (most recent call last):
  File ""/usr/home/neko/tinc/version.py"", line 23, in <module>
    version = result.stdout.strip().removeprefix(""release-"")
AttributeError: 'str' object has no attribute 'removeprefix'","Ugh. I put too much trust into pylint's compatibility checks (it notices these things… sometimes).
FreeBSD 13.1:
ninja: Entering directory `/usr/home/neko/tinc/build'
[1/21] Generating src/include/version_git.h with a custom command
Traceback (most recent call last):
  File ""/usr/home/neko/tinc/version.py"", line 23, in <module>
    version = result.stdout.strip().removeprefix(""release-"")
AttributeError: 'str' object has no attribute 'removeprefix'",True,{}
